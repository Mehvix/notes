---
title: "Week 0"
weight: 1
---



# 1-18: Course Introduction

- [Slides](https://eecs16a.org/lecture/Lecture0A_Slides.pdf)
- Notes [0](https://eecs16a.org/lecture/Note0.pdf), [1A](https://eecs16a.org/lecture/Note1A.pdf)

---

All logistics, no notes!

# 1-20: Introduction to Imaging, Tomography, and Linear Equations

- [Slides](https://eecs16a.org/lecture/Lecture0B_Slides.pdf)
- Notes [1A](https://eecs16a.org/lecture/Note1A.pdf), [1B](https://eecs16a.org/lecture/Note1B.pdf)

---

## System Design

- We use _devices_, such as imagers, that provide _information_, such as a visual representation of a system
    - Often, these devices donâ€™t work alone -- they are part of a larger system that uses a combination of both physical sensors and signal processing techniques.
- When we take projections of images, we tend to need to take multiple measuring (pictures) from differing angles
    - Otherwise we have issues with overlap and ambiguity
    - To generate 3D models, we need these multiple perspectives
- We ideally want to design a system that gives us a set of linear equations
    - Some times we can only approximate these linear equations
    - Lots of physical processes (i.e xrays!) are exponential so we just slap a log on it
        - .$\hat y = p \cdot (e^{x_1} + \dots + e^{x_n})$
        - .$y = -\log_e (\hat y \cdot p^{-1}) = x_1 + \dots + x_n$
        - .$\hat y$ is our measured energy value
        - .$x_n$ is the .$n$th 'pixel'
        - .$p$ is the power of the energy source
    - To solve, we need enough independent equations that do not contain redundant information, otherwise there will be multiple ambiguous solutions
    - Different models are made up of different configurations (of the energy source and measuring sensor) and result in different system of equations
        - We can obtain equations by moving both the energy source and measuring sensor (think document scanner) to get each individual pixel
        - We can also move the energy source alone instead -- think camera pointed at image with a projector used to light up certain (group of) pixel(s)
            - Different patterns have pros/cons -- speed, resolution, accuracy, number of measurements, energy use

## Linear Algebra

- The study of linear functions and linear equations, typically using vectors and matrices
- Linearity is not always applicable, but can be a good first-order approximation
- There exist good fast algorithms to solve these problems (and lots of fun properties!)
- Consider .$f(x_1, \dots, x_n) : \mathbb{R}^n \to \mathbb{R}$; .$f$ is linear if the following hold...
    1. Homogeneity: .$f (\alpha x_1, \dots, \alpha x_n) = \alpha f(x_1, \dots, x_n)$
        - If I scale the input by a scalar (i.e. by a factor of 2) then the output should also scale by the same factor
    2. Super position (distributivity): if .$x_i = y_i + z_i$ then .$f(y_1 + z_1, \dots, y_n + z_n) = f(y_1, \dots y_n) + f(z_1, \dots z_n)$
        - 2 possible inputs:
            1. Pass the first input through the system to get a value.
            2. Pass another input through the system, and get another value.
            3. Add those two values to get a result.
        - 1 possible input:
            1. Pass the summation of value 1 and value 2 through the system to get a result.
        - If the result of both approaches are equal, then distributivity holds. Otherwise, distributivity does not hold.
- Linear functions can always be expressed as .$f(x_1, \dots, x_n) = c_1 x_1 + \dots + c_n x_n$
    - For .$\mathbb{R}^2$, that is, .$f(x_1, x_2) = c_1 x_1 + c_2 x_2$
    - We know this system is linear so it follows these two rules above. So we should set up an equation where we can apply these properties.
        > $$ x_1 = 1 \cdot x_1 + 0 \cdot x_2;\ x_2 = 0 \cdot x_1 + 1 \cdot x_2$$
        > $$\text{Let } y_1 = 1, z_1 = 0; y_2 = 0, z_2 = 1$$
        > $$ \Longrightarrow x_1 = x_1 y_1 + x_1 z_1;\ x_2 = x_2 y_2 + x_2 z_2$$
        > $$ \Longrightarrow x_1 = x_1 (y_1 + z_1);\ x_2 = x_2 (y_2 + z_2)$$
        > $$\text{Therefore, } f(x_1, x_2) = f(x_1 y_1 + x_2 z_1, x_1 y_2 + x_2 z_2)$$
        > $$= x_1f(y_1, y_2) + x_2f(z_1, z_2)$$
        > $$= x_1f(1, 0) + x_2f(0, 1)$$
        > $$= c_1 x_1 + c_2 x_2\ \blacksquare$$
- Linear Set of Equations
{{< columns >}}<!-- mathjax fix -->
Consider the set of .$M$ linear equations with .$N$ variables:
$$\begin{matrix}a_{11} x_1 + a_{12} x_2 + \dots + a_{1N} x_{N} = b_1\\\ a_{21} x_1 + a_{22} x_2 + \dots + a_{2N} x_{N} = b_2\\\ \text{} \vdots\\\ a_{M1} x_1 + a_{M2} x_2 + \dots + a_{MN} x_{N} = b_M\end{matrix}$$
<---><!-- mathjax fix -->
...it can be written compactly using augmented matrix:
$$\begin{bmatrix}a_{11} & a_{12} & ... & a_{1N} & \text{|} & b_1\\\ a_{21} & a_{22} & ... & a_{2N} & \text{|} & b_2\\\ \vdots & \text{} & \vdots & \text{ } & \text{|} & \vdots\\\ a_{M1} & a_{M2} & ... & a_{MN} & \text{|} & b_M\end{bmatrix}$$

{{< /columns >}}
- Algorithm for solving linear equations
    - Three basic operations that **don't change** a solution:
        1. Multiply an equation with _nonzero_ scalar
            - .$2x+3y=4$ is same as .$4x+6y=8$
        2. Adding a scalar constant multiple of one equation to another
        3. Swapping equations (changing arbitrary labels, trivial)
    - These will be explained in more depth later (next week Tuesday) 



