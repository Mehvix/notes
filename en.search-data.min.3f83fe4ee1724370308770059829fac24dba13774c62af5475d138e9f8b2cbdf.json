[{"id":0,"href":"/e-29/0/","title":"0: Intro \u0026 Tolerancing","section":"Engineering 29","content":" 01-18: Course introduction # Overview # This class focuses on three main components \u0026ndash; manufacturing processes, dimensional tolerances, and design communication \u0026ndash; and how they interact with one another.\nThe class is made up of 9 modules:\nFundamentals Subtractive manufacturing processes Additive manufacturing processes Forming processes Joining processes Graphical visualization techniques Metrology: measuring manufactured objects Geometric dimensioning and tolerancing The future of manufacturing Why manufacturing? # In 2018, U.S. manufacturing accounted for 11.6% of the U.S. economy, 18.2% of global manufacturing output, and 8.2% of the U.S. workforce \u0026ndash; source Manufacturing output is growing, and is returning to the U.S.; output increased \u0026gt;30% between end of 2008 and 2014 67% of U.S. R\u0026amp;D is funded by industry Even when production is offshore, design is often done here anyway Automation is increasing, yet there is a shortage of skilled (human) talent Even if you don\u0026rsquo;t want to go into manufacturing industry, research and academia still require manufacturing knowledge Even if the process if outsourced, design is still done in the US. To design well, you have to have a base-level understanding of manufacturing \u003e Manufacturing output and employment are rising \u003e Many companies have regionalized their supply chains since the pandemic Processes # In this class we will consider multiple families of processes: This is a rapidly moving field that is always adapting This class should give you a top level overview so you can evaluate novel methods Materials # In this class we will consider multiple families of materials: Materials choices influence performance For example, consider the progress of the plane: In 1903 the right brothers low-density wood with steel wire and silk In 1935 the Douglas DC3 used aluminum alloy (since it became feasible to produce and manipulate) Now the 2010 Boeing 787 Dreamliner is made up of 50 wt% composites 20 wt% aluminum 15 wt% titanium 20% lower fuel consumption per passenger mile Composite materials are two(+) materials combined together to get best of both worlds, in aviation typically stiff/strong carbon fibers embed in tough/fatigue-resistant polymers. Materials choices influence market size There isn\u0026rsquo;t always a best material; different materials fit different markets/needs Opposite side of the coin: There may be multiple valid material choices for a particular function Tolerance # Tolerancing is a formal way of specifying limits on the amount of dimensional variability allowable in manufactured parts We need a range because measurements will never be 100% precise; we need to define an acceptable range Some sources of variation Human operator changes and/or errors Tool wear Environmental changes (temperature, humidity leads to tiny expansions / contractions) Input material variability Measurement error Affordable mass-production relies on interchangeability of parts When mating parts of given designs, it should not matter which specific parts Therefore part dimensions must be consistent But no manufacturing process is perfectly consistent If you don\u0026rsquo;t understand the process of manufacturing and the capabilities of tools, then you will won\u0026rsquo;t know how to create manufacturable designs - Tighter tolerances (closer tolerance limits) are generally more expensive to achieve - The solid green line shows an ideal process - The dotted green line shows the impact of an error shifting the distribution, shifting the tails to approach the tolerance upper / lower bound - The red line shows a unsuitable process (even if it's calibrated accurately, the poor precision causes high variance that it's not really feasible; however, if outside of the limits an additive (or less common subtractive) could be used to ) How E29 integrates manufacturing and tolerancing # Tighter tolerances are more expensive The physics of a process determine how tight a tolerance is achievable and how much it costs Therefore we need to understand how manufacturing processes work in order to: Select a suitable process for the application Specify reasonable tolerances Geometric Dimensioning and Tolerancing: a graphical language for specifying tolerances robustly Design Communication # Important to effectively describe your ideas and designs graphically Persuade \u0026ndash; we need to be able to show are perspective Instruct \u0026ndash; we need an agreed an unambiguous way to communicate Document \u0026ndash; we need to convey how to construct our final design Seek feedback \u0026ndash; we need to ensure everyone is on the same page Drawings can be 2D or 3D representations Interpreting 2D drawings made by others Creating 2D “working drawings” with unambiguous instructions Design communication is not only graphical Oral, written Manufacturing relies on teams Teaming activities 01-20: Fundamentals of Tolerancing # See why we study tolerancing from yesterday\u0026rsquo;s notes Basic tolerance formats # Unilateral e.g. Inches: .$.500^{+0.005}_{-0.000}$, Metric: .$35^{+0.05}_0$ (notice sigfig notation) Bilateral Most common; start with nominal then you have some tolerance bounds above and below Equal or unequal deviations from nominal dimension Same number of decimal places for upper and lower limits e.g. Inches: .$.500 \\pm .005$ or .$.500^{+0.005}_{-.010}$, Metric: .$35 \\pm 0.05$ or .$35^{+0.05} _{-0.10}$ Limit Given only bounds, not the nominal value e.g. Inches: .$.250, .248$, Metric: .$35.05, 35.00$ Tolerance buildup # In the real world we have error, so the way we define dimensions have an impact Best dimensions to label depend on function That is, dimensioning should be done intentionally such that critical distances result in minimal error, e.g.suppose distance between .$X$ and .$Y$ is critical ![Side Projection](/docs/e-29/0/buildup.png) - Chain is bad since the potential (and often times real world) maximum error is large - The errors compound since dimensions are in reference to other dimensions that ~~may~~ will contain error. - The more dimensions chained, the greater the possible error - Baseline is better -- every feature references a single base. - However the worst case is still significant - .$X$ may be off by .$\\pm .05$ and .$Y$ may be off .$\\mp 05$, compounding to .$\\pm 0.10$! - Direct is ideal - Depends on which dimensions are critical (that is, .$X, Y$) Normal cumulative distribution function # - Tighter tolerances (closer tolerance limits) are generally more expensive to achieve - The physics of **the process used determines the curve's characteristics** - .$\\sigma$ is the [stdiv](https://en.wikipedia.org/wiki/Standard_deviation) (width) of this density - .$\\mu = x_0$ is the target (average) value we give - This probability density characterizes how this function is distributed and the chance a given range of values occur - The area under the curve in a given range is the probability the value falls within that range - Single values, i.e .$x_0$, have a 0% probability. We can only calculate ranges because this is a **density function**. \u003e ![Distribution](/docs/e-29/0/distribution.png) \u003e Probability density, e.g. given by [Gaussian/Normal probability density function](https://en.wikipedia.org/wiki/Gaussian_function): \u003e $$p(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-\\frac{(x-x_0)^2}{2\\sigma^2}}$$ Why do we care about statistics? We want to look at a process, look at tolerances, and figure out whether it\u0026rsquo;s worth to manufacture using this process If you know the distribution of a process, you can work out the probability a given part satisfies spec limits. There is no easy, exact analytical way to integrate the normal probability density function. The probability that a randomly chosen member of a normally distributed population has a value .$\\leq x$ is $$\\int_{-\\infty}^x p(x)\\ dx = P(x) = Z\\bigg(\\frac{x-\\mu}{\\sigma}\\bigg) = \\frac{1}{2}\\bigg[1 + \\text{erf}\\bigg(\\frac{x-\\mu}{\\sigma\\sqrt{2}}\\bigg)\\bigg]$$ .$\\text{erf()}$ is the error function .$Z$ is the normal cumulative distribution function; values of .$Z$ are tabulated in a Z table Example probability of part lying between within spec limits ![Distribution Example](/docs/e-29/0/dist-ex.png) Process capability and tolerancing # Sigma, .$\\sigma$, is the standard deviation of dimensions actually produced by a process Six sigma processes Six Sigma (6σ) is a set of techniques and tools for process improvement. [\u0026hellip;] A six sigma process is one in which 99.99966% of all opportunities to produce some feature of a part are statistically expected to be free of defects.\nSpecification limits are .$12\\sigma$ apart. Here, 2 parts per billion lie outside specification limits if process is \u0026lsquo;in control\u0026rsquo; (i.e. if mean output of process is centered between specification limits) Arose because the cost of manufacturing, specifically the process that creates an error, has a cost. This cost can grow very large, very quickly, when mass-manufacturing. You\u0026rsquo;re best off spending money improving the process so the distribution gets tighter The alternative is either (1) accepting errors (resulting in faulty products) or (2) testing all components to ensure they are \u0026lsquo;good\u0026rsquo; and tossing out the bad ones Process capability: .$C_p = \\frac{\\text{USL - LSL}}{6\\sigma}$ Classes of Fit # Tolerances should be\u0026hellip; Not too tight: tight tolerances are expensive Not too loose: otherwise function is compromised ![Zones](/docs/e-29/0/zones.png) 1. **Clearance fit:** designed with space left between two components - e.g. a shaft with a bearing need to have some give / free space 2. **Interference (push) fit:** designed to be touching - You may want interference because you want the friction between the components; you want the two pieces to not move/rotate/etc - How? Elastic or even plastic deformation - e.g. two pieces may need to fit tightly with friction as to prevent vibrations - Expansion fit: - If there are large forces/torques acting on these two components so you want them **very tight** - e.g. you may temporarily expand one component (e.x. with heat) to fit on/around the other, then it will shrink down - Shrink fit: - Same as expansion, but using some cooling process (e.x. liquid nitrogen) - Why do this over heat? - It's typically more expensive to cool down - The material may deform / weaken -- e.g. steel will be degraded if heated up 3. **Transition fit:** complete interchangeability is compromised to allow looser tolerance on individual components. - If fit type is not critical. - But even then, why not choose one or the other? Because you don't want a large gap and the materials/parts cannot withstand the force needed to assemble them with an interference fit. - The pieces are just for alignment -- think Ikea assembly pegs; they're just to align components. - It's easier to manufacture these parts ### Snap fits ![Snap](/docs/e-29/0/snap.png) - Involves temporary elastic deflection which enables parts to interlock, e.g. involving bending of one component - Done often with molded parts - Tends to involve Cantilever (e.g. casings), Annular (e.g. pen lids, take-out soup container lids) - Designed to be assembled once, and typically not disassembled (multiple times) -- irreversible. - Relatively simple: you don't need screws/glues/etc. -- useful for rapid prototyping since you don't have to consider fasteners - Takes advantage of the fact that the material has some elasticity - You need to stay within the elasticity limits of the material - Most 3D plastics have 'enough' give - You (generally) want to design such that the stress is from bending, not stretching - [More](https://coloringchaos.github.io/form-fall-16/joints), [additional](https://www.pinterest.com/Gilson_Design/), [extra](https://www.hubs.com/knowledge-base/how-design-snap-fit-joints-3d-printing/), [readings](https://productdesignonline.com/wp-content/uploads/2019/08/Snap-Fit-Design-Manual.pdf) Terminology Definitions # Don\u0026rsquo;t stress about memorizing these !\n![Clearance and interference fits](/docs/e-29/0/fit-ex.png) - **Maximum material condition _(MMC)_:** The greatest allowable amount of material left on the part (max size for a shaft; min size for a hole) - **Minimum/least material condition _(LMC)_:** The least allowable amount of material left on the part (min size for a shaft; max size for a hole) - Important with MMC since they tell us how much they're able to 'slosh around' - **Basic size:** Exact theoretical size from which limits are derived - Different form nominal since basic refers to the standard table which gives respective upper and lower bounds (MMC and LMCs) - Hole basis: Basic size is minimum size of hole - Shaft basis: Basic size is maximum size of shaft -- used when many components need to fit on to one shaft. - Basic size could be chosen to be in-between hole and shaft basis - **Tolerance:** Allowable variation of one particular dimension - **Fundamental deviation:** Difference between basic size and the closer of the MMC and LMC - **Allowance:** Difference between maximum material conditions of the two components Types of fit # These types are created by ANSI: American National Standards Institute Exact values are tabulated in many source RC: Running and sliding clearance fits Nine categories: RC1: Close sliding: assemble without perceptible “play” (e.g. watches) Less than a 1/1000\u0026quot;. Basically impossible for air, let alone liquids, through. RC2: Sliding fits: seize with small temperature changes (e.g. ) RC3: Precision running: not suitable for appreciable temperature differences RC4: Close running: moderate surface speeds and pressures RC5/6: Medium running: higher speed/pressure RC7: Free running: where accuracy not essential and/or temperature variations large RC8/9: Loose running Go for lower if you want minimal vibration/gaps \u0026ndash; no perceivable play. Has drawbacks: The less clearance, the easier it is to seize up \u0026ndash; especially if two components are touching and made up of different materials (different expansion/contraction rates). Susceptible to dust, you would have to seal the machine or use it in clean conditions. If you go less precise, you don\u0026rsquo;t need to go slow, cheaper operator costs, cheaper tooling RC Chart ![RC fits -- from Machinery’s Handbook, Industrial Press](/docs/e-29/0/rc.png) RC Table ![Table](/docs/e-29/0/rc-table.png) LC: Locational clearance fits Normally stationary, but freely assembled/disassembled Used when you need clearance to dis able and clean LC Chart ![Classes of LC fit](/docs/e-29/0/lc.png) - LT: Location transition fits - Accuracy of location important - Small amount of clearance or interference OK - e.g. ikea furniture pegs - LN: Locational interference - When you need friction - Accuracy of location is critical ![Other classes of fit](/docs/e-29/0/misc-fits.png) FN: Force fits When you need to hold a load (typically uses temporary heating) Designed to transmit frictional loads from one part to another Example: Which type of fit? ![](/docs/e-29/0/ex-fit.png) Processes, tolerances, and surface quality # How do we relate physical processes and tools to these values? From MF Ashby, Materials Selection in Mechanical Design\nRoughness # How do we define roughness? You may use tool that uses a tiny needle to \u0026lsquo;scan\u0026rsquo; the surface, measuring deflections as you go From MF Ashby, Materials Selection in Mechanical Design\nRMS roughness: root mean square of deviations over the measured surface length i.e.: .$R^2 = L^{-1} \\int_0^L y^2\\ dx$ Usually, tolerance, .$T$, lies between 5R and 1000R Generally, if you go high rotation speed and slow translational speed you get less rough surfaces RMS Roughness Example "},{"id":1,"href":"/eecs-16a/0/","title":"0: System Design \u0026 Linear Equations","section":"EECS 16A","content":" 01-18: Course Introduction # Slides Notes 0, 1A All logistics, no notes!\n01-20: Introduction to Imaging, Tomography, and Linear Equations # Slides Notes 1A, 1B System Design # We use devices, such as imagers, that provide information, such as a visual representation of a system Often, these devices don’t work alone \u0026ndash; they are part of a larger system that uses a combination of both physical sensors and signal processing techniques. When we take projections of images, we tend to need to take multiple measuring (pictures) from differing angles Otherwise we have issues with overlap and ambiguity To generate 3D models, we need these multiple perspectives We ideally want to design a system that gives us a set of linear equations Some times we can only approximate these linear equations Lots of physical processes (i.e xrays!) are exponential so we just slap a log on it .$\\hat y = p \\cdot (e^{x_1} + \\dots + e^{x_n})$ .$y = -\\log_e (\\hat y \\cdot p^{-1}) = x_1 + \\dots + x_n$ .$\\hat y$ is our measured energy value .$x_n$ is the .$n$th \u0026lsquo;pixel\u0026rsquo; .$p$ is the power of the energy source Tomography Example ![](/docs/eecs-16a/0/to.png) To solve, we need enough independent equations that do not contain redundant information, otherwise there will be multiple ambiguous solutions Different models are made up of different configurations (of the energy source and measuring sensor) and result in different system of equations We can obtain equations by moving both the energy source and measuring sensor (think document scanner) to get each individual pixel We can also move the energy source alone instead \u0026ndash; think camera pointed at image with a projector used to light up certain (group of) pixel(s) Different patterns have pros/cons \u0026ndash; speed, resolution, accuracy, number of measurements, energy use Linear Algebra # The study of linear functions and linear equations, typically using vectors and matrices Linearity is not always applicable, but can be a good first-order approximation There exist good fast algorithms to solve these problems (and lots of fun properties!) Consider .$f(x_1, \\dots, x_n) : \\mathbb{R}^n \\to \\mathbb{R}$; .$f$ is linear if the following hold\u0026hellip; Homogeneity: .$f (\\alpha x_1, \\dots, \\alpha x_n) = \\alpha f(x_1, \\dots, x_n)$ If I scale the input by a scalar (i.e. by a factor of 2) then the output should also scale by the same factor Super position (distributivity): if .$x_i = y_i + z_i$ then .$f(y_1 + z_1, \\dots, y_n + z_n) = f(y_1, \\dots y_n) + f(z_1, \\dots z_n)$ 2 possible inputs: Pass the first input through the system to get a value. Pass another input through the system, and get another value. Add those two values to get a result. 1 possible input: Pass the summation of value 1 and value 2 through the system to get a result. If the result of both approaches are equal, then distributivity holds. Otherwise, distributivity does not hold. We can account for both Homogeneity and Super position by proving the function holds under the following equation: $$\\alpha_1 f(x_1, \\dots x_n) + \\dots + \\alpha_n f(y_1, \\dots, y_n) = f(\\alpha_1 x_1 +\\alpha_n y_1, \\dots, \\alpha_1 x_n + \\alpha_n y_n)$$ where .$y_n$ is a some scalar Linear functions can always be expressed as .$f(x_1, \\dots, x_n) = c_1 x_1 + \\dots + c_n x_n$ For .$\\mathbb{R}^2$, that is, .$f(x_1, x_2) = c_1 x_1 + c_2 x_2$ We know this system is linear so it follows these two rules above. So we should set up an equation where we can apply these properties. $$\\begin{align} x_1 \u0026amp;= 1 \\cdot x_1 + 0 \\cdot x_2;\\ \u0026amp;x_2 = 0 \\cdot x_1 + 1 \\cdot x_2 \\\\ \\text{Let}\\quad y_1 \u0026amp;= 1, z_1 = 0; \u0026amp;y_2 = 0, z_2 = 1 \\\\ \\Longrightarrow x_1 \u0026amp;= x_1 y_1 + x_1 z_1;\\ \u0026amp;x_2 = x_2 y_2 + x_2 z_2 \\\\ \\Longrightarrow x_1 \u0026amp;= x_1 (y_1 + z_1);\\ \u0026amp;x_2 = x_2 (y_2 + z_2) \\end{align}$$ $$\\begin{align} \\text{Therefore, } f(x_1, x_2) \u0026amp;= f(x_1 y_1 + x_2 z_1, x_1 y_2 + x_2 z_2) \\\\ \u0026amp;= x_1f(y_1, y_2) + x_2f(z_1, z_2) \\\\ \u0026amp;= x_1f(1, 0) + x_2f(0, 1) \\\\ \u0026amp;= c_1 x_1 + c_2 x_2\\ \\blacksquare \\end{align}$$\nLinear Set of Equations Consider the set of .$M$ linear equations with .$N$ variables: $$\\begin{matrix}a_{11} x_1 + a_{12} x_2 + \\dots + a_{1N} x_{N} = b_1\\\\\\ a_{21} x_1 + a_{22} x_2 + \\dots + a_{2N} x_{N} = b_2\\\\\\ \\text{} \\vdots\\\\\\ a_{M1} x_1 + a_{M2} x_2 + \\dots + a_{MN} x_{N} = b_M\\end{matrix}$$ ...it can be written compactly using augmented matrix: $$\\begin{bmatrix}a_{11} \u0026 a_{12} \u0026 ... \u0026 a_{1N} \u0026 \\text{|} \u0026 b_1\\\\\\ a_{21} \u0026 a_{22} \u0026 ... \u0026 a_{2N} \u0026 \\text{|} \u0026 b_2\\\\\\ \\vdots \u0026 \\text{} \u0026 \\vdots \u0026 \\text{ } \u0026 \\text{|} \u0026 \\vdots\\\\\\ a_{M1} \u0026 a_{M2} \u0026 ... \u0026 a_{MN} \u0026 \\text{|} \u0026 b_M\\end{bmatrix}$$ An interesting thing to notice about this representation is that the symbols corresponding to our unknowns have vanished entirely! Algorithm for solving linear equations Three basic operations that don\u0026rsquo;t change a solution: Multiply an equation with nonzero scalar .$2x+3y=4$ is same as .$4x+6y=8$ In other words, no solution exists that satisfies the second equation, but not the first. Consequently, the second equation is not only implied by, but also implies the first equation. When each of two equations imply the other, we say that they are equivalent. Adding a scalar constant multiple of one equation to another Example If we have the equations.. $$(1)\\ 5a+6b=7$$ $$(2)\\ 8a+9b=10$$ ...we can multiply .$(2)$ by the scalar 3 and add it to .$(1)$, to obtain the new system $$(3)\\ 29a+33b=37$$ $$(2)\\ 8a+9b=10$$ Clearly, observe that any solution to the first system will also be a solution to the second, since the first system of equations implies the second. But is the reverse true? Well, observe that equation .$(1)$ can be recovered by taking equation .$(3)$ and subtracting our scalar (in this case, 3) multiplied by equation .$(2)$. In other words, our second system is, not only implied by, but also implies the first system, so it does not introduce any new solutions. Thus, replacing the first system with the second does not change the solution set of our linear system, so this operation is valid. Swapping equations (changing arbitrary labels, trivial) Note 1AB Extra # Affine function: a function that can be written as a sum of a linear function and a scalar constant, so though .$\\beta (x)=2x+1$ is not linear, it is still affine Notice that the definition of affine functions includes all linear functions (by setting the scalar constant to 0), so every linear function is affine, but not all linear functions are affine. These definitions mean that while all functions describing a line can be shown to be affine, not all of them are linear. This has the unfortunate consequence that, in informal conversation, affine functions may be called linear, since both describe a line. This usage, though common, is **wrong!**, as seen with .$\\beta (x)$ above Linear Equation: Formally, a linear equation with the unknown scalars .$x_1, x_2, \\dots x_n$ is an equation where each side is a sum of scalar-valued linear functions of each of the unknowns plus a scalar constant. Expressed algebraically, we obtain the most general form of a linear equation, where the .$f_i$ and .$g_i$ are each linear functions with a single scalar input and output, and .$b_f$ and .$b_g$ are two scalar constants: $$f_1(x_1) + f_2(x_2) + \\dots + f_n(x_n) + b_f = g_1(x_1) + g_2(x_2) + \\dots + g_n (x_n) + b_g$$ Now, recall that linear functions with a single scalar input and output can be expressed in a very particular form \u0026ndash; we know that we can write .$f_i(x) = a_i \\cdot x$ and .$g_i(x) = a_i \u0026rsquo; \\cdot x$, where all the .$a_i$ and .$a_i \u0026lsquo;$ are scalar constants. Substituting, we find that the general form of a linear equation can be rewritten as $$a_1x_1 + a_2 x_2 + \\dots = a_n x_n + b_f = a_1\u0026rsquo; x_1 + a_2 \u0026rsquo; x_2 + \\dots + a_n \u0026rsquo; x_n + b_g$$ Notice that this expression can be thought of as a “weighted sum” of the .$x_i$, where the weights are the scalar constants .$a_i$. When the weights do not depend on any of the terms (such as when the weights are constants), we call the weighted sum a linear combination of said terms. So the above expression is typically referred to as a linear combination of the .$x_i$. That is, A linear equation is one that equates two linear combinations of the unknowns plus a constant term.\nOur system will have infinitely many solutions if any two variables are ambiguous Our system will have no solutions if we have a row of zeroes followed by a non-zero That is, .$\\begin{bmatrix}0 \u0026amp; 0 \u0026amp; \u0026hellip; \u0026amp; 0 \u0026amp; \\text{|} \u0026amp; \\alpha\\end{bmatrix} \\Longrightarrow 0x_1 + 0x_2 + \\dots 0x_n = \\alpha y$ is clearly impossible (no solutions) for any non-zero .$\\alpha$ Practice questions "},{"id":2,"href":"/cheatsheets/bioe-C165/","title":"BioE C165, FA24","section":"Cheatsheet PDFs","content":"Open PDF in new tab "},{"id":3,"href":"/cheatsheets/cs-161/","title":"CS 161, FA24","section":"Cheatsheet PDFs","content":"Open PDF in new tab "},{"id":4,"href":"/cheatsheets/cs-162/","title":"CS 162, SP24","section":"Cheatsheet PDFs","content":"Open PDF in new tab "},{"id":5,"href":"/cheatsheets/cs-168/","title":"CS 168, FA22","section":"Cheatsheet PDFs","content":"Open PDF in new tab "},{"id":6,"href":"/cheatsheets/cs-170/","title":"CS 170, FA22","section":"Cheatsheet PDFs","content":"Open PDF in new tab "},{"id":7,"href":"/cheatsheets/cs-182/","title":"CS 182, FA23","section":"Cheatsheet PDFs","content":"Open PDF in new tab "},{"id":8,"href":"/cheatsheets/cs-184/","title":"CS 184, SP24","section":"Cheatsheet PDFs","content":"Open PDF in new tab "},{"id":9,"href":"/cheatsheets/eecs-126/","title":"EECS 126, SP23","section":"Cheatsheet PDFs","content":"Open PDF in new tab "},{"id":10,"href":"/cheatsheets/eecs-127/","title":"EECS 127, FA23","section":"Cheatsheet PDFs","content":"Open PDF in new tab "},{"id":11,"href":"/cheatsheets/eecs-151/","title":"EECS 151, FA24","section":"Cheatsheet PDFs","content":"Open PDF in new tab "},{"id":12,"href":"/cheatsheets/eecs-16b/","title":"EECS 16B, SU22","section":"Cheatsheet PDFs","content":"Open PDF in new tab "},{"id":13,"href":"/cs-170/mt1/","title":"Midterm 1: Cheat Sheet","section":"CS170","content":" I never finished these. Consider checking out [Alec Li's notes](https://smartspot2.github.io/assets/pdf/CS170_Lecture_Notes.pdf) and [Jeffrey Shen's final cheatsheet](https://jshen13.github.io/notes/fa20/cs170_sg.pdf). \\(\\) Asymptotic Bound # | Notation | Meaning | Definition | | --------------------- | ------- | --------------------------------------------------- | | $$\\mathcal O(\\cdot)$$ | $$\\le$$ | $$\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} \u003c \\infty$$ | | $$\\Theta (\\cdot)$$ | $$=$$ | $$\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} = c$$ | | $$\\Omega(\\cdot)$$ | $$\\ge$$ | $$\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)}\u003e 0$$ | $$\\begin{aligned} c \u0026\u003c \\log^\\star n \\\\\\ \u0026\u003c \\log n \\\\\\ \u0026\u003c n^{1/3}\\\\\\ \u0026\u003c n^{1/2} = \\sqrt n\\\\\\ \u0026\u003c 2^{\\log{n}} = n\\\\\\ \u0026\u003c n \\log (n) = \\log(n!) \\\\\\ \u0026\u003c n^3\\\\\\ \u0026\u003c 2^{\\sqrt{n}}\\\\\\ \u0026\u003c 2^n\\\\\\ \u0026\u003c 3^n\\\\\\ \u0026\u003c n! \\end{aligned}$$ Master Theorem # $$\\begin{aligned} T(n) \u0026amp;= \\overbrace{a\\cdot T\\left(\\frac n b\\right)}^\\text{Divide into $a$ parts $\\sim\\ b^{-1}$} + \\overbrace{C \\cdot n^d}^{\\text{Combining Work}} \\\\ \\text{Level 0: } \u0026amp; n^d \\\\ \\text{Level 1: } \u0026amp; n^d \\frac a {b^d} \\\\ \\text{Level 2: } \u0026amp; n^d \\left(\\frac a {b^d}\\right)^2 \\\\ \u0026amp; \\vdots \\\\ \\text{Level }k:\\ \u0026amp; n^d \\left(\\frac a {b^d}\\right)^k \\qquad \\text{(Base: } \\frac n {b^k} \\leq 1 \\Longrightarrow k = \\log_b n)\\\\ \\text{Total Work:}\\ \u0026amp; n^d \\cdot \\sum_{i=0}^k \\left(\\frac a {b^d}\\right)^i \\\\ \\therefore\\ T(n) \u0026amp;= \\begin{cases} \\Theta (n^d) \u0026amp; \\dfrac a {b^d} \u0026lt; 1\\ \\equiv\\ d\u0026gt;\\log_b a\\\\ \\Theta (n^d \\cdot \\log n) \u0026amp; \\dfrac a {b^d} = 1\\ \\equiv\\ d= \\log_b a \\\\ \\Theta (n^{\\log_b a}) \u0026amp; \\dfrac a {b^d} \u0026gt; 1\\ \\equiv\\ d \u0026lt; \\log_b a \\end{cases} \\end{aligned}$$\nCase Derivations ### Case 1: Geometric decaying sum, first term dominates $$\\begin{aligned} \u0026 n^d \\cdot \\sum_{i=0}^k \\left(\\frac a {b^d}\\right)^i \\text{ with } p= \\dfrac a {b^d} \u003c 1 \\\\\\ \u0026= n^d \\cdot (1 +p+\\dots+p^k) \\\\\\ \u0026=\\ n^d \\cdot \\left(\\frac{p^{k+1}-1}{p-1} \\right)\\\\\\ \u0026= \\Theta (n^d) \\end{aligned}$$ ### Case 2: Same work at all levels $$\\begin{aligned} \u0026 n^d \\cdot \\sum_{i=0}^k \\left(\\frac a {b^d}\\right)^i \\text{ with } p= \\dfrac a {b^d} = 1 \\\\\\ \u0026= n^d \\cdot (1^0 +1^1+\\dots+1^k)) \\text{ with } k=\\log_b n \\\\\\ \u0026= n^d \\cdot (k+1) \\\\\\ \u0026= n^d \\cdot (\\log_bn + 1)\\\\\\ \u0026= \\Theta (n^d \\log n) \\end{aligned}$$ ### Case 3: Geometric growing sum, leafs dominate $$\\begin{aligned} \u0026 n^d \\cdot \\sum_{i=0}^k \\left(\\frac a {b^d}\\right)^i \\text{ with } p= \\dfrac a {b^d} \u003e 1 \\\\\\ \u0026= n^d \\cdot (1 +p+\\dots+p^k) \\\\\\ \u0026=\\ n^d \\cdot \\left(\\frac{p^{k+1}-1}{p-1} \\right) \\\\\\ \u0026=\\ \\Theta \\left(n^d \\cdot \\left(\\frac{p^{k+1}-1}{1} \\right)\\right) \\\\\\ \u0026=\\ \\Theta \\left(n^d \\cdot p^{k+1}\\right) \\\\\\ \u0026=\\ \\Theta \\left(n^d \\cdot \\left(\\frac a {b^d}\\right)^{k}\\right) \\\\\\ \u0026=\\ \\Theta \\left(n^d \\cdot \\left(\\frac a {b^d}\\right)^{\\log_b n}\\right) \\\\\\ \u0026=\\ \\Theta \\left(n^d \\cdot \\left(b^{\\log_b\\left(\\dfrac a {b^d}\\right)}\\right)^{\\log_b n}\\right) \\\\\\ \u0026=\\ \\Theta \\left(n^d \\cdot \\left(b^{\\log_b n}\\right)^{\\log_b\\left(\\dfrac a {b^d}\\right)}\\right) \\\\\\ \u0026=\\ \\Theta \\left(n^d \\cdot n^{\\log_b\\left(\\dfrac a {b^d}\\right)}\\right) \\\\\\ \u0026=\\ \\Theta \\left(n^d \\cdot (n^{\\log_b a - \\log_b b^d})\\right) \\\\\\ \u0026=\\ \\Theta \\left(n^d \\cdot (n^{\\log_b a - d})\\right) \\\\\\ \u0026= \\Theta\\ (n^{\\log_b a}) \\end{aligned}$$ Representation # $1 + p + p^2 + \\cdots + p^k = \\dfrac{p^{k+1}-1}{p-1}$\nLog facts\nChange log base: $\\log_b N = \\dfrac{\\log_a N}{\\log_a b} \\implies \\log_a N = \\log_b N \\cdot \\log_a b$ Represent $x$ using $\\log$ of an arbitrary base: $x = b^{\\log_b x}$ Expanding log division: $\\log_a \\left(\\dfrac{x}{y}\\right) = \\log_a x - \\log_a y$ Definitions: The power to which you need to raise 2 in order to obtain $N$ Going backward, it can also be seen as the number of times you must halve N to get down to 1: $\\lceil \\log N \\rceil$ Number of bits in the binary representation of N: $\\lceil \\log(N+1)\\rceil$ Depth of a complete binary tree with N nodes: $\\lfloor \\log N \\rfloor$ $1 + \\frac 1 2 + \\frac 1 3 + \\cdots + \\frac 1 N = \\ln N + \\gamma$ Show $\\log (n!) = \\Theta (n \\log n)$ Upper: $$\\begin{aligned}n! \u0026\u003c n^n\\\\\\ \\log n! \u0026\u003c \\log n^n \\\\\\ \u0026=\\mathcal O (\\log n^n) \\\\\\ \u0026=\\mathcal O(n \\log n) \\end{aligned}$$ Lower: $$\\begin{aligned}n! \u0026\u003e \\frac n 2 ^{\\frac n 2}\\\\\\ \\log n! \u0026\u003e \\log (\\frac n 2 ^{\\frac n 2})\\\\\\ \u0026=\\Omega \\left(\\frac n 2 \\log \\frac n 2 \\right)\\\\\\ \u0026= \\Omega (n \\log n)\\end{aligned}$$ Fast Integer exponentiation using repeated squaring\nNaive takes $\\mathcal O(n)$ multiplies: $k^{n} = n\\cdot n\\cdot \\dots n$ Base-2 decomp takes $\\mathcal O(\\lceil\\log_2 k\\rceil)$: E.x. $k=71: 9^{71} = 9^{64} \\cdot9^4\\cdot9^2\\cdot 9^1$ Use base-2 since $\\log_{b} x = \\log_{2} x / \\log_{2} b$ is minimized when $b=2$. Show that in any base $b\\ge 2$, the sum of any three single-digit numbers is at most two digits long.\n$$\\begin{aligned} \\text{[sum of 3 digits in base b]} \u0026amp;\\leq \\text{[2-digit number]}\\\\ \\text{argmax } x_b + y_b + z_b \u0026amp;\\leq b\\cdot\\alpha + \\beta\\\\ 3(b-1) \u0026amp;\\leq b^2-1 \\qquad(1)\\\\ \\text{Base:}\\qquad\\quad 3(2-1)\u0026amp;\\leq 2^2 -1\\\\ 3 \u0026amp;\\leq 3\\ \\Box \\\\ \\text{Hyp: }\\quad3(k+1-1)\u0026amp;\\leq (k+1)^2 -1\\\\ 3k\u0026amp;\\leq k^2+2k\\\\ k \u0026amp;\\leq k^2\\ \\Box \\end{aligned}$$\n$(1)$: $k$ digits in base $b$ can represent every number in $[0, b^k) \\equiv [b^k-1]$ Show that any binary integer is at most four times as long as the corresponding decimal integer.\nFor any decimal (base-10) integer $x$ of length $n$, we know the number of bits to represent in base $b$ is $\\lceil \\log_b 10^n\\rceil$; therefore\u0026hellip; $$\\begin{aligned} \\text{[length in base-2]} \u0026amp;\\leq 4\\cdot \\text{[length in base-10]}\\\\ \\lceil \\log_2 (x+1) \\rceil \u0026amp;\\leq 4\\cdot \\lceil \\log_{10} (x+1) \\rceil\\\\ \\log_2 10^n \u0026amp;\\leq 4\\cdot \\log_{10} 10^n\\\\ \u0026amp;\\leq 4\\cdot n\\\\ 2^{\\log_2 10^n}\u0026amp;\\leq 2^{4\\cdot n}\\\\ 10^n \u0026amp;\\leq 16^n\\ \\Box\\end{aligned}$$\nShow that any d-ary tree with n nodes must have a depth of $Ω(\\log n/ \\log d)$\n$$\\begin{aligned} n \u0026amp;= \\sum_{i=1}^f d^i = d^1 + d^2+\\dots+d^f\\\\ \u0026amp;= d^f-1\\\\ \\log_d n+1 \u0026amp;= \\log_d d^f\\\\ \\log_dn+1 \u0026amp;= f\\\\ \\Longrightarrow f \u0026amp;= \\lfloor\\log_d n\\rfloor \\\\ \u0026amp;= \\Omega \\frac{\\log n}{\\log d}\\end{aligned}$$\nOperation Adjacency Matrix Adjacency List Notes Memory $\\mathcal O(n^2)$ bytes $\\mathcal O(n+m)$ machine words (pointers) Matrix better when dense Checking if edge $(u,v)$ exists $\\mathcal O(1)$ $\\mathcal O(d_u +1)$ Iterating all neighbors of $u$ $\\mathcal O(n)$ $\\mathcal O(d_u+1)$ BFS $\\mathcal O(n^2)$ $\\mathcal O(n+m)$ Iterate over each neighbors (row) for all elements Fast Fourier Transform (FFT) # Goal: efficiently multiply two polynomials $A(x), B(x)$, of degrees $d_a, d_b$, in $\\mathcal O(n\\log n)$ time\nSelection: Find points (roots of unity) $x_0, x_1, \\dots, x_{n-1}$ $n = 2^{\\lceil \\log_2 (d_a + d_b + 1) \\rceil} \\le 2^{\\lceil \\log_2 (2d + 1) \\rceil} $ where $d := \\text{max}(d_a, d_b)$ Final polynomial $C(x)$ has maximum degree of $2d$, so we evaluate at $2d+1$ points Zero-pad $A(x), B(x)$ with $n - d_a, n-d_b$ zeros respectively Evaluate two polynomials at a set of points : $\\mathcal O(n \\log n)$ Multiply the evaluated points (for every point $w$ evaluated, compute $C(w) = A(w) \\cdot B(w)$ : $\\mathcal O(n)$ Interpolate: Take the resulting points and recover the polynomial they define with IFFT: $\\mathcal O(n \\log n)$ Exam tips Use FFT as a blackbox algorithm for polynomial multiplication Frame problem as a polynomial problem, e.x. through cross-correlation Anything better than $\\mathcal O (n\\log n)$ i.e. $\\mathcal O(n^2)$ can be done with FFT Depth First Search (DFS) # Graph Theory # Dijkstra # Shortest Paths # Divide and Conquer (D\u0026amp;C) # Minimum Spanning Tree (MST) # Bellman-Ford # Huffman Encoding # Union Find # Quickselect # "},{"id":14,"href":"/e-29/1/","title":"1: Fundamentals of Graphical Communication \u0026 Subtractive Processes","section":"Engineering 29","content":" 01-25: Fundamentals of graphical communication # Evolution of graphical visualization # - Hand drawing - Instrument drawing (using mechanical things to measure distances) - 2D CAD (initially only able to draw side views) - 3D CAD (solid modeling) - Automatic generation of 2D working drawings - Enable easy communication of measurements between designer and manufacturer - Created with the assumption that manufactured objects are made up of elementary objects, [geons?](../cogsci-c100/perception.md#recognition-by-components-model) - Now we have the ability to run algos to analyze models, removing unnecessary bits - We're moving towards computer-generated geometry that's contained by human input ![](/docs/e-29/1/evo2.png) --- Increasingly complex geometries Topological optimization Internal lattices The way we interface with drawings has to keep up with this New interfaces Virtual and augmented reality for visualizing designs Why bother sketching by hand? # ![](/docs/e-29/1/evo1.png) - Why not go straight to CAD? - Some possible reasons: - There is a connection between drawing and your own creativity; a feedback loop of sorts - CAD bottlenecks you to designing a certain way - Find one’s own distinctive style - Avoid making detailed decisions too early - Keep geometries more freeform - Ideas may come to mind anywhere, anytime - Potentially quicker Sketch Examples - Leonardo da Vinci: “helicopter” (c. 1489) ![](/docs/e-29/1/heli.png) - Charles and Ray Eames: chair ![](/docs/e-29/1/chair.png) - Renzo Piano + Richard Rogers: Pompidou Center ![](/docs/e-29/1/piano.png) - Philippe Starck: lemon squeezer ![](/docs/e-29/1/lem1.png) - Aside: how is it made? ![](/docs/e-29/1/lem3.png) ![](/docs/e-29/1/lem2.png) --- - Jonathan Ive/Apple design team: iPhone ![](/docs/e-29/1/iphone.png) - Burj Khalifa: Adrian Smith ![](/docs/e-29/1/tower.png) - Tesla Model 3: Franz Holzhausen ![](/docs/e-29/1/tesla.png) - Concept drawing for Berkeley Engineering ![](/docs/e-29/1/cal.png) Essentials of 2D sketching # - Line types matters - **Solid:** edges - **Dashed:** hidden detail - **Chain:** centerline. - `- . - . ` ... - **Faint:** construction - Align, but don't touch, features - **Dimension lines:** - Fainter than edges, and not connected. - Long, thin arrows. - Lots of differing standards, just be consistent ![](/docs/e-29/1/sketch.png) 3D pictorial approaches # Isometric drawing # - 'iso' = same, 'metric' = measure - Any lines parallel .$x,y,z$ on the lines are equal length - Orthogonal edges of a 3D object map to: - Vertical lines - Lines at .$\\pm 30^\\circ$ to horizontal - Enables creating reasonably realistic drawings fairly easily - Dimensions in these orthogonal directions are preserved on page - Dimensions in other directions are not preserved on page ![](/docs/e-29/1/iso-sketch.png) - Circles in isometric - Use construction lines for bounding box - Mark midpoints - Draw longer quadrants first - Through holes: use construction lines for obscured circle; darken later - What if circle is not on an orthogonal face? ![](/docs/e-29/1/iso-circ.png) Coded plans for practicing isometric sketching # Principle: number in cell gives height of column to be drawn Codes could be given on isometric or square grid ( plan view) Square grid: viewpoint explicitly specified ![](/docs/e-29/1/plan-iso.png) ![](/docs/e-29/1/plan-grid.png) Different views / perspectives may obscure different features. Chose the one that minimizes information loss / ambiguity You can shade certain surface to convey shadow (and thus depth, 3D information) Plan View Draw Example ![](/docs/e-29/1/draw-ex.png) Axonometric drawing # - Orthogonal edges are represented by: - Vertical lines - Lines at .$\\pm 45^\\circ$ to horizontal - Advantage: - Floorplans are not skewed/distorted - Disadvantage: - Areas of equal orthogonal faces are not equal on drawing - Can look more \"distorted\" ![](/docs/e-29/1/axo-ex.png) --- \u003e![](/docs/e-29/1/axoeg.png) \u003e Example of axonometric drawing \u003e - Sometimes called “planometric” \u003e - Popular in architecture to preserve floorplans Oblique drawings # - Front view is undistorted - Conveys lots of information of a single face - Angles are arbitrary (here they're ~45) - Receding lines drawn at a constant angle - Judgement needed to select scale for receding direction ![](/docs/e-29/1/obl.png) ### Perspective drawing - Simulates how the eye sees 3D objects: further away objects/details are smaller - Much more challenging than other methods - Receding lines not parallel - But CAD software can generate - Horizon line - Vanishing point(s) - One point: dimensions referenced from closest surface - Two points: dimensions referenced from closest edge ![](/docs/e-29/1/ex-perp.png) --- Introduction to sketching tools # ### Digital sketching tools - Autodesk Sketchbook - Now discontinued! :( - OneNote is an alright alternative - Import isometric grid on Layer 2 - Draw on Layer 1 - Google Jamboard - Adobe Photoshop, Illustrator - Software resource page in bCourses ### Analog sketching tools - Set square/drawing triangle - Pencils: - Various hardness/softness - Mechanical vs traditional - Pens - Ballpoint - Felt tip - Technical Possible ways of enhancing 3D sketches # - Shading -- simulate the effect of light falling on object - e.x shadows, glare, - Visual clarity -- edges bolder: example of how it clears confusion - Suggesting motion, sound, texture, etc. ![](/docs/e-29/1/pounce.png) --- 01-27: Subtractive processes: types of subtractive process; mechanics of cutting # Subtractive manufacturing processes # Subtractive processes are those that begin with standard stock material (in rod, bar, sheet, plate form etc) and remove material to impart shape Types of subtractive process # Material comes in range of mediums: billet (below, left), sheet, foil, wire, pellets, etc. A subtractive process removes material from a larger piece of material to define the geometry needed Subtractive processes therefore generate waste material How we deal with this is important Take 5 minutes to brainstorm all the ways you can think of to remove material in a controlled way from a solid piece of stock to create a geometry Also think about what could happen to the waste material What are some ways of removing material? Can we re-use the extra material? How can we cut away material? Some possibilities: # - Cutting -- taking a sharp edge to material - Drilling, boring, reaming - Milling - Lathe operations: turning, facing, tapping - Shearing/punching/puncturing - Sawing - Chiseling - Collectively: “machining” - Electric field - Electrical discharge machining (EDM): electrode, wire - Localized melting or vaporization - Laser cutting, laser ablation - Flame, plasma cutting - Hot wire (typically used for plastics) - _Aside:_ is melting really subtractive? - Misc - Chemical methods ([Etching](https://en.wikipedia.org/wiki/Etching#Industrial_uses)) - Explosives (think mining) - Forcing apart (using physical force) Abrasion \u0026ndash; rough, abrasive wheels rotate at high speed across the surface of the component, removing particles of the workpiece. This approach is well suited even to the hardest of materials, although control of geometry is not as great as in cutting operations, for example. Grinding, sanding, lapping, polishing, filing Abrasive jet (water jet) Sand blasting Why would we choose a subtractive process # Instead of an additive process? Instead of a forming process, e.g. casting? #### Some possible reasons to: - Stock materials tend to be readily available (and inexpensive compared with the specialist powders that are used in some additive processes such as selective laser melting - Precision and finish are exceptionally good – probably better than any other family of processes - Need strength / structure - Material cannot be molded (it's the only feasible process) - Doesn't alter heat treatment (if feed and speed isn't too high) - Short runs -- no _specialized_ tooling costs - Easy customization \u0026 More control for iterative product development – every component produced can be different if needed - All you need is to generate new `.gcode`; versus a whole mold #### Why not choose subtractive? - Slow for large run sizes compared to forming processes - Most processes are “serial”, meaning that each feature on the component needs to be produced sequentially, making the processes slow. This is in contrast, for example, to molding/casting operations where the entire component is produced in approximately one step. - Fairly costly in comparison - Large amount of waste generated (low efficiency) - High operator skill is often demanded, raising processing costs - Cuts across metal grains -- not as strong as forged or possibly cast components focus on material cutting Cutting operations rely on wedge-shaped teeth Mechanics of lathe turning of metals # To understand the key concepts of metal cutting, we focus specifically on lathe turning i.e. a reduction in the diameter of a cylindrical component using a cutting tool. We focus on the turning of metals and their alloys, although turning is also widely used to process polymeric materials and even composite materials (wood being one “composite” that is regularly turned). Cutting operations rely on wedge-shaped teeth Lectures 4 and 5 will focus on cutting-based operations; Lecture 6 will look at some of the others A close look at a metal cutting operation\nTerminology # The workpiece (or simply work — the solid material that is to be reduced in diameter) is held firmly at one end in a chuck, whose jaws are tightened against the workpiece enough that the friction between the work and the chuck is always enough to resist the torques experienced by the work during cutting. The work is rotated, using an electric motor, at angular velocity .$\\omega$, which is typically hundreds or even thousands of revolutions per minute. Let us call the axis of rotation z. If the radius of the workpiece is a at the location of cutting, then the linear, tangential velocity of the work relative to the tool is .$V_\\text{cut} = \\omega a$, provided that .$\\omega$ is expressed in radians/second (to convert from rev/min to rad/sec multiply by .$2\\pi/50$). The cutting tool is mounted on a cross-slide/carriage assembly, which enables precise control of the cutting edge along the z axis and also radially outwards from the z axis (let us call this radial direction the x axis). The carriage and cross-slide could be moved by manual screws or by computer-controlled motors with positional feedback. Once the work is rotating at its target speed, the tool is positioned slightly to the right of the end of the work and the tool is moved inwards in the x direction (towards the rotational z axis) by a distance .$d$, called the depth of cut. The tool is then moved from right to left along the workpiece at a velocity called the feed rate given by .$V_\\text{feed} = f\\omega$, where .$f$ is the feed, or the distance moved by the tool along the z axis in one revolution of the work. Feed rate is a velocity, while feed is a distance per revolution — this subtlety of terminology is important to note. Note that in almost any turning process, .$V_\\text{cut} \u0026raquo; V_\\text{feed}$ A close look at a metal cutting operation # High-speed video: cutting tool moves across surface\nTeeth are at a specific, optimal wedge angle wrt the material to shave away stock Material is sheared off the workpiece (like butter and knife) Quality of cut depends on rake angle (front angle), .$\\alpha$, of tool - Rake angle vertical (.$\\alpha = 0$): material piles up and lot of heat is generated - Rake angle too large: tool is fragile, can dig into material - Rake angle just right: cutting happens close to tool - What is “just right” for the rake angle .$\\alpha$? - .$30^\\circ$ is a good [magic](https://en.wikipedia.org/wiki/Magic_number_(programming)) starting value - Clearance angle should be non-zero - Allows you to run the tool in reverse over the material without cutting ![](/docs/e-29/1/ang.png) Material Removed # The metal that is cut, or shaved, away from the workpiece is called the chip, and depending on (1) how brittle or ductile the work material is, (2) the shape of the cutting tool, and (3) the speed of cutting, the chip may be either a fairly continuous spiral or a series of small chips that regularly fracture. Many small chips are desirable from a practical perspective because, unlike very long continuous chips, they do not tend to become tangled around the work and potentially scratch it. Cutting tools will often have protrusions on their front surface that are designed to break up a chip as it comes off the workpiece. So in turning, a spiral of material is being removed from the work that has initial cross-section .$d \\times f$ and with the tool sweeping through the material with velocity .$V$. Thus, the volumetric removal rate of material is .$R_\\text{MR} = Vdf$. Cutting depends on material properties # More ductile materials (aluminum, mild steel, copper etc): long, spiral-shaped chips of material More brittle materials (e.g. cast iron): comes off in short chips Basic types of chips produced in metal cutting and their micrographs:\n(a) continuous chip with narrow, straight primary shear zone;\n(b) secondary shear zone at the tool-chip interface; (c) continuous chip with built-up edge;\n(d) segmented or nonhomogeneous chip; and\n(e) discontinuous chip.\n"},{"id":15,"href":"/eecs-16a/1/","title":"1: Gaussian Elim. \u0026 Matrices + Vectors","section":"EECS 16A","content":" 01-25: Gaussian Elimination, Vectors # Slides Notes 2A, 2B Upper Triangular Systems # - Consider the following equation $$x-y+2z=1$$ $$y-z=2$$ $$z=1$$ ...which can be represent as an [augmented matrix](https://en.wikipedia.org/wiki/Augmented_matrix): $$\\begin{bmatrix} 1 \u0026 -1 \u0026 2 \u0026 \\text{|} \u0026 1\\\\\\ 0 \u0026 1 \u0026 -1 \u0026 \\text{|} \u0026 2\\\\\\ 0 \u0026 0 \u0026 1 \u0026 \\text{|} \u0026 1 \\end{bmatrix}$$ These are called upper triangle matrices \u0026ndash; they are nice in that they\u0026rsquo;re easy to solve! The solution is reached when the diagonal is all one, the remaining is zero (excluding the rightmost \u0026lsquo;answer\u0026rsquo; colum) Row Echelon Form # More precisely, a matrix is in row echelon form when the following criteria are met: * All nonzero rows are above all zero rows. * The leading coefficient of a non-zero row is always to the right of the leading coefficient of the row above it. $$\\begin{bmatrix} 1 \u0026 * \u0026 * \u0026 * \u0026 \\text{|} \u0026 *\\\\\\ 0 \u0026 1 \u0026 * \u0026 * \u0026 \\text{|} \u0026 *\\\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \u0026 \\text{|} \u0026 *\\\\\\ 0 \u0026 0 \u0026 0 \u0026 0 \u0026 \\text{|} \u0026 0\\\\\\ \\end{bmatrix}$$ The leading coefficient of every non-zero row (which we call the pivot, and say is in the pivot position) is 1. Some textbooks will require this third property, others don\u0026rsquo;t Reduced Row Echelon Form # Reduced Row Echelon Form: requires that, in addition to the upwards propagation of variables in step (3), we will obtain a matrix with the following properties, in addition to the two mentioned above: 1. The matrix is in row echelon form. 2. The leading coefficient of every non-zero row (which we call the pivot, and say is in the pivot position) is 1. 3. Each column with an element that is in the pivot position of some row has 0s everywhere else. $$\\begin{bmatrix} 1 \u0026 0 \u0026 * \u0026 0 \u0026 \\text{|} \u0026 *\\\\\\ 0 \u0026 1 \u0026 * \u0026 0 \u0026 \\text{|} \u0026 *\\\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \u0026 \\text{|} \u0026 *\\\\\\ 0 \u0026 0 \u0026 0 \u0026 0 \u0026 \\text{|} \u0026 0\\\\\\ \\end{bmatrix}$$ Sometimes abbreviated (especially in programming) as rref. By construction, the Gaussian elimination algorithm always results in a matrix that is in reduced row echelon form. Once an augmented matrix is reduced to reduced row echelon form, variables corresponding to columns containing leading entries are called basic variables, and the remaining variables are called free variables If there just isn\u0026rsquo;t enough information and the equations do not contradict each other, then there exist an infinite number of solutions. When this happens, choose some variable (ideally, which is in most of the equations) and then solve each equation in terms of that variable (e.x. .$z$ is in all equations, so now write .$x,y,\\dots$ in terms of .$z$). Example We start with the following system: $$x-y+2z=1$$ $$2x+y+z=8$$ $$-4x+5y = 7$$ ...which we can write as a matrix $$\\begin{bmatrix} 1 \u0026 -1 \u0026 2 \u0026 \\text{|} \u0026 1\\\\\\ 2 \u0026 1 \u0026 1 \u0026 \\text{|} \u0026 8\\\\\\ -4 \u0026 5 \u0026 0 \u0026 \\text{|} \u0026 7 \\end{bmatrix}$$ ...and we can **row-reduce** to upper triangle (Row echelon) ...which we can use [**back substitution**](https://en.wikipedia.org/wiki/Triangular_matrix#Forward_and_back_substitution) to solve Tomograph Example Error # In real systems, we will always have noise (error) that makes our systems slightly skewed So what if we repeat the example above, but have a measurement of .$+0.1$\u0026hellip; are there any solutions? Graphing # We can represent our solution as a set of linear equations, meaning we can represent them graphically 01-27: Vectors, Matrices, Multiplications, And Span # Slides Notes 2A, 2B Last lecture, we showed how vectors and matrices could be used as a way of writing systems of linear equations more compactly, demonstrating through our tomography example that modeling a set of measurements as a system of equations can be a powerful tool.\nIn these following notes, we are going to more thoroughly discuss how to perform computations with vectors and matrices. In future notes, we will consider additional properties of vectors and matrices and see how these can help us understand real-world systems.\nVectors # - Given a collection of .$n$ real numbers such as .$x_1, x_2, \\dots x_n$, we can represent this collection as a single point in an .$n$-dimensional _real space_ .$\\mathbb{R}^n$, denoted as a .$\\vec x$ - Each .$x_i$ (for .$i$ between .$1$ and .$n$) is called a **component**, or element, of the vector. $$\\vec x = \\begin{bmatrix} x_1 \\\\\\ x_2 \\\\\\ \\vdots \\\\\\ x_n \\end{bmatrix}$$ The size of a vector is the number of components it contains Two vectors .$\\vec x$ and .$\\vec y$ are said to be equal, .$\\vec x = \\vec y$, if they have the same size and .$x_i = y_i$ for all .$i$ Vectors are interesting because they can represent any set of numbers Representing as vectors lets us apply a lot of nice operations to them + represent them graphically In Tomography, we can write a vector to represent the amount of light absorbed by each bottle in a row or column. E.x. color (RGB values), pictures (set of pixels), solar cycles, Electrical circuit quantities Vectors Representing State # Vectors can be used to represent the state of a system, defined as follows: State: The minimum information you need to completely characterize a system at a given point in time, without any need for more information about the past of the system.\nState is a powerful concept because it lets us separate the past from the future. The state completely captures the present\u0026ndash; and the past can only affect the future through the present E.x: Consider modeling the dynamics of a quadrotor. The state of a quadrotor at a particular time can be summarized by its 3D position, angular position, velocity, and angular velocity, which can be represented as a vector .$\\vec q \\in \\mathbb{R^{12}}$, as illustrated: Special vectors # #### Zero \u0026 One Vector: - You can usually tell the size of the zero from the context: if .$\\vec x \\in \\mathbb{R}^{n}$ is added to .$\\vec 0$, then .$\\vec 0$ must also be in .$\\mathbb{R}^{n}$ $$\\vec 0 = \\begin{bmatrix} 0 \\\\\\ 0 \\\\\\ \\vdots \\\\\\ 0 \\end{bmatrix}$$ $$\\vec 1 = \\begin{bmatrix} 1 \\\\\\ 1 \\\\\\ \\vdots \\\\\\ 1 \\end{bmatrix}$$ #### Standard Unit Vector: - A standard unit vector is a vector with all components equal to .$0$ except for one element, which is equal to .$1$. A standard unit vector where the .$i$th position is equal to .$1$ is written as .$\\vec e_i$ - The system .$e_1, \\dots, e_n \\in \\mathbb{R}^{n}$ is called the _standard basis_ in .$\\mathbb{R}^{n}$ $$\\vec e_1 = \\begin{bmatrix} 1 \\\\\\ 0 \\\\\\ \\vdots \\\\\\ 0 \\end{bmatrix},\\ \\vec e_2 = \\begin{bmatrix} 0 \\\\\\ 1 \\\\\\ \\vdots \\\\\\ 0 \\end{bmatrix},\\ \\vec e_n = \\begin{bmatrix} 0 \\\\\\ 0 \\\\\\ \\vdots \\\\\\ 1 \\end{bmatrix}$$ When talking about standard unit vectors in the context of states, we might also use the word “pure” to refer to such states. This is because they only have one kind of component in them. Other states are mixtures of pure states. Vector Operations # Addition # Must be same size and space (e.g. complex numbers, real numbers, etc.) Properties: Many of the properties of addition you are already familiar with when adding individual numbers hold for vector addition as well. For three vectors .$\\vec x, \\vec y, \\vec z \\in \\mathbb{R}^n$ (and .$\\vec 0 \\in \\mathbb{R}^n$), the following properties hold: - Commutativity: $$\\vec x + \\vec y = \\vec y + \\vec x$$ - Additive identity: $$\\vec x + 0 = \\vec x$$ - Associativity: $$(\\vec x + \\vec y) + \\vec z = \\vec x + (\\vec y + \\vec z)$$ - Additive inverse: $$\\vec x + (- \\vec x) = 0$$ Vector addition can be performed graphically as well: Scalar Multiplication # We can multiply a vector by a number, called a scalar: Scalar: a number. In mathematics and physics, scalars can be used to describe magnitude or used to scale things (e.g. cut every element of a vector in half by multiplying by 0.5, or flip the signs of each element in a vector by multiplying by −1).\n- In general, for a scalar .$\\alpha$ and vector .$\\vec x$, this looks like this: $$\\alpha \\begin{bmatrix} x_1 \\\\\\ x_2 \\\\\\ \\vdots \\\\\\ x_n \\end{bmatrix} = \\begin{bmatrix} \\alpha x_1 \\\\\\ \\alpha x_2 \\\\\\ \\vdots \\\\\\ \\alpha x_n \\end{bmatrix} $$ - We can obtain the zero vector by multiplying any vector by 0: $$0\\vec x = \\vec 0$$ - Properties: - Associative, distributive, and multiplicative identity hold -- trivial - As an example, we can scale a vector .$\\vec x \\in \\mathbb{R}^{2}$ by 2 or -2: ![](/docs/eecs-16a/1/2x.png) Vector Transpose # - .$\\vec x$ is always a column vector, so to convert (represent) a row vector, we apply the transpose: .$\\vec x^T$ - If the elements of the matrix .$A \\in \\mathbb{R}^{N \\times M}$ are .$a_{ij}$ - The elements of .$A^T \\in \\mathbb{R}^{M \\times N}$ are .$a_{ji}$ - Matrix transpose is not (generally) an inverse! $$\\vec x = \\begin{bmatrix} x_1 \\\\\\ x_2 \\\\\\ \\vdots \\\\\\ x_N \\end{bmatrix}; \\vec x \\in \\mathbb{R}^{N \\times 1}$$ $$\\vec x^T = \\begin{bmatrix} x_1 \u0026 x_2 \u0026 \\dots \u0026 x_N \\end{bmatrix}; \\vec x^T \\in \\mathbb{R}^{1 \\times N} $$ The transpose of a row vector is a column vector Thus, the transpose of the transpose of a vector recovers the original vector. It is important to recognize that, though the transpose of a vector contains the same elements as the original vector, it is still a different vector! That is to say, for any vector .$\\vec x$ (with at least two components), .$\\vec x ^T \\neq \\vec x$ The transpose of a matrix has a very nice interpretation in terms of linear transformations, namely it gives the so-called adjoint transformation. Vector-Vector Multiplication # By convention, a row vector can only be multiplied by a column vector (and vice versa). Multiplication is valid only for specific matching dimensions! Width of the first, matches length of the second\u0026rsquo;s transpose e.x. given .$\\vec x, \\vec y \\in \\mathbb{R}^{N\\times 1}$ We can take the transpose of .$y$ and multiply by .$\\vec x$: This is also known as inner product or dot product Commutative for real numbers (this ceases to be true when we start working with complex numbers in 16B) $$\\vec y^T \\vec x = y_1 x_1 + y_2 x_2 + \\dots + y_N x_N = \\text{some scalar} \\in \\mathbb{R}^{1\\times1}$$ Alternatively, we can take .$\\vec x$ and multiply by the transpose of .$y$ Also known as outer product Do not commute! $$\\vec x \\vec y^T = \\text{some matrix} \\in \\mathbb{R}^{N \\times N}$$ Matrices # - A collection of numbers in a rectangular form - Or, given .$\\mathbb{R}^{M \\times N}$, a collection of .$M$ rows and .$N$ column vectors - Remark: Matrices are often represented by capital letters (e.g. .$A$), $$A = \\begin{bmatrix} a_{11} \u0026 \\dots \u0026 a_{1N} \\\\\\ \\vdots \u0026 \\ddots \u0026 \\vdots\\\\\\ a_{M1} \u0026 \\dots \u0026 a_{MN} \\end{bmatrix}$$ A matrix is said to be square if .$M=N$ (that is, if the number of rows and number of columns are equal). Relation between scalars, vectors, and matrices A vector is a degenerate matrix, that is, .$\\vec x \\in \\mathbb{R}^{n \\times 1}$ A scalar is a degenerate vector or matrix, that is, .$a \\in \\mathbb{R}^{1 \\times 1} $ Transpose: - Just as we could compute the **transpose** of a vector by transforming rows into columns, we can compute the transpose of a matrix, .$A^T$ , where the rows of .$A^T$ are the (transposed) columns of .$A$ $$A^T = \\begin{bmatrix} a_{11} \u0026 \\dots \u0026 a_{M1} \\\\\\ \\vdots \u0026 \\ddots \u0026 \\vdots\\\\\\ a_{1N} \u0026 \\dots \u0026 a_{NM} \\end{bmatrix}$$ Mathematically, .$A^T$ is the .$N\\times M$ matrix given by .$A^T_{ij}$ A square matrix is said to be symmetric if .$A = A^T$ , which means that .$A_{ij} = A_{ji}$ for all .$i, j$. Special Matrices # - **Zero Matrix:** Trivial - **Identity Matrix:** Square matrix whose diagonal elements are .$1$ and whose off-diagonal elements are all .$0$ $$I_3 = \\begin{bmatrix} 1 \u0026 0 \u0026 0 \\\\\\ 0 \u0026 1 \u0026 0\\\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix}$$ Note that the column vectors (and the transpose of the row vectors) of an .$N \\times N$ identity matrix are the unit vectors in .$ \\mathbb{R}^{N}$. The identity matrix is useful because multiplying it with a vector .$\\vec x$ will leave the vector unchanged: .$I \\vec x = \\vec x$. In fact, we will see that multiplying a square matrix by an identity matrix of the same size will yield the same initial matrix: .$AI = IA = A$ Column vs Row # The interpretation of rows and columns that come from the system-of-linear-equations perspective of doing experiments. There, each row of the matrix represents a particular experiment that took one particular measurement. For a given row, the coefficient entries represent how much the corresponding state variable affects the outcome of this particular experiment. In contrast, the columns represent the influence of a particular state variable on the collection of experiments taken together. These perspectives come in handy in interpreting matrix multiplication.\nMatrix Operations # Matrix Addition # Two matrices of the same size can be added together by adding their corresponding components. For instance, we can add two matrices A and B (both in .$ \\mathbb{R}^{m \\times n}$) as follows: Matrix-Vector Multiplication # Given .$A \\in \\mathbb{R}^{M \\times N}, \\vec x = \\mathbb{R}^{N\\times 1}$, we end with some vector .$\\in \\mathbb{R}^{M\\times 1}$ Visual View Matrix-Matrix Multiplication # Matrix-Matrix multiplication involves multiplying each row vector in .$A$ with each column vector in .$B$, starting from the top row of matrix .$A$ and leftmost column of matrix .$B$. Effectively, the left matrix is multiplied by each column vector in the second matrix to produce a new column of .$AB$ Given .$A \\in \\mathbb{R}^{M \\times N},\\ B = \\mathbb{R}^{N\\times L}$, we end with some matrix .$\\in \\mathbb{R}^{M \\times L}$ We can also interpret the .$A \\vec x$ product in the context of .$A$’s columns: Matrix multiplication does not commute! That is .$A \\times B \\neq B \\times A$ In fact, both quantities can only be calculated if the number of rows in .$A$ equals the number of columns in .$B$ and the number of rows in .$B$ equals the number of columns in .$A$. Matrix Multiplication is Associative Fun fact: Computers have to do so many multiply and add operations that it\u0026rsquo;s optimized at a processor level (leaned about this is 61C) "},{"id":16,"href":"/eecs-16a/2/","title":"2: (In)dependence \u0026 Circuit Analysis","section":"EECS 16A","content":" 02-01: Linear (in)dependance, Matrix Transformations # Slides Note 3 Recall the simple tomography example from Note 1, in which we tried to determine the composition of a box of bottles by shining light at different angles and measuring light absorption. The Gaussian elimination algorithm implied that we needed to take at least 9 measurements to properly identify the 9 bottles in a box so that we had at least one equation per variable. However, will taking any 9 measurements guarantee that we can find a solution? Answering this question requires an understanding of linear dependence. In this note, we will define linear dependence (and independence), and take a look at what it implies for systems of linear equations.\nLinear Dependence # Linear dependence is a very useful concept that is often used to characterize the “redundancy” of information in real world applications. Closely tied to the idea of free and basic variables as we’ve already seen We will give three (equivalent) definitions of linear dependence: A set of vectors .$\\{\\vec v_1, \\dots \\vec v_n \\}$ is linearly dependent if there exists scalars .$\\alpha_1, \\dots, \\alpha_n$ such that .$\\alpha_1 \\vec v_1 + \\dots + \\alpha_n \\vec v_n = \\vec 0$ and not all .$\\alpha_i$ are equal to zero. This combination of all-zero scalars has a special name: the \u0026ldquo;trivial solution.\u0026rdquo; A set of vectors .$\\{\\vec v_1, \\dots \\vec v_n \\}$ is linearly dependent if there exists scalars .$\\alpha_1, \\dots, \\alpha_n$ and an index .$i$ such that .$\\vec v_i = \\sum_{j\\neq i} \\alpha_j \\vec v_j$. In other words, a set of vectors is linearly dependent if one of the vectors could be written as a linear combination of the rest of the vectors A set of vectors is either linearly dependent or linearly independent. More specifically, consider the sum in the first definition. If there is a solution to satisfy this equation other than to make all the scalars .$\\alpha_1 = \\dots = \\alpha_n = 0$, (that is, a nontrivial solution) then the vectors are linearly dependent. Why three (equivalent) definitions? Because each is useful in different settings. It is often easier mathematically to show linear dependence with definition (1) since we don’t need to try to “single out” a vector to get started with the proof. (2) gives us a more intuitive way to talk about redundancy. If a vector can be constructed from the rest of the vectors, then this vector does not contribute any information that is not already captured by the other vectors. Proof of equivalency Linear Independence # From the first definition of linear dependence we can deduce that a set of vectors .$\\{\\vec v_1, \\dots, \\vec v_n \\}$ is linearly independent if .$\\alpha_1 \\vec v_1 + \\dots + \\alpha_n \\vec v_n = \\vec 0$ implies .$\\alpha_1 = \\dots = \\alpha_n = 0 $ A set of vectors is linearly independent if it is not linearly dependent. E.x. any two vectors that are multiples of one another are dependent Systems of Linear Equations # Recall that a system of linear equations can be written in matrix-vector form as .$A\\vec x = \\vec b$, where .$A$ is a matrix of variable coefficients, .$\\vec x$ is a vector of variables, and .$\\vec b$ is a vector of values that these weighted sums must equal. We will show that just looking at the columns or rows of the matrix .$A$ can help tell us about the solutions to .$A\\vec x = \\vec b$. Theorem 3.1 # If the system of linear equations .$A\\vec x = \\vec b$. has an infinite number of solutions, then the columns of .$A$ are linearly dependent - If the system has infinite number of solutions, it must have at least two distinct solutions .$\\vec x_1, \\vec x_2$ which must satisfy $$A\\vec x_1 = \\vec b$$ $$A\\vec x_2 = \\vec b$$ - Subtracting the first equation from the second equation, we have $$A (\\vec x_2 - \\vec x_1) = \\vec 0$$ - Define alpha as ...\n$$\\vec \\alpha = \\begin{bmatrix} \\alpha_1 \\\\\\ \\vdots \\\\\\ \\alpha_n \\\\\\ \\end{bmatrix} = \\vec x_2 - \\vec x_1$$ Because .$\\vec x_1, \\vec x_n$ are distinct, not all .$\\alpha_i$\u0026rsquo;s are zero. Let the columns of .$A$ be .$\\vec a_1, \\dots \\vec a_n$. Then, .$A \\vec \\alpha = \\sum^n_{i=1} \\alpha_i \\vec a_i = \\vec 0$. By definition, the columns of .$A$ are linearly dependent. The sum term says that, in other words, matrix-vector multiplication is a linear combination of columns: Theorem 3.2 # If the columns of .$A$ in the system of linear equations .$A\\vec x = \\vec b$ are linearly dependent, then the system does not have a unique solution. - Start by assuming we have a matrix A with _linearly dependent columns_ $$A = \\begin{bmatrix} | \u0026 | \u0026 \u0026 | \\\\\\ \\vec a_1 \u0026 \\vec a_2 \u0026 \\dots \u0026 \\vec a_n \\\\\\ | \u0026 | \u0026 \u0026 | \\\\\\ \\end{bmatrix}$$ - By the definition of linear dependence, there exist scalars .$\\alpha_1, \\dots, \\alpha_n$ such that .$\\alpha_1\\vec a_1 + \\dots + \\alpha_n \\vec a_n = \\vec 0$ where not all of the .$\\alpha_i$’s are zero. We can put these αi’s in a vector: $$\\vec \\alpha = \\begin{bmatrix} \\alpha_1 \\\\\\ \\vdots \\\\\\ \\alpha_n \\\\\\ \\end{bmatrix}$$ - By the definition of matrix-vector multiplication, we can compactly write the expression above: $$A\\vec \\alpha = \\vec 0$$ $$\\text{where } \\vec \\alpha \\neq \\vec 0$$ Recall that we are trying to show that the system of equations .$A\\vec x = \\vec b$ does not have a unique solution. We know that systems of equations can have either zero, one, or infinite solutions. If our system of equations has zero solutions, then it cannot have a unique solution, so we don’t need to consider this case. - Now let’s consider the case where we have at least one solution, .$\\vec x$: - Therefore, .$\\vec x + \\vec \\alpha$ is also a solution to the system of equations! Since both .$\\vec x$ and .$\\vec x + \\vec \\alpha$ are solutions, and .$\\vec \\alpha \\neq \\vec 0$, the system has more than one solution. We’ve now proven the theorem. $$A \\vec x = \\vec b$$ $$A \\vec x + \\vec 0= \\vec b$$ $$A \\vec x + A \\vec \\alpha = \\vec b$$ $$A (\\vec x + \\alpha) = \\vec b$$ Note that we can add any multiple of .$\\alpha$ to .$\\vec x$ and it will still be a solution – therefore, if there is at least one solution to the system and the columns of .$A$ are linearly dependent, then there are infinite solutions.\nIntuitively, in an experiment, each column in matrix .$A$ represents the influence of each variable .$x_i$ on the measurements. If the columns are linearly dependent, this means that some of the variables influence the measurement in the same way, and therefore cannot be disambiguated. See page five for good example. Implications: # This result has important implications to the design of engineering experiments. Often times, we can’t directly measure the values of the variables we’re interested in. However, we can measure the total weighted contribution of each variable. The hope is that we can fully recover each variable by taking several of such measurements. Now we can ask: “What is the minimum number of measurements we need to fully recover the solution?” and “How do we design our experiment so that we can fully recover our solution with the minimum number of measurements?”\nConsider the tomography example. We are confident that we can figure out the configuration of the stack when the columns of the lighting pattern matrix .$A$ in .$A\\vec x = \\vec b$ are linearly independent. On the other hand, if the columns of the lighting pattern matrix are linearly dependent, we know that we don’t yet have enough information to figure out the configuration. Checking whether the columns are linearly independent gives us a way to validate whether we’ve effectively designed our experiment.\nRow Perspective # Optional! Intuitively, each row represents some measurement If the number of measurements taken is at least the number of variables and we cannot completely determine the variables, then at least one of our measurements must be redundant (it doesn’t give us any new information). This intuition suggests that the number of variables we can recover is equal to the number of unique measurements, or the number of linearly independent rows \u0026ndash; this formal proof will come in a later note when we talk about rank. Now have two perspectives: in the matrix, each row represents a measurement, while each column corresponds to a variable. Therefore, if the columns are linearly dependent, then we have at least one redundant variable. From the perspective of rows, linear dependency tells us that we have one or more redundant measurements. Span # Span of the columns of .$A$ is the set of all linear combinations of vectors .$\\vec b$ such that .$A\\vec x = \\vec b$ has a solution .$\\exists \\vec x$ s.t. .$A \\vec x = \\vec b \\Longrightarrow \\vec b \\in \\text{span(cols}(A))$ That is, the set of all vectors that can be reached by all possible linear combinations of the columns of .$A$ Formally, .$\\text{span}(\\vec v_1, \\dots, \\vec v_N) = \\bigg\\{\\sum_{i=1}^N \\alpha_i \\vec v_i\\ |\\ \\alpha_i \\in \\mathbb{R},\\ \\vec a_i \\in \\mathbb{R}^{M}\\bigg\\}$ A set of vectors is linearly dependent if any one of the vectors is in the span of the remaining vectors. That is, if any one of the vectors could be represent as the combination of the remaining vectors (that is, it\u0026rsquo;s in the span of the others) On the other hand, if each vector adds another dimension to the span (contains novel information) then they\u0026rsquo;re said to be linearly independent span, range, and column space of .$A$ all refer to the span of the columns of .$A$ Two Examples - e.x. what is the span of the cols of .$A = \\begin{bmatrix} 1 \u0026 1 \\\\\\ 1 \u0026 -1\\\\\\ \\end{bmatrix}$? $$\\text{span(cols of A)} = \\bigg\\\\{ \\vec v\\ |\\ \\vec v = \\alpha \\begin{bmatrix} 1\\\\\\ 1\\\\\\ \\end{bmatrix} + \\beta \\begin{bmatrix} 1\\\\\\ -1\\\\\\ \\end{bmatrix}; \\alpha, \\beta \\in \\mathbb{R}\\bigg\\\\} = \\mathbb{R}^{2}$$ - e.x. what is the span of the cols of .$A = \\begin{bmatrix} 1 \u0026 -1 \\\\\\ 1 \u0026 -1\\\\\\ \\end{bmatrix}$? $$\\text{span(cols of A)} = \\bigg\\\\{ \\vec v\\ |\\ \\vec v = \\alpha \\begin{bmatrix} 1\\\\\\ 1\\\\\\ \\end{bmatrix}; \\alpha \\in \\mathbb{R}\\bigg\\\\} = \\text{line } (x_1 = x_2)$$ 02-03: Intro to Circuit Analysis # Slides Note 11 A, B Our ultimate goal is to design systems that solve people’s problems. To do so, it’s critical to understand how we go from real-world events all the way to useful information that the system might then act upon. The most common way an engineered system interfaces with the real world is by using sensors and/or actuators that are often composed of electronic circuits; these communicate via electrical signals to processing units, which are also composed entirely of electronic circuits. In order to fully understand and design a useful system, we will need to first understand Electrical Circuit Analysis.\nThere are four main steps involved when designing information devices and systems Analog World Sensor Input Data Processing Actuation (16B) Tiny Bit of Solid-State Physics # Conductors have lots of electrons Move around very easily E.x. copper, gold, silver, water Conductors have lots of electrons But they are at an energy level where they need to be given some energy level (e.x 1 eV) to move E.x. solar cell, diodes Insulators do not let electrons pass through them E.x. capacitors have a big insulator in the middle, that is, current only goes through a capacitor when the magic smoke is released Electrical Quantities # Quantity Symbol Units What Current .$I$ Amps, .$A$ Flow of charges (e.g. electrons) in the circuit due to a potential difference Voltage .$V$ Volts, .$V$ Potential energy (per charge) between two points in the circuit Resistance .$R$ Ohms, .$\\Omega$ Material’s tendency to resist the flow of current. Voltage .$\\pm$ depends on reference point Voltage, or electric potential, is only defined relative to another point (mountain/height analogy). Similarly, in circuits, we will frequently define a reference point, called ground, against which other voltages can be measured. Current .$\\pm$ depends on direction ## Circuit Diagram - Collection of elements, where each element has some voltage across it and some current through it - Two main elements: 1. **Notes:** Points where _elements_ meet 2. **Junctions:** Points where different _material_ meet - Voltage = difference of two potential ![](/docs/eecs-16a/2/diag.png) Basic Circuit Elements # Wire # The most common element in a schematic is the wire, drawn as a solid line The .$IV$ relationship for a wire is: - .$V_\\text{elem} = 0$: A wire is an ideal connection with a **constant**, zero voltage across it. - .$I_\\text{elem} = ?$: The current through a wire can take any value, and is determined by the rest of the circuit. ![](/docs/eecs-16a/2/wire.png) Resistor # - The .$IV$ relationship of a resistor is called Ohm’s Law: - .$V_\\text{elem} = I_\\text{elem} R $: The voltage across a resistor is determined by Ohm’s Law. - .$I_\\text{elem} = V_\\text{elem} / R$: The current through a resistor is determined by Ohm’s Law. ![](/docs/eecs-16a/2/resist.png) **Limit check** - The slope is proportional to .$R^{-1}$, that is, the larger the resistance the lower the slope - .$\\lim_{R \\to 0}$ results in an wire (above) - .$\\lim_{R \\to \\infty}$ results in an open circuit (below) Open Circuit: # - This element is the dual of the wire. - .$V_\\text{elem} = ?$: The voltage across an open circuit can take any value, and is determined by the rest of the circuit. - .$I_\\text{elem} = 0$: No current is allowed to flow through an open circuit; always zero. ![](/docs/eecs-16a/2/open.png) Voltage Source: # A voltage source is a component that forces a specific voltage across its terminals. The + and − sign indicates which direction the voltage is pointing. The voltage difference between the “+” terminal and the “−” terminal is always equal to Vs, no matter what else is happening in the circuit. - .$V_\\text{elem} = V_S$ -- The voltage across the voltage source is always equal to the source value. - .$I_\\text{elem} = ?$ -- The current through a voltage source is determined by the rest of the circuit. ![](/docs/eecs-16a/2/vsrc.png) Current Source: # A current source forces current in the direction specified by the arrow indicated on the schematic symbol. The current flowing through a current source is always equal to Is, no matter what else is happening in the circuit. Note the duality between this element and the voltage source. - .$V_\\text{elem} = ?$ -- The voltage across a current source is determined by the rest of the circuit. - .$I_\\text{elem} = I_S$ -- The current through a current source is always equal to the source value. ![](/docs/eecs-16a/2/isrc.png) Rules for Circuit Analysis # See also: 26.3 Kirchhoff’s Rules Kirchhoff’s Current Law (KCL) # Node: A place in a circuit where two or more of the above circuit elements meet - The net current flowing into/out-of any node is zero: $$(-i_1)+(-i_2)+i_3 = 0$$ - That is, the current flowing into a node must equal the current flowing out of that node $$ i_1+i_2=i_3$$ ![](/docs/eecs-16a/2/kcl.png) Kirchhoff’s Voltage Law (KVL) # - The sum of voltages across the elements connected in a loop must be zero - Mathematically, KVL states that: $$\\sum_\\text{loop} V_k = 0$$ $$\\Longrightarrow V_A - V_B - V_C = 0$$ ![](/docs/eecs-16a/2/kvl.png) Height Analogy # If you walk in a circle (a loop) so that you end up back where you started, than your total change in elevation must be zero, no matter how much you go up or down. If you walk in a line, ending up somewhere different, than your total change in elevation is equal to the sum of all of the elevation changes along the way. Real World Analogy The sum of voltages across the elements connected in a loop must be equal to zero “what goes up must come down” If the arrow corresponding to the loop goes into the “+” of an element, we subtract the voltage across that element. We went “downhill” from higher voltage to lower voltage so we lost “elevation.” If the arrow goes into the “-” of an element, we add the voltage across that element This is like going “uphill” Ohm’s Law and Resistors # $$V_\\text{element} = I_\\text{element}R$$\nThe unit of .$R$ is Volts/Amperes, called Ohms .$\\Omega$. See also: 25.3 Ohm’s Law: Resistance and Resistors "},{"id":17,"href":"/e-29/2/","title":"2: Cutting-based Processes \u0026 Other Subtractive Processes","section":"Engineering 29","content":" 02-01 Cutting-based Processes # ## Modeling of material cutting - Chips are created and separated from the work by plastic deformation, i.e. shearing, of the work. - Sheer plane is created by the tool (teal segment) - Throughout the shear plane, the shear stress must equal or exceed the shear strength of the work material for cutting to proceed. - The value of the shear angle is not something that we directly control, but depends on several factors. ## Lathe operations To analyze chip formation, we consider the 2D y–z plane, with the x axis out of the page We assume that all plastic deformation occurs in a single plane, the shear plane, which is oriented at an shear angle .$\\phi$, to the direction of relative motion .$V_\\text{cut}$ of the tool and work. The shear plane meets the sharp edge of the cutting tool at the bottom of the cut. The area of the shear plane is .$fd / \\sin \\phi$ where .$f$ is the feed (also denoted by .$t_0$ in some texts), and .$d$ is the cut depth (out of the page; also denoted by .$w$ in some texts). Turning on a lathe # Nomenclature of cutting process # The tool itself has a carefully designed shape. Its front face is positioned at an angle .$\\alpha$, the rake angle, from a plane normal to the direction of relative tool–workpiece motion. As we will see, the rake angle will always be chosen to be greater than zero, to ensure a clean cut and to reduce the amount of mechanical work needed to produce a cut. The flank angle, meanwhile, is that between the bottom of the tool and the post-cutting workpiece surface. The flank angle needs to be greater than zero to reduce friction and any resulting scratching or fusion between the tool and the freshly machined surface. We can control the rake and flank angles by manufacturing a cutting tool to our specifications. Merchant’s circle: cutting forces # Force diagram that resolves the reaction force exerted by the tool on the work\nIt is important to consider the magnitudes and directions of the forces that are exerted by the tool on the workpiece during cutting. These forces determine the torque required to rotate the work, the amount of elastic distortion of the work or the lathe that might occur during cutting (potentially leading to inaccuracies in the manufactured component), and also whether the tool will experience a load large enough to fracture it.\nOne way to analyze these forces is with Merchant’s Circle. This Circle is a graphical device developed in the 1940s by Eugene Merchant to visualize cutting loads. The circle itself does not represent the shape of the work being cut. This is a force diagram – i.e. the lengths of lines represent magnitudes of forces, not physical distances. The directions of the lines do correspond to actual orientations in space. The horizontal axis corresponds to the cutting direction. We can use Merchant’s Circle to understand how to design and optimize the cutting process. For example, suppose that we have obtained an estimate of .$\\phi$ from experimental measurements of the chip thickness. We could then use the trigonometrical relationships illustrated in Merchant’s Circle, substituting our estimated .$\\phi$ and our known .$\\alpha$ for the tool, to estimate the friction angle .$\\beta$, which would be difficult to measure directly. This approach might be used to compare the effect on friction angle of various candidate tool materials, coatings, or lubricants.\nRelating cutting geometry to cutting forces\nMaterial properties link the geometry of the tool and cutting path to the forces involved. The material being cut needs to exceed its shear yield stress to start deforming (cutting) and creating a chip. If the material exceeds its ultimate shear strength, the chip becomes more likely to fragment into pieces as it forms (which may help clear waste material away). However, the more strain involved in chip formation for a given material, the more work has to be invested in the cutting operation. Therefore designing the cutting operation to limit shear strain can help to limit cutting energy required. Predicting shear strain .$\\gamma$ # Since we wish to limit the amount of shear strain, .$\\gamma$, occurring during cutting, we need to understand how it depends on parameters that we can control. Parameters we control: .$f, V_\\text{cut}, d, \\omega, \\alpha$. Parameters we don’t directly control, but can measure: .$c, F_c , F_t$ Parameters we don’t directly control and are hard to measure directly: .$\\phi, \\beta$, and forces other than .$F_c$ and .$F_t$ Next, we show (via geometry) how shear strain .$\\gamma$ depends on shear angle .$\\phi$ (which is hard to measure directly) and on rake angle .$\\alpha$ (which is known in advance). To predict shear angle .$\\phi$, we then have two options: Measure chip thickness, .$c$, and use geometry to work out .$\\phi$ in terms of .$f, c$ and .$\\alpha$, or Use Merchant’s shear angle relationship to express .$\\phi$ in terms of .$\\alpha$ and .$\\beta$, and find .$\\beta$ by measuring cutting and thrust forces .$F_c$ and .$F_t$ (e.g. by force sensors on the cutting tool holder) Then, we can take action to control shear strain and cutting force. Relationship between .$\\phi$ and .$\\gamma$ # Using chip thickness to .$\\approx \\phi$ # If we did not have any experimental estimate of .$\\phi$ (since it\u0026rsquo;s a function of the material\u0026rsquo;s properties) but we did have an estimate of .$\\beta$ and knowledge of rake angle .$\\alpha$ (since we can control the tool we use(\u0026rsquo;s rake angle)) and the shear strength of the work material, .$\\tau_y$, we could use Merchant’s shear angle relationship to predict both .$\\phi$ and the cutting force.\nWe can measure a chip to get .$c$ Can then use the relationship between .$\\phi$ and .$\\gamma$ to estimate .$\\gamma$ Merchant’s shear angle relationship #### Study Advice: - Don't memorize this derivation! - This is to show how we can do process diagnosis if we understand each step of the process and how they relate to one another - Understand merchant forces, shear/friction angle, the physical relationship between these angles, and terms (cutting depth, feed (cut amount per rotation), feed rate (speed moving tool along machine)) Merchant’s shear angle relationship # The total reaction force exerted by the tool on the work, .$R$, can be resolved in any of three useful coordinate frames: The first frame is defined by the cutting direction. .$F_c$ is the cutting force, the force in the direction of relative motion of the tool and work. This force is important because the mechanical work done by the lathe is equal to the cutting force times the distance moved in the direction of cutting. The force perpendicular to the cutting force, the thrust force, .$F_t$, can contribute to bending of the work during turning and can become problematic and lead to vibration, particularly with long slender workpieces if they are not supported at both ends. The second frame is defined by the rake (front) face of the tool, and decomposes the reaction force into a frictional force .$F$ parallel to the rake face, and a normal reaction component .$N$. These loads are related by the friction angle: .$\\beta = \\arctan (F/N)$ where .$F/N$ is the coefficient of friction between the chip and the tool. This coefficient can be considerably larger than 1, particularly if chip material bonds to the front of the tool (leading to a built-up edge) and chip–tool sliding involves plastic deformation of the chip. Ideally .$\\beta$ will be as small as possible, which can be achieved with liquid lubrication of the cutting location and/or by special tool coatings which make it smooth and reduce the coefficient of friction. The third frame is defined by the shear plane, and is composed of the shear force .$F_s$ which acts within the shear plane, and the normal component .$F_n$ We assume that shear stress equals the shear strength of the workpiece material in the shear plane, and that shear stresses are lower elsewhere in the material. Also assume that the value of the shear angle .$\\phi$ is naturally such that the shear strength, .$\\tau_y$, of the workpiece material is reached in the shear plane at the lowest possible cutting force .$F_c$. If we know the material’s shear strength, the friction angle .$\\beta$, and the shear angle .$\\phi$, we can (roughly) estimate the required cutting force .$F_c$. Need to solve for .$\\phi$ in terms of parameters we can control: .$\\alpha$ (directly through tool geometry) and .$\\beta$ (indirectly through lubrication). To find value of .$\\phi$ for maximum shear stress at a given .$F_c$, set derivative .$\\frac{d\\tau}{d\\phi}$ to zero and solve: Aside: This equation assumes that all deformation occurs in the sheer plane The lower the friction angle, the higher the sheer angle, requiring larger cutting forces - To estimate .$\\beta$, we can measure .$F_c$ and .$F_t$ and use the force-resolving circle, and then substitute into the expression for .$\\phi$: $$\\tan(\\beta - \\alpha) = \\frac{F_t}{F_c}$$ $$\\beta = \\arctan\\bigg(\\frac{F_t}{F_c}\\bigg) + \\alpha$$ Insights: Increasing the rake angle .$\\alpha$ (via tool design) and lowering friction angle .$\\beta$ (by application of an appropriate lubricant/coolant – e.g. water/oil mixture) both help to increase shear angle, reducing the area of the shear plane. However there are limits: for instance, if .$\\alpha$ becomes too large, .$F_t$ may become negative in which case the tool would dig into the workpiece and result in a very poor finish. There\u0026rsquo;s a limit to how high .$\\alpha$ can reasonably be, though. If it becomes so large that the angle enclosed at the tool tip is extremely sharp, the tool will become highly susceptible to cracking. Moreover, at very large .$\\alpha$ the thrust force may change direction and tend to pull the tool into the work, leading to vibration and a very poor finish. Examples of process changes This model is an approximation; alternative models exist Merchant’s circle: examples of process changes\nThe larger .$\\phi$, the shorter the shear plane and the smaller the cutting force is expected to be for a given feed, cut depth and material (reducing the cutting force is desirable). If .$\\phi \\approx 0$, the shear plane would be large and the cut would be rough. As a rule of thumb, if the angle between the shear plane and the rake face of the tool is about 90°, cutting will be of reasonably high quality as long as adequate lubrication and a reasonable cutting speed are used. Meanwhile, knowledge of .$\\gamma$ can help give a picture of how much plastic deformation is occurring in the chip between the moment of first yield and the chip leaving the cutting tool. Cutting power # The above analysis relies on having knowledge of multiple geometrical parameters, the friction coefficient, and material properties such as shear strength. These values will often not be available; another approach is to characterize metal cutting operations with a specific energy value, which is the energy required to remove a unit volume of material from the work. Specific energies are usually reported with quite a wide range (e.g. 0.4–1.1 J/mm.$^3$ for aluminum alloys) to take into account the variability of tool–material friction and tool geometries that might be used. Different workpiece materials are associated with different specific energies, .$U$ (J/mm.$^3$): the work that must be done per unit volume material removed. However, these energies, which are widely tabulated in handbooks, provide a simple way to relate cutting speed, force and power. The cutting power is simply the product of material removal rate and specific energy. The material removal rate can be computed as the product of cutting speed, feed and cut depth. Broadly speaking, the harder the tool and the softer the workpiece, the larger the feeds and speeds that can be successfully used. The ductility of the workpiece (strain at fracture) also plays a role in determining suitable feed and speed. Not all of the cutting power will go straight into plastic deformation of the work material. In a typical process about 30% of the work done would be dissipated as tool–chip friction. Additionally, the electrical power input to the lathe will exceed the cutting power required, because the motor will not be perfectly efficient and there will also be some mechanical losses in the lathe. .$U$ approximately folds in work done in the shear plane, work done against friction, and mechanical losses in the lathe – hence each material has a quite wide range for .$U$ Example values of .$U$ (J/mm.$^3$): Aluminum alloys: 0.4 – 1.1 Titanium alloys: 3.0 – 4.1 Steels: 2.7 – 9.3 Expression linking .$U$, cutting power .$P_C$, and geometry: Since .$F_C$ depends on the tool, we can find the span of possible .$f, d$ values with the equation above (which need to be sufficiently great to remove material from the work) We have discussed the concepts of shear plane, rake angle and cutting power, etc, in the context of lathe turning But these concepts apply across a whole range of metal-cutting processes, including facing processes on a lathe, as well as drilling, milling, planing, and even processes that use tools with many small cutting edges, such as sawing and rasping. In all of these processes the cutting edge shape is optimized to reduce the amount of mechanical work done to remove material, and give a clean, smooth cut. Tool temperatures and lifetimes # The basic requirement of any cutting tool is that it must be made of a material that is harder than the material it is cutting. For cutting many metals and alloys, we can use high speed steel (HSS), which is a hardened steel containing tungsten, chromium and vanadium as alloying elements. The cutting speeds that are possible with HSS, however, are lower than can be achieved with harder, higher-melting-point, tool materials. An example of such a material would be tungsten carbide. Cutting tool materials, being very hard, are very challenging to machine, and so are made either by grinding or by powder metallurgy, where powder mixtures are pressed in a mold into the shape of the required tool insert and are then baked to fuse the powder. We say tool insert because the objects made by powder metallurgy are small square items that are mounted into a larger holder. The inserts usually have multiple usable edges, so as soon as one of them is blunt or fractured, the insert can simply be rotated in the holder without re-aligning the tool in the machine. An example of a tool material produced by powder methods is “cemented carbide” which is hard tungsten carbide powder bound together with cobalt. Cemented carbides are harder wearing than conventional high-speed steel and easier to produce than pure tungsten carbide tools. Coatings are also important in tool fabrication. Titanium nitride and diamond-like carbon are examples of coatings that reduce chip–tool friction, in part by reducing the surface roughness of the tool The useful lifetime of a cutting tool is a function both of the material and of the cutting velocity at which it operates. This is because as the cutting speed increases, the rate of frictional heat dissipation rises, heating and softening the tool material, and enabling it to erode more quickly: Taylor tool life equation: $$VT^n = C$$ - .$V$ = cutting speed = .$V_\\text{cut}$ - .$T$ = tool lifetime - .$n, C$ are empirical constants - .$n \u003c 1$ and predominated by the melting temperature of the tool material - Smaller .$n$ values indicate that cutting tool lifetime falls more rapidly as cutting velocity increases than materials with .$n$ approaching 1. - Example .$n$ values: ![](/docs/e-29/1/ntbl.png) ![](/docs/e-29/1/ideal-n.png) One advantage of using a tool material that can withstand a higher cutting speed is that one can reduce processing time. Another potential advantage is to be able to reduce the feed while not lengthening the total processing time. Smaller feeds can enable smoother finishes to be achieved, so finishing cuts will tend to have smaller feeds than roughing cuts (which remove large amounts of material quickly at the start of a turning process) Examples of tool wear # Some general effects of tool wear include: * increased cutting forces * increased cutting temperatures * poor surface finish * decreased accuracy of finished part * May lead to tool breakage * Causes change in tool geometry Certain tool materials do not work well with other work materials Typical recommended cutting speeds and feeds # Cermets: Composite between ceramic and metal. Used if you need an especially tough tool Carbides are hard but brittle, so they take tiny particles (typically cobalt) and mix it with a metal (tungsten often used) Talk to the Jacobs staff about this and they can teach you a lot Cutting tool design # (a) Schematic illustration of a right-hand cutting tool for turning. Although these tools have traditionally been produced from solid tool-steel bars, they are now replaced by inserts of carbide or other tool materials of various shapes and sizes, as shown in (b). The insert is the actual cutting feature.\nSurface roughness in machining # Takeaway: Roughness varies with radius .$R_n$ and feed .$V_\\text{feed} = f$ If you want a mirror finish, you have to decrease feed rate .$R_P$: Peak-to-valley roughness Example: .$R_n = 0.5 \\text{ mm; } f = 0.1 \\text{ mm}$ Actual roughness will be up to 2-3 times worse than this ideal value: built-up edge, cracking, scratching from chips, etc Turning example Autodesk computer-aided manufacturing (toolpath planning) demo Etcheverry Machine Shop manual lathe demo 02-03: Other cutting processes based on plastic deformation # Cutting-based operations other than turning: - Milling - Drilling - Reaming - Boring - Broaching - Tapping - Punching Milling # - [Milling in action](https://youtu.be/bdD57NeOuio?t=151) - [Etcheverry demo video (manual)](https://bcourses.berkeley.edu/files/79640852/download?download_frd=1) - [Etcheverry demo video (CNC)](https://bcourses.berkeley.edu/files/79641045/download?download_frd=1) - Cut depth tends to be much greater than feed Types of milling - Peripheral (plain, down) milling - Tool axis is parallel to surface being machined - Slab, slotting, side milling, straddle, form - Face (up milling) milling - Tool axis is perpendicular to surface being machined - Conventional, partial, end, profile, pocket, surface contouring ![](/docs/e-29/1/perim.png) ![](/docs/e-29/1/facem.png) Both have pros/cons Teeth orientation is different (down milling puts lots of force on the teeth) ## Drilling - [Drilling](https://youtu.be/bdD57NeOuio?t=127) - Flutes carry away material - However, you end up with scratches on the side wall when drilling - Reaming - Reaming involves enlarge existing holes - Provide better tolerance and smoother finish than drilling - Reaming tools: vertical flutes ![](/docs/e-29/1/bit.png) Boring # Boring = “inside turning” Single point tool moving along the inside of a rotating workpiece Broaching # Tool used to get square (or non-circle) holes How keyways are put into gears Cut per tooth is analogous to the feed Example Geometry # (a) Typical parts finished by internal broaching.\n(b) Parts finished by surface broaching. The heavy lines indicate broached surfaces;\n(c) a vertical broaching machine.\nTapping # Creates an internal (though external of possible, just uncommon) threads with no pitch nor diameter You start by creating a hole a bit smaller than the minor diameter, then drive the tap in Tend to be treated to ensure they\u0026rsquo;re strong enough Notice that the diameter tapers off, so you\u0026rsquo;re progressively enlarging the hole Punching # Comes in a set including both the punch and die Creates an edge using shear forces \u0026ndash; think industrial hole puncher There has to be a gap between the punch and die; around 6-10% of the desired hole size (varies with type of material) Otherwise tool or medium can be damaged Video demo Other subtractive processes not based on plastic deformation # Laser cutting # In laser cutting, an intense beam of light imparts heat locally to the material and converts the solid either to liquid or directly to vapor to form an edge Where this melted material goes (may) matter depending on the job Extremely quick With the right type of laser you can cut many materials In ablation, a laser beam vaporizes material from the surface of a component to shape it without cutting all the way through it. A thin band of material is removed: the kerf Has some thickness, maybe a thousandth, which may matter The cut isn\u0026rsquo;t completely vertical \u0026ndash; intensity isn\u0026rsquo;t uniform, and beam may not be completely orthogonal (and even then there is some geometry of the focal-spot) http://alumni.media.mit.edu/~yarin/laser/physics.html\nElectrode discharge machining (EDM) # An electrical field is applied between a high-melting-point electrode (which creates sparks, plasma) and the material that that is to be shaped is usually submerged in water. The gap breaks down electrically and a high current flows, heating and vaporizing the work material. The electrode might be made of a wire (for profiling operations) or might be a custom-shaped electrode (e.g. made of graphite) to enable parallel transfer of a complex geometries to a workpiece. Used when you require extreme precision Wire has a constant width, there\u0026rsquo;s no focusing issues like with laser cutting Wire EDM # Not obvious in this example, but the wire can be adjusted about the .$z$-axis too Rate limitation is a function of how quickly you can cut + remove the material https://www.mdpi.com/2076-3417/10/6/2082/htm Abrasive jet # Intro video A high-pressure (≫ 100 MPa) jet of water containing fine, hard particles (usually garnet) impact a sheet of material and cut through it. It\u0026rsquo;s not the water itself, rather, there are tiny particles in the water itself which concentrate the forces enough Material must be emersed under water Surface finish will be more rough (matt texture) than EDM or laser cutting https://www.omax.com/news/blog/controlling-taper "},{"id":18,"href":"/e-29/3/","title":"3: Additive Processes: Intro \u0026 Extrusion","section":"Engineering 29","content":" The rise of additive manufacturing # Additive manufacturing or “3D printing” has been receiving enormous attention both in industry and as a tool for education and design. Something that sets additive manufacturing apart from other families of processes is the enormous rate of innovation in process technology and machine design, together with the fact that much of this innovation is done by small start-up companies and even by individuals, with the development in some cases being crowd-funded. There are huge differences between the versatility and achievable tolerances of “maker-grade” (or consumer-grade) and industry-grade tools, and in this part of the course we will describe and analyze some of the processes that are available, and provide a framework for analyzing new additive manufacturing tools as they become available.\nThe richness of innovation in machine design has been helped by the fact that the established players in 2D printing (HP, Epson, etc.) have until very recently been largely absent from 3D printing. This situation has begun to change, especially with the introduction of HP’s “Multi Jet Fusion” systems, but there is no doubt that the market is highly fragmented, and to understand it, one needs knowledge of the underlying material processing principles.\nReasons to use additive manufacturing # Additive manufacturing has conventionally been seen as a means of prototyping components that would then be mass-produced with some other, faster, process. Prototyping remains an important application, but there are many reasons why one would produce final, functional components additively. Reasons for selecting an additive process over another kind of process include:\nGeometry needs customization, \u0026ldquo;mass customization\u0026rdquo; Medical implants and prostheses; dental aligners, crowns, bridges, surgical guides, clothing, footwear Run size too small for custom tooling There are some components where machining would require too much time and/or labor to be economical, and mass-production techniques such as casting or injection molding would incur considerable tooling costs (complex injection molds can cost tens of thousands of dollars) e.x. Aircraft cabin components (e.g. ducting, seats); titanium alloy turbine blades; mounting brackets; engine fuel nozzles The desired geometry cannot be made in any other way Multi-material, graded stiffness or color Internal porosity for reduced mass The idea of “complexity as practical” or that “complexity is free” is often talked about as a distinctive advantage of additive manufacturing. Reasons for geometrically complex designs: particular aesthetic goals, to improve the aerodynamic performance of a vehicle, or to optimize mechanical properties (e.g. stiffness-to-weight ratio, or compressibility) of a component by introducing fine porous structures that mimic geometries found in nature (e.g. bone, cork, and branched tree-like structures). Supply chain is challenging in some way (geographically or temporally) Enables more decentralized/distributed production Space Station: producing spare parts on the International Space Station — see the start-up company Made in Space that is developing fused deposition modeling tools to work in vacuum and zero-gravity, as well as recycling machines for the printable material, the idea being to produce components on demand without having to wait for a new spacecraft to be launched from Earth to deliver them; Producing spare parts for military use in theaters of war, where components are frequently needed more quickly than they could be shipped, installing a full machine shop in the field may not be practical, and carrying a comprehensive array of spare parts would be cumbersome Printing of food, where freshness is important and people decide what they would like to eat just minutes before they eat it. Assembly costs can be significantly reduced. Items that would necessitate the use of many components if made with traditional manufacturing approaches could be produced in a single piece by exploiting the extra geometrical flexibility allowed by additive manufacturing, thus saving assembly costs. Less workers (human controllers) required \u0026ndash; cheaper, less (human) error Why Not: Potentially waste more material Supports are annoying to remove Working principles for additive manufacturing # New additive processes and tools enter the market every month, so any detailed description of process technology will rapidly become outdated. Perhaps the most useful way to think about additive manufacturing technology is to isolate the different functions that are involved in any additive process, and consider the multiple independent ways in which each function might be fulfilled. Printing tools could be conceived that combine those solution principles in many different ways:\n- Material supply: - Gas (semiconductor manufacturing) - Solution (Electroplating) - Laminae (sheets of material), i.e [Fabrisonic](https://fabrisonic.com/technology/) - Energy: - Heat - Cooling (cryo-printing, biological tissue) - Plasma - Spatial: - moving tool versus moving work - belt/string drive - screen projector - [scanning mirrors](https://en.wikipedia.org/wiki/Laser_scanning#Scanning_mirrors) (galvanometer scanner) This is a very rapidly developing field. Some of these seem unrealistic, and they may be, but only for now.Technology is rapidly increasing and what is unfeasible today may be feasible very soon. Think neural networks\u0026ndash; we\u0026rsquo;ve known the underlying concepts since 1873 but only now has technology become fast enough for it to become feasible Simple model for extrusion # Material must able to heat up and cool down while maintaining it\u0026rsquo;s key properties Higher the temperature, more energy required, lower the viscosity Radius matters Narrow is significantly harder Typical nozzle diameters are in the range 100–250 μm So more resolution is harder to achieve Distance to drive wheel and extruder block needs to be short enough so the material doesn\u0026rsquo;t buckle Considerations # - Turning corners - Need to synchronize extrusion rate - If .$Q$ is too high, then you'll end up with corner bulges - Volume conservation - Voids/porosity - If material isn't hot enough to remain molten, then it won't fill the voids ![](/docs/e-29/3/holes.png) - Thermal gradients (difference in temperatures) - Can cause warping - Heat the component during printing - Heated beds (or 'ovens' -- used in industrial machines) can help prevent this ![](/docs/e-29/3/cure.png) Types of additive process # Fused deposition modeling (FDM) # - Need models for heat transfer at printing location - Also called Fused Filament Fabrication (FFF) - Print time depends strongly on: - Machine, - Component size/geometry, - In-fill strategy - After CAD is complete, model is ran through software (i.e. cura) which turns the model into a series of triangles, which is then used to generate some tool path that forms the model - There's some information loss throughout this process Variations at Jacobs - Type A -- most basic \u0026 common - Single extrusion nozzle (one material) - PLA: Poly Lactic Acid -- plant-based, recyclable, but not industrial-grade due to it's brittleness - Ultimaker 3 - PLA, PETG (tougher, bit more flexible than PLA) - Dual nozzle -- capable of support material (or just various colors) - LulzbotTaz 6 - 1.2 mm nozzle - Stratasys Fortus 380 MC - ABS (reasonably tough: lego-brick material); others possible (i.e nylon) - Soluble support - Markforged X7 - One of the first printers that enables you to include carbon fiber-reinforced nylon - Printed composite - Stiffer than many aluminum alloys Industrial usage Examples: Curtain headers, internal brackets for Airbus A350; air duct components. Material: “Ultem” (polyetherimide), PEEK, nylon Used due to the ability to rapidly manufacture in bulk + light weight compared to alternatives Support structures and extrusion diameter # Stair-step effect You can fix this with post-processing processes i.e. acetone vapor, sanding Some FDM machines have two or more extrusion dies which can deposit different materials independently. One of these extrusion heads might be set up to deposit dedicated support material, which is often soluble in water or a weak NaOH solution and can thus be readily removed from the printed part A widely used rule of thumb is that an overhang with an angle of up to 45° can be printed without any support material. Stress Line Additive Manufacturing (SLAM) # - Fused deposition modeling (FDM) [sometimes known as fused filament fabrication (FFF)] is usually carried out layer-by-layer but inter-layer voids or defects can reduce strength or make strength highly directional. - If the filament orientation can be optimized based on knowledge of the way the part will be loaded (i.e. aligning filaments with the principal stress lines), strength could be improved. - This is what SLAM aims to achieve. - Extrusion nozzle path planning is more challenging than in layer-by-layer FDM. ![](/docs/e-29/3/slam.png) FDM of metal powder/polymer mixtures # The filament material itself is crucial in determining the performance of the printed object. Filaments with new properties enter the market all the time. Materials with widely varying elasticity are available. It is possible to buy filaments with embedded metal particles, wood particles, carbon powder or even graphene (sheets of few-atom-thick carbon with exceptional in-plane thermal and electrical conductivity). These additives control the optical properties (e.g. reflectivity), and, with a post-printing sintering step, electrical conductivity (enabling printing of e.g. circuit boards) and possibly even thermal conductivity.\nNevertheless, the working principle of FDM is that a thermoplastic material is temporarily softened inside the print head and then extruded layer by layer on to the emerging component. So it is likely that the largest constituent by volume of any FDM filament will continue to need to be a thermoplastic material. At the moment, organic thermoplastic polymers are the primary ingredient of most filament materials. However, we have already seen the working principle of FDM translated from organic thermoplastic polymers to metals and to glass, which can be extruded in a sufficiently viscous form that it holds its shape long enough to be deposited on to a component.\nA heated nozzle brings the feedstock filament close to its melting point, then an electrical current passed through the filament and into the substrate further heats the material causing it to fuse on to the substrate. It has also been demonstrated with bulk metallic glasses, which are special alloys that remain amorphous at readily attainable cooling rates – i.e. they do not crystallize and can therefore achieve a desirable combination of hardness and toughness. Meanwhile, use of arc welding in conjunction with robotics to deposit metal has been demonstrated as a lower-resolution, but much faster, way of depositing material Filament ~85 wt% metal powder; polylactic acid (PLA) binder - Sinter at 980 °C (copper) or 830 °C (bronze) to fuse particles - If you get high enough pressure, then the metal atoms themselves will fuse - You're not melting the object; shape is retained - Same side of the coin: pores still exist - \"Pores are just cracks waiting to grow\" due to their sharp edges - Quench; pickle or polish ![](/docs/e-29/3/pow.png) \u003e Left: After printing; Right: After Polishing Direct ink writing # This is a hybrid between FDM and sintering, and involves extruding a paste containing particles of the structural material in a solvent. The material can be extruded successfully through syringe needles as small as a micrometer in diameter. Lead zirconium titanate ceramic particles in a solvent dispensed via nozzle Piezoelectric material The material paste is thixotropic, or shear-thinning, which means that when it is loaded and starts to flow, its apparent viscosity falls enabling it to be squeezed through the needle. Versus than thermally softening polymer (like squeezing toothpaste from a tube) When its shear strain rate falls again, its viscosity rises, so the extruded structure retains its shape and does not deform significantly under the action of gravity or surface tension. Once the structure has been printed, heat is applied to drive of the solvent and sinter the particles. Applications include making micro-scale sensors and actuators, and tissue scaffolds. ![](/docs/e-29/3/ink2.png) - Material flow is achieved by using a (shear- thinning) ink - Features down to ~ 1 micrometer possible by extrusion through fine needles - Advantages: heat not required; more material possibilities (notably ceramics) ![](/docs/e-29/3/istress.png) ![](/docs/e-29/3/ink1.png) - Shear stress in material, .$\\tau$, is defined by: $$\\tau = \\tau_y + K \\dot \\gamma ^n$$ - .$\\tau_y$ is zero-shear-rate yield stress (Pa) - .$K$ is a material constant - .$\\hat \\gamma$ is shear (deformation) rate (1/s) - .$n$ is shear-thinning exponent (\u003c1 for this process to work) "},{"id":19,"href":"/eecs-16a/3/","title":"3: Transformations \u0026 Inverse","section":"EECS 16A","content":" 02-08: Matrix Transformations # Slides Note 4 Linear Transformations # Linear Transformation: In the previous practice set, we discussed the idea of a matrix .$A^{M \\times N}$ as a linear transformation. Effectively, in the equation .$A \\vec x = \\vec b$, the matrix itself can be considered a transformation .$f : \\mathbb{R}^{N} \\to \\mathbb{R}^{M}$ which takes a vector .$\\vec x^{N \\times 1}$ of inputs and returns a vector .$\\vec b^{M \\times 1}$ of outputs That is, matrices are operators that transform vectors - Just as .$f$ is a linear transformation iff [homogeneity and super position hold](0#linear-algebra), matrix-vector multiplications satisfy linear transformation: $$A \\cdot (\\alpha \\vec x) = \\alpha A \\vec x$$ $$A \\cdot (\\vec x + \\vec y) = A \\vec x + A \\vec y $$ State Transformation # As such, we can think about matrices as state transformations; If we have a list of inputs representing some current state at some timestep .$n$ (given by .$\\vec x(n)$), then when a matrix .$A$ operates on that state, it transforms it into a new state at the next time step (.$\\vec x(n + 1)$). Consider a timestep to be a very small unit of time. Our systems here will be discrete, meaning that the transition of water happens exactly at each timestep, and not between timesteps Aside: But in reality, water is flowing continuously! To model this rigorously, we need linear differential equations, but for now, if the timestep we take is very small, the discrete model is quite good as an approximation. Example: Water Pulps ( Note5 ) - At each time step, some portion of the water in each pump goes to itself, and some portion goes to each of the other pumps. The general state transition matrix formula for an .$n$-state system (assuming the initial and final state vectors have the same length .$n$) is as follows: $$ \\begin{bmatrix} \\vec P_{1 \\to \\dots} \u0026 \\vec P_{2 \\to \\dots} \u0026 \\dots \u0026 \\vec P_{N \\to \\dots} \\\\\\ \\end{bmatrix}$$ $$\\equiv$$ $$\\begin{bmatrix} P_{1 \\to 1} \u0026 P_{2 \\to 1} \u0026 ... \u0026 P_{N \\to 1}\\\\\\ P_{1 \\to 2} \u0026 P_{2 \\to 2} \u0026 ... \u0026 P_{N \\to 2}\\\\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots\\\\\\ P_{1 \\to N} \u0026 P_{2 \\to N} \u0026 ... \u0026 P_{N \\to N} \\end{bmatrix} $$ \u003e ![](/docs/eecs-16a/2/fournode.png) \u003e $$\\begin{bmatrix} 0.4 \u0026 0.1 \u0026 0.4 \u0026 0.1\\\\\\ 0.1 \u0026 0.2 \u0026 0.1 \u0026 0.4\\\\\\ 0.2 \u0026 0.3 \u0026 0.2 \u0026 0.2\\\\\\ 0.3 \u0026 0.4 \u0026 0.3 \u0026 0.3 \\end{bmatrix}$$ Notice that all of the water goes somewhere and none comes up out of thin air; that is, the water is a conserved quantity. We don’t have any leakage or generation of water in the system. This isn’t always true, but the idea of conservation will largely hold true, especially for systems based in physical reality. We can tell if the transformation is conservative by looking at each column’s values describe the movement of water from a specific node to other nodes. If any column’s values do not sum to exactly 1, then something is being lost or created in the system as a whole. In addition, if a specific column’s sum is greater than 1, matter is entering the system through that node; conversely, if a specific column sum is less than 1, matter is leaving the system through that node. Recognize that, given information about only a single node’s column sum, we can never definitely say if the overall system is conservative or not; we only know if it might be conservative, based on other nodes. Diagram .$\\to$ Matrix: Given a state transition diagram, we can create the corresponding state transition matrix by reading the values at each arrow, noting the directionality (these are directed edges) and populating the rows one by one. Similarly, given a matrix, we can draw the appropriate number of nodes and label arrows going to/from each node with the values as indicated by the matrix. How do we go back in time? That is, we want some transition matrix .$B$ such that .$\\vec x (t-1) = B \\vec x(t)$ Flipping the direction of the edges won\u0026rsquo;t work\u0026hellip; Transpose won\u0026rsquo;t either\u0026hellip; Which leads us to\u0026hellip; 02-10: Inverse # Slides Notes 5, 6 Matrix Inverse # Purpose We know that .$\\vec x(t+1) = Q \\vec x (t)$ and want some reverse-matrix .$P$ such that .$\\vec x (t) = P \\vec x (t+1)$ $$P \\vec x(t+1) = PQ\\vec x(t)$$ $$P \\vec x(t+1) = I \\vec x(t)$$ $$\\vec x(t+1) = Q \\vec x(t)$$ $$\\vec x(t+1) = Q(P \\vec x(t+1))$$ $$\\vec x(t+1) = I \\vec x(t+1)$$ Consider .$A$ as an operator on any vector .$\\vec x \\in \\mathbb{R}^{n}$: What does it mean for .$A$ to have an inverse? It suggests that we can find a matrix that \u0026ldquo;undoes\u0026rdquo; the effect of matrix .$A$ operating on any vector .$\\vec x \\in \\mathbb{R}^{n}$. What property should .$A$ have in order for this to be possible? A should map any two distinct vectors to distinct vectors in .$ \\mathbb{R}^{n}$, i.e., .$A \\vec x_1 \\neq A \\vec x_2$ for vectors .$\\vec x_1, \\vec x_2$ such that .$\\vec x_1 \\neq \\vec x_2$. Definition: Let .$P, Q \\in \\mathbb{R}^{N \\times N}$ be square matrices (we tackle non-square in 16B) .$P$ is the inverse of .$Q$ if .$PQ = QP = I$ We say .$P = Q^{-1}$ and .$Q = P^{-1}$ Steps to solve with Gaussian Elimination are shown on slide 50 or \u0026lsquo;more\u0026rsquo; formally in Notes 6, page 3 - For any .$n \\times n$ matrix .$M$, we can perform Gaussian elimination on the augmented matrix: - If at termination of Gaussian elimination, we end up with an identity matrix on the left, then the matrix on the right is the inverse of the matrix .$M$ - If we don’t end up with an identity matrix on the left, we will have a row of zeros, (which indicates that the rows of .$M$ are linearly dependent) and that the matrix is not invertible $$\\begin{bmatrix} \u0026 \u0026 | \u0026 \u0026 \\\\\\ \u0026 M \u0026 | \u0026 I_n \u0026 \\\\\\ \u0026 \u0026 | \u0026 \u0026 \\\\\\ \\end{bmatrix} $$ $$ \\begin{bmatrix} \u0026 \u0026 | \u0026 \u0026 \\\\\\ \u0026 I_n \u0026 | \u0026 M^{-1} \u0026 \\\\\\ \u0026 \u0026 | \u0026 \u0026 \\\\\\ \\end{bmatrix}$$ Inverse of a 2x2 matrix # You can derive this via Gaussian elimination (flip .$a$ with .$d$, negate .$b$ and .$c$, then divide by .$ad-bc$) $$A = \\begin{bmatrix} a \u0026 b\\\\\\ c \u0026 d\\\\\\ \\end{bmatrix}$$ $$A^{-1} = \\frac{1}{ad-bc} \\begin{bmatrix} d \u0026 -b\\\\\\ -c \u0026 a\\\\\\ \\end{bmatrix}$$ .$ad-bc$ is the determinant, so we can check quickly if an inverse exists for a square matrix by checking if they determinant exists See slide 8 Determinant is the area the vectors form. So if they vectors form some zero-area (or volume in 3D) then it\u0026rsquo;s not one-to-one and thus not invertible Theorems # Theorem Note 6.1 # If .$A$ is an invertible matrix, then its inverse must be unique\n- Suppose .$B_1, B_2$ are both inverses of the matrix .$A$. Then we have --- - Notice that by associativity of matrix multiplication, the left hand side of the equation above becomes - We see that .$B_1 = B_2$, so the inverse of any invertible matrix is unique. $$AB_1 = B_1 A = I$$ $$AB_2 = B_2 A = I$$ --- $$AB_1 = I \\Longrightarrow B_2(AB_1) = B_2 I = B_2$$ $$B_2 (AB_1) = (B_2 A)B_1 = IB_1 = B_1$$ $$\\therefore B_1 = B_2$$ Another important property of inverses is that the “left” inverse and the “right” inverse are equal to each other. In particular\u0026hellip; Theorem Note 6.2 # If .$QP = I$ and .$RQ = I$, then .$P = R$. The matrix .$P$ can be thought of as the “right” inverse of .$Q$ and the matrix .$R$ can be thought of as the “left” inverse of .$Q$.\nWe start the proof by noticing that we know two things .$QP = I$ and .$RQ = I$. To move ahead, we can try setting .$QP = RQ$, but we cannot proceed from here, since the multiplication by .$Q$ is on different sides. So instead we take the equation .$QP = I$ and multiply both sides on the left by .$R$. This gives $$R(QP) = R(I) = R$$ Now, using the associative property of matrix multiplication we have that $$R(QP) + (RQ)P = IP = P$$ Here we used .$RQ = I$. Combining these two equations, we have that .$R = P$, and we are done Theorem Note 6.3 # If a matrix A is invertible, there exists a unique solution to the equation .$A \\vec x = \\vec b$ for all possible vectors .$\\vec b$.\nLet’s try to prove this. To do so, we need to prove two statements: That there exists at least one solution to the equation .$A \\vec x = \\vec b$, and that There exists no more than one solution to the equation .$A \\vec x = \\vec b$. For both of the above statements, .$\\vec b$ can be any vector in .$\\mathbb{R}^{n}$ Let’s prove the first statement first. Imagine we are given a vector .$\\vec b$. Consider the candidate solution .$\\vec x = A^{−1} \\vec b$. Observe that $$A \\vec x = A(A^{-1} \\vec b) = (AA^{-1}) \\vec b = \\vec b$$ Thus, our candidate solution satisfies the equation .$A \\vec x = \\vec b$, so there exists at least one solution to that equation! Now, let’s show the second statement \u0026ndash; that no more than one solution to the equation .$A \\vec x = \\vec b$ can exist. Consider a particular solution .$\\vec x$, so .$A \\vec x = \\vec b$. Pre-multiplying both sides of this equation by .$A^{−1}$, we obtain $$A^{-1}(A \\vec x) = A^{-1} \\vec b \\Longrightarrow \\vec x = A^{-1} \\vec b$$ Therefore, if .$\\vec x$ exists, it must be the particular vector .$A^{−1} \\vec b$. In other words, there exists at most one solution to the equation .$A \\vec x = \\vec b$, so we have proven the second statement Theorem Note 6.4 # If a matrix .$A$ is invertible, its columns are linearly independent.\nLet’s prove this theorem. We know that the statement “the columns of .$A$ are linearly independent” is equivalent to the statement “.$A \\vec x = \\vec 0$ only when .$ \\vec x = \\vec 0$.” This fact follows from the definition of linear independence: by definition, if .$\\vec v_1, \\dots, \\vec v_n$ are linearly independent, then .$\\sum_{i=1}^n x_i \\vec v_i$ is only .$\\vec 0$ when .$x_i = 0$. Using the column perspective of matrix multiplication (covered in Note 3), .$A \\vec x = \\sum_{i=1}^n x_i \\vec v_i$ where .$\\vec v_i$ is the .$i$th column of .$A$. Therefore, .$A \\vec x = \\vec 0$ only when all .$x_i = 0$. Therefore, we can rephrase what we’re trying to prove as $$A^{-1} \\text{ exists } \\Longrightarrow A \\vec x = \\vec 0 \\text{ only when } \\vec x = \\vec 0$$ To prove this, assume that .$A$ is invertible. Let .$\\vec v$ be some vector such that .$A \\vec x = \\vec 0$: $$A \\vec x = \\vec 0 \\text{ left-multiply by } A^{-1}$$ $$A^{-1} A \\vec v = I \\vec v = \\vec 0$$ $$\\vec v = \\vec 0$$ Theorem Lecture # .$A$ is invertible, iff the columns of are linearly independent.\nThat is, If columns of .$A$ are liner dependent then .$A^{-1}$ does not exist If .$A^{-1}$ exists, then the cols. of .$A$ are linearly independent Proof concept: Assume linear dependence and invertibility and show that it is a contradiction - From linear dependence: .$\\exists \\vec \\alpha \\neq 0$ such that .$A \\vec \\alpha = 0$: - But .$\\vec \\alpha \\neq 0$, hence, .$A^{-1}$ DNE $$A \\vec \\alpha = 0$$ $$A^{-1} A \\vec \\alpha = A^{-1} 0$$ $$I \\vec \\alpha = 0$$ Thus, the following statements are equivalent: - Matrix .$A$ is invertible - .$A$ has linearly independent columns - .$A$ is [full rank](https://en.wikipedia.org/wiki/Rank_(linear_algebra)) - .$A \\vec x = \\vec b$ has a unique solution - .$A$ has a trivial [nullspace](https://en.wikipedia.org/wiki/Kernel_(linear_algebra)) - The [determinant](https://en.wikipedia.org/wiki/Determinant) of is not zero "},{"id":20,"href":"/e-29/4/","title":"4: Additive Processes: Light-based, etc.","section":"Engineering 29","content":" Processes based on light-sensitive liquids # Stereolithography (SLA) # Also called Digital Light Printing (DLP) Thermoforming molds are most commonly made with stereolithography, i.e orthodontic aligners Used because the molds need complete geometric customizability A tray, bath or vat of a photo-sensitive liquid (a resin) is locally crosslinked (solidified) with a scanning laser beam or projected light pattern (i.e Photoinitiator), usually violet (~405 nm) or ultraviolet (~365 nm) Unwanted bonding can be avoided by making the base oxygen-permeable (e.g. by making it out of an elastomeric material, as in the Carbon 3D systems) since oxygen inhibits the photocrosslinking reaction and an oxygen-rich layer will form in the resin just above the permeable window because of air diffusing through the window - Covalent bonds form between the molecules in the liquid, forming a solid material (this reaction is called photocrosslinking) - Absorption of photons as they pass through the liquid limits crosslinking to a small layer (typically tens of μm thick) at a time - Parts are more [isotropic](https://en.wikipedia.org/wiki/Isotropy) (versus FDM), have almost matte finish - Two machine design approaches: 1. Right: Light shines up through a window; part gradually drawn up out of a tray of resin - Requires more liquid 2. Projection Printing (below): Light shines down onto liquid surface; platform moves down into the vat as the part builds up - Printed object drawn upwards out of tray of resin - Separation from tray: peeling or O2-inhibited dead layer In older SLA configurations, the platform is submerged in the resin, the illumination comes in from above the resin surface, and the platform moves down into the resin bath after each layer was printed. Sometimes a mechanical ‘wiper’ is used to distribute a thin, uniform layer of uncured resin on top of the component before the next exposure step In new designs, the illumination is shone through a window in the bottom of the resin tray, and the platform moves upwards, pulling the object out of the tray as it prints. This approach has the advantage of requiring a less deep resin tray, and eliminating the need for a wiper, but means that the machine designer must ensure that the resin does not bond to the window at the base of the resin tray. Resin solidification in stereolithography # Beer-Lambert model: Absorption of the illuminating light means that exposure dose .$E(z)$ (measured in W/m.$^2$) of the light is at its highest at the point where the light enters the resin, and decreases exponentially with depth below resin surface .$z$: $$E(z) = E_0 e^{-z/D_p}$$ This curve (a property of the dye/resin) follows a first-order exponential decay This is common across most materials that absorb light; for each unit traveled by the photon, there\u0026rsquo;s a finite probability of getting absorbed. E.x. 10% of photos are absorbed in the first 10 microns, 10% of the remaining photons in the next 10 microns, etc. - A newer, potentially faster, approach for processes that rely on photocrosslinking is to expose each 2D layer in one single exposure step, rather than scanning a beam of light. The digital micromirror devices that are an integral component of modern video projectors can be used to pattern the photocrosslinking wavelength of light. Even with this layer-by-layer approach, there is still a need to - Whether 3D printing will always involve this slicing approach is an open question. Since slicing often imparts anisotropic mechanical properties to printed components and limits their layer-to-layer strength, there may be a strong case for developing full 3D control over the material deposition process, so that, for example, the deposition head would move in the x, y and z directions simultaneously. Path planning to avoid collision between the machine and the component would be a significant challenge slice a 3D object into multiple 2D images. .$D_p$ is the penetration depth, a resin property The resin at a particular location will photocrosslink when the total illumination dose exceeds a critical value called the curing dose The depth into the resin at which the curing dose is reached is termed the curing depth .$E$ is the dose: the time integral of power intensity over the layer time Measured in J/m.$^2$ In projector-based systems, the source is .$E_0 = I_0\\ t_\\text{layer}$ .$I_0$ is the illumination irradiance/power intensity, which is proportional to the energy of the incoming particles per area W/m.$^2$ In laser-scanning systems, .$E_0$ is a function of illumination power intensity (W/m.$^2$), beam diameter w (m), and scanning speed, v (m/s): - Gelation just occurs at the **curing depth**, .$D_c$ where the resin receives the **curing dose**, .$E_c$: $$E_c = E_0 e^{-D_c/D_p} \\Longrightarrow D_c = D_p \\ln \\bigg( \\frac{E_0}{E_c} \\bigg)$$ - Cured material may not be very strong at curing depth, so layers typically overlap in .$z$ direction to ensure material is all well-gelled - Thermal and light curing are done to finish these surfaces Hydrodynamic stresses in dead zone # This is the central rate-limiter in stereolithography Suction pressure forms around bottom of part Proportional to the square of the part width Thermal management for high print speeds # Oil cools down print, enables meters per hours printing SLA vs FDM # Type Pros Cons SLA Can reduce layer thickness to much smaller levels than FDM (see especially the Carbon 3D system which claims sub-micrometer layer thicknesses) Only a single resin material can be patterned per object Can use digital micromirror devices to print an entire layer in one flash – potentially higher throughput than FDM Mechanical properties of photocrosslinkable resins lag behind those of FDM filaments With thinner layers, can get more isotropic mechanical strength than in layered FDM FDM Very wide range of printable filament materials now available, with specialist mechanical, thermal, optical, and electrical properties Anisotropic mechanical strength because of layered deposition – weaker layer-to-layer than within layers Apparatus can be very affordable (a few hundred dollars in some cases) Surface roughness comparable to extruded filament diameter – cannot directly print shiny surfaces Computed Axial Lithography # CAL: Developed at Cal! A layer-free tomographic approach to photopatterning involving synthesis of 3D light dose Benefits: higher speed, the ability to print into more viscous materials, and the ability to avoid the use of solid supporting structures for delicate geometries. Enables a wider range of resin materials (notably higher viscosity resins) There a discrete number of layers, but then end up being \u0026lsquo;smeared\u0026rsquo; so they are relatively smooth Poly Jet printing # Also called ink-jet printing Used when a high degree of material heterogeneity is needed in a single object (e.g. in color, or mechanical stiffness) These have been commercialized, for example, by the company Stratasys with the brand name “PolyJet” - Inkjet-dispensed polymer inks are built up layer by layer and photocured (crosslinked). Layers down to ~16.$\\mu$ thick. - Elastic modulus and color can be varied spatially by mixing inks - A wide range of mechanical properties (including elastomers) are now possible - Rigid glassy polymers to soft rubber-like performance possible - Note that these are “simulated” materials: the printed inks are photocured whereas the final production material may be, e.g., thermoplastic - Typical machines can carry about five different material cartridges at a given time, and can tune material properties by depositing finely interspersed patterns of droplets of these materials. - Far more expensive than FDM or basic SLA tools. - Electrically conductive materials are beginning to emerge --- - Available in Jacobs Hall: - Objet260 Connex3 - Objet350 Connex3 - Interchangeable ink cartridges - Soft, rubbery, tacky: - Tango range - ~ few MPa Young’s Modulus - Rigid: - Vero (white, black, yellow, magenta, cyan, clear available) - Digital ABS - ~ few GPaYoung’s Modulus - Soluble support: - FullCure705 - Remove by hand, water or NaOH solution Powder/binder methods # Selective laser Sintering (SLS) # Use a heat source (usually a scanning laser beam) to sinter powders of the structural material directly, without a binder - Can be applied to thermoplastic polymers (esp. Nylon), metals, and even ceramics - A thin layer of the powder is rolled across the printing bed, and then a laser is scanned across the layer, delivering enough heat that the powder particles melt only at their surfaces. - Atoms or molecules at the contacting interfaces between particles diffuse faster in the elevated temperature and cause adjacent particles to connect to each other. - Powder particles are heated enough that surfaces melt-- atoms/molecules at their surfaces interdiffuse, bonding the particles. - Because the powder is not fully melted, parts usually retain some porosity - Can weaken the component compared to continuous bulk material - The pores can serve as stress concentrators and promote crack propagation across the component - The surface finish can be rough — the roughness is comparable to the metal particle size ### Selective Laser Melting (SLM) - Also called Direct Metal Laser or Directed Energy Deposition - Laser (infrared light) actually melts the powder - Removes porosity by melting the particles - Thermal gradients can be a problem - Computer generators now account for thees gradients and deformations - Changes pattern order and energy distribution - There has been a move away from metal SLS towards complete melting of the metal powder that is being fused. - Greater control of grain structure and lower porosity than with selective laser sintering - Fully dense structures achievable - Scanning laser beam completely melts the powder during processing - No binders being employed but rather the structure of the component being built up directly from metal. - These processes may be layer-by-layer or, increasingly commonly, via a direct spray - Isn't feasibly monetarily right now Examples of components # 3D printed gas turbine blades Polycrystalline nickel superalloy Layer by layer powder fusion Survived 13,000 rpm at 1250 °C - Application: pressure sensor housing in General Electric jet engine compressor - Made using SLM - Co-Cr alloy - 19 of them in the GE LEAP engine - Replaces a casting process - Development time up to a year faster than using casting - Example of remanufacturing with SLM - Used when material is very expensive and not recyclable/reusable ![](/docs/e-29/3/reman.png) Electron-beam melting # - Like SLM, produces fully dense parts - Operates in vacuum to avoid metal oxidation and so that the electrons can follow a straight path without colliding with air molecules. - In contrast, SLM uses an inert gas atmosphere - Vacuum allows higher temperatures to be used (\u003e 800 K) - Reduces oxidation and porosity due to adsorbed gases - Materials more limited than SLM - Examples: Ti grade 2, Ti6Al4V, Inconel 718, CoCrMo - Features down to a few micrometers are possible although printing times are slow compared with SLS or even SLM ![](/docs/e-29/3/ebeam.png) ![](/docs/e-29/3/ebeam1.png) Hybrid subtractive/additive manufacturing # In the last few years hybrid machines have been demonstrated that combine a subtractive machining center (lathe, mill) with an additive capability The idea is to start with the smallest possible piece of stock material, deposit additional features of a component (e.g. flanges) additively on to that stock, and then machine back to the final shape, benefiting from the higher precision and surface finish of turning and milling. A machine made by DMG-Mori is now on the market and uses a metal spray together with a laser to deposit material, rather than a powder bed approach. Powder-binder method # \u003e One approach to printing objects from powders (which may include metal, polymer or ceramic powders) is to selectively dispense a binder (a sprayable ‘glue’, usually a polymer) on to layers of dry powder, holding the powder together in specific locations. After printing, the part is removed from the surrounding unbound loose powder. For polymeric parts, the binder can be colored and constitutes part of the final object. For metal or ceramic printing, the binder is subsequently be driven off (vaporized) with high heat after the whole part has been printed, and the powder is also sintered together by the heat (see below for explanation of sintering). Polymer powder and deposited binder (may be colored). Left: schematic illustration of the threedimensional-printing process. Source: After E. Sachs and M. Cima. Can also be applied to binders with metal powders, which are later sintered/fused (Desktop Metal, Markforged…) Emerging methods # Directly fuse thermoplastic powders layer-by-layer Something like a 3D photocopier Powdered materials # - Polymer powder production - Ball milling: grind below glass transition - Metal powder production - Solid-state reduction: crush ore, pass through furnace - Atomization:rapidly freeze molten spray - Electrolysis: deposition in powder form (e.g. Cu) - Chemical, e.g. precipitation from solution - Size distributions typically Gaussian - SLM: typical average ~ 30 microns - The more spherical, the more easily it flows - Some powders more porous Design for additive manufacturing # Stretch-dominated lattices e.g. octet truss structure One of the stiffest structures known Produced, e.g., by projection microstereolithography Tuning material properties with structure # Printed cellular structures can offer new classes of material Current challenges with 3D printing # Speed – for a single material and non-freeform geometry, machining is still probably quicker; injection molding is certainly faster Lower mechanical strength – directionality, porosity, surface flaws Surface finish – roughness often of many microns Resolution – from ~ 0.25 mm for basic FDM down to a few microns for SLA/SLS/SLM. Sub-micrometer resolution possible for two-photon SLA. Expense of input material – fine filaments, powders, inks: some proprietary consumables Potential future applications of 3D printing # Food? Clothes? Human organs? Houses? What are the challenges of 3D printing? Intellectual property; forgery Difficulty of regulating production (e.g. of weapons; organs) Carbon footprint (energy input) of 3D-printed components vs traditionally manufactured components Overall will 3D printing create or destroy jobs? "},{"id":21,"href":"/eecs-16a/4/","title":"4: Vector Spaces \u0026 Eigenstuff","section":"EECS 16A","content":" 02-15: Vector Spaces: Null Spaces and Columnspaces # Slides Notes 7 8 Important Jargon # Rank a matrix .$A$ is the number of linearly independent columns Nullspace of a matrix is the set of solutions to .$A \\vec x = 0$ A vector space is a set of vectors connected by two operators: .$+, \\times$ \u0026mdash; page 48 A vector subspace is a subset of vectors that have “nice properties” \u0026mdash; page 50 A basis for a vector space is a minimum set of vectors needed to represent all vectors in the space Dimension of a vector space is the number of basis vectors Column space is the span (range) of the columns of a matrix Row space is the span of the rows of a matrix Vector Spaces # A vector space .$\\mathbb{V}$ is a set of vectors and two operators .$+, \\cdot$ that satisfy: **Vector Addition** - Associative: .$\\vec u + (\\vec v + \\vec w) = (\\vec u + \\vec v) + \\vec w$ - Commutative: .$\\vec u + \\vec v = \\vec v + \\vec u$ - Additive Identity: There exists an additive identity .$\\vec 0 \\in \\mathbb{V}$ such that .$\\vec v + \\vec 0 = \\vec v$ - Additive Inverse: There exists .$- \\vec v \\in \\mathbb{V}$ such that .$\\vec v + (-\\vec v) = \\vec 0$. We call .$-\\vec v$ the additive inverse of .$\\vec v$. - Closure under vector addition: The sum .$\\vec v + \\vec u$ must also be in .$\\mathbb{V}$ **Scalar Multiplication** - Associative: .$\\vec \\alpha(\\beta \\vec v) = (\\alpha \\beta) \\vec v$ - Multiplicative Identity: There exists .$1 \\in \\mathbb{R}$ where .$1 \\cdot \\vec v = \\vec v$ - Distributive in vector addition: .$\\alpha (\\vec u + \\vec v) = \\alpha \\vec u + \\alpha \\vec v$ - Distributive in scalar addition: .$(\\alpha + \\beta)\\vec v = \\alpha \\vec v + \\beta \\vec v$ - Closure under scalar multiplication: The product .$\\alpha \\vec v$ must also be in .$\\mathbb{V}$. ... for any .$\\vec v, \\vec u, \\vec w \\in \\mathbb{V}; \\alpha, \\beta \\in \\mathbb{R}$ These can be grouped by axioms of closure, addition, and scaling shown on slide 10 For example .$ \\mathbb{R}^{n}$ is the vector space of all .$n$-dimensional vectors. In fact, the set of all matrices the same size is also a vector space .$ \\mathbb{R}^{n \\times o}$ since it fulfills all of the properties above as well In this class we will generally only deal with vector spaces containing vectors in .$\\mathbb{R}^{n}$. Subspaces # A subspace .$\\mathbb{U}$ consists of a subset of .$\\mathbb{V}$ in vector space (.$\\mathbb{V}, \\mathbb{F}, +, \\cdot$). .$\\mathbb{U} \\subset \\mathbb{V}$ and have 3 properties Contains .$\\vec 0 $, i.e., .$\\vec 0 \\in \\mathbb{U}$ Closed under vector addition: .$\\vec v_1, \\vec v_2 \\in \\mathbb{U} \\Longrightarrow \\vec v_1 + \\vec v_2 \\in \\mathbb{U}$ Closed under scalar multiplication: .$\\vec v \\in \\mathbb{U}, \\alpha \\in \\mathbb{F} \\Longrightarrow \\alpha \\vec v \\in \\mathbb{U}$ Examples on slide 13 Intuitively, a subspace is a closed subset of all the vectors in .$ \\mathbb{V}$. Any linear combination of vectors in the subspace must also lie in that subspace. Just as basis and dimension are defined for vector spaces, they have equivalent definitions for subspaces. Basis for a Subspace: set of linearly independent vectors that span the subspace (minimal set of subspace-spanning vectors) Subspace Dimension: number of vectors in subspace-basis Basis # Basis: Given a vector space .$\\mathbb{V}$, a set of vectors .$\\{\\vec v_1, \\dots \\vec v_n\\}$ is a basis of the vector space if it satisfies the following properties: .$\\vec v_1, \\dots, \\vec v_n$ are linearly independent vectors .$\\text{span}(\\{\\vec v_1, \\dots, \\vec v_n\\}) = \\mathbb{V} \\Longrightarrow \\forall \\vec v \\in \\mathbb{V}, \\exists \\alpha_1, \\dots, \\alpha_{n-1} \\in \\mathbb{R}$ such that .$\\vec v_1 = \\alpha_1 \\vec v_2 + \\dots \\alpha_{n-1} \\vec v_n$ Minimum set of vectors that spans a vector space\nA basis of a vector space is the minimum set of vectors needed to represent all vectors in the vector space. If a set of vectors is linearly dependent and “spans” the vector space, it is still not a basis \u0026ndash; we can remove at least one vector from the set and the resulting set will still span the vector space Basis is not unique # Intuitively, think about multiplying one of the vectors in a given basis by a nonzero scalar will not affect the linear independence or span of the vectors. We could alternatively construct another basis by replacing one of the vectors with the sum of itself and any other vector in the set. Mathematically, suppose that .$\\{\\vec v_1, \\dots, \\vec v_n \\}$ is a basis for the vector space we are considering. Thus .$\\{\\alpha \\vec v_1, \\dots, \\vec v_n \\}$ where .$\\alpha \\neq 0$ is also a basis because, just as we’ve seen in Gaussian elimination row operations, multiplying a row by a nonzero constant does not change the linear independence or dependence of the rows. We can generalize this to say that multiplying a vector by a nonzero scalar also does not change the linear independence of the set of vectors. In addition, we know that .$\\text{span}(\\{ \\vec v_1, \\dots, \\vec v_n \\}) = \\text{span}( \\{\\alpha \\vec v_1, \\dots, \\vec v_n \\} )$ Any vector in .$\\text{span}(\\{ \\vec v_1, \\dots, \\vec v_n \\})$ can be created as a linear combination of the set .$\\text{span}(\\{ \\alpha \\vec v_1, \\dots, \\vec v_n \\})$ by dividing the scale factor on .$\\vec v_1$ by .$\\alpha$. We can use a similar argument to show that .$\\{\\alpha \\vec v_1, \\dots, \\vec v_n \\}$ is also a basis for the same vector space. To generalize, for .$\\mathbb{R}^{N}$, any .$N$ (and only .$N$) linearly independent vectors form a basis\nDimension # Dimension: The dimension of a vector space is the number of basis vectors. Since each basis vector can be scaled by one coefficient, the dimension of a space as the fewest number of parameters needed to describe an element or member of that space. The dimension can also be thought of as the degrees of freedom of your space \u0026ndash; that is, the number of parameters that can be varied when describing a member of that space. A vector space can have many bases, but each basis must have the same number of vectors:\nSuppose a basis for the vector space we’re considering has .$n$ vectors. This means that the minimum number of vectors we can use to represent all vectors in the vector space is .$n$, because the vectors in the basis would not be linearly independent if the vector space could be represented with fewer vectors. Then we can show that any set with less than .$n$ vectors cannot be a basis because it does not have enough vectors to span the vector space \u0026ndash; there would be some vectors in the vector space that cannot be expressed as a linear combination of the vectors in the set. In addition, we can show that any set with more than .$n$ vectors must be linearly dependent and therefore cannot be a basis. Combining the two arguments, we have that any other set of vectors that forms a basis for the vector space must have exactly .$n$ vectors! Column Space # The range/span/column space of matrix .$A \\in \\mathbb{R}^{m \\times n}$ \u0026ndash; which we can represent as a set of vectors .$\\{ \\vec a_1, \\dots \\vec a_n \\}$ \u0026ndash; is a set of all possible linear combinations: $$\\text{span}\\big(\\{\\vec a_1, \\dots, \\vec a_n\\}\\big) = \\Bigg\\{\\sum_{i=1}^N \\alpha_i \\vec a_i\\ |\\ \\alpha_1, \\dots, \\alpha_n \\in \\mathbb{R} \\Bigg\\} = \\big\\{A \\vec x =\\ \\vec x \\in \\mathbb{R}^{n}\\big\\}$$ That is, the column space of a matrix .$A \\in \\mathbb{R}^{m \\times n}$ is the span of the .$n$ columns in .$A$ It\u0026rsquo;s the space of all outputs that the operator can map to. Thinking about .$A$ as a linear transformation from .$ \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$, the column space is effectively the set of all outputs that this matrix can transform input vectors to Note that in the general case, input vectors and output vectors can be different lengths The column space describes all possible output vectors .$\\vec b = \\mathbb{R}^{m \\times 1}$ It can be shown that .$\\text{span}(A)$ forms a subspace of .$ \\mathbb{R}^{m}$ Note that .$\\text{span}(A)$ is not necessarily .$ \\mathbb{R}^{m}$ Row Space # Similarly, the row space is the span of the .$n$ rows Rank # The rank of .$A$ is defined as the dimension of the column space of .$A \\in \\mathbb{R}^{m \\times n}$ .$\\text{rank}(A) = \\text{dim(span(A))}$ .$\\text{dim(span}(A\\text{)) ≡ dim(col(}A))$ It’s all too easy to confuse an actual space consisting of vectors, like a matrix range describing the output (column) space, with the dimension of that space, which is just a single scalar number. Keep them straight! .$ \\text{rank}(A) = \\text{dim(span}(A)) \\leq \\text{min}(m, n)$ This is at most .$m$, but certainly can be less, since an arbitrary .$A \\in \\mathbb{R}^{m \\times n}$ is not guaranteed to have columns whose span is all of .$ \\mathbb{R}^{m}$ Consider the simple counterexample of the zero matrix .$\\vec 0 \\in \\mathbb{R}^{m \\times n}$, which maps all .$n$-dimensional input vectors to the .$m$-dimensional all-zero vector. In general, using the column-wise representation of matrix-vector multiplication we can show that .$\\text{rank(}A)$ is the number of linearly independent columns in .$A$. Any output vector can be represented as a linear combination of the columns of .$A$. But some of these columns might themselves be linear combinations of other columns, which means we can replace any redundant column with a weighted sum of the other columns. By removing all redundancies, we find that a matrix with .$k \\leq \\text{min}(n, m)$ linearly independent column vectors can \u0026ldquo;unlock\u0026rdquo; exactly .$k$ dimensions in the output. Thus, we find that .$\\text{rank}(A)$ also equals the number of pivots in the RREF of .$A$. Since each pivot must belong to a row and a column, the number of pivots in .$A \\in \\mathbb{R}^{m \\times n}$ is limited by the smaller dimension. For a tall matrix .$m \u0026gt; n$, the columns are the limiting dimension; for a wide matrix .$n \u0026gt; m$ the rows are. Null Space # The null-space of .$ \\mathbb{R}^{m \\times n}$ is the set of all vectors .$\\vec x \\in \\mathbb{R}^{m}$ such that .$A\\vec x = 0$ $$\\text{null}(A) = \\big\\{\\vec x\\ |\\ A \\vec x = \\vec 0, \\vec x \\in \\mathbb{R}^{m}\\big\\}$$ That is, the set of all inputs that get mapped to .$\\vec 0$ by .$A$ $\\text{dim(null}(A))$ can be interpreted as the number of input directions for which the output is \u0026ldquo;compressed\u0026rdquo; down to zero. We know that it can be at most .$m$, since all of the input vectors have .$m$ components. It\u0026rsquo;s the set of vectors not in columns space, that is, the number of linearly dependent columns: $$m - \\text{dim(span}(A)) = \\text{dim(null}(A))$$ The loss of dimensionality from the input space to the output space shows up in the nullspace. .$\\vec 0$ is always in the null space — trivial Null space This wouldn\u0026rsquo;t hold if we had affine (instead of linear) functions Null space DNE when the determinant is not zero \u0026ndash; see last week Procedure to Compute a Null-Space # Computing the nullspace of .$A$ requires us to solve .$A \\vec x = \\vec 0$ \u0026ndash; the procedure is as follows: Put .$A$ in RREF. Initialize the set .$\\mathbb{S} = \\{ \\vec 0 \\}$. Check each column for leading entries and find the number of .$F$ree and .$B$asic variables. if .$F = 0$, stop and skip to the last step. if .$F \\neq 0$, repeat the following for each free variable: Set that free variable to .$1$, and all others to zero. Solve .$A \\vec x$ under these conditions; add the solution vector to .$\\mathbb{S}$. Conclude that .$\\text{null}(A) = \\text{span}(\\mathbb{S})$. Example is given on page 37-38 Rank-Nullity Theorem # How is the number of free variables related to the total number of columns in a matrix .$A \\in \\mathbb{R}^{m \\times n}$? Well, each column of a matrix either contributes a \u0026ldquo;new direction\u0026rdquo; to the output or it is redundant with other columns and their already-discovered directions. In other words, each of .$n$ columns adds a dimension to .$\\text{span}(A)$ or to .$\\text{null}(A)$. Therefore, the following holds: $$\\text{dim(span}(A)) + \\text{dim(null}(A)) = n$$ $$\\text{rank}(A) + \\text{dim(null}(A)) = n$$\n02-17: Eigenvectors, values # Eigenvectors and Eigenvalues # Consider a square matrix .$ A \\in \\mathbb{R}^{n \\times n}$. An eigenvector of .$A$ is a nonzero vector .$\\vec x \\in \\mathbb{R}^{n}$ such that $$A \\vec x = \\lambda \\vec x$$ where .$\\lambda$ is a scalar value, called the eigenvalue of .$\\vec x$.\nThat is, an eigenvector represents a sort of stability point: vectors aligned with an eigenvector will not change direction under a linear transformation .$A$ Rather, they will simply be scaled by some factor. Note that eigenvectors are a property of the matrix itself and do not depend on the specific vector being transformed (input) The eigenvalue describes this stretching or compressing factor for vectors aligned with an eigenvector This means any vector that’s \u0026lsquo;some\u0026rsquo; multiple of the eigenvector, when it’s transformed by .$A$, will become a scaled version of itself that\u0026rsquo;s a \u0026lsquo;some\u0026rsquo; multiple of the eigenvalue Example on page 45 Geometrically, an eigenvector, corresponding to a real nonzero eigenvalue, points in a direction in which it is stretched by the transformation and the eigenvalue is the factor by which it is stretched Because these two terms are so commonly used in conjunction, we often refer to an eigen(value/vector) pair Note that scaling a given eigenvector for an eigenvalue will still produce a valid eigenvector, since the vector’s direction will not be changed Given non-invertible .$A \\in \\mathbb{R}^{n \\times n}$ there are at least .$1$ and at most .$n$ eigenvalues Given non-invertibility, some .$\\lambda_i = 0$, so we have at least 1 eigenvalue. Indeed, all eigenvalues can be .$0$ (such as for .$\\vec 0$)! However, non-invertibility does not place any other restrictions on our set of eigenvalues, so all other .$n-1$ eigenvalues can be distinct from this .$\\lambda_i$ Properties to know A matrix is uninvertible iff .$0$ is an eigenvalue (because there exists a vector .$\\vec v$ such that .$A \\vec v = \\vec 0$. A scalar times an eigenvector is still an eigenvector: .$(A(c \\vec v) = c A \\vec v = c \\vec v = (c \\vec v))$ Eigenvectors with distinct eigenvalues are linearly independent (eigenvectors in the same span have the same eigenvalue) .$A^{-1} \\vec v = \\lambda^{-1} \\vec v$ .$A \\vec v = \\lambda \\vec v \\Longrightarrow A^{-1} A \\vec v = A^{-1} \\lambda \\vec v \\Longrightarrow \\vec v = \\lambda A^{-1} \\vec v \\Longrightarrow \\lambda^{-1} \\vec v = A^{-1} \\vec v$ Determinants # The determinant is a quantity we can define for any square matrix The determinant is nonzero if and only if the matrix is invertible and the linear map represented by the matrix is an isomorphism For a .$2 \\times 2$ matrix, the formula is: - The absolute value of .$ad − bc$ is the area of the parallelogram, and thus represents the scale factor by which areas are transformed by .$A$. $$\\text{det}\\Bigg( \\begin{bmatrix} a \u0026 b \\\\\\ c \u0026 d \\\\\\ \\end{bmatrix}\\Bigg) = ad - bc$$ If linearly dependent, some vectors will lie on top of each other so the area will be zero Similarly in 3D, if any column vectors are multiples of each other, we \u0026ldquo;squash\u0026rdquo; a volume into a plane or a line. That is, determinant of any square matrix is zero if the columns are linearly dependent. For a .$3 \\times 3$ matrix, the shape is a parallelipiped, and we form hyper-volumes in higher dimensions. We can calculate determinants for higher dimension matrices as well, as described here The determinant of the transpose of .$A$ equals the determinant of .$A$: .$\\text{det}(A) = \\text{det}(A^\\text{T})$ \u0026lsquo;Proving\u0026rsquo; this geometrically on a whiteboard is fun, try out the .$2 \\times 2$ case Therefore, if .$A^\\text{T}$ has an eigenvalue .$\\lambda$, then .$A$ also has the eigenvalue .$\\lambda$ because .$\\text{det}(A - \\lambda I) = \\text{det}(A^\\text{T} - \\lambda I)$ This implies that in all the properties mentioned above, the word \u0026ldquo;column\u0026rdquo; can be replaced by \u0026ldquo;row\u0026rdquo; throughout For example, viewing an .$n \\times n$ matrix as being composed of .$n$ rows, the determinant is an .$n$-linear function. See this article which relies on the idea of elementary matrices (not covered) or this more advanced, out-of-scope stackoverflow post that deals with 16B-level topics (and beyond) Computing Eigenvalues and Eigenvectors # Solving this equation for nonzero (nontrivial) solutions .$\\vec x$ will yield our eigenvectors: $$A \\vec x = \\lambda \\vec x \\label{a}\\tag{1}$$ $$\\Longrightarrow (A - \\lambda I_n) \\vec x = \\vec 0_n$$ $$\\Longrightarrow A' \\vec x = \\vec 0_n$$ Note that .$A$ and .$I_n$ are fixed and only 1 parameter here that can vary in this equation: .$\\lambda$ - We want to find values of .$\\lambda$ such that .$A' = (A − \\lambda I_n)$ has linearly dependent columns - That is, we want to find values of .$\\lambda$ that cause the **determinant** of .$A'$ to become zero - Linear dependence of the columns creates a nontrivial null-space for .$A'$ - .$N$th order characteristic polynomial with .$N$ solutions - Work-through on [page 6](https://eecs16a.org/lecture/Note9.pdf#page=6) $$A' = \\begin{bmatrix} a_{11} - \\lambda \u0026 a_{12} \u0026 ... \u0026 a_{1n}\\\\\\ a_{21} \u0026 a_{22} - \\lambda \u0026 ... \u0026 \\vdots \\\\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots\\\\\\ a_{n1} \u0026 \\dots \u0026 ... \u0026 a_{nn} - \\lambda \\end{bmatrix}$$ For the .$2 \\times 2$ case determinant is $$\\lambda^2 - (a+d)\\lambda + (ad - bc) = 0$$ Solving this quadratic equation, we can find the .$\\lambda$ values. Then, for each .$\\lambda_i$ we find, we revisit .$\\eqref{a}$ and solve for the corresponding .$\\vec x_i$ The polynomial on the left hand side of the above equation is known as the characteristic polynomial for the matrix .$A$. If a matrix has repeated eigenvalues, they may (or may not) have distinct eigenvectors. In general, multiplicity of eigenvalues will result in the same multidimensional eigenspace (Aside) \u0026hellip;except if the matrix is defective An .$n \\times n$ matrix is defective iff it does not have .$n$ linearly independent eigenvectors That is, a defective matrix always has fewer than .$n$ distinct eigenvalues, since distinct eigenvalues always have linearly independent eigenvectors In which case the rank is decreased Eigenspace # If the eigenvectors are distinct, they form an eigenspace $$E_\\lambda = \\text{null}(A - \\lambda I_n) = \\text{null}(A\u0026rsquo;)$$\nThat is, null space of some matrix is the set of all vectors that satisfy .$\\eqref{a}$ OR all of the eigenvectors that correspond to some eigenvalue OR the eigenspace that corresponds to the eigenvalue Exactly like the concept of span; the eigenspace is a subspace, the span of all eigenvectors for that eigenvalue (including .$\\vec 0$) Any input vectors that lie in this space (for 2 distinct eigenvectors, a plane; for 1, a line) will be scaled by the shared eigenvalue under a linear transformation. Eigenspace is a subspace, which means it\u0026rsquo;s closed under scalar multiplication Thus, if two vectors are related by a scalar, they must both lie in the same eigenspace of .$\\lambda_i$: .$E_{\\lambda_i}$ That is, the eigenvectors that make up some eigenspace aren\u0026rsquo;t unique But, every eigenvector can only correspond to one eigenvalue If for some .$A$, where .$A \\vec x_1 = \\lambda_1 \\vec x_1$ and .$A \\vec x_1 = \\lambda_2 \\vec x_1$ then .$\\lambda_1 = \\lambda_2$ Thinking about a physical diagram may help clarify; .$\\lambda_1 \\neq \\lambda_2$ would require some single initial state or vector aligned with .$\\vec x_1$ to be scaled by two different values upon being transformed by .$A$ This cannot happen, so the two eigenvalues cannot be distinct Aside: Complex eigenvalues can exist as well; they are much harder to visually understand, but mathematically, we find them using the exact same process as before. Mean-product formula # Mean-product formula is a nicer way of solving this, versus finding the roots of the polynomial $$m \\pm \\sqrt{m^2 - p}$$ $m$ is the mean of the trace, which is the same as the mean of the eigenvalues $p$ is the product of the eigenvalues, which is the determinant Theorems # Theorem 9.1 # Given two eigenvectors .$\\vec v_1$ and .$\\vec v_2$ corresponding to two different eigenvalues .$\\lambda_1$ and .$\\lambda_2$ of a matrix .$A$, it is always the case that .$\\vec v_1$ and .$\\vec v_2$ are linearly independent.\nProof on page 9 Theorem 9.2 # Let .$\\vec v_1,\\vec v_2, \\dots , \\vec v_m$ be eigenvectors of an .$n \\times n$ matrix with distinct eigenvalues. It is the case that all the .$\\vec v_i$ are linearly independent from one another.\nProof on page 10 Proposition 1 # If an square .$n \\times n$ matrix .$A$ isn\u0026rsquo;t invertible, then it has some eigenvalue .$\\lambda_i = 0$\nIf a matrix is not invertible, then the dimension of its null space isn\u0026rsquo;t necessarily greater than 0 because there must be a linearly dependent row or column. If this is true, then there\u0026rsquo;s a non-zero vector .$\\vec x$ such that .$A \\vec x = 0 \\vec x$ If the matrix is not invertible, it has a nontrivial null-space. Then, by definition, there is some nonzero .$\\vec x$ for which .$A \\vec x = 0 \\vec x = \\vec 0_n$. We pattern match to .$\\eqref{a}$ and notice the equation is exactly the same if we multiply the right by .$\\vec x: A \\vec x = 0 \\vec x$. This is kind of like pulling a scalar .$0$ out of .$\\vec 0$, leaving .$0 \\vec x$. Now, we clearly see .$\\lambda = 0$ Proposition 2 # For an invertible .$A$ with some eigenvalue .$\\lambda$, .$A^{−1}$ has eigenvalue .$ \\frac{1}{\\lambda}$\nWe can start at .$\\eqref{a}$: left-multiply both sides by .$A^{−1}$ to get .$\\vec v = A^{-1} \\lambda \\vec v \\Longrightarrow A^{-1} \\vec v = \\frac{1}{\\lambda} \\vec v$. Pattern match to .$\\eqref{a}$ again and we’ve shown the statement is true Note: Given invertibility, all .$\\lambda_i \\neq 0$ so this is always true States # Steady States # We know that a steady state .$\\vec x^*$ of a transformation matrix .$A$ is defined to be such $$A \\vec x^* = \\vec x^* $$ In other words, it is an element of the eigenspace of .$A$ corresponding to the eigenvalue .$\\lambda = 1$. The above equation tells us that if we start at a steady state, then we will remain unaffected by the transformation matrix over time. Therefore, to solve for the steady-state of a system represented by .$P$, we solve .$\\eqref{a}$, substituting .$\\lambda = 1$ Note that this amounts to solving for the null-space of .$(P − I_n)$. Great walk-through on page 53 Predicting Behavior for General Initial States # Given a system and an initial state, can we predict how it’ll dynamically change over time? We saw in the Page Rank example that we seem to approach a sort of steady-state after many timesteps, but under what conditions does this happen?\nSimpler Case: .$\\vec x (0) = \\alpha \\vec v$ # - Suppose our initial state is actually a perfect multiple of an eigenvector of the system. - Over time, upon repeated applications of .$A,$ we accumulate factors of .$\\lambda$; ultimately, .$A^n \\vec x = \\alpha (\\lambda^n \\vec x)$ -- as we can see derived to the right $$\\vec x (0) = \\alpha \\vec v$$ $$\\vec x (1) = A\\vec x (0) = \\alpha \\lambda \\vec v$$ $$\\vec x (2) = A\\vec x (1) = \\alpha \\lambda^2 \\vec v$$ $$\\vdots$$ $$\\vec x (n) = A\\vec x (n-1) = \\alpha \\lambda^n \\vec v$$ Based on this pattern, we notice the following behaviors based on the value .$\\lambda$ as .$n \\to \\infty$: .$\\lambda \u0026gt; 1: \\vec x (n) \\to \\infty$ \u0026ndash; Diverge, exponential growth. .$\\lambda = 1: \\vec x (n) \\to k\\vec v$ \u0026ndash; Converge, steady-state. .$0 \u0026lt; \\lambda \u0026lt; 1: \\vec x (n) \\to \\vec 0$ \u0026ndash; Converge, exponential decay. .$\\lambda = 0: \\vec x (n) = 0 \\vec v = \\vec 0$ \u0026ndash; Converge(?), instantaneous disappearance. .$\\lambda \u0026lt; 0$: Take .$|\\lambda|$ and refer to the appropriate case above. But recognize the sign switches at each timestep General Case: .$x(0) = \\alpha_1 \\vec v_1 + \\alpha_2 \\vec v_2 + . . . + \\alpha_n \\vec v_n$ # This form says that the initial state is now not a scalar multiple of just one eigenvectors, it’s a linear combination of all of them Note that this is still not fully general; we assume here that all initial states are in the span of the eigenvectors of .$A$, which isn’t guaranteed. But this case devolves into the previous one; we can simply treat each element individually, apply the techniques from the Simpler Case, and put them back together. The final form is as follows: $$\\vec x (n) = \\alpha_1 (\\lambda_1^n \\vec v_1) + \\alpha_2 (\\lambda_2^n \\vec v_2) + . . . + \\alpha_n (\\lambda_n^n \\vec v_n) \\label{b}\\tag{2}$$ Given a matrix .$A$ and some initial state .$\\vec x$, how can we actually get to this equation format? - First, we solve for the .$(\\vec v_i, \\lambda_i)$ pairs of .$A$ - Then, we use Gaussian elimination to find the .$\\alpha_i$’s; Putting eq. .$ \\eqref{b}$ in matrix form yields:\n- ...and we compute the inverse of the matrix of eigenvectors, arriving at: $$\\vec x(0) = \\begin{bmatrix} | \u0026 | \u0026 \u0026 | \\\\\\ \\vec v_1 \u0026 \\vec v_2 \u0026 \\dots \u0026 \\vec v_n\\\\\\ | \u0026 | \u0026 \u0026 | \\\\\\ \\end{bmatrix}\\begin{bmatrix} \\alpha_1 \\\\\\ \\alpha_2 \\\\\\ \\vdots \\\\\\ \\alpha_n \\\\\\ \\end{bmatrix}$$ $$\\begin{bmatrix} \\alpha_1 \\\\\\ \\alpha_2 \\\\\\ \\vdots \\\\\\ \\alpha_n \\\\\\ \\end{bmatrix} = \\begin{bmatrix} | \u0026 | \u0026 \u0026 | \\\\\\ \\vec v_1 \u0026 \\vec v_2 \u0026 \\dots \u0026 \\vec v_n\\\\\\ | \u0026 | \u0026 \u0026 | \\\\\\ \\end{bmatrix}^{-1} \\vec x (0)$$ Let’s assume that we drop any terms corresponding to .$\\alpha_i = 0$ since those terms are, well, zero. Then, with what remains, we can make some intuitive observations: .$|\\lambda_i | \u0026gt; 1: \\vec x (n) \\to \\infty$ \u0026ndash; Diverge, even if other components in the linear combination decay, the state itself \u0026ldquo;blows up\u0026rdquo; to .$\\infty$ as this component overshadows all others. .$|\\lambda_i| = −1: \\vec x (n) \\to\\ ?$ \u0026ndash; Diverge because that component oscillates forever. .$−1 \u0026lt; \\lambda_i \\leq 1: \\vec x (n) \\to \\vec x^*$ \u0026ndash; Converge, that is, steady-state! Each .$i$th term either decays to zero (.$|\\lambda_i| \\leq 1$) or stays the same (.$|\\lambda_i| = 1$), such that .$\\vec x^* = \\sum_{i,\\lambda_i=1} \\alpha_i \\vec v_i$. We can normalize this steady-state if we want proportions (column values sum to 1) rather than absolute numbers Some Useful Information # If a matrix has .$n$ distinct real eigenvalues, their .$n$ associated eigenvectors are all linearly independent. An eigenspace for a given eigenvalue is the span of all eigenvectors, including .$\\vec 0$, and is also a subspace by definition. Say we calculate an eigenvector for an eigenvalue; we can pick any scalar multiple of the result and this will still be an eigenvector, since scaling a vector does not change its direction. This follows from the scalar multiplication property of subspaces. A given eigenvector can only be associated with one eigenvalue, since a vector can only be scaled by some single value upon being transformed by a matrix. But, a eigenvalue can be associated with multiple eigenvectors, the span of which form an eigenspace. If a matrix has some .$\\lambda = 0$, then for some .$\\vec x, A\\vec x = \\lambda\\vec x =\\vec 0$, so .$A$ has a nontrivial null-space. Therefore, it is not invertible. If a matrix has some .$\\lambda = 1$, then any initial state that is aligned with the corresponding eigenvector is a steady-state. More generally, any initial state for which .$\\lambda = 1$ comprises part of the linear combination potentially has a nonzero steady-state, so long as all other .$|\\lambda_i| \u0026lt; 1$. - The rotation matrix (that rotates any vector by .$\\theta$ degrees counterclockwise) is: $$A(\\theta) = A_R = \\begin{bmatrix} \\cos\\theta \u0026 -\\sin\\theta \\\\\\ \\sin\\theta \u0026 \\cos\\theta \\\\\\ \\end{bmatrix}$$ "},{"id":22,"href":"/e-29/5/","title":"5-6: Forming Processes","section":"Engineering 29","content":" # Before \u003e So far in the class, we have seen a wide range of additive and subtractive processes which are capable of creating components in metals, alloys, polymeric materials, ceramics, and composites. The one thing that these processes all have in common is that they are serial — meaning that one feature is produced after another in a predefined sequence. This serial nature inherently limits productivity and may require considerable operator skill. High operator skill, which leads to high overhead costs, is especially needed when a tool such as a lathe is manually operated, but may be needed even if the tool is computer numerically controlled, because work still has to be properly mounted and the machine correctly aligned to it. Subtractive processes have been used for centuries, both in the mass-production of precision components, and in one-off custom and prototyping jobs. Additive manufacturing has until recently been seen as a purely prototyping tool, although increasingly is being adopted for short-to-medium production runs. \u003e Casting, and injection molding, on the other hand, form all features in a component almost simultaneously by forcing molten material into a mold, and potentially offer a faster, more affordable route to mass production. Injection molding is suitable only for mass production because of the high expense of the molds needed, and production runs of \u003e10,000 are usually needed for economic operation. Casting comes in many flavors, from high pressure die-casting — which is really the equivalent of injection molding for processing metals — to gravity-driven sand-casting, which is used both for long production runs and for one-off fabrication jobs because of its ability to create very large components (\u003e 1 m in some cases) with reasonable simplicity. The higher throughput of casting comes at the expense of lower achievable tolerances than machining (considerable fractions of a millimeter, as opposed to tolerances of a few micrometers). Forming processes such as casting are thus often followed by subtractive secondary processing to bring key features within tolerance. In this module we will highlight some of the attributes of casting and injection molding. Forming of Polymers (Molding Processes) # Injection molding # An injection molding machine consists of a mechanism to melt and extrude the polymer, and a molding unit. Injection molding is the workhorse of plastics manufacturing and can achieve cycle times of under a minute. Most plastics that are injection molded are thermoplastics, meaning that they can be reversibly changed between solid and fluid states by heating and cooling. Injection molding, however, can also be used to inject materials that covalently crosslink when heated (thermosetting plastics), making components that are more heat-resistant than thermoplastics. Injection molding has even been adapted to mold metal powders which are then sintered inside the mold (powder injection molding).\nPolymer Melting # In conventional injection molding, the material to be molded enters the machine as solid pellets, which are drawn into a rotating, heated screw whose diameter decreases along its length to compress the material, drive out air voids, and turn it into a continuous molten flow. This flow is then extruded from a nozzle into a clamped mold, which is typically machined from tool steel but may contain inserts of other materials for specific applications.\nVery thick material (viscosity) isn\u0026rsquo;t an issue due to large pressures used (Pressures typ. \u0026gt; 100 MPa) Pellets go into hopper where they\u0026rsquo;re carried along and melted The inside diameter of the screw gets larger so the pellets get compressed as they\u0026rsquo;re pushed along the screw until all air is driven out and it\u0026rsquo;s a constant stream Wire mesh ensures only \u0026rsquo;liquid\u0026rsquo; passes (removes any debris/dust/funky filament) Machinery # The core is the part that is inserted into the mold (surrounding case) These two components constrain geometry Must have a very tight fit due to very high pressures (hydrolics is commonly used) Process Stages # Heat up and screw the molten plastic to the tip of the core Plunge the core into the mold and inject the molten material Hold for a few seconds to let the material to solidify Retract the core and bring back the mold to release the new piece Cycle times approx. 10 s to 1 minute The mold is held at a temperature that is high enough to allow the polymer to fill the mold before solidifying, but cool enough that cycle time is not excessively long. The molded material needs to fall to below its glass transition temperature, below which the material becomes rigid, before it is ejected from the mold. Ejection is usually automated, with mechanical ejector pins emerging from the mold to push the molded component into a collection bin.\nFeatures # Connectors are placed as to minimize material used and heat; fractals can be used to optimize these patterns\nHot Runners # Overmolding and insert molding # - Multiple polymers - Rigid and rubbery - Can make hinges between rubber and rigid material - Enables tooth brush bristles to be held in - You need a precise temperature in the range of the material so it deforms enough to bind with another surface while not permanently deforming - Different colors - Encase metallic objects -- object is molded around for.. - Rigidity - Strength - Abrasion resistance - Way to circumvent having to 3D printed threads Physical limitations on geometry # As soon as coming in contact with surface, the polymer looses heat Thus, penetration depth is limited by how quickly the polymer \u0026lsquo;freezes\u0026rsquo; You can increase pressure and temperature (thus viscosity) to circumvent this \u0026ndash; but there are of course tradeoffs (longer heat up time, \u0026lsquo;maximum heat\u0026rsquo; material can withstand) For very tiny surface the surface geometry starts to matter too (e.x. income-angle may matter, as does mold material and how it interacts with the polymer) Defects # Flash \u0026ndash; extra material squeezed out around edges, typically not a big deal Flow lines \u0026ndash; may matter for certain applications Short shot \u0026ndash; not enough material injected Typically because extruder doesn\u0026rsquo;t output enough or because mold is pulled away too soon Misrun \u0026ndash; material doesn\u0026rsquo;t make it to end of material Warping \u0026ndash; uneven section thickness, causing non-constant heat density and thus warping The more rigid geometry, the more differential thermal contraction can happen before warping occurs Why ribs are used commonly used \u0026ndash; small regions of strips of material is, from a structural POV, better than evenly distributing it across the surface Trapped air \u0026ndash; solved by adding very tiny venting channels for air to escape Can fail if clogged with tiny debris, causing flash Silver streak \u0026ndash; polymer flowing over surface and solidifying too early Sink marks \u0026ndash; mass below surface pulls downwards, resulting in tiny dip Caused by ribs (supports) in particular! Visible in polished surfaces \u0026ndash; thus you can avoid it by giving the surface a finish Design of Molds # - Cost of molds drives economic batch size - ≳ 10,000 parts - Design considerations - Draft angle: typically 1 − 2° - Air vents - Advanced features - Multi-core molds - Active water cooling - Materials with very high thermal conductivity e.g. Cu-Be alloys \u003e For large moldings where achieving rapid enough cooling of the component is a challenge, high-thermal-conductivity materials such as copper–beryllium alloys may be used for part of the mold. - Material shrinkage needs to be compensated for in the sizing of the mold - Examples of typical linear contractions between solidification and room temperature: | Material | Approx. linear shrinkage (%) | | -------- | ---------------------------------------------------------------- | | ABS | 0.6 | | Nylon | 2.0 -- [crystaline](https://en.wikipedia.org/wiki/Crystallinity) | | PC | 0.7 -- [amorphic](https://en.wikipedia.org/wiki/Amorphism) | | PE | 2.5 | | PS | 0.4 | | PVC | 0.5 | \u003e Watercooling system around mold \u003e Surface texturing methods # - Polishing - Sanding - Grinding - Blasting -- for more complex geometry - Sand or glass beads - EDM - Chemical etching - Ferric chloride, nitric acid ![](/docs/e-29/5/text1.png) ![](/docs/e-29/5/text2.png) Nanoscale Features # Nanopatterned hard mold coatings such as chromium nitride have recently been introduced to enable injection molding of nanostructures giving butterfly winglike structural color \u0026ndash; structural color\nOther Polymer Forming Processes # Reaction Injection Molding # For if you aren\u0026rsquo;t making many copies (so creating a mold isn\u0026rsquo;t worth while) Materials are reactive when they come in contact \u0026ndash; think of epoxy Enables thermosets, not just thermoplastics, to be molded Compression Molding # A lower-throughput but simpler and more affordable polymer molding technique is compression molding, in which a charge of the material to be formed is placed directly into the mold, and the mold halves are then brought together. The simplicity of the technique lends it to modest-sized production runs, and it is particularly suitable for thermosetting polymers, which crosslink when heated and can be removed from the mold at the molding temperature, because they do not need to be brought below a glass transition to acquire rigidity\nMuch simpler apparatus; tens of MPa (rather than hundreds) Relies on a thermosetting material to solidify part Flash is common Extrusion # - Wide range of length-scales possible - FDM printing (~0.1 mm) - Large pipes and construction sections (\u003e 1 m possible) - \"Keeping mass as far away from center is a good way to optimize usage\" - Before leaving die, materials which are extruded outwards slightly because the high pressures cause the extrusion to shrink down - Hollow sections possible with specially designed mandrels - E.x aluminum alloys (80-20), PVC are common extrusion materials ![](/docs/e-29/5/ext-ex.png) Blow Molding # Blow molding is very widely used to produce components with thin side walls, such as plastic bottles. An extruded tube of softened thermoplastic polymer is clamped between two halves of a mold and air pressure inside the tube is increased. This expands the material until it conforms to the mold, stretching the material and making it thinner as it does so.\nBetter than injection molding for very thin walls Extrusion followed by inflation Or, can use injection molded preform (e.x. plastic bottle threading) Forming of metals and alloys (Casting processes) # Reasons to use casting # You have an established component design which needs to be mass-produced: casting can create many parts in less time than machining or additive manufacturing. Geometric versatility: with appropriate mold design, sophisticated re-entrant geometries can be produced in about the same time as a simple geometry. Processing time does not increase strongly with geometric complexity, as it does in machining. The need to process high-melting-point (“refractory”) alloys: melting point is correlated with hardness, making machining increasingly difficult as melting temperature increases. A highprecision casting technique such as investment casting can be a good option for achieving demanding tolerances with refractory alloys. A desire to minimize material wastage: in casting, very little material is used beyond that required for the actual component, and any surplus (e.g. for risers and runners, as discussed below) can be re-melted and re-used. In contrast, in subtractive manufacturing much of the stock may be machined away as chips which are laborious and may be somewhat energy-intensive to recycle. Variables in casting Material insertion: gravity- or pressure-driven? Mold material: expendable or permanent? Pattern material: expendable or permanent? Sand Casting # Gravity-fed Heat loss and shrinkage is a concern, so extra risers are included (which also serve as vents) Manual process that creates large objects Few-hundred runs a year, takes a few hours per run If the mold halves do not mate perfectly, molten metal may travel along their interface, leading to flash, which is usually thin enough to be easily broken off or abraded/machined away In sand casting, a single-use mold is produced by compacting a sand mixture around a pattern, which has the same shape as the final required component. The pattern might be made by machining timber or metal, or by additive manufacturing. The mold is prepared in two halves, the cope (top) and drag (bottom), with the sand being contained within a metal flask that has two interlocking parts. The pattern is removed from the compacted sand mixture before the mold is closed up. If re-entrant or hollow components are to be cast, one or more cores are introduced into the mold before the cope and drag are brought together. These cores are also single-use and may be made from sand that is bound with organic material such as gelatin. The mold needs to have several features in addition to the cavity that will contain the actual cast component. First we need a downsprue, or sprue, into which the molten metal can be poured. Second we need runners which are horizontal channels that carry the molten metal from the sprue to the mold cavity. Thirdly we need one or more risers, which allow air to escape from the mold as the metal enters, and are also designed to be the last part of the metal to solidify. Risers can thus provide a small amount of surplus material to compensate for the volume shrinkage that occurs when the metal solidifies. Risers need to be strategically positioned around the mold cavity to supply this material where it is needed. The design of sprues, runners and risers requires skill and experience, and is one of the key competitive advantages of successful foundries. Photos Materials # Sand, or silica, is used as a mold material because of its high melting point (~1600 ˚C) relative to that of the material being cast (e.g. 660 ˚C for aluminum). Sand on its own, however, will not hold the shape of the mold. Green sand is a sand, clay, and water mixture which holds together via the capillary forces between particles and by particle jamming between the larger sand particles and the much smaller clay particles. Green sand has the advantage that it can simply be shaken off the cast component after solidification, and recycled many times.\nIf a mold cavity has particularly large unsupported regions, a stronger mold material may be needed. In this case the clay and water may be replaced by a stronger binder, which may thermally or chemically cure to make a solid mold material. Such molds are more robust but are not reusable.\nAn alternative approach is to use loose sand and compact it under vacuum between plastic sheets to make it solid. The plastic is vaporized as soon as the molten metal hits it.\nOptions for sand-based molds: Green sand Typically SiO2, particles a ≥ 10µm in diameter Mixed with 7-10% clay (e.g. kaolinite, 2SiO2.Al2O3.2H2O). Typically \u0026lt; 2 µm diameter Bound with 2-4% water Clay particles promote mechanical jamming of sand particles and with the water bind sand together Shake off and sieve to re-use Dry or chemically bound sand - Mix sand with an organic binder - May require heat to cure: 200 − 320 ℃ - Or may cure via a chemical reaction - Enables larger unsupported mold cavities than green sand ![](/docs/e-29/5/mat.png) But sand harder to re-use: needs grinding down Why use sand? It is refractory: i.e. high melting point – higher than the metal/alloy being poured. e.g. silica: melts at 1600 ℃; pure aluminum: melts at 660 ℃ Gravity casting: pouring # As molten metal is poured by hand from the crucible in which it has been heated, it accelerates under gravity and flows into the mold cavity. The height of the sprue is crucial in determining the speed with which the metal enters the cavity, and hence how long it takes to fill. If filling is insufficiently fast, there is a risk that metal will solidify before filling is complete; if, however, it is too fast, the momentum of the molten metal may dislodge sand from the walls of the mold, leading to the inclusion of sand impurities in the cast component and weakening the casting.\n\u003e The speed can be estimated by considering the amount of gravitational potential energy that is converted to kinetic energy during the pouring process. The other important concept here is continuity, where we assume that the molten metal is incompressible (constant volume). So molten metal will flow at a higher velocity along narrower parts of a runner, for example. ![](/docs/e-29/5/pour.png) Bernouilli’s Law (conservation of energy): # We can usually neglect head losses and pressure changes: Continuity (conservation of mass): # - Continuity of mass and energy together explain why the downsprue is sometimes tapered: to prevent a pressure drop and aspiration of air (or sand) from the sidewalls into the molten metal. - Mold filling time: ![](/docs/e-29/5/eq3.png) Solidification # Solidification occurs when sufficient heat has been conducted out of the metal into the surrounding mold (or from the top of a sprue or riser to the air). The outside of the component will usually solidify earliest because of its proximity to the sand, leading smaller grains or crystals of metal to form near the surface of the component and larger, columnar grains to be directed radially towards the center of the component. This inhomogeneous grain structure may give undesirable mechanical properties which may need to be corrected by subsequent heat treatment or by machining back the surface.\nA widely used model for solification time is Chvorinov’s Rule, in which the solidification time is expressed as the product of a mold constant, .$C_M$, and a geometrical term, .$(V/A)^2$. The mold constant is a purely material-dependent constant depending on the properties of the alloy being cast and the mold material. The geometrical term is the square of the .$V$olume to surface .$A$rea ratio of the component being cast. The reason the exponent is taken to equal 2 is that most of the heat leaves the cast material by conduction (rather than convection or radiation), so heat is transported by diffusion. The relevant timescale thus increases as the square of the relevant linear dimension for heat transport.\n- Total solidification time .$T_{TS}$ is composed of the sum of: - Pouring time, .$T_{MF} = V/Q$ - Solidification time, .$T_S$ - .$T_{TS} = T_{MF} + T_S;\\ \\ T_S \\gg T_{MF}$ (heat) - Chvorinov’s rule: $$T_{TS} \\approx C_m \\left(\\frac{V}{A}\\right)^n$$ - .$V$: Mold Volume - .$A$: Surface Area - .$VA$ is geometry dependent _only_ - .$C_m$: Mold constant (material property) - .$n \\approx 2$: heat transport from molten metal is largely by conduction; so is governed by diffusion of atomic vibrations – consider [Fick’s laws of diffusion](https://en.wikipedia.org/wiki/Fick's_laws_of_diffusion) - Solidification begins from the outside of the mold cavity - Small “chill crystals” form (which can be machined away) - Columnar grains grow inwards - Equiaxed grains near center Shrinkage # Two types of shrinkage are relevant in casting. The first is solidification shrinkage, which is a volumetric reduction associated with the phase change from liquid (amorphous) to solid (ordered, crystalline). A good question to ask about solidification shrinkage is whether the material is effectively solid or liquid while this shrinkage is happening, as its state during shrinkage will determine the shape of a component after the shrinkage occurs. To answer this question, we can envision the liquid-to-solid phase change happening through the nucleation and growth of solid metal crystals within the cooling molten metal. Thus, up until the moment when solidification is complete, we can reasonably think of the material as still being fluid, so that gravity will cause it to fill the walls of whatever container it is in. Thus, solidification shrinkage will not be uniform in all directions, but rather will predominantly be in the vertical direction (see the shrinkage question in the homework on casting).\nThe second form of shrinkage is thermal contraction, a type of shrinkage that you have probably already encountered in other contexts. Here, the solid cast component reduces in dimensions linearly with temperature, as its temperature falls from the melting point down to the temperature at which it is extracted from the mold.\nCast components exhibit shrinkage: - **Solidification shrinkage** (due to liquid-to-solid phase change: disordered liquid becomes a denser, more ordered lattice structure). May lead to unwanted porosity if additional molten metal cannot enter the region vacated by the shrinking metal. ![](/docs/e-29/5/shrink.png) Thermal contraction (reduction in solid volume as component cools from melting point to room temperature). May lead to hot tearing/hot cracking since the material is relatively soft just below its melting point. Possible defects and remedies # Defect Description/cause Possible remedy/ies Porosity Small voids in casting; caused by solidification shrinkage .$^1$ Appropriately placed risers to supply material during solidification; chills Misrun Metal solidifies before reaching the extremities of the mold cavity Avoid high-aspect-ratio features in design; pour metal at higher temperature; use heated mold (e.g. cast iron); redesign sprue/runner/gate and/or add additional sprue locations Hot cracking/tearing Differential thermal contraction of solidified material: material which has just solidified, but is still soft because of its high Chills to promote faster cooling of thicker sections so molten regions are not trapped inside the casting Pin holes Air entrapped in molten metal flow More careful pouring; appropriate sprue design Flash Metal escapes along parting line between two mold halves More careful packing of sand; post-processing of casting to remove flash Cold shut Metal flows through multiple paths in mold and solidifies before the metal from the different paths meets Same remedies as for misrun Cold shot Splattered, solidified metal entrained in flow Slower pouring Sand wash Erosion of mold surface in metal flow Reduce pouring velocity/height Sand blow Embedded sand particles in casting Careful design of sprue taper .$^1$: Voids can appear in the more massive regions of a casting which solidify later than the surrounding material, or the surface of a casting sinks, producing aVdefect known as a pipe. Some of the effects of solidification shrinkage can be counteracted by introducing chills, which are more thermally massive and conductive regions of a mold, made, e.g., of steel and embedded in the mold in close proximity to the more massive regions of a cast component to accelerate cooling.\nOther Casting Processes # Vacuum molding: a sand-casting variant # Sand held in place under compressive stress No need for binders – sand is easy to recover Plastic burns away quickly when molten metal poured Low-pressure casting # Rather than pouring the molten metal directly into the mold, it is held in a ladle beneath the mold, and pneumatic pressure is used to drive the metal through a tube into the mold. This has the advantage that it can be automated, so that filling time can be made highly repeatable. It also helps to prevent the oxides that form at the surface of the molten metal from being injected to the mold — in gravity casting, some of these oxides risk entering the mold during pouring and weakening the cast component. The mold in low-pressure casting is typically metallic (e.g. cast iron) and reusable.\nAdvantages over sand casting: Metal enters cavity at a more controlled velocity Mold is reusable: better surface finish Molten metal is taken from center of the bath – scum (oxides) from surface does not enter the mold Hot Chamber # 1. Suitable for metals with lower melting points (e.g. Zn, Sn, Pb, in some cases Mg) 2. Plunger system exposed to high temperatures: the metal being cast must not chemically attack this mechanism 3. Pressures around 7-35 MPa 4. Production rates up to 500 parts per hour High-Pressure Die Casting (Cold Chamber) # Die casting comes in two main types: hot chamber and cold chamber. The choice of machine design depends on the melting point of the metal to be cast, with the hot chamber approach more suited to lower-melting-point materials for which it is feasible to build a plunger assembly that can be immersed in the molten material. The pressures in die casting range from several MPa to over 100 MPa, which is comparable with plastic injection molding and enables molten metal to be driven rapidly into the fine geometries in a mold. Casting dies are made of alloys with higher melting points than the metal to be injected, and require highly precise machining.\nSuitable for metals with higher melting points (e.g. Al and alloys, brass, Mg alloys) since plunger mechanism is not immersed in the melt Pressures around 14-140 MPa are needed because the molten metal cools more rapidly These high pressures can cause flash Not as fast as hot-chamber die casting because of the ladling process Rubber Plaster Molding # Rubber-plaster molds at General Foundry “Chills” Investment casting # Involves coating a single-use wax pattern with a slurry which is a suspension of ceramic particles in liquid. The slurry is baked to solidify it, the pattern is melted out, the metal cast and the mold then broken off after solidification. The pattern can be produced to extremely fine tolerances (e.g. by 3D printing or machining), and the slurry particles are far finer than sand particles, so the surface finish achievable in this way is far superior to that of sand casting.\nPrepare wax pattern Several components may be connected on a “tree” Coat in fine-particle refractory material (ceramic slurry) Build up and solidify refractory coating Melt out wax Pour molten metal and solidify Break mold away from component Other forming processes # Drawing # Pull solid material through a die, instead of pushing as in extrusion Strain-hardens the material as well as reducing diameter Deep drawing # Rapid way of forming thin-walled, 3D metal shapes Sinks Drinks cans Pressing # Deformation of sheet metal between tools/dies # Vehicle body panels Introduce stiffening features, curvature Forging # Deforming metallic materials at significant fraction of melting temperature Pressing nearly molten metal with a die to form a shape 60-70% melting point Can be open- or closed-die (left and right below, respectively) Rolling # Reduce thickness of metallic sheet between stacked rollers Can be a continuous process Material is generally near but below melting point Cold rolling possible for small thickness reductions: smooth finish "},{"id":23,"href":"/eecs-16a/5/","title":"5: Basis \u0026 Circuit Analysis","section":"EECS 16A","content":" 02-22 Basis # Note 10 Slides Change of Basis # - Previously we’ve seen that a basis for a vector space is a minimal spanning set of vectors. - We can also define the standard basis vectors, e,x. the standard basis for .$ \\mathbb{R}^{3}$ is the set .$\\mathbb{E}$: $$\\mathbb{E} = \\big(\\hat i, \\hat j, \\hat k \\big)$$ $$\\dots \\equiv ( \\vec e_1, \\vec e_2, \\vec e_3)$$ $$\\dots \\equiv \\left( \\begin{bmatrix} 1\\\\\\ 0\\\\\\ 0\\\\\\ \\end{bmatrix}, \\begin{bmatrix} 0\\\\\\ 1\\\\\\ 0\\\\\\ \\end{bmatrix}, \\begin{bmatrix} 0\\\\\\ 0\\\\\\ 1\\\\\\ \\end{bmatrix}\\right) $$ We can represent any set of vectors that form as basis as a linear combination of the standard .$ \\mathbb{R}^{3}$ basis vectors\nWhen you plot a vector, the basis is normally implicit as the standard basis vectors Change Of Basis Operation: Preserves the geometrical vector but modify its coordinates such that when plotted in the new basis, the original and final vector are physically the same - Such that we're essentially re-expressing the coordinates of some .$\\vec v$ (formed with basis .$\\mathbb{E}$) in some new basis .$\\mathbb{E}'$ - We know that the basis vectors define the linear transformation matrix: $$\\begin{bmatrix} | \u0026 \u0026 | \\\\\\ \\vec e_1 ' \u0026 \\dots \u0026 \\vec e_n ' \\\\\\ | \u0026 \u0026 | \\\\\\ \\end{bmatrix}$$ - Thus, we need to solve for the scalars that multiply each of the new basis vectors, .$v_i ' $, to produce the same physical vector .$\\vec v$ as before: $$\\begin{bmatrix} | \u0026 | \\\\\\ \\vec e_1 ' \u0026 \\vec e_2 ' \\\\\\ | \u0026 | \\\\\\ \\end{bmatrix}\\begin{bmatrix} v_1 ' \\\\\\ v_2 ' \\\\\\ \\end{bmatrix} = \\begin{bmatrix} v_1 \\\\\\ v_2 \\\\\\ \\end{bmatrix} = \\vec v $$ - Generally, we can say that if given a vector .$\\vec v$ expressed with coordinates in the standard .$n$-dimensional basis .$\\mathbb{E}$, then we can solve for the coordinates .$\\vec v ' $ in a different .$n$-dimensional basis .$A$ with .$\\vec v ' = A^{-1} \\vec v$ - .$A$ is formed with the columns of the new basis. To do the opposite (basis .$A \\to \\mathbb{E}$), we apply .$A$: .$\\vec v = A \\vec v ' $ - Finally, suppose that we’re given .$\\vec v$ with coordinates in an arbitrary basis .$P$ (matrix with columns .$\\vec p_1, \\dots, \\vec p_n$), and we want to change to another arbitrary basis .$Q$ with columns .$\\vec q_1, \\dots, \\vec q_n$. We must apply the transformation .$Q^{-1} P$. This follows from first transforming .$\\vec v$ to the standard basis from .$P$, and then transforming to the new basis .$Q$ The only question is whether we preserve the coordinates (which are the mathematical representation) and change the physical vector in accordance with the new basis, or preserve the physical vector and find the new coordinates. Page 57 has pretty figures Matrix Change of Basis # We can apply our knowledge to linear transformations to understand what it means to change the basis of a matrix\nGiven transformation .$T \\in \\mathbb{R}^{n \\times n}$ with input .$\\vec v_1$ and output .$\\vec v_2$, we can apply our column-wise interpretation of the matrix-vector product, but now, we must take care of the fact that our vectors may lie in a different basis than .$E$. - Suppose we have basis vectors .$\\vec a_1, \\dots, \\vec a_n$ forming .$A \\in \\mathbb{R}^{n \\times n}$, and vectors .$\\vec v_1, \\vec v_2$ represented in this basis: .$\\vec v_i = v_{i,1} ' \\vec a_1 + \\dots v_{i,n} ' \\vec a_n$ - Each .$v_{i,k}$ is the .$k$th element of the vector .$\\vec v_i$ - We can also represent .$T$ in this basis as .$T ' $ - We start with .$\\vec v_1 = A \\vec v_1 ' $ and .$\\vec v_2 = A\\vec v_2 ' $. - Since .$T\\vec v_1 = \\vec v_2$ by definition of linear transformation .$T$, we can plug in: .$TA\\vec v_1 ' = A\\vec v_2 ' \\Longrightarrow A^{−1} T A \\vec v_1 ' = \\vec v_2 ' $. - Clearly, just as how we had .$T\\vec v_1 = \\vec v_2$, we have an analogous transformation in the new basis: .$T ' \\vec v_1 ' = \\vec v_2 ' $, where .$T ' = A^{−1} T A $. \u003e ![](/docs/eecs-16a/5/cob.png) \u003e .$T ' $ is equivalent to .$A$, then .$T$, then .$A^{−1}$ Diagonalization # Why bother with change of basis? In practical applications, matrix operations form the core of some very computationally heavy algorithms \u0026ndash; we need to be able to easily invert matrices, raise them to high powers, and multiply them commutatively; all of these can be accomplished with diagonal matrices, where all entries not on the diagonal are zero An identity matrix of any size, or any multiple of it (a scalar matrix), is a diagonal matrix. Its determinant is the product of its diagonal values First, we must choose a diagonalizing basis .$A$ that consists of the .$n$ eigenvectors of .$T$. This is only possible if .$T$ is diagonalizable, which requires it to have .$n$ linearly independent eigenvectors Note this is different from the .$n$ columns being independent! Then, to figure out how .$T$ transforms .$\\vec v_1$, we write .$\\vec v_1 = \\vec v_{11} \u0026rsquo; \\vec a_1 + \\dots + \\vec v_{1n} \u0026rsquo; \\vec a_n$ $$T \\vec v_1 = T \\vec v_{11} \u0026rsquo; \\vec a_1 + \\dots + T v_{1n} \u0026rsquo; \\vec a_n$$ $$\\dots = v_{11} (T \\vec a_1) + \\dots + v_{1n} (T\\vec a_n)$$ $$\\dots = v_{11} (\\lambda_1 \\vec a_1) + \\dots + v_{1n} (\\lambda_n \\vec a_n)$$ Using the middle matrix (diagonal!) as a sort of \u0026ldquo;sifting\u0026rdquo; matrix; each row only has one nonzero value, so we only multiply the .$v_{1i} \\vec a_i$ value by the corresponding .$\\lambda_i$: $$T \\vec v_1 = \\begin{bmatrix} | \u0026amp; \u0026amp; | \\\\ \\vec a_1 \u0026amp; \\dots \u0026amp; \\vec a_n \\\\ | \u0026amp; \u0026amp; | \\\\ \\end{bmatrix}\\begin{bmatrix} \\lambda_{1} \u0026amp; \u0026amp; \\\\ \u0026amp; \\ddots \u0026amp; \\\\ \u0026amp; \u0026amp; \\lambda_{n} \\end{bmatrix}\\begin{bmatrix} v_1 \u0026rsquo; \\\\ v_2 \u0026rsquo; \\\\ \\vdots \\\\ v_n \u0026rsquo; \\\\ \\end{bmatrix}$$ Notice now we have an equation of the form: $$T \\vec v_1 = AD \\vec v_1 \u0026rsquo; \\Longrightarrow T\\vec v_1 = ADA^{-1} \\vec v_1 \\Longrightarrow T = ADA^{-1}$$ Here, .$D$ is the diagonal matrix containing the eigenvalues of the transformation One useful result is that .$T^k = AD^k A^{-1}$ (expand and group .$A^{-1}A = I$) Since .$D$ is easy to raise to high powers (.$D^k$ contains all diagonal entries raised to the .$k$th power), the computation of numerous transformations becomes much easier To raise a diagonal matrix to a power, one can raise each element to that power 02-24 Intro to Circuit Analysis # Slides Note 11 A B We will label nodes instead of junctions because all of the junctions that are connected to each other by wires can be labeled with a single voltage variable .$u$. A set of such junctions connected to each other only via wires is defined as a node. Nodes have the same voltage at every point on them. Circuit Analysis Algorithm # Select a reference ( ground) node .$u_1 = 0$ - This node will have 0 potential -- all voltages are measured relative to this node - Arbitrary selection -- any node can be chosen for this purpose. - In this example, we choose the node at the bottom of the circuit diagram. \u003e![](/docs/eecs-16a/5/s1.png) Label Nodes .$[u_2, \\dots, u_{n}]$\nFirst lets look at the nodes with voltage set by Voltage Sources. Voltage sources set the voltage of the node they are connected to. - In the example, there is only one source, .$V_S$, and we label the corresponding source .$u_1$ (names are arbitrary, but must be unique). - Now we label all remaining nodes in the circuit except the reference -- in this example there are two, .$u_2$ and .$u_3$. \u003e![](/docs/eecs-16a/5/s2.png) Label currents .$[I_1, \\dots, I_k]$ through non-wire elements - The direction is arbitrary (top to bottom, bottom to top, it won’t matter, but stick with your choice in subsequent steps). - Then mark the element voltages following the _passive sign convention._ \u003e![](/docs/eecs-16a/5/s3.png) 4. **Label element potentials** based on passive sign convention. - The element voltage for .$I_S$ is not marked in the example since it will not be needed in the calculations below. Same for the voltage source. There is no harm in marking those, too. \u003e![](/docs/eecs-16a/5/s4.png) 5. **KCL Equations** - Write KCL equations for all nodes with unknown voltage, .$u_2$ and .$u_3$ in the example. - See [Week 2](2.md#kirchhoffs-current-law-kcl) \u003eAt .$u_2$ we get (sum of all currents entering the node equals sum of currents exiting): \u003e$$I_{R_1} = I_{R_2} + I_{R_4}$$ \u003eand similar for .$u_3$: \u003e$$I_{R_4} + I_{I_S} = I_{R_3}$$ 6. **Element IV Relationships** - Find expressions for all element currents in terms of voltage and element characteristics (e.g. Ohm’s law) for all circuit elements except voltage sources. - In the example there are five unknown elements: .$R_1, R_2, R_3, R_4, I_S$ - Find expressions for element currents for all elements (except the voltage source) using their characteristics. \u003eApplying Ohm’s law to the two resistors, we find that \u003e \u003e$$I_{R_1} = \\frac{V_{R_1}}{R_{1}}$$ \u003e$$I_{R_2} = \\frac{V_{R_2}}{R_{2}}$$ \u003e$$I_{R_3} = \\frac{V_{R_3}}{R_{3}}$$ \u003e$$I_{R_4} = \\frac{V_{R_4}}{R_{4}}$$ \u003e$$I_{I_S} = I_S$$ \u003eand we have .$u_1 = V_S$ Solve .$A\\vec x = \\vec b$ \u0026ndash; see page 12 and/or slide 14 .$\\vec x = [I_1, \\dots, I_k, u_1, \\dots, u_n]^T$: The unknown element variables we\u0026rsquo;re solving for .$\\vec b \\in \\mathbb{R}^{k+n}$: The vector of elements values we\u0026rsquo;re solving for Units are either .$V$olts or .$A$mps .$A \\in \\mathbb{R}^{k+n \\times k+n}$ Steps: If there are .$n$ nodes (including the ground node), use KCL on .$(n−1)$ nodes to fill in .$(n−1)$ rows of .$A$ and .$\\vec b$ $n-1$ because we know that one of the nodes is ground If there .$k$ non-wire elements, use the IV relationships of each non-wire element to fill in the remaining .$k$ equations (rows of .$A$ and values of .$\\vec b$). Branch Current # - Sometimes we want to solve for [branch currents](https://en.wikipedia.org/wiki/Nodal_analysis): These are easily obtained from the node voltages and element equations. \u003e For example above, the current .$I_{R_4}$ through resistor .$R_4$ is \u003e$$I_{R_4} = \\frac{V_{R_4}}{R_4} = \\frac{u_2 - u_3}{R_4}$$ Voltage Divider # Passive sign convention # - The [passive sign convention](https://en.wikipedia.org/wiki/Passive_sign_convention) dictates that **positive** current should **_enter_ the positive terminal** and **_exit_ the negative terminal** of an element. ![](/docs/eecs-16a/5/passive.png) As long as this convention is followed consistently, it does not matter which direction you arbitrarily assigned each element current to; the voltage referencing will work out to determine the correct final sign. When we discuss power later in the module, you will see why we call this convention “passive.”\nTrivial Junctions # Trival junction: A junction connecting only two elements. KCL dictates that the current entering the junction must be equal to the current exiting. Since there are only two elements, it follows that the two currents must be equal (as long as we label the direction of current flow to be the same – if not, the currents will simply be opposite in sign). Therefore, another simplification to our analysis procedure is to label the currents only in the non-wire elements in our circuit (Sometimes these currents are called branch currents) When we use KCL, we can now consider nodes (instead of junctions) i.e. the current flowing into the node is equal to the current leaving the node. "},{"id":24,"href":"/eecs-16a/6/","title":"6: Voltage Dividers \u0026 Measurement","section":"EECS 16A","content":" \\(\\) 03-01: Voltage Dividers # Voltage Divider # The voltage divider circuit consists of a voltage source (.$V_S$) and two resistors (.$R_1$ and .$R_2$) Example: 1. We label the node connected to the voltage supply as .$u_1 (= V_S)$, since the voltage supply goes between this node and ground. 2. Label the remaining node as .$u_\\text{mid}$ and the voltages and currents through every element in the circuit with .$V_i$ and .$I_i$ respectively 3. Write KCL equations for all nodes with unknown voltage - in this case, this is just .$u_\\text{mid}$, since .$u_1 = V_S$. - The current entering that node is .$I_{R_1}$ and the current leaving it is .$I_{R_2}$ - Since these currents must be equal, .$I_{R_1} = I_{R_2}$ ![](/docs/eecs-16a/6/volt2.png) 4. Find expressions for element currents for all elements (except the voltage source) \u0026ndash; all steps on page 3 $$I_{R_1} = \\frac{V_S - u_\\text{mid}}{R_1}$$ $$I_{R_2} = \\frac{u_\\text{mid}}{R_2}$$ 5. Substitute the element currents into our KCL equation. We have $$I_{R_1} = I_{R_2} \\Longrightarrow \\frac{V_S - u_\\text{mid}}{R_1} = \\frac{u_\\text{mid}}{R_2}$$ 7. Solve the above equation. Rearranging, we find that $$V_S R_2 −u_\\text{mid}R_2 = u_\\text{mid}R_1$$ $$ \\Longrightarrow u_\\text{mid}(R_1 +R_2) = V_SR_2$$ $$ \\Longrightarrow u_\\text{mid} = \\frac{R_2}{R_1 + R_2} V_S = \\frac{1}{1+ \\frac{R_1}{R_2}} V_S = \\alpha V_S$$ The reason this circuit is called a \"voltage divider\" is that _we can create any output voltage_ of .$u_\\text{mid} = \\alpha V_S$ for any .$\\alpha \\in [0,1]$ (assuming that all of the resistance values are non-negative) by varying the ratio of the resistor values .$R_1/R_2$. As we will see shortly, varying this ratio is exactly the mechanism we will use to convert the relative position of a user’s touch to a voltage. .$R_2$, the **resistor in the numerator**, is the one next to ground. .$R_1$ is connected to a non-zero voltage node (in this case .$u_1 = V_S$). Capacitor Divider # The capacitor divider is similar, differing in that the numerator is now the component closest to $V_{in}$ rather than closest to ground (as in the voltage divider with resistors) $$V_{out} = \\frac{C_1}{C_1 + C_2} V_{in}$$ ![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Impedance_voltage_divider.svg/330px-Impedance_voltage_divider.svg.png) Current Divider # Current $I_X$ in a resistor $R_X$ that is in parallel with a combination of other resistors of total resistance $R_T$ is $$I_X = \\frac{R_T}{R_X + R_T}I_T$$ - $I_T$ is the total current entering the combined network of $R_X$ in parallel with $R_T$ - $R_T$: Total resistance of the circuit to the right of resistor $R_X$ ![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Current_division_example.svg/375px-Current_division_example.svg.png) 03-03: Power and Voltage/Current Measurement # Physics of Circuits # Read 7B 25.2 - 5\nPower refers to the rate of energy change, .$P = \\frac{dE}{dt} \\text{ [Watts]}$ .$\\dots \\Longrightarrow dE = V\\ dQ \\Longrightarrow \\frac{dE}{dt} \\equiv P = V \\frac{dQ}{dt} = VI$ .$P_\\text{el} = I_\\text{el} \\cdot V_\\text{el} = V^2_\\text{el} \\cdot R^{-1}_\\text{el} = I^2 _\\text{el} R _\\text{el}$ $P \u0026gt; 0 \\implies$ (positive) power dissipated, negative power generated. By PSC, resistors always dissipate power because current enters the .$+$ terminal Voltage sources tend to generate power, since current comes out of the .$+$ terminal (and the product .$P = IV \u0026lt; 0$) $P \u0026lt; 0 \\implies$ (positive) power generated, negative power dissipated. In an isolated (circuit) system, the sum of the power (across all components) should equal zero by conservation of energy Useful sanity-check .$R = \\rho \\frac{L}{A}$ Touchscreen # Given that the top (red) layer has a resistivity .$\\rho$ and a cross-sectional area .$A$, the resistance of the top layer from the touchpoint to the right-hand end is given by .$R_1 = \\rho \\frac{L_\\text{rest}}{A}$, the resistance of the top layer from the left-hand end to the touchpoint is given by .$R_2 = \\rho \\frac{L_\\text{touch}}{A}$ We can see that .$u_\\text{mid}$ can be found because it\u0026rsquo;s a voltage divider: $$u_\\text{mid} = \\frac{\\rho \\frac{L_\\text{touch}}{A}}{\\rho \\frac{L_\\text{rest}}{A} + \\rho \\frac{L_\\text{touch}}{A}}V_S = \\frac{L_\\text{touch}}{L_\\text{touch} + L_\\text{rest}}V_S = \\frac{L_\\text{touch}}{L}V_S$$ .$L = L_\\text{touch} + L_\\text{rest}$: The length of the touchable portion of the screen The relationship we have found between .$u_\\text{mid}$ and .$V_S$ is very convenient because .$u_\\text{mid}$ is not dependent on any material property such as .$\\rho$ and .$A$. This means that the top layer can be built with any material and the relationship between .$u_\\text{mid}$ and .$V_S$ is still valid. There are always some non-idealities in the world \u0026ndash; by making .$u_\\text{mid}$ independent of any material property, we can make the circuit model immune to such non-idealities. We also have the freedom to choose a material for the top layer that is good for display purposes (rather than needing a specific material for the touchscreen to work).\nMeasuring a Circuit # The voltmeter measures voltage across the circuit, while the ammeter needs to be put in-line with the circuit so that the current flows through the ammeter.\nThe measurement should not change the energy of the circuit It turns out that the most complete and concise way of guaranteeing these measurement tools do not influence the circuit is to state that they do not allow any power dissipated through the measurement device. Voltmeter # Because our voltmeter is made to measure voltage, we can naturally assume that the .$V \\neq 0$; this means that a voltmeter must have .$I = 0$ going into it to ensure .$P = IV = 0$.\n.$I=0$ occurs when in open-circuits, where exactly zero current is flowing.\nRecall that, for a given voltage, the higher the associated resistance, the lower the current and therefore the lower the dissipated power. That is, .$\\lim{R \\to \\infty} \\Longrightarrow I = 0$ $$V_\\text{el1} = I_\\text{meas} R$$ $$V_? - V_\\text{el1} - V_\\text{meas} = 0$$ $$\\Longrightarrow V_? = V_\\text{el1} + V_\\text{meas}$$ $$\\Longrightarrow V_? = I_\\text{meas} R + V_\\text{meas}$$ $$\\therefore V_? = V_\\text{meas} \\iff I_\\text{meas} = 0$$ --- $$I_\\text{meas} = \\frac{V_\\text{meas}}{R_\\text{meas}}$$ $$\\therefore I_\\text{meas} = 0 \\iff R_\\text{meas} \\gg V_\\text{meas}$$ \u003e Voltmeters are added in **parallel** to the circuit, otherwise they would stop the current from flowing. \u003e ![](/docs/eecs-16a/6/mcurrent.png) Ammeter # The ammeter has the circuit’s current flowing through it. Therefore, to ensure .$P = IV = 0$, the ammeter needs .$V = 0$.\n.$V=0$ occurs in short-circuits (ideal wires), where exactly zero potential difference exists\n$$I_? = I_R + I_\\text{meas}$$ $$\\therefore I_? = I_\\text{meas} \\iff I_R = 0$$ --- $$I_R = \\frac{V_\\text{meas}}{R}$$ $$\\therefore I_R = 0 \\iff V_\\text{meas} = 0$$ \u003e Ammeters are added in **series** to the circuit, otherwise they would short-circuit the measured component. \u003e ![](/docs/eecs-16a/6/mvoltage.png) "},{"id":25,"href":"/e-29/6/","title":"6-7: Joining processes","section":"Engineering 29","content":" \\(\\) Joining Processes # Welding-based # There are many ways of assembling mechanical components to create mechanisms and structures. Examples of joining processes include the use of fasteners such as bolts and rivets, adhesives, and push fits, in which interference is used to connect components together. Welding, meanwhile, involves fusing two components by melting the material near their interface, and possibly introducing additional material of the same kind to fill any gaps between the components. Metallic and polymeric materials can be welded, and the techniques used to melt the material vary with the properties of the materials being joined.\nIt is important to note that welding involves complete fusion of the components being joined: the joint is made of the same material as the components and thus can be extremely strong relative to other joining techniques because it enables us to eliminate inter-material interfaces along which cracks might propagate. Drawbacks of welding, however, include the fact that because we are heating a portion of the components above their melting point, dimensional distortion of the components may occur, and even if distortion does not occur there may be modification of the material’s mechanical properties in a heat affected zone (HAZ) around the weld. This property modification may involve recrystallization or annealing of metallic materials, softening the component after it cools.\nWelding terminology # A heat source emits heat some distance from the weld. A fraction .$f_1$ of this heat reaches the material, and a fraction .$f_2$ of the heat that arrives is retained within the weld region, and actually is used in melting material. The remainder of the heat is lost either to the surroundings, or conducted through the solid components where it may modi.$f_y$ the microstructure without melting the material. The energy required for melting a unit volume of the material may be approximated as being proportional to the square of the absolute melting temperature. If we know the rate of heat generation and the heat transfer factor .$f_1$ and melting factor .$f_2$, we can thus determine the volumetric rate at which material can be melted and thus how fast a weld with a given cross-sectional area can be created\nProportion of total heat from source contributing to melting of metal: .$f_1 f_2 H$ .$H$: Heat from source .$f_1$: Heat transfer factor \u0026ndash; amount of heat that goes into welding material .$f_2$: Melting factor \u0026ndash; amount of heat that goes into welding region - Energy required for melting: $$U_m = K T^2_m$$ - .$U_m$: Melting energy (J/mm.$^3$) - .$K = 3.33 \\cdot 10^{-6}$ J/(mm.$^3$K.$^2$) - .$T_m$: Melting temp (K) - Power for melting: $$U_m A_w v = f_1 f_2 IE$$ - .$IE$: Electric Power - .$I$: Current (Amps) - .$E$: Voltage (Volts) Rates of melting material: $$R_{H,w} = f_1 f_2 R_H = U_m R_{w, V} = U_m A_w v$$ - .$R_\\{H,w}$: Rate of heat delivery to weld [.$W$atts] - .$R_H$: Power of heat source - .$R_\\{w,V}$: Volumetric rate of melting; .$A_w v$ - .$U_m$: Melting energy (J/mm.$^3$) - .$A_w$: Cross-section area of weld - .$v$: Velocity of heat source Oxyacetylene welding # This versatile technique has been used for many decades to weld metals, and involves a two-stage reaction, first the combustion of acetylene to produce carbon monoxide, hydrogen and heat, and second the reaction of the CO with hydrogen and oxygen to produce carbon dioxide, water, and more heat.\nThis approach lends itself to welding in remote locations (all that is needed is a gas tank and torch) and because of the high temperature of the flame, many materials can be welded. Can also be done underwater.\nOne well known challenge with this technique is hydrogen embrittlement where the hydrogen gas generated can become incorporated into the microstructure of the component, weakening it.\n@ 1:00\nArc welding # In arc welding of any kind, a voltage is applied between the workpiece and an electrode which are separated by a gap of a few millimeters. The electric field across this gap is large enough to ionize the gas and generate a plasma in the gap. This plasma is electrically conductive, yet still highly resistive so that heat is generated as the current passes through the plasma. It is this heat that melts the material. Because the plasma is so highly localized and the heat is generated within a millimeter or so of the weld, the welded region can be precisely controlled.\nManual Metal Arc (Stick) Welding # In Manual arc welding, the electrode is a hand-held rod of the same material as the workpiece, and it melts as the weld forms, providing material to fill the gap between components. The rod has a length of several inches, so the length of weld that can be produced in one welding operation is limited. This limits the speed of the technique. The rod is usually coated with a flux, which melts during welding to produce an acidic liquid on the surface of the work, etching away naturally occurring oxides to expose the metal surface and enable a strong, continuous metallic weld to be produced.\n@ 1:37\nSubmerged arc welding # This process is suitable for producing long, straight welds in larger components. The electrode is a consumable wire that is fed into the system from a spool, and a powdered flux is fed in front of the advancing weld from a hopper. The weld region lies submerged by the flux, which helps to prevent sparks and strong ultraviolet radiation from the weld escaping from to the surroundings. The flux and electrode handling mechanism is usually mounted on a motorized carriage that moves along the component at a constant rate.\n@ 3:06\nMetal Inert Gas (MIG) Welding # Here, the electrode is consumable and fed from a continuous spool of wire. Instead of flux, an inert gas such as Argon is fed around the electrode as a shield, to prevent oxidation of the workpiece surface.\n@ 5:50\nDip vs Spray Transfer in MIG Welding # @ 6:50 + 8:30\nTungsten Inert Gas (TIG) Welding # Like MIG welding, an inert gas shield is used, but instead of a consumable electrode, a tungsten electrode with much higher melting point is used. If filler material is needed it is introduced from the side using rods of materials. The electrode can maintain a sharp shape (less than a millimeter diameter), so that highly precise and consistent welds can be produced. This also makes it much harder to learn.\n@ 11:25\nDC (Direct Current) Electrode is held negative Suitable for all metals except Al and its alloys AC (Alternating Current) Used for Al and alloys because of the robust oxide that aluminum forms which needs to be removed to enable a clean weld Frequencies 20-150 Hz used Positive-electrode part of cycle helps strip oxide from the weld pool but leads to electrode heading Negative-electrode part of cycle heats workpiece Electrical Resistance Welding # Electrodes are clamped across a stack of metal sheets to be welded. A current is passed through the stack, resistively heating the material between the electrodes. Material at the center of the stack heats up the most, because the thermal conduction path by which generated heat can escape to the surroundings is the longest there. The amount of heat energy generated can be precisely controlled, which makes this excellent for joining thin sheets that could be destroyed by a flame or an arc. The weld region is sometimes referred to as a nugget and the process is called a spot weld. Seam welding is a continuous form of spot welding whereby the sheet material passes between two conductive rollers and a series of overlapping spot welds are made in rapid succession. This process is suitable for creating sealed metal containers.\n- Spot welding - Sheets clamped between electrodes - Current passes through - Lozenge of material melts around the interface - Seam welding - Sheets pass between conductive rollers - Current is pulsed - Continuous weld is formed from overlapping spot welds \u003e @ 16:48 \u0026 17:20 Friction (Stir) Welding # Two components are rotated relative to each other at high speed under load (e.g. by mounting in a lathe). The heat generated by friction softens both components’ surfaces and they fuse.\n- Two components undergo relative rotational motion in contact - Heat resulting from friction at the interface leads to melting - Components are pressed together until they fuse and cool @ 20:48\nUltrasonic Welding # - A horn couples ~40 kHz vibrations into the components - Oscillatory compression of the components translates to shear motion at the intended joint, and dissipation of energy as heat via friction - \"Energy directors\" are features at the welded interface that lower contact area, and concentrate the loads, promoting material melting Laser Welding # - Focused laser beam provides the heat - Readily automated weld paths - Extremely precise welds (sub-mm-size) are possible Electron Beam Welding # - Focused beam of electrons (produced, e.g., by thermionic emission) is accelerated and steered towards workpiece by electromagnetic field reaching an electron energy of ~30-100 keV - Loss of kinetic energy of electrons upon collision with workpiece generates heat - Carried out in vacuum: as low as ~10-4 Torr (0.01 Pa) - As with laser welding, extremely high-precision and small welds are possible - Similar pros and cons as for e- beam melting additive m.$f_g$ vs selective laser melting - Can make especially deep, narrow welds Typical Power Densities in Welding # Power density reaching material surface Type of welding Typical power density (W/mm.$^2$) Oxyacetylene 10 Arc 50 Resistance (electrical) 1000 Laser 9000 Electron beam 10000 Modeling Heating in Welding # It is helpful to be able to predict the size of the weld pool and HAZ for given process parameters Rosenthal developed a simple equation for how temperature varies around a heat source $$T(w,y,z) - T_0 = \\frac{q}{2\\pi kR} e^{-\\left(\\frac{v(w+R)}{2a}\\right)}; R = \\sqrt{w^2 + y^2 + z^2}$$ - $T_0$: Temperature of work at start - $v = \\frac{dw}{dt}$: Velocity of beam - $q$: Rate of heat delivery [Watts] - $R$: Distance along weld - $k$: Thermal conductivity - $a$: Thermal diffusivity - Time .$t_{8/5}$ for temperature to fall from 800 °C to 500 °C as the heat source passes is a key parameter for determining condition of HAZ: ideally about 10-25 s for _carbon steels_ ![](/docs/e-29/6/orient.png) Non-Welding Joining Methods # Other joining methods that involve introducing molten material to an interface are soldering and brazing, but in both these processes the gap-filling material is an alloy with a lower melting point than the components being joined. Soldering is used, for example, to join electrical components to printed circuit boards or to connect pipes in plumbing. Brazing is simply the term used for soldering when the filler melts above 400˚C. There is some inter-mingling of atoms of the filler and component material near the interfaces, which lends the joints strength, but soldered/brazed joints are still not as strong as welded ones can be.\nBrazing # - Filler is a metal or [eutectic alloy](https://en.wikipedia.org/wiki/Eutectic_system#Alloys) with lower melting point than the work - Advantages cf welding - Good for thin walls - Less heat required - Suitable for joining dissimilar metals - Avoid HAZ - Use capillary forces to fill inaccessible joints - Disadvantages cf welding - Lower strength - Appearance: differing colors - Weakens at high service temperatures - Applications - Piping, preparing cutting tools e.g. cemented carbide Types of adhesive # - Pressure-sensitive - Viscoelastic solid -- forms under load - Conforms to target solid - Maximize van der Waals interactions - Promotes mechanical interlocking - Thermoplastic - e.g. hot-melt glue - Irreversible liquid-solid transition - Radical-driven crosslinking: UV or thermally cured - Epoxy resins (2-part; reacts when mixed to cure) - Thermosetting silicones - Cyanoacrylate:rapidly polymerizes in presence of water Fasteners: Riveting # Simple to process and automate Can\u0026rsquo;t be loosed by vibration (used in aircrafts) Typically cheaper (doesn\u0026rsquo;t need to be toleranced precisely) Doesn\u0026rsquo;t need the depth that threaded components do Fasteners: Screws and Bolts # - Screw characterized by: - Major, minor diameters - Pitch (inverse of turns per inch), thread angle - Length - Conventional formats: - `[Diameter]-[Turns / unit] x [Length]` - `#4-40 x 0.5`: Imperial; #4 [diameter](https://www.boltdepot.com/fastenerinformation/machinescrews/machine-screwdiameter.aspx), 40 turns per inch, 0.5 length (in) - `1/4-20 x 5/8`: Imperial; 1/4 ..., 20 ..., 5/8 - `M3-0.50 x 10`: Metric; 3 mm radius, 0.50 Pitch (mm), 10 length (mm) - Various head styles available - Square, [counterbore](https://en.wikipedia.org/wiki/Counterbore), [countersunk](https://en.wikipedia.org/wiki/Countersink), round etc - Important to protect against loosening in use - Sprung, split washers - Glue "},{"id":26,"href":"/eecs-16a/7/","title":"7: 2D Touchscreens \u0026 Superp. + Equivalence","section":"EECS 16A","content":" \\(\\) 03-08: 2D Resistive Touchscreens # Bottom Plate # - Trivially, we see that if we add a wire connected to $u_\\text{mid}$ that will have the same voltage across it (wires have zero voltage drop) - So why have the bottom plate at all? It lets us take the measurement for $V_\\text{out}$ using connection points on the edge of the plate instead of having to put a probe or wire at the actual touch point every time! ![](/docs/eecs-16a/7/wire.png) ![](/docs/eecs-16a/7/imperf.png) ### What if this bottom plate is non-ideal? That is, $R \\neq 0$ ? - Both of these resistors are followed by an open circuit. From the definition of an open circuit, we know that zero current will flow through it. - If $i_\\text{mid} = i_{R4} +i_{R3}$ from KCL, and $i_{R4} = i_{R3} = 0$ from the definition of an open circuit (Ohm’s Law says that $0V = R \\cdot 0A$), the voltage across these new resistors will be $0$. This means that, even with an imperfectly conductive bottom plate, the voltage $V_\\text{out}$ will still be equal to $u_\\text{mid}$, even with the addition of these new resistors. To measure an output voltage, we need to put some device at the open circuit labeled $V_\\text{out}$. Interesting Circuit # These are two parallel voltage dividers, thus we can write: $$u_2 = \\frac{kR_1}{R_1 + k R_1} V_s = \\frac{k}{1+k}V_S$$ $$u_3 = \\frac{kR_2}{R_2 + k R_2} V_S = \\frac{k}{1+k}V_S$$ - We see that regardless of the resistances $R_1$ and $R_2$, the potentials $u_2$ and $u_3$ are the same! This holds as long as $k$ is constant: $$u_2 = u_3 = \\frac{k}{1+k}V_S$$ ![](/docs/eecs-16a/7/interesting.png) ![](/docs/eecs-16a/7/int2.png) - We can add $R_3$ and it won't change the circuit behavior - Since $u_2 = u_3$, there is no $\\Delta V$, thus no current flows through the resistor. - We can also find this with KCL: $R_3 i_3 = u_2 - u_3 = 0 \\therefore i_3 = 0$ - This means that $R_3$ is at the special $(0, 0)$ point on the $I$-$V$ plot, where it behaves the same way as a wire or open circuit - That is, we could replace $R_3$ with an open circuit and nothing would change 2D Resistive Touchscreen # - Now, let’s introduce the physical structure of a 2D touchscreen: it consists of a top red plate and a bottom black plate. When a finger touches the screen, the top red plate is pushed into contact with the bottom black plate at the touch point. - The top and bottom ends of the top red plate as well as the left and right ends of the bottom black plate are made of materials that have very low resistivities $\\rho$, we can treat them as ideal wires ($\\rho = 0$). The materials of the transparent screen that we touch in the middle have much higher resistivity. ![](/docs/eecs-16a/7/2d1.png) ### Top Plate ![](/docs/eecs-16a/7/red.png) - We can treat the red plate as a bunch of vertical resistor strips, where each vertical strip is connected to the strips next to it by horizontal resistors as well. - When we touch the plate, we split it into a top and bottom half, or $R_\\text{rest}$ and $R_\\text{touch}$. - Rather than considering many vertical strips, we will divide the red plate into just three equal vertical segments represented by resistors, which are connected by horizontal resistors $R_{h1}$ and $R_{h2}$. - Adding a voltage supply $V_S$ we can see this is the same interesting circuit as before! - Since $R_\\text{rest}$ and $R_\\text{touch}$. are the same for each segment, we know that $u_2 = u_3 = u_4$. As with the “interesting circuit” can replace horizontal resistors $R_{h1}, R_{h2}$ with open circuits. $$u_3 = \\frac{R_\\text{touch}}{R_\\text{rest} + R_\\text{touch}}V_S$$ $$\\dots = \\frac{\\rho \\frac{L_\\text{touch}}{A}}{\\rho \\frac{L_\\text{touch}}{A} + \\rho \\frac{L_\\text{rest}}{A}}$$ ![](/docs/eecs-16a/7/wpsu.png) $$\\dots = \\frac{L_\\text{touch}}{L}V_S \\text{ for } L_\\text{touch} = L_\\text{touch, vertical}$$\nThis means that $u_3$ is mapped to the vertical position touched in the same way as the 1D touchscreen. When measuring the vertical position touched ($L_\\text{touch, vertical}$), the bottom black plate connects to a voltmeter and measures $u_3$, the same way it did in the 1D touchscreen Note that, although we have represented the top red plate by three segments of equal width in the circuit model we built, the value of $u_3$ will remain the same if we choose to represent the top red plate by an infinite number of segments. ## Bottom Plate ![](/docs/eecs-16a/7/bot.png) - We know from linear algebra that if we want to find two values (i.e. vertical and horizontal position), we will need two measurements. - To find the horizontal position, we connect the supply voltage source $V_S$ to the bottom black plate, and connect the top red plate to a voltmeter. As before, we choose to represent the bottom black plate by three segments of equal width which are connected in between by vertical resistors $R_{v1}, R_{v2}$. $$u_3 = \\frac{R_\\text{touch}}{R_\\text{touch} + R_\\text{rest}} V_S = \\frac{L_\\text{touch}}{L}V_S$$ The important simplification used is replacing $R_{h1}, R_{h2}$. with open circuits for the $L_\\text{touch}$, horizontal measurement and $R_{v1}, R_{v2}$. for the $L_\\text{touch}$, vertical measurement. However, this kind of simplification is valid only if the resistor is at $(0, 0)$ on the $I$-$V$ plot, which means the resistor has zero current flow and therefore zero voltage drop ($IR = V$). - From the $I$-$V$ plots, although a resistor, a wire and an open circuit can behave quite differently, their behaviors are exactly the same at $(0, 0)$. - This means that at $(0, 0)$, these three circuit elements can be replaced by one another and the same behavior $(I = 0, V = 0)$ is still expected. ![](/docs/eecs-16a/7/plot.png) Fast Analysis # Prior, we used the fact that all of the segments had $R_\\text{rest} = R_\\text{touch}$. In this section, we’ll consider a similar circuit where the resistances are all different\n1. **Write equations for the nodes with voltage sources between them.** - Here, the ground node and $u_1$ have $V_S$ between them, so $u_1 = V_S$ 2. **Write KCL for any unknown nodes, using the $V = IR$ relationship, and taking into account any current sources connected to the node** - If we consider node $u_2$, the sum of the currents flowing out of $u_2$ through $R_1, R_5, R_3$ is 0. $$ \\frac{u_2 - V_S}{R_1} + \\frac{u_2}{R_3} + \\frac{u_2 - u_3}{R_5} = 0,$$ $$\\frac{u_3 - V_S}{R_2} + \\frac{u_3}{R_4} + \\frac{u_3 - u_2}{R_5} = 0$$ - Now, we have just two equations and two unknowns ($u_2$ and $u_3$) so all the remains to be done is to solve the equations by hand. ![](/docs/eecs-16a/7/fast1.png) \u003e You can check that the signs of your voltage drops are correct by checking that the node in question is **always positive in the numerators**. So in the first equation, $u_2$ is positive, while in the second equation, $u_3$ is positive What if we have a current source? How do we KCL? # Remember that we treat all currents as flowing out of the node. We should also take the direction of the current source into account. In this case, the left branch of $u_1$ has a current source $I_S$ flowing in, so $−I_S$ current flows out. So our equation is $$-I_S + \\frac{u_1 - u_2}{R_1} + \\frac{u_1 - u_3}{R_2} = 0$$ ![](/docs/eecs-16a/7/fast2.png) 03-10: Superposition and Equivalence # Equivalence # If we pick two terminals within a circuit, we say that another circuit is equivalent to the original circuit if it exhibits the same $I$-$V$ relationship at those two terminals.\nAn example of an $I$−$V$ is that of a resistor, i.e., $V = IR$ or $I= \\frac{V}{R}$ We can do this since voltage and current are governed by a linear relationship (in 16A), and a line can be uniquely determined by exactly two points, we can capture the original circuit with a simplified circuit that has exactly two components: a voltage (or current) source and a resistor ### [Short-circuit current](https://en.wikipedia.org/wiki/Short_circuit): \u003e Current $I_\\text{sc} \\equiv I_{No}$ when $V_S = 0$. Used for norton equivalent If we look at the $I$-$V$ plot of a voltage source $V_S$, where $I$ is the current going through the voltage source, then the plot would be a vertical line: ![](/docs/eecs-16a/7/eqv.png) $V_S = 0$ means that it allows any current to go through, however the voltage drop always remains zero. This is exactly what a wire element (sometimes called a short circuit) does. ### [Open-circuit voltage](https://en.wikipedia.org/wiki/Open-circuit_voltage): \u003e Voltage $V_\\text{open} \\equiv V_{Th}$ when $I_S = 0$. Used for thevenin equivalent If we plot the $I$-$V$ graph of a current source $I_S$, we get the a horizontal line: ![](/docs/eecs-16a/7/eqi.png) If we turn off the current source, $I_S = 0$, which means no matter what voltage you apply, there will be no current. This is equivalent to an open circuit. Motivation # When we add a new component to a circuit, it interacts through only 2 parameters: current $I$ and voltage $V$. Equivalent circuits are used to simplify interactions between circuits.\nLet’s take the simplest case where interactions are only through one pair of nodes. In that case, we just have two possible quantities: the voltage across the nodes and the current flowing through the connections. The relationship between this current and this voltage would then fully define the interactions between the circuits. This is where the idea of equivalence comes in. If we have a circuit that exhibits the same $I$−$V$ relationship from the standpoint of a pair of nodes, the other circuit (the one you are interacting with) can’t tell the difference.\nThe idea of equivalence is to be able to replace one (or both) of the interacting circuits with a simpler circuit that will give us the same overall behavior.\nLimitations # The $I$-$V$ characteristic is the only feature preserved by an equivalent circuit Equivalence tells us nothing about the power in a circuit. From the standpoint of any other nodes in the circuit (i.e. any pairs of nodes), the circuit may or may not be equivalent That is, looking at the same circuit but examining a different pair of terminals may not produce equivalent $I$−$V$ relationship. Series \u0026amp; Parallel # These are proven starting page 10 of notes We cannot use these to simplify our circuit if there are dependent sources. Remember that only independent sources are zeroed out, and there are no resistor formulas for dependent sources. In addition, some resistor configurations cannot be decomposed into combinations of parallel and series resistances. - **[Series](https://en.wikipedia.org/wiki/Series_and_parallel_circuits#Series_circuits)**: - The voltage is the sum of the voltage drops of the individual components: $$V = V_1 + \\dots + V_n = I (R_\\text{total})$$ - From _KCL_ we know **elements will have the exact same _current_ through them**: $$I = I_1 = \\dots = I_n$$ - Resistance is the sum of their individual resistances: $$R_\\text{total} = R_1 + \\dots R_n$$ - **[Parallel](https://en.wikipedia.org/wiki/Series_and_parallel_circuits#Parallel_circuits)**: - From _KVL_ we know **elements will have the exact same _voltage_ across them**: $$V = V_1 = \\dots = V_n$$ - The current in each individual element is found by Ohm's law: $$I = I_1 + \\dots + I_n = V R_\\text{total}$$ - Total resistance will always be less than the value of the smallest resistance $$\\frac{1}{R_\\text{total}} = \\sum_{i=1}^n \\frac{1}{R_i}$$ \u003e [Notation](https://en.wikipedia.org/wiki/Series_and_parallel_circuits#Notation): We use $\\parallel$ to denote parallel components Comparison of effective resistance (left), inductance (middle) and capacitance (right) of two resistors, inductors and capacitors in series and parallel\nThevenin # \u003e Any linear two-terminal circuit can be replaced at terminals $A$–$B$ by an equivalent combination of a voltage source $V_{Th}$ in a series connection with a resistance $R_{Th}$ -- [wiki](https://en.wikipedia.org/wiki/Th%C3%A9venin%27s_theorem) 1. **Find** $V_{Th}$: - We recognize that it equals the difference in node potentials at $A$ and $B$, so performing NVA on the original circuit will yield $V_{Th}$ - Connect an **open circuit** across the two output terminals and measure the voltage across them. This measured $V_{oc}$ equals $V_{Th}$. 2. **Find** $R_{Th}$: **Zero out any independent sources.** Remember, this means voltage sources turn into a wire and current sources turn into an open circuit. Then apply either a test current into the terminal and measure the resultant voltage, or apply a test voltage and measure the resultant current. $R_{Th}= \\frac{V_{test}}{I_{test}}$ ![](https://upload.wikimedia.org/wikipedia/commons/d/dc/TheveninEquivalent-2.png) ![](/docs/eecs-16a/7/thev.png) Norton # \u003e Any linear two-terminal circuit can be replaced by a current source $I_{No}$ and a single resistor $R_{No}$ in parallel -- [wiki](https://en.wikipedia.org/wiki/Norton%27s_theorem) 1. **Find** $I_{No}$: Connect a **short circuit** across the two output terminals and measure the current through it. This measured $I_{Sc}$ equals $I_{No}$. 2. **Find** $R_{No}$: **Zero out any independent sources.** Remember, this means voltage sources turn into a short circuit and current sources turn into an open circuit. Then apply either a test current into the terminal and measure the resultant voltage, or apply a test voltage and measure the resultant current. $R_{Th}= \\frac{V_{test}}{I_{test}}$ - Note that the second step doesn’t change because $R_{No}$ is equal to $R_{Th}$! ![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/NortonEquivalentCircuits.png/1024px-NortonEquivalentCircuits.png) ![](/docs/eecs-16a/7/norton.png) Relation / Conversion # A Norton equivalent circuit is related to the Thévenin equivalent by $$R = R_{Th} = R_{No}$$ $$V_{Th} = I_{No}R$$ $$I_{No} = \\frac{V_{Th}}{R} $$ ![](https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Norton-to-thevenin.png/260px-Norton-to-thevenin.png) Note that $R_{No}$ is equal to $R_{Th}$, since the slope of the $I$-$V$ curve is the same. Now, instead of looking at the $V$-axis intercept, we find the intersection with the $I$-axis: At the intersection with the $I$-axis, the voltage drop between $A$ and $B$ is zero, which is equivalent to placing a wire between $A$ and $B$ (i.e. shorting $A$ and $B$). We denote the current through the wire be $I_{No}$.\n**Why this works:** - Since the $I$-$V$ relationship is linear, we can calculate the slope (which is the reciprocal of resistance) from any two points. $V_{Th}$ and $I_{No}$ are the points where the $I$-$V$ curve crosses the$V$ and $I$ axes, respectively (see the left-hand figure). ![](/docs/eecs-16a/7/eqgraph.png) However, this method does not work if $V_{Th}$ and $I_{No}$ do not provide two unique points on the $I$-$V$ curve (see the right-hand figure). Specifically, this method only works if there is at least one independent source in the circuit. When there are no independent sources, $V_{Th} = I_{No} = 0$ which does not provide enough information to calculate Req. Superposition # Recall two weeks back: To solve for the currents and node potentials in a circuit, we set up a matrix problem of the form $A\\vec x =\\vec b$ where $\\vec x$ contained the unknown currents and node potentials, $\\vec b$ contained the independent current and voltage sources, and $A$ described the relationship between them. Since this matrix equation describes a real system, we know that there is a unique solution. Therefore, $A$ is invertible: $$\\vec x = A^{−1} \\vec b$$ This means that we can describe any current or node potential (ie. any element of $\\vec x$) as a linear combination of the independent current and voltage sources (the elements of $\\vec b$).\nFor example, consider a circuit with $n$ independent sources voltage sources $V_{s1} \\dots V_{sn}$, and $m$ independent current sources $I_{s1} \\dots I_{sm}$. An arbitrary node potential $u_i$ (or equivalently, an arbitrary current $i_i$) can be written as $$u_i = \\alpha_1 V_{s1} + \\dots +\\alpha_n V_{sn} + \\beta_1 I_{s1} + \\dots \\beta_m I_{sm}$$ where the $\\alpha$’s and $\\beta$’s are coefficients from inverting $A$. Since this equation is linear, we can calculate each term of this equation separately and then add them together at the end.\nFor example, if we want to calculate the first term, $\\alpha_1 V_{s1}$ we can set all of the other voltage and current sources to zero, then solve for $u_i$. Repeating this for every source then adding the results is equivalent to calculating $u_i$ with all of the sources present. However, splitting up the calculations can help us see simplifications and patterns that might be less obvious with all of the sources present.\n**TL;DR:** - For each independent source $k$ (either voltage source or current source) - Set all other independent sources to $0$ - _Voltage source:_ replace with a wire -- no voltage drop - _Current source:_ replace with an open circuit -- no current flows - Compute the circuit voltages and currents due to this source $k$ - Compute $V_\\text{out}$ by summing the $V_{\\text{out; }k }$s for all $k$. We can apply the idea of replacing elements with equivalent elements (e.g. replacing a $V_S = 0$ voltage source with a wire) to resistors as well. When do resistors have an equivalent representation? Recall that by Ohm’s law, the $I$-$V$ graph across a resistor. From this we can see: - Zero voltage source and zero resistance are equivalent to wires (i.e. short circuits); - Zero current source and infinite resistance are equivalent to open circuits ![](/docs/eecs-16a/7/limgraph.png) "},{"id":27,"href":"/e-29/7/","title":"7-9: Visualization","section":"Engineering 29","content":" Orthographic projections # Formal (working) drawings: purpose # - Need a formal way of documenting designs - Legal documents i.e patents; contracts may rely on them - Must stand on their own -- readable to any human - No subsequent explanation - No verbal assists - No ambiguity - Solution: multi-view [orthographic projection](https://en.wikipedia.org/wiki/Orthographic_projection) - World-wide engineering standard - Can easily include tolerances ![](/docs/e-29/7/purpose.png) What is a projection? # Projection of a 3D object’s edge onto a 2D plane by rays perpendicular to that plane such that they are parallel to one another (unlike real-world) ![](/docs/e-29/7/proj1.png) Dashed lines represent hidden detials ![](/docs/e-29/7/proj2.png) Projections are independent of projection distance Projection depends on part orientation # - Use judgement to select most useful/informative orientation - Often, a projection is clearest when a significant flat surface of the object is parallel to the projection plane - Left is a better pictorial view (it's more 3D) - Right is better because it's face is parallel ![](/docs/e-29/7/orient.png) Multi-view orthographic projection # Usually can’t convey all information about an object using a single projection Use multiple projections from different viewpoints What is an orthographic projection? # Orthos: Greek for \u0026ldquo;right\u0026rdquo;, \u0026ldquo;true\u0026rdquo;, or \u0026ldquo;correct\u0026rdquo; Each projection is formed by rays perpendicular (at right angles) to its projection plane The different views of a multi-view drawing are taken from viewpoints at right angles to each other Multi-view orthographic projection is a standardized, accepted form of representing objects Graphos: drawing ## \"Glass-box\" interpretation - Need an agreed way to organize different projections on the page - Imagine projecting object onto sides of a box - Unfold the box onto the page - So-called \"third-angle\" projection - Will not necessarily show all six projections - Projections are aligned ![](/docs/e-29/7/glass.png) ## Example of multi-view orthographic projection - Lines connecting a given point in adjacent views are always perpendicular to the \"unfolding\" line (of the \"glass box\") ![](/docs/e-29/7/mview.png) ![](/docs/e-29/7/visible.png) ![](/docs/e-29/7/hidden.png) View interpretation # Need to consider how many views needed to remove ambiguity Multiview characteristics # - Inclined face - Face in 2 views - Line in 3rd view ![](/docs/e-29/7/incl.png) - Oblique face - Face in 3 views ![](/docs/e-29/7/obl.png) Which is the oblique face? # How many views? # \u003e- Example: cut from sheet material \u003e- Unlikely to be multiple levels of relief \u003e- Projections of edges therefore unnecessary \u003e- Grooves or etched patterns would be labeled as such \u003e![](/docs/e-29/7/how0.png) --- \u003e![](/docs/e-29/7/how2.png) \u003eIn this case, two views not enough to describe geometry completely -- we need 3 \u003e- Thick enough material that there could conceivably be multiple levels of relief: side view needed \u003e- In this particular example, all features pass through the full thickness of the material \u003e![](/docs/e-29/7/how.png) --- \u003e![](/docs/e-29/7/how3.png) \u003eWould any two views be enough to describe the geometry completely? Example of hidden lines # First- vs third-angle orthographic projection # - 3rd angle projection used in U.S. - glass box convention ![](/docs/e-29/7/3rd.png) - 1st angle projection (Europe, Japan, India) - top/bottom and left/right arrangement reversed ![](/docs/e-29/7/1st.png) Example of why specifying 1st or 3rd angle matters ANSI standards (Y14.5) # - Adopted by drafters and engineers to expedite the transfer of information - Maximum information with the minimum drawing - Will only cover highlights here - Views - At least two views (except flat sheet) - Add views as required so the dimensions of the object can be defined entirely in true length measurements - Add views as necessary for presentation clarity - Solid lines - Assumed to be intersections of planes or optical limits of cylinders - Tangent edges are usually not shown, or shown using phantom lines - Hidden lines - Use to add information, clarity (good practice not to over-use) - Use views requiring the fewest hidden lines - Center lines - Use to mark the centers of holes, or cylindrical surfaces ≥180º - Circles - Assumed to be intersections of cylinders and orthogonal planes - Section views - Used for clarification of internal geometries - Explained in a later lecture \u003e ![](/docs/e-29/7/scuts.png) \u003e ![](/docs/e-29/7/scut2.png) \u003e Small cuts on curved surfaces \u003e![](/docs/e-29/7/radii.png) \u003e Small radii, intersections of blended planar surfaces shown as a line \u003e![](/docs/e-29/7/threads.png) \u003e Representing threads use schematic representations \u003e![](/docs/e-29/7/rotat.png) \u003e Parts with odd rotational symmetry \u003e Simplify to a symmetrical view even though that is not a strictly accurate projection \u003e![](/docs/e-29/7/atan.png) \u003e Tangent and non-tangent surfaces \u003e - A line drawn where a curved surface meets a planar surface indicates no tangency: i.e. there is an abrupt change in the angle of the surface \u003e - No drawn line indicates tangency: i.e.surface angle is continuous/smooth Pictorial views # Review of isometric, oblique, and perspective # Color; shading # Section views # Advanced projections # Auxiliary views # Additional notation # Dimensioning # Showing welds # "},{"id":28,"href":"/eecs-16a/8/","title":"8: Capacitors \u0026 Capacitive Touchscreen","section":"EECS 16A","content":" \\(\\) 03/15 Capacitors # Structure and Physics # See also, [7B 24](../physics-7b/24.md) - [Capacitors](https://en.wikipedia.org/wiki/Capacitor) is a circuit element that stores charge - Positive [charges](https://en.wikipedia.org/wiki/Charge_(physics)) build up on the (top) surface of the plate connected to the positive terminal and negative charges build up on the (bottom) surface of the plate connected to the negative terminal. - Capacitors have an associated quantity, [**$C$apacitance**](https://en.wikipedia.org/wiki/Capacitance) (farads); the ratio of the amount of [electric charge](https://en.wikipedia.org/wiki/Electric_charge) $Q$ (coulombs) stored on a conductor to a difference in electric potential $V$ - Units: [Farads](https://en.wikipedia.org/wiki/Farad), $F = \\frac{C}{V}$. - Depends on the physical geometry of a capacitor $$C = \\varepsilon_0 \\frac{A}{d}$$ - $A$: Area of plates - $d$: Distance between plates - $\\varepsilon_0$: [Permittivity](https://en.wikipedia.org/wiki/Permittivity) of [free space](https://en.wikipedia.org/wiki/Vacuum_permittivity), $8.854\\cdot 10^{-12} \\frac{\\text{F}}{\\text{m}}$ \u003e![](/docs/eecs-16a/8/cap.png) \u003eA physical diagram of a capacitor, with 2 metal plates and a [dielectric](https://en.wikipedia.org/wiki/Dielectric) (commonly air) between them For most purposes, capacitors do not have polarity\u0026ndash; their orientation doesn’t impact their behavior. The plate that corresponds to the \u0026ldquo;+\u0026rdquo; terminal, stores $+Q = +CV$ and the plate that corresponds to the \u0026ldquo;-\u0026rdquo; terminal stores $−Q = −CV$ The amount of charge $Q$ on a capacitor is related to its geometrical structure (capacitance $C$) and the voltage applied to it $V$: $$Q=CV$$ When we apply a voltage across the conductive plates, we create a potential difference, and so charges will build up on the plates They will not build up indefinitely because this potential difference is not infinitely strong At some point, an additional positive charge will be ambivalent about joining the plate; while there is a potential difference $V_+ − V_−$ between the plates attracting the charge, there are also repulsive forces from the charges that already exist on the plate After this amount of critical charge forms on the plate, no additional charge will enter Geometry The more the $A$rea, the more the total charge that can fit on the plate because the individual charges can spread out more, decreasing the repulsive forces Smaller the $d$istance between the plates, the more strongly the $+$ and $−$ charges attract each other That is, for the same voltage, decreasing the distance of plate separation increases the charge that will build up on the plate ## Energy Storage \u003e When we apply a potential difference, charges build up on the plates; these charges are the reason that a capacitor stores energy. The repulsion between charges on a given plate means that moving a charge onto the plate takes energy (supplied by the voltage source). **The more charge already on a plate, the more energy it takes to push another charge on.** $$V = \\frac{dE}{dQ}$$ $$dE = V dQ$$ $$dE = V \\cdot d (CV)$$ $$\\int dE = C \\int_0^V V\\ dV$$ $$ \\Longrightarrow E = \\frac{1}{2}CV^2$$ This is the energy of a capacitor when it is fully charged, holding the complete $Q$ determined by $C$ and $V$. $I$-$V$ Relationship and Behavior # Current # $$Q = CV$$ $$\\frac{dQ}{dt} = \\frac{dCV}{dt}$$ $$ \\Longrightarrow I = C \\frac{dV}{dt}$$ - **Current is only flowing through the capacitor if the voltage across the capacitor is changing with time** - If the voltage is no longer changing, then the current through the capacitor will equal 0. - That is, in [steady state](https://en.wikipedia.org/wiki/Steady_state#Electrical_engineering) (after the current has been running for a very long time), direct current (DC) capacitors act as open circuits ![](/docs/eecs-16a/8/graph.png) If the voltage across it is constant, then the plates are already full of charge for that voltage That is, any additional charge will feel the repulsive forces of the existing charges and will not want to enter the plate. Note that the negative charges build up on the bottom plate; this happens because the positive charges on the top plate push the positive charges away from the bottom plate. This means that in reality, the charges entering the top plate are not the same exact physical charges that exit the bottom plate, but it doesn’t matter! From the perspective of the other circuit elements (and for our purposes), current flows just the same\nVoltage # $$I = C \\frac{dV}{dt}$$ $$I\\ dt = C\\ dV$$ $$\\int I\\ dt = \\int_0^V C\\ dV$$ $$It = C(V(t) - V(0))$$ $$V(t) = \\frac{I}{C}t + V(0)$$ ![](/docs/eecs-16a/8/g2.png) To integrate the left-hand side, we assume that the current $I$ is constant wrt time. Network Simplifications # Full derivations start [page 5](https://eecs16a.org/lecture/Note16.pdf#page=5) Note We can only simplify (that is, find $C_{eq}$) iff we know the starting states of each capacitor ### Parallel ![](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Capacitors_in_parallel.svg/220px-Capacitors_in_parallel.svg.png) - Parallel capacitors share terminal nodes, thus the voltage across capacitors is equal at steady state. - Therefore, their capacitances add up: $$C_{eq} = \\sum_i C_i = C_1 + \\dots + C_n$$ - Intuitively, charge is apportioned among them by size. ![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Kondensator_C1_plus_C2.svg/220px-Kondensator_C1_plus_C2.svg.png) ### Series ![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Capacitors_in_series.svg/220px-Capacitors_in_series.svg.png) - Series capacitors have the same current through them by KCL - The entire series acts as a capacitor smaller than any of its components: $$\\frac{1}{C_{eq}} = \\sum_i \\frac{1}{C_i} = \\frac{1}{C_1} + \\dots + \\frac{1}{C_n}$$ - Intuitively, the separation distance, rather than plate area, adds up - The inner middle two plates carry equal and opposite amounts of charge, so their net contribution to charge storage is $0$ - If all initially uncharged, the charge across all are equal to each other at steady state ![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/01/Kondensator_C1_C2_Reihe.svg/220px-Kondensator_C1_C2_Reihe.svg.png) Note: The parallel operator $\\parallel$ is just a mathematical tool; it happened to describe the equivalence for resistors in parallel but the operator actually applies to capacitors in series. As with resistors in parallel, capacitors in series are best simplified pairwise; that is, for a system with capacitors in series can be simplified as $C_{eq} = C_1 \\parallel C_2 = \\frac{C_1 C_2}{C_1 + C_2}$\n03/18 Capacitive Touchscreen # When there is touch, we form a capacitor It is worth noting that there is capacitance everywhere because everything is a conductor (to some extent). There is capacitance between your fingers and your laptop keys, your fingers and our phone, and (to a much lesser extent) you and Pluto!\nMeasuring $V$ or $I$ # - When we have no touch, we have an open circuit so we only have $C_0$ - When we do touch, we close the circuit so $C_1$ and $C_2$ both begin charging: $$C_0 + C_1 \\parallel C_2$$ $$C_0 + \\frac{C_1 C_2}{C_1 + C_2}$$ $$C_0 + \\Delta C$$ $$C_0 + C_{eq}$$ ![](/docs/eecs-16a/8/touch2.png) DC # - Assuming $V_{out}(0) = 0$ $$I_S = C_{eq} \\frac{d V_{out}(t)}{dt}$$ $$V_{out} = \\int_0^t \\frac{I_S}{C_{eq}}dt$$ $$\\dots = \\frac{I_S t }{C_{eq}}$$ $$ \\Longrightarrow C_{eq} = \\frac{I_S t}{V_{out}} $$ ![](/docs/eecs-16a/8/op1.png) Downside: - $V_C$ will grow to infinity - Can't to build a current source easily AC # If we replace our regular direct current (DC) source with an alternating current (AC) source then we don\u0026rsquo;t have to worry about $V_C \\to \\infty$ $$V_C(t) = \\begin{cases} \\frac{I}{C}t \u0026amp; t \\in \\gamma [0, \\frac{T}{2}) \\\\ -\\frac{I}{C}(t- \\frac{T}{2}) + \\frac{I}{C} \\frac{T}{2} \u0026amp; t \\in \\gamma [\\frac{T}{2}, T) \\\\ \\end{cases}; \\gamma \\in \\mathbb{Z^+}$$ Measuring $\\Delta C$ # We can’t measure capacitance directly, but if we can transform capacitance into a voltage, we can measure that.\n### Attempt 1 Doesn't work: $V_{out} = V_s$ regardless of if there is a touch or not ![](/docs/eecs-16a/8/cap1.png) Attempt 2 # **Phase 1 ($\\phi_1$):** Close $s_1$, open $s_2$ $$Q_{eq} = C_{eq} V_S $$ ![](/docs/eecs-16a/8/cap2.png) **Phase 2 ($\\phi_2$):** Close $s_2$, open $s_1$ - Results in [Charge sharing](https://eecs16a.org/student-resources/charge_sharing_algorithm.pdf) causing unknown/ambiguous initial conditions ![](/docs/eecs-16a/8/cap22.png) Attempt 3 # **Phase 1 ($\\phi_1$):** Close $s_1, s_3$, open $s_2$ - $C_{eq}$ charges: $Q_{eq} = C_{eq} V_S$ - $C_{ref}$ discharges: $Q_{ref} = C_{ref} V_{out} = 0$ $$Q_{\\phi 1} = C_{eq} \\cdot V_S$$ ![](/docs/eecs-16a/8/cap31.png) By [conservation of charge](https://en.wikipedia.org/wiki/Charge_conservation) $$Q_{\\phi 1} = Q_{\\phi 2}$$ $$C_{eq} \\cdot V_S = C_{eq} \\cdot V_{out} + C_{ref} \\cdot V_{out}$$ $$ \\therefore V_{out} = \\frac{C_{eq}}{C_{eq} + C_{ref}} V_S$$ therefore, when touching we change voltage! **Phase 2 ($\\phi_2$):** Close $s_2$, open $s_1, s_3$ - $V_{C_{eq}} = V_{out}$ - $V_{C_{ref}} = V_{out}$ $$Q_{\\phi 2} = C_{eq} \\cdot V_{out} + C_{ref} \\cdot V_{out}$$ ![](/docs/eecs-16a/8/cap32.png) ![](/docs/eecs-16a/8/vout.png) "},{"id":29,"href":"/eecs-16a/9/","title":"9: Op-Amps, Comparators \u0026 Charge Sharing","section":"EECS 16A","content":" \\(\\) 03/29: Operational Amplifier and Comparator # Dependent Sources # As briefly mentioned before, the voltage and current sources covered so far have been independent sources, meaning they have a constant, fixed value. However, dependent sources also generate currents and voltages but their output depends on some other \u0026ldquo;controlling\u0026rdquo; current .$i_x$ or voltage .$v_x$ in the circuit.\n\u003e**VCVS:** Voltage-controlled voltage source \u003e![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/Voltage_controlled_voltage_source_circuit.svg/200px-Voltage_controlled_voltage_source_circuit.svg.png) \u003e* .$V = f_a (v_x)$ \u003e* [Unitless](https://en.wikipedia.org/wiki/Dimensionless_quantity).$^1$ voltage gain .$a$ \u003e* E.x. [Voltage amplifier](https://en.wikipedia.org/wiki/Amplifier#Ideal) \u003e* Input, output impedance: .$\\infty, 0$ \u003e**CCCS:** Current-controlled current source \u003e![](https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Current_controlled_current_source.svg/200px-Current_controlled_current_source.svg.png) \u003e* .$I = f_c (i_x)$ \u003e* [Unitless](https://en.wikipedia.org/wiki/Dimensionless_quantity).$^1$ voltage gain .$c$ \u003e* E.x. [Current amplifier](https://en.wikipedia.org/wiki/Amplifier#Ideal) \u003e* Input, output impedance: .$0, \\infty$ \u003e**VCCS:** Voltage-controlled current source \u003e![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Voltage_controlled_current_source.svg/200px-Voltage_controlled_current_source.svg.png) \u003e* .$I = f_b (v_x)$ \u003e* Units: [Siemens](https://en.wikipedia.org/wiki/Siemens_(unit)), .$S$; .$\\Omega^{-1}, \\mho$ \u003e* E.x. [Transconductance](https://en.wikipedia.org/wiki/Transconductance) amplifier with conductance .$b$ \u003e* Input, output impedance: .$\\infty, \\infty$ \u003e**CCVS:** Current-controlled voltage source \u003e![](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Current_controlled_voltage_source.svg/200px-Current_controlled_voltage_source.svg.png) \u003e* .$V = f_d (i_x)$ \u003e* Unit: Ohms \u003e* E.x. [Transresistor](https://en.wikipedia.org/wiki/Transconductance#Transresistance) with resistance .$d$ \u003e* Input, output impedance: .$0, 0$ $^1$The proportionality constant between dependent and independent variables is unit/dimension-less if they are both currents (or both voltages)\nOp-Amp # An operational amplifier (op-amp) is a device that transforms a small voltage difference into a very large voltage difference. Made up of\u0026hellip; - Two input terminals with potentials: - $U_+$ (non-inverting) and - $U_-$ (inverting) - **Signal voltage** = $\\Delta U = U_+ - U_-$ - Two power supply terminals - $V_{DD}$ (positive power supply) and - $V_{SS}$ (negative power supply) - One output terminal with potential: - $U_{out} \\in [V_{SS}, V_{DD}]$ \u003e![](/docs/eecs-16a/8/sym.png) - We can model the op-amp behavior with the two VCVS circuit to the right - Notice that no current is drawn from either power supply terminals so the behavior of the circuit shouldn't change - $A$ is the internal signal [gain](https://en.wikipedia.org/wiki/Gain_(electronics)) - Unit-less quantity - The larger $A$, the sharper/quicker the transition between $V_{SS}$ and $V_{DD}$ \u003e![](/docs/eecs-16a/8/op.png) With KVL we can find $U_{out}$: Except we can\u0026rsquo;t have $U_{out} \u0026gt; V_{DD}$ or less than $V_{SS}$ so we end up clipping $U_{out}$ \u0026ndash; this is called railing $$U_{out} = V_{SS} + \\frac{V_{DD} - V_{SS}}{2} + A \\Delta U$$ $$\\dots = \\frac{V_{DD} + V_{SS}}{2} + A \\Delta U$$ $$\\dots = \\begin{dcases} V_{SS} \u0026amp; \\frac{V_{DD} + V_{SS}}{2} + A \\Delta U \u0026lt; V_{SS} \\\\ V_{DD} \u0026amp; \\frac{V_{DD} + V_{SS}}{2} + A \\Delta U \u0026gt; V_{DD} \\\\ \\frac{V_{DD} + V_{SS}}{2} + A \\Delta U \u0026amp; \\text{otherwise} \\\\ \\end{dcases}$$ - **Rail-determined offset:** $\\dfrac{V_{DD} + V_{SS}}{2}$ - $y$-intercept in $V_{out}, \\Delta U$ graphs - Zero in NFB, that is $$U_+ = U_-$$ - **Signal gain:** $A \\Delta U = A (U_+ - U_-)$ - $A$ is the slope of the zone between rails - $A \\approx \\infty$ is a vertical line Op-Amp as a Comparator # The sign of the output will indicate which input voltage is larger. We often want to know whether $V_?$ is smaller or larger than $V_{ref}$ so we\u0026rsquo;ll set $ V_- = V_{ref}$ and $V_+ = V_?$ - The blue region is the (super narrow, and in the ideal case, perfectly vertical) linear region where the input actually has \"space\" to be amplified without clipping - For the vast majority of realistic inputs, the outputs sits at one of the rails (here, $V_{SS} = −2V$ and $V_{DD} = 3V$) - In this way, the sign of the output directly gives the relationship between $V_{?}$ and $V_{ref}$ - Note that with zero input difference, the output voltage ($y$-intercept) sits at the **rail-offset**: $\\left(0, \\dfrac{V_{DD} + V_{SS}}{2} \\right) = (0, 0.5)$ ![](/docs/eecs-16a/8/blu.png) Comparator # - **[Comparator](https://en.wikipedia.org/wiki/Comparator):** Enables us to take a _wonky_ digital signal (i.e voltage) and convert it to a binary output signal - Optimized for binary output and speed - Used in devices that measure and digitize analog signals i.e [ADCs](https://en.wikipedia.org/wiki/Analog-to-digital_converter) ![](/docs/eecs-16a/8/comps.png) $$U_{out} = \\begin{cases} V_{DD} \u0026 U_+ \u003e U_- \\\\\\ V_{SS} \u0026 U_+ \u003c U_- \\\\\\ \\end{cases}$$ ![](/docs/eecs-16a/8/comp.png) Capacitive Touchscreen with Comparator # AC # See last weeks notes: 8: AC Source\n- Because they are on the same node, we can observe $U_+ = V_C$ and $U_− = V_{ref}$ - The power sources are $V_{DD} = 3.3V$ and $V_{SS} = 0$, thus we can write the following: $$V_{out} = \\begin{cases} 3.3V \u0026 V_C \u003e V_{ref} \\\\\\ 0V \u0026 V_C \u003c V_{ref} \\\\\\ \\end{cases}$$ So how do we choose $V_{ref}$? We want our comparator to be high (on, $V_{out} = V_{DD}$) depending on touch (or lack thereof) Thus we should set $V_{ref}$ to be between the peak of $V_C$ with a finger and the peak of $V_C$ without a finger To be fairly robust to noise/error, $V_{ref}$ should be exactly between the two peaks: $$V_{ref} = \\frac{V_{C, touch} + V_{C, no\\ touch}}{2} = \\dots = \\frac{1}{2} \\frac{C_{eq} + \\Delta C}{C_{eq} + C_{ref} + \\Delta C}\\frac{C_{eq}}{C_{eq}+C_{ref}}$$ \u003e![](/docs/eecs-16a/8/peeks.png) \u003eWhen there is a finger present, $V_C$ is always less than $V_{ref}$ so the output voltage is 0 \u003e![](/docs/eecs-16a/8/notouch.png) \u003eNow every period of the current source cycle, $T$, we can measure if there is a finger touching this pixel DC # We can also use a DC voltage source too and end up with the same equation\n03/31: Charge Sharing and Negative Feedback # Charge Sharing # Floating node: Node out of or into which no charge can flow \u0026ndash; virtual ground We apply charge sharing to these nodes If the sum of charges is 0 on a floating node, the sum of charges on that floating node at steady state will stay 0. Examples: Nodes connected only to capacitor plates Nodes connected only to op-amp inputs or comparator inputs Notation: In each phase, the circuit has a different configuration by opening/closing different switches. Generally, a switch labeled $\\phi_i (i = 1,2,3, \\dots)$ will be closed in phase $i$ and open in all other phases. Switches labeled $\\phi_1$ will be closed in phase 1 and open in phase 2, Switches labeled $\\phi_2$ will be open in phase 1 and closed in phase 2. Algorithm # Step 1 # Label the voltages across all the capacitors. Choose whichever direction (polarity) you want for each capacitor - this means you can mark any one of the plates with the “+” sign, and then you can mark the other plate with the “−” sign. Make sure you stay consistent with this polarity across phases.\nStep 2 # Draw the equivalent circuit during both phases. For this problem, phase 1: $\\phi_1$ closed, $\\phi_2$ open, and phase 2: $\\phi_1$ open, $\\phi_2$ closed. Also, label all node voltages on the circuit for both phases. No need to try and maintain the same names, since certain nodes of the phase 1 circuit might be merged or split in phase 2. $\\phi_1$ ![](/docs/eecs-16a/9/p1.png) $\\phi_2$ ![](/docs/eecs-16a/9/p2.png) Step 3 # Identify all “floating” nodes in your circuit during phase 2. You can identify those nodes as the nodes connected only to capacitor plates, op-amp inputs or comparator inputs. These will be the nodes where we apply charge sharing.\nIn this case the only node that is floating during phase 2 is node $u_3$. (Node $u_2$ is connected to the voltage source, i.e. $u_2 = V_S$, and the 3rd node is the ground node)\nStep 4 # For steps 4-6 we will examine each phase 2 floating node individually. Pick a floating node from the ones you found in step 3 and identify all capacitor plates connected to that node during phase 2. Then, calculate the charge on each of these plates in the steady state of phase 1. To do so, identify all nodes in your circuit during phase 1. Label all node voltages, and write the voltages across each capacitor as functions of node voltages (step 2 should help you with that). Do this according to the polarities you have selected. Then the charge is found as $Q = CV_C$ (where $V_C$ is the voltage across a capacitor). - **Careful:** The plate marked with the “−” sign will have $Q = -CV_C$ and the plate marked with the “+” sign will have $Q = CV_C$ stored onto them. - **Careful:** We assume here that you know all node voltages during phase 1. If you don’t, before starting this procedure calculate the node voltages you need using one of the previously introduced circuit analysis techniques (most likely KVL). Looking at our single floating node we can see that the “+” plates of $C_1$ and $C_2$ are connected to it during phase 2. Let’s calculate the charge on these plates connected to the floating node $u_3$ during **phase $\\phi_1$, denoted $Q_{u3}^{\\phi 1}$** $$Q_{u3}^{\\phi 1} = V_1^{\\phi 1} C_1 + V_2^{\\phi 1} C_2 $$ $$\\dots = (V_S - 0)C_1 + 0$$ $$\\dots = V_S C_1$$ Step 5 # **Find the total charge on each of the floating nodes** in the steady state of phase 2 as a function of node voltages using the same process as Step 4. Make sure you kept the polarity same and pay attention to the sign of each plate. $$Q_{u3}^{\\phi 2} = V_1^{\\phi 2} C_1 + V_2^{\\phi 2} C_2 $$ $$\\dots = (u_3 - u_2)C_1 + (u_3 - 0)C_2$$ $$\\dots = (u_3 - V_S)C_1 + u_3 C_2$$ Step 6 # **Apply conservation of charge.** The charge in the steady state of phase 1 we calculated in Step 4, $Q_{u3}^{\\phi 1}$, is the initial charge of phase 1. Charge must be conserved at a floating node, so the steady state charge of phase 2, $Q_{u3}^{\\phi 2}$, should equal the initial charge $Q_{u3}^{\\phi 1}$. We can then write in terms of the unknown(s). $$Q_{u3}^{\\phi 1} = Q_{u3}^{\\phi 2} $$ $$V_S C_1 = (u_3 - V_S)C_1 + u_3 C_2 $$ $$u_3 = \\frac{2C_1}{C_1 + C_2}V_S$$ Step 7 # **Repeat steps 4-6 for every floating node**. This will give you one equation per floating node (i.e. if you have $m$ floating nodes you will have $m$ equations). You can then solve the system of equations to find the node voltages during phase 2 (unknowns). In this problem we did not go through step 7 since we only had one floating node during phase 2. This means we have only one unknown node voltage ($u_3$) for which we solved using our single equation from Step 6. [Example 2 on page 4](https://eecs16a.org/lecture/Note17B.pdf#page=4) has multiple floating nodes. Important Notes # A node that is floating during phase 2 is not necessarily floating during phase 1. In fact, it could have been two separate nodes during phase 1 depending on how your switches are configured. We only care about the floating nodes during phase 2 since those are the nodes with unknown voltages. What about floating nodes during phase 1? You should be able to calculate the voltage of these nodes based on the initial condition of the circuit and the circuit techniques that you have learned so far (most likely KVL). When handling charge sharing problems you should avoid using any parallel or series capacitance formulae that you have learned. Any simplification of the circuit might lead to mistakes since the circuit in different phases is configured differently and some capacitors placed in series during one phase may be in parallel or even not connected at all in another phase! "},{"id":30,"href":"/e-29/10/","title":"10: Metrology","section":"Engineering 29","content":" \\(\\) Terminology # Metrology: The scientific study of measurement When we manufacture many nominally “identical” components and then measure them, our measurements will inevitably show variation. Some of this variation will come from actual differences between the components’ dimensions — stemming, for example, from variation of the properties of the stock material used, cutting tool wear over time, changes in machine temperature during processing, or small, random, operator errors. Additional variation can, however, come from the measurement process itself, as there may be operator error in using a measuring instrument, or the instrument’s response may drift over time.\nIdeally, we would have some way to distinguish unambiguously between measurement errors and true dimensional deviations which might take a component outside of the specified tolerance zone. In reality, however, measurement and true dimensional errors are superimposed in the reading that we obtain. The best we can do is minimize measurement errors through the use of proper technique and appropriate instrument calibration. Reducing measurement error often costs money, however, either by requiring more expensive equipment or by needing a slower, more meticulous measurement process. The measurement process used needs to be appropriate for the task at hand. As long as the measurement error is a small fraction of the tolerance zone size, it will usually suffice.\nResolution, discrimination: The smallest difference between two measurements that can be detected E.x. in an instrument with a digital readout, the resolution corresponds to the change in reading that occurs when the least significant digit of the readout is incremented or decremented. In an “analog” instrument, such as a micrometer with a Vernier scale, the resolution is determined by the spacing between tick marks on the finest scale on the instrument. - **Accuracy:** The amount of deviation of a measurement from the [true value](https://en.wikipedia.org/wiki/Statistical_parameter) (\"inaccuracy\" really) - Description of only [systematic errors](https://en.wikipedia.org/wiki/Systematic_errors), a measure of [statistical bias](https://en.wikipedia.org/wiki/Statistical_bias) of a given measure of [central tendency](https://en.wikipedia.org/wiki/Central_tendency); low accuracy causes a difference between a result and a true value; ISO calls this _trueness_ - **Repeatability/precision:** The ability to avoid scatter/variation in successive measurements of the same physical dimension - Description of [random errors](https://en.wikipedia.org/wiki/Random_errors), a measure of [statistical variability](https://en.wikipedia.org/wiki/Statistical_variability) \u003e Accuracy is the proximity of measurement results to the true value; precision is the degree to which [repeated](https://en.wikipedia.org/wiki/Repeatability) (or [reproducible](https://en.wikipedia.org/wiki/Reproducibility)) measurements under unchanged conditions show the same results. Given a [statistical sample](https://en.wikipedia.org/wiki/Statistical_sample) or set of data points from repeated measurements of the same quantity, the sample or set can be said to be accurate if their [average](https://en.wikipedia.org/wiki/Average) is close to the true value of the quantity being measured, while the set can be said to be precise if their [standard deviation](https://en.wikipedia.org/wiki/Standard_deviation) is relatively small. Resolution, accuracy and repeatability all play a role in determining measurement error. A measurement technique could exhibit large errors in individual measurements, but when those measurements were averaged might yield a mean value that was accurate. Such a technique would have poor repeatability, and inaccurate individual measurements, but would effectively be accurate on average.\nConversely, a measurement technique might show little measurement-to-measurement variability (highly repeatable) but might always give a result that deviated greatly from the true value (highly inaccurate). Such a technique would be described as biased and would indicate poor instrument calibration.\nBasic Measurement Tools # How to read a (Micrometer\u0026rsquo;s) Vernier scale # Internal Hole Micrometer # Dial Gage # Sources of Measurement Error # - **Parallax:** where the scale is inadvertently held some distance from the edge being measured, and the angle of viewing affects the reading that is taken - **Geometrical errors:** The instrument is not aligned properly to the dimension that is to be measured. - [Cosine error](https://en.wikipedia.org/wiki/Cosine_error): When failing to use the flat portions of a caliper’s jaws to ensure the axis of a cylindrical component lies perpendicular to the diameter being measured (Measurement \u003e diameter) ![](/docs/e-29/10/geo.png) Instrument/component Distortions: when the instrument is loaded excessively (e.g. pressing too hard on a caliper thumbwheel) and either the instrument or the component distorts elastically. The distortion may be invisible to the eye, but may be larger than the resolution of the measurement tool. Hole gage is likely to be more accurate than calipers, because the hole gage will tend to center itself within the hole whereas the jaws of the caliper may come to rest across a chord of the hole, rather than a diameter, and thus underestimate the dimension. We thus expect caliper measurements of internal diameters to be biased towards underestimation. Calibration errors/drift Could be due to wear of tools Sampling Principles # $N$: Number of measurements of the same dimension $\\sigma$: Standard deviation of underlying measurement process $\\hat \\sigma$: Best estimate of standard deviation of the process, based on $N$ measurements of it: $$\\hat \\sigma = \\sqrt{\\frac{\\sum_{i=1}^N (x_i - \\hat x)^2}{N-1}}$$ The mean of our $N$ values will not exactly equal the true value. But if the measurement process is centered on the true value, the mean of $N$ measurements follows a normal distribution with standard deviation $\\sigma / \\sqrt N$ \u0026ndash; central limit theorem $\\sigma / \\sqrt N$: Standard error of the mean We can express a confidence interval for the true dimension e.g. just a 0.3% chance that true value lies outside $\\hat x \\pm \\dfrac{3 \\hat \\sigma}{\\sqrt N}$ See 68–95–99.7 rule ## Measurement Processes: Important Messages - Measurement processes have inherent variability - Multiple measurements of a single dimension help build confidence in our estimate of the dimension - Part-to-part dimensional variation and measurement variation both need to be considered ![](/docs/e-29/10/p2p.png) Advanced Metrology # Electromechanical Systems: Coordinate Measuring Machines (CMMs) # Industrial dimensional measurement has increasingly moved towards automated coordinate measurement machines (CMMs). A CMM has a solid probe mounted in a rigid frame and its position is actuated with motors and leadscrews having highly accurate positional feedback. In sophisticated machines, the probe may have five or more degrees of freedom to enable access to complex geometries. The probe is touched against multiple locations on a component under test, contact is detected by force sensors in the probe assembly, and software interprets the measurements to check dimensions against a solid model.\nThe probe is usually spherical and made of a hard material with a low friction coefficient such as synthetic ruby, to enable many measurements to be made without the tip significantly eroding or visibly scratching the component under test.\nLower-cost CMM machines are available, which are not as rigid but are more portable. These usually have the probe assembly on an articulated arm, with encoders in each joint that determine angular positions of the joints and thus the position of the tip at any given moment. We will see a demonstration of such an arm, a Romer system from Hexagon Metrology, in Lab 7on dimensional measurements. The accuracy of an arm-mounted CMM may be more than ten times poorer than a conventional, more rigid frame-mounted system.\nStereo Vision Systems # Stereo vision systems use the same principle as human sight to extract depth information from pairs of images. By illuminating a component with structured light to define unambiguous features on a surface, and then sweeping a pair of cameras around the component, software can determine complex 3D shapes which would require hours of laborious mechanical scanning to measure with a CMM.\nThey require the surface being measured to scatter light uniformly, so polished surfaces have to be laboriously coated with a thin layer of fine powder – which must later be removed. This requirement removes some of the advantages over traditional CMMs. There is a basic tradeoff between dimensional resolution and field of view, and there is debate about how well the accuracy of these systems has been characterized.\nBasic Principles # Same depth-measuring principle as human vision Differences between the images captured by two cameras give surface position information Requires a light-scattering finish on component (not mirror-finish) Scanning White Light Interferometry # Object and reference beams interfere at camera to give \u0026ldquo;fringes\u0026rdquo; which show surface position of object with ~ nm resolution Consider two cases: Monochromatic (single wavelength) light: can lead to ambiguous results if $z \u0026gt; \\lambda$ White light (unambiguous determination of $z$) Path length difference (object vs reference): $2z$ For a single wavelength: Constructive interference when $z = k \\lambda /2$ Destructive interference when $z = (2k+1)\\lambda/4$ $k \\in \\mathbb{Z}^+$ E-field at camera = $E_0 (1 + e^{4\\pi z / \\lambda})$ White light: many wavelengths mix to give an intensity \u0026ldquo;envelope\u0026rdquo; at the sensor Object can be scanned over long distances in $z$ direction and topography measured unambiguously $z$ Optical Interferometry vs Contact Metrology # A different type of optical metrology exploits the wave properties of light to make dimensional measurements with a resolution smaller than a single wavelength. This technique has seen wide deployment, for example, in measuring sub-micrometer structures on integrated circuits, and characterizing finely polished mirrors, lenses and prisms.\nIn optical interferometry as shown in the class, a beam of light is split by a semi-mirrored surface (beamsplitter). One of the resulting beams (the reference beam) reflects off a flat mirror and back towards an image sensor. The other beam (object beam) is directed down to the sample surface, and then back up to the image sensor.\nLet us first consider monochromatic (single-wavelength) light. When the distance travelled by the object beam is an odd number of half wavelengths greater or less than that travelled by the reference beam, the beams destructively interfere at the image sensor and yield a dark signal at a particular pixel. When the path length difference is an even number of half wavelengths, there is constructive interference and a bright signal. For intermediate path length differences, there is an intermediate signal. Each pixel in the image sensor picks up light from a different location on the sample object, and at any given instant will receive different interference intensities if the object is not perfectly smooth. The object being measured is slowly scanned vertically away from the beamsplitter, and as the path lengths change, the signals at the image sensor oscillate. With monochromatic light, however, these oscillations are periodic and the relative positions of adjacent portions of the surface cannot be unambiguously determined, especially if the surface roughness is more than about a quarter of a wavelength.\nThus, white light is more commonly used. Here, the effects of the many wavelengths superimpose on a grayscale image sensor, and the interference intensity is at its peak only when the path length difference between object and reference beams is exactly zero. As the path length differences change, the intensity oscillations decay in magnitude, and software can fit an envelope to these intensity variations to establish relative surface positions.\nThis technique is suitable for highly accurate and precise measurements of sub-micrometer dimensional variations, but is typically limited to fields of view of a few millimeters. Moreover, because it relies on reflections, surfaces must be reasonably flat; otherwise the reflected light would not bounce back towards the image sensor.\nSummary of Metrology Techniques # Kurtz and Nesbitt, Optical Engineering 50(7), 073605 (2011) on bCourses under \u0026ldquo;Supplementary materials\u0026rdquo; "},{"id":31,"href":"/eecs-16a/10/","title":"10: NFB, GRs \u0026 Buffer + Loading","section":"EECS 16A","content":" \\(\\) 04/05: # Negative Feedback (NFB) # The main idea is \u0026lsquo;how do we get an op-amp to output a voltage that isn\u0026rsquo;t railing?\u0026rsquo; Negative feedback refers to the idea that there is some output amount that is the ideal or intended amount If the actual amount becomes larger than this reference, then the system must detect this deviation and bring it down to the reference. Similarly, if the actual amount drops too low, the system must bring it back up to the reference. Negative-feedback amplifiers helps maintain the output voltage at a constant level despite the fact that the op-amp wants to rail the output. $$\\begin{aligned} V_{out} \u0026= A(U_+ − U_−) \\\\\\ V_{out} \u0026= A(V_{in} − V_{out}) \\\\\\ V_{out} + A \\cdot V_{out} \u0026= A \\cdot V_{in} \\\\\\ V_{out}(1 + A) \u0026= A \\cdot V_{in} \\\\\\ V_{out} \u0026= V_{in} \\frac{A}{A+1} \\\\\\ V_{out} \u0026\\approx V_{in}\\ \\text{ for }\\ A \\approx \\infty \\end{aligned}$$ \u003e ![](/docs/eecs-16a/10/nfb.png) \u003e To incorporate negative feedback into our op-amp design, we must create a connection that goes from the output into the negative input So when $V_{in} \\in [V_{SS}, V_{DD}]$ we get a non-clipped output Therefore, it\u0026rsquo;s common to omit the supply terminals when the op-amp is in negative feedback When the op-amp is acting as a comparator (i.e. not in negative feedback) the output voltage is basically always either $V_{DD}$ or $V_{SS}$ However, when an op-amp is in negative feedback, the output voltage is generally independent of the supply We are implicitly stating that the supply voltages are large enough that we never clip That is, when negative feedback is applied around an amplifier with high open-loop gain it reduces the overall gain of the complete circuit to a desired value due to the loop gain Summary of terms Checking for NFB # One convenient method is to check what happens if the output voltage happens to fluctuate by a little bit above the desired output; when this change occurs and propagates back to the input of the op-amp, does it cause the output to come back down to the desired level? If so, the system is in negative feedback.\nZero out all independent sources as in Thevenin-Norton Equivalencies Voltage sources become wires and current sources become open circuits \u0026ldquo;Dink\u0026rdquo; the output If in NFB and $V_{out} \\uparrow$, then $U_- \\uparrow$ and $U_+ - U_- \\downarrow$ (the difference between the higher and lower voltages decreases if the lower voltage increases.) Then, $A(U_+ − U_−) \\downarrow$ also. From this, we can directly say that $V_{out} \\downarrow$ That is, an increase in the output voltage ultimately led to a decrease in the output voltage. Example on page 3 Golden Rules # 1: $i_- = i_+ = 0$ # No current flows in/out of the input terminals $U_-$ and $U_+$\nFor ideal op-amps, regardless of NFB Thus, the behavior of the input terminal\u0026rsquo;s circuits shouldn\u0026rsquo;t change 2: $U_- = U_+ \\iff$ NFB # - That is, the voltage potential at the positive input terminal (relative to ground) and the voltage at the negative input terminal (relative to the same ground) are the same - Intuitively, the \"error signal\" going into the op amp must be zero - Implied by $A \\to \\infty$, full proof on [page 7](https://eecs16a.org/lecture/Note18.pdf#page=7) $$\\begin{aligned} v_{in} - f v_{out} \u0026= v_c \\\\\\ v_{out} \u0026= A v_c \\\\\\ \\Longrightarrow v_{out} \u0026= \\frac{A}{1+Af}v_{in} \\\\\\ \\end{aligned}$$ Thus, $v_{in} = 0V \\implies v_c = 0V$ and $v_{out}$ can be non-zero even when $v_c = 0$ given $A = \\infty$ DAC # Digital-to-Analog Converter: Component that takes in digital signals (bits) and translates them into output analog voltages.\n04/07: Buffering, Loading, \u0026amp; Design # Reference: Op-Amp Example Circuits # Signals vs. Supply Voltages # - In real systems, voltages are typically fluctuating signals - e.x. changes in light intensity or electrical brain activity read from an EEG - Signals are voltages, they are different from the supply voltages of an op-amp because they are typically much smaller and they change over time \u003eTo distinguish, we will use the following symbol to represent time-varying voltage signals: \u003e![](/docs/eecs-16a/10/sig.png) Note that while we are alright having signals as our inputs to op-amps, voltage signals generally should not be used for power since they\u0026rsquo;d create time-varying behavior Loading # Loading: an electrical component or portion of a circuit that consumes (active) electric power\nThe loading effect makes it hard to design circuits because they mean that components will behave differently depending on what they\u0026rsquo;re connected to Specifically, if the circuit afterwards draws current through some element\u0026rsquo;s $R_{el}$, then the output voltage drops. Furthermore, the amount it drops also depends on the rest of the circuit\u0026rsquo;s resistance $R_{th}$ \u0026ndash; but we don’t want to have to redesign our circuit every time we change $R_{el}$ Example # - In the real world, the battery (voltage source) has some [parasitic](https://en.wikipedia.org/wiki/Parasitism#Etymology), [**internal resistance**](https://en.wikipedia.org/wiki/Internal_resistance) along with the wires -- $r$ - Thus, the voltage drop across the bulb depends on the value of $r$, which is determined by the battery’s internal structure - Current flows in this circuit, so some of the battery’s voltage is lost to the internal resistance of the battery - Most of the time this just means the battery/wires heat up $$V_{lightbulb} = \\frac{R_l}{R_l + r} V_{battery}$$ ![](/docs/eecs-16a/10/load.png) We want some way to ensure that no matter what $r$ is, the voltage dropped across the bulb was a constant, isolating it from the source Buffering # Buffer (amplifier): provides electrical impedance transformation from one circuit to another, with the aim of preventing the signal source from being affected by whatever currents (or voltages, for a current buffer) that the load may be produced with\nBuffers are a powerful tool because they allow us to split circuits into blocks that we can analyze separately and then combine later When circuit blocks behave the same way regardless of what they’re are connected to, we don’t need to worry about what’s inside, making it much easier to design complex circuits. Example # - We can throw a **unity gain buffer** in our situation above to solve our issue - In a unity gain buffer, $v_{in} = v_{out}$ - The voltage at the non-inverting input is $V_{bat}$ since no current can flow into the op-amp ([GR#1](10.md#1-i_---i_--0)) and the same voltage appears at the output because of our unity-gain buffer - This is the case if, by Ohm’s law, current must flow out of the op-amp-- which is perfectly fine since it’s only the inputs that current cannot flow into or out of. $$V_{lightbulb} = U_{out} = V_{battery}$$ ![](/docs/eecs-16a/10/unity.png) Now the full $V_{bat}$ will be dropped across the bulb, and we don’t need to worry about any loading effects No matter what the $r$ or $R$ values are, the circuit’s behavior is consistent Design Procedure # 1: Specification # Concretely restate the goals for the design.\nFrequently, a design prompt will include a lot of text, so we’d like to restate all of the most important features of our design. We’ll refer to these specifications later to determine if our design is complete. 2: Strategy # Describe your strategy (often in the form of a block diagram) to achieve your goal.\nTo do this, start by thinking about what you can measure vs. what you want to know For example in our capacitive touchscreen, we want to know if there is a touch and we can measure voltage. Since we know that a touch can change the capacitance, we break this down into the following block diagram: 3: Implementation # Implement the components described in your strategy.\nThis is where pattern matching is useful: remind yourself of blocks you know, (ex. voltage divider, inverting amplifier) and check if any of these can be used to implement steps of your strategy. 4: Verification # Check that the design from 3 does what we specified in 1\nCheck block-to-block connections, as these are the most common point for problems. Does one block load another block causing it to behave differently than expected? Are there any contradictions (ex. a voltage source with both ends connected by a wire, or a current source directed into an open circuit)? "},{"id":32,"href":"/math-53/10/","title":"10: Parametric Equations and Polar Coordinates","section":"Math 53","content":" 10.1 Curves Defined by Parametric Equations # Parametric equations are written as .$(f(t), g(t))$ They define curves (not functions!) Time .$t \\in [t_i, t_f]$ Initial point: .$\\big(f(t_i), g(t_i)\\big)$ Terminal point: .$\\big(f(t_f), g(t_f)\\big)$ For parametric equation in form .$\\big(h + r \\cdot \\sin(t), k + r \\cdot \\cos(t)\\big)$ on .$t \\in [0, 2\\pi]$ , the resulting curve is a circle clockwise centered around the point .$(h,k)$ Likewise, .$(r \\cdot \\cos(t), r \\cdot \\sin(t))$ is counter clockwise Useful Desmos calculator If we need to graph an equation in form .$x = g(y)$ , we can use parametric equations .$x = g(t)$ and .$y = t$ 10.2 Calculus with Parametric Curves # Tangents # Given .$x = f(t)$ and .$y = g(t)$ where both .$f$ and .$g$ are differentiable, we can get the tangent line to the curve by finding .$\\frac{dy}{dx}$ We can find .$\\frac{dy}{dt}$ using the chain rule: $$\\frac{dy}{dx} \\cdot \\frac{dx}{dt}$$ If .$\\frac{dx}{dt} \\neq 0$ , then we can solve .$\\frac{dy}{dt}$ : $$\\frac{dy}{dx} = \\frac{\\frac{dy}{dt}}{\\frac{dx}{dt}}$$ Horizontal tangents exist when .$\\frac{dy}{dt}= 0$ (assuming .$\\frac{dx}{dt} \\neq 0$ ) Vertical tangents exist when .$\\frac{dx}{dt}= 0$ (assuming .$\\frac{dy}{dt} \\neq 0$ ) Double Derivative # $$\\frac{d^2y}{dx^2} = \\frac{d}{dx}\\Big(\\frac{dy}{dx}\\Big) = \\frac{d}{dt}\\cdot\\frac{dt}{dx}\\Big(\\frac{dy}{dx}\\Big) = \\frac{\\frac{d}{dt}\\Big(\\frac{dy}{dx}\\Big)}{\\frac{dx}{dt}}$$\nAreas # Given .$x = f(t)$ and .$y = g(t)$ over .$t \\in (\\alpha, \\beta)$ , we can calculate the area between .$C$ and the .$x$ -axis with the following equation $$A = \\int_\\alpha^\\beta f\u0026rsquo;(t) \\cdot g(t)\\ dt $$ Likewise, between .$C$ and the .$y$-axis we derive the parametric equation for .$y$ : $$A = \\int_\\alpha^\\beta f(t) \\cdot g\u0026rsquo;(t)\\ dt $$\nArc Length # To find length .$L$ of curve .$C$ given in form .$x = f(t)$ and .$y = g(t)$ on .$t \\in [\\alpha, \\beta]$ where .$\\frac{dx}{dt} = f\u0026rsquo;(t) \u0026gt; 0$ (meaning that .$C$ is traversed once from left to right as .$t$ increases from .$\\alpha$ to .$\\beta$ ) and where .$f\u0026rsquo;$ and .$g\u0026rsquo;$ are continuous on .$[\\alpha, \\beta]$ : $$L = \\int_\\alpha^\\beta \\sqrt{\\Big(\\frac{dx}{dt}\\Big)^2 + \\Big(\\frac{dy}{dt}\\Big)^2}\\ dt$$ Note that trig functions (.$\\sin, \\cos, \\text{etc.})$ ) loop every .$\\frac{\\pi}{2}$ because of the formula finds the absolute value.\nSurface Area # Suppose the curve .$C$ given the equations .$x = f(t)$ and .$y = g(t)$ on .$\\ t \\in [\\alpha, \\beta]$ where .$f\u0026rsquo;$ and .$g\u0026rsquo;$ are continuous, and .$g(t) \u0026gt; 0$ , is rotated about the .$x$ -axis. If .$C$ is traversed exactly once, then the area of the resulting surface is given by $$S = 2\\pi \\int_\\alpha^\\beta y(t) \\sqrt{\\Big(\\frac{dx}{dt}\\Big)^2 + \\Big(\\frac{dy}{dt}\\Big)^2}\\ dt$$ Similarly, if instead .$C$ is rotated about the .$y$ -axis instead we use the following: $$S = 2\\pi \\int_\\alpha^\\beta x(t) \\sqrt{\\Big(\\frac{dx}{dt}\\Big)^2 + \\Big(\\frac{dy}{dt}\\Big)^2}\\ dt$$\n10.3 Polar Coordinates # Pole = origin; labeled .$O$ Polar axis = line through .$O$ Polar coordinates = .$r, \\theta$ .$r$ is distance from point .$P$ and .$O$ .$\\theta$ is the angle between the polar axis and the line .$OP$ .$(r, \\theta) = (-r, \\theta + \\pi)$ Converting between Cartesian # .$x = r\\cdot \\cos\\theta$ .$y = r\\cdot \\sin\\theta$ .$r^2 = x^2 + y^2$ .$\\tan\\theta = \\frac{y}{x}$ Symmetry # If polar equation is the same when .$\\theta = -\\theta$ , the curve is symmetric about the polar axis If polar equation is the same when .$r = -r$ or when .$\\theta = \\theta + \\pi$ , the curve is symmetric about the pole If polar equation is the same when .$\\theta = \\pi-\\theta$ , then the curve is symmetric about the vertical line .$\\theta = \\pi/2$ Polar Tangents # Knowing that $$x = r \\cdot \\cos\\theta = f(\\theta)\\cdot\\cos\\theta$$ $$y = r \\cdot \\sin\\theta = g(\\theta)\\cdot\\sin\\theta$$ We can use the product rule to find the tangent equation $$\\frac{dy}{dx} = \\frac{\\frac{dy}{d\\theta}}{\\frac{dx}{d\\theta}} = \\frac{\\frac{dr}{d\\theta} \\sin\\theta + r\\cos\\theta}{\\frac{dr}{d\\theta}\\cos\\theta - r \\sin\\theta} $$\nHorizontal Tangent: .$\\frac{dy}{d\\theta} = 0$ (when .$\\frac{dx}{d\\theta} \\neq 0$ ) Vertical Tangent: .$\\frac{dx}{d\\theta} = 0$ (when .$\\frac{dy}{d\\theta} \\neq 0$ ) Notice that for .$r = 0$ , then .$\\frac{dy}{dx} = \\tan\\theta$ if .$\\frac{dr}{d\\theta} \\neq 0$ We can then write the full formula: $$y-y_0 = \\frac{dy}{dx}\\Big(\\theta\\Big)(x-x_0)$$ 10.4 Area and Lengths in Polar Coordinates # Area of Polar Region # Knowing that the area of a \u0026ldquo;slice\u0026rdquo; can be written as .$A = \\frac{1}{2}r^2\\theta$ , we can expand this to the case where the curve is a function .$r = f(\\theta)$ : $$A = \\int_a^b \\frac{1}{2} r^2\\ d\\theta$$\nArc Length of Polar Curve # Given a polar curve .$r = f(\\theta), a \\leq \\theta \\leq b$ , we can re-write our base equations as $$x = r\\cos\\theta = f(\\theta)\\cos\\theta$$ $$y = r\\sin\\theta = f(\\theta)\\sin\\theta$$ Thus we can use the product rule when differentiating to get $$\\frac{dx}{d\\theta} = \\frac{dr}{d\\theta}\\cos\\theta - r\\sin\\theta$$ $$\\frac{dy}{d\\theta} = \\frac{dr}{d\\theta}\\sin\\theta + r\\cos\\theta$$ and using .$\\cos^2\\theta + \\sin^2\\theta = 1$ , we have $$\\Big(\\frac{dx}{d\\theta}\\Big)^2 + \\Big(\\frac{dy}{d\\theta}\\Big)^2 = [\\text{ugly stuff, see page 711}] = \\Big(\\frac{dr}{d\\theta}\\Big)^2 + r^2$$ so when .$f\u0026rsquo;$ is continuous, we can write the arc length equation as $$L = \\int_a^b \\sqrt{\\Big(\\frac{dx}{d\\theta}\\Big)^2 + \\Big(\\frac{dy}{d\\theta}\\Big)^2} d\\theta = \\int_a^b \\sqrt{r^2 + \\Big(\\frac{dr}{d\\theta}\\Big)^2}d\\theta$$\nCommon shapes # Rose # $$a\\cdot[\\sin \\text{or} \\cos](k\\cdot\\theta)$$\n.$r$ = .$a$ .$\\sin$ = Symmetry over .$\\theta = 0$ .$\\cos$ = Symmetry over .$\\theta = \\pi/2$ If .$k$ is even, rose will have .$2k$ petals. If .$k$ is odd, rose will have .$k$ petals. .$T = 2\\pi/k$ is range of a petal\u0026rsquo;s cycle .$2\\pi/T = k$ cycles displayed in graph .$A_{\\text{petal}} = \\frac{\\pi a^2}{4k}$ Cardioid # $$r(\\theta) = a(1-\\cos\\theta)$$ $$A = \\frac{3}{2}\\pi a^2$$ $$L = 8a$$\nLimaçon # $$r = b+a\\cos\\theta$$ Other equations I\u0026rsquo;m too lazy to type out\n"},{"id":33,"href":"/e-29/11/","title":"11-12: GD\u0026T","section":"Engineering 29","content":" \\(\\) Why use GD\u0026amp;T? # Limitations of conventional tolerancing # Example: four pins need to make a clearance fit with four holes\nTolerance limits on pin and hole spacing need to be specified (Left) Tolerance zones for centers of holes (Right) What if a pin is positioned at the extreme edges of both tolerance zones? Case 1 is extreme along $x$ Case 2 is extreme along both $x$ and $y$ In conventional tolerancing, tolerance zones are inherently one-dimensional In two- or three-dimensional designs, we risk accepting non-functional parts if each dimension is considered in isolation Options: tighten tolerances, enlarge clearance, or use\u0026hellip; GD\u0026amp;T: standard graphical language, ASME Y14.5, that allows tolerances to be unambiguously defined on drawings Allows different features to be related to each other (3D) Specifies how measurements are set up and made with datums Datums # Theoretical datums # Theoretical datums are defined on drawings using features of the component to be manufactured Datums can be Planes (e.g. flat surfaces of the component) i.e after facing operations Axes (e.g. axis of a hole or cylindrical feature) i.e when turning Every datum is given a letter on the drawing which uniquely identifies it Example: three perpendicular datum planes: Datums in measurement # Real manufactured objects deviate (even if slightly) from the ideal geometry Surfaces not perfect planes Axes not perfectly straight, etc So, we need a procedure to interpret measurements from a component to establish a \u0026ldquo;best fit\u0026rdquo; for the datum plane or axis Use a physical \u0026ldquo;datum simulator\u0026rdquo; like a rigid, flat surface (e.g. granite table) to rest against the component Measure multiple points $(x,y,z)$ with CMM or optical metrology and fit the plane or axis datum in software (e.g. use least-squares regression \u0026ndash; advanced software available for this) The number of datums needed to define a given tolerance depends on the geometry of the component and the type of tolerance Example: Physical Planar Datum Simulators # In measurement, we place a flat surface against the component as a datum simulator Needs to be at least $\\approx 10$ times smoother than the target surface We measure wrt this datum rather than the part\u0026rsquo;s features For any given dimension specified in GD\u0026amp;T, datums are defined with an order of preference. During measurement: First plane makes three-point contact with surface Second plane makes two-point contact Third plane: one-point contact Introductory examples # Example: hole in a block # Surfaces are not smooth in a real part, so we measure the hole center from the datums $A,B,C$ Example: hole spacing in plate # Four pins need to make a clearance fit with four holes \u0026ndash; tolerance limits on pin and hole spacing need to be specified Center positions # MMC: Maximum Material Condition # - Use when want **clearance** - MMC means least \"play\" is available between the components - Bonus tolerance is added if components are not in MMC. - **Example**: if actual size of hole is .252\" rather than .250\", size of tolerance zone increases from .006\" to .008\" diameter ![](/docs/e-29/11/mmc.png) LMC: Least Material Condition # - Use if want **interference** - Or for, e.g., holes very close to the edge of a part - Bonus tolerance now added if more material is left on component ![](/docs/e-29/11/lmc.png) Feature Control Frames # (Left) Geometric characteristic: symbol \u0026ndash; see more below (Middle) Size of the tolerance zone \u0026ndash; either a linear dimension or a diameter of a tolerance zone, depending on the type of tolerance (Right) Datum reference letters, if applicable Noted in the order in which they are to be established during measurement. Range of GD\u0026amp;T symbols # Categories of Tolerance # Form Tolerances # Straightness # 1 Straightness of an edge, or a line on a surface (top) # Tolerance defined as the maximum distance between the closest two parallel lines including all points on the edge under consideration Single dimensional value (no diameter symbol, Ø) Controls bowing, waisting, and barreling of cylindrical features 2. Straightness of an axis (bottom) # - **Cylindrical tolerance** zone must fit inside this diameter - Needs diameter symbol, Ø - Compute axis position by forming an [equidistant set](https://en.wikipedia.org/wiki/Equidistant_set) by [bisecting](https://en.wikipedia.org/wiki/Bisection) pairs of measured points on surface of the cylindrical feature - Matters because we are generally trying to mate one cylindrical feature with another - e.g. peg and hole - Note that a cylindrical feature can have a straight axis without having straight edges, as would be the case when a feature exhibits waisting or barreling. Flatness # 2D version of straightness \u0026ndash; applies only to planar feature To measure, we sample a series points on the surface (physical edge) Can be accomplished with optical interferometry or the entire surface in one scan, or, approximately, by stylus profilometry \u0026ndash; e.g. by running a dial gage across the surface multiple times and measuring the needle deflection Tolerance zone is defined as the maximum allowable spacing between the closest two planes that enclose all points on the manufactured surface Tells us nothing about relationship with any other surface Not used, e.g. , to control thickness uniformity of a plate Disadvantage of using multiple linear measurements to check flatness is that the relative locations of these measurements are not known, so checking the flatness tolerance against the exact definition described above (maximum distance between two parallel planes) is then not strictly possible Circularity (Roundness) # Controls out-of-roundness within any plane perpendicular to the axis of the cylinder The tolerance value specifies the maximum allowable difference between radii of two concentric circles that are as close together as possible and that enclose all points of the manufactured circumference Center position of circles is fit to measurement data to give minimal difference in radii (minimum zone circle) To test this tolerance strictly, one would have to measure the shape of the circumference with stylus, and then use a data-fitting algorithm to identify the two circles with the smallest difference in radii that enclose all points How far from perfectly circular any particular circumference of a cylindrical feature is allowed to be. In many machine shops, an approximate measure of circularity is often obtained by placing the component in a V-block (right), and rotating it while a dial gage stylus rests on the upper surface. The peak-to-peak, $\\Delta d$, deflection of the gage needle is taken as an estimate of out-of-roundness. When a circularity tolerance is applied to a cylindrical feature, we require the tolerance to be independently met at all points along its axis. When we consider all longitudinal positions simultaneously, our tolerance is one of cylindricity: Cylindricity # \u0026lsquo;3D version\u0026rsquo; of circularity All points on surface of cylindrical feature must lie between two concentric cylinders separated by no more than the tolerance value Axial position and orientation of cylinders is fit to measurement data to give minimal difference between radii (MZC: minimum zone cylinder) Considers all points on the surface of the feature simultaneously Summary # - The range of acceptable material positions is contained by the tolerance zone: - 2D region for straightness/circularity - 3D region for flatness/cylindricity Profile # Specify the allowable deviation of a line or surface from a perfect profile Can be bilateral (equal or unequal), or unilateral, shown above Can be specified with or without a datum reference Line profile tolerance example Any line trace along the profile and parallel to its edges must satisfy the tolerance Every point along a line tracing the surface of the toleranced feature must lie within a band whose width is given by the tolerance zone size. The tolerance is defined between two endpoints that are labeled using letters $X \\iff Y$ in the example below Can be (but does not need to be) referenced to one or more datums Unless otherwise stated, the tolerance band is equilateral around the nominal position of the line. Surface profile tolerance # All points on the indicated surface must lie within the tolerance zone, considered simultaneously\nProfile tolerances: with vs without datum # Yellow shows looser tolerance zone without datums; just says that the line\u0026rsquo;s/surface\u0026rsquo;s shape has to fit the tolerance \u0026ndash; not that that surface itself has to be constrained by it\u0026rsquo;s to fit with other parts Unilateral vs Bilateral # Orientation tolerances # While form tolerances dictate the required “quality” of a single feature, and profile tolerances may or may not be anchored to a particular datum or datums, orientation tolerances inherently require the use of datums, because they are about relating one feature to another. We need to establish a datum to represent one feature before we can determine how the second feature relates to it. Orientation tolerances are as follows.\nParallelism # Can be applied to surfaces and axes One of the features is assigned a datum letter, and the other feature is referenced to it - Surface parallelism: when the non-datum feature is a plane, the **tolerance zone** tells us the maximum allowable distance between two planes which are: 1. Parallel to the established datum 1. As close together as possible 2. Enclose all points on the referenced surface - As with flatness, though, a parallelism tolerance makes no statement about how the distance between the two features should be controlled/where the tolerance zone lies - That distance can be controlled by a separate dimensional tolerance as shown on the left side - E.x Two surfaces could be parallel but the wrong distance apart Note that a parallelism tolerance is quite different from a flatness tolerance in that the planes being used to check a parallelism tolerance must lie parallel to a specified datum; this requirement does not exist for a flatness tolerance Axis # When the toleranced feature is an axis, we specify a cylindrical tolerance zone with a particular diameter — this tolerance zone is, however, constrained to be parallel to the datum, which differs from a simple straightness tolerance.\nEstablishing an axis datum # - If the axis datum is the first datum being established: find best-fit center-line for points measured on the surface of the cylindrical feature (e.g. by CMM) - Best-fit could be found by minimizing, e.g. sum of squared differences from surface points to axis - If other datum(s) have been previously established: the axis datum is also constrained to be perpendicular to previous datum(s) - Fitting process incorporates this constraint Checking an axis tolerance # Measure multiple points on the surface of the cylindrical manufactured feature Find the effective position of the axis at all points along its length Find \u0026ldquo;median position\u0026rdquo; between measured surface points Manufactured axis will not be perfectly straight - Ask whether all points along the manufactured axis fit within a cylindrical tolerance zone of the specified diameter that has the prescribed relationship to the given datum: - Tolerance zone may be parallel, perpendicular, concentric, etc. relative to datum - Tolerance zone can take the most favorable possible position for meeting the tolerance - Applies along the whole length of the toleranced feature Perpendicularity # - Perpendicularity tolerances are very similar conceptually to parallelism tolerances, but the tolerance feature and datum lie at 90˚ to each other rather than parallel - Can be applied to surfaces and axes - Surface perpendicularity: all points must lie between two planes, separated by the tolerance value and perpendicular to the referenced datum Axes # Axis perpendicularity: all points on the axis must lie within a cylinder with the diameter of the tolerance zone and perpendicular to the referenced datum Angularity # - Traditional (non-GD\u0026T) approach - Angular tolerance is specified as a number of degrees - Tolerance zone is wedge- shaped - GD\u0026T approach -- requires that all points on the tolerance feature lie between two planes that are: 1. At the specified angle from the given datum, and 2. Separated by no more than the size of the tolerance zone An angularity tolerance in GD\u0026T - Note that an angularity tolerance of this kind is rather different from a “traditionally” defined angular tolerance, which would place a range on the effective angle between two features Note that an angularity tolerance of this kind is rather different from a “traditionally” defined angular tolerance, which would place a range on the effective angle between two features (as shown in the left above). In the traditional approach, the tolerance zone gets wider as the distance from the intersection point between the two features increases. Depending on what the component is supposed to do in use, one might argue that either the traditional approach or the GD\u0026amp;T approach would be the more useful way of tolerancing an angled feature. For example, if the component is intended to serve as a wedge to set the angle between two flat components, the traditional tolerancing approach might work best. On the other hand, if the component is supposed to be a mirror on to which a plane-wave of light is incident, we might rather use the GD\u0026amp;T approach so that the local angle of the surface is kept within certain bounds all the way along its length. The designer needs to think carefully about exactly what manufacturing defect is to be avoided\nLocation # Concentricity # This tolerance is useful, for example, when designing rotating machinery, in which multiple components may need to be placed on a shaft without resulting in out-of-balance loads. Concentricity relates two axes One datum axis and one toleranced cylindrical feature All points on the axis of the tolerance feature must lie within a cylindrical tolerance zone centered on the datum axis Symmetry # Relates two planar features All median points lying mid-way between the two surfaces of the toleranced feature must lie within the tolerance zone Tolerance zone is centered on the datum feature Tolerance zone defined by two planes In some components, one feature is intended to be centered relative to another, and a symmetry tolerance defines how far those two features can deviate from symmetry. Here when we say “feature” we refer to opposing pairs of surfaces with equal size — a particular type of feature known as a feature of size. The opposite sides of the slot above constitute a feature of size, as do the opposite outside faces of the component itself. As shown above, one feature is specified as a datum (by labeling one side of the feature with a lettered symbol). The other feature is labeled with its nominal dimension and also with a feature control frame that contains the symmetry symbol, the size of the tolerance zone, and the relevant datum. The tolerance zone tells us how far the midplane of the toleranced feature can deviate relative to the midplane of the datum feature (which would be established by measuring points on both sides of the feature — i.e., the height of the component in the example\nRunout # Runout tolerances differ from both circularity/cylindricity and concentricity tolerances in that they constrain peak-to-peak deviation of the surface of one feature when it is rotating about a datum axis. (No fitting of bounding circles or cylinders or of effective central axes is required.) Runout tolerances are thus helpful for tolerancing components that must rotate relative to other components while maintaining a certain amount of clearance — for example, a shaft turning within a cylindrical cavity. Runout is also important for ensuring cutting tool performance — in a milling tool or drill for example, limiting runout enables clean cuts to be made, as the tool will not periodically collide with the workpiece.\nCircular runout # - Runout considers how the surface profile of an object varies as it rotates about a specified axis - Useful for specifying performance of rotating machinery, cutting tools etc. - **Circular runout**: - Imagine placing a dial gage on the surface of a cylindrical feature - Peak-to-peak variation of the reading as it rotates is circular runout - Circular runout tolerance must not be exceeded at any location along the axis of the feature A circular runout tolerance limits the peak-to-peak deviation of points on any given circumference of a cylindrical feature, when it rotates about the specified datum axis. In the example shown on above, for example, circular runout could be measured by clamping the component in a chuck to establish datum A, then rotating the component with a dial gage in contact with the toleranced feature. The peak-to-peak movement of the indicator would need to be less than the tolerance specified. A circular runout tolerance must be satisfied independently at any circumference on the cylindrical feature to which it applies (not just the location at which the tolerance arrow appears to point).\nPlanar features # - Can also apply to planar features perpendicular to specified datum axis - Runout tolerance must not be exceeded at any radial location Cylindrical, or total, runout # - Total runout is more restrictive than circular runout - Imagine taking dial gage readings at many locations along length of feature - Gage readings referenced to the rotation axis (axis = 0) - Peak-to-peak variation of all readings taken together must not exceed tolerance value - This is unlike circular runout, where each axial location is independent \u003e This is the “3D” version of circular runout: the datum is established, and the component rotated, and the total peak-to-peak variation across all axial positions is found (e.g. by scanning a dial gage along the component as it rotates). Total runout will usually be larger than circular runout; the example below illustrates why: \u003e Total runout for planar features # Total runout can be applied to a planar feature perpendicular to the datum axis Tolerance value must not be exceeded when considering overall peak-to-peak positional variation of all radial locations together Often, a rotating component will be mounted at two locations (e.g. on two bearings at opposite ends of a shaft). Then, a runout tolerance will be specified relative to both of those datums using the convention illustrated below. The runout using datums A and B in this example is likely to be different from the runout that we would measure using only one of the datums, because the rotational axis established could change position as more points on the component’s surface are included in the fitting process. Multiple datums # It is common for rotating components to be held in bearings at both ends Associate a datum feature with each end of the component Rotation axis for evaluating runout can be based on these two datums together Fit the axis to points measured along both datums Reflects operation of component more accurately Range of GD\u0026amp;T symbols # Examples # Perpendicularity # Add perpendicularity tolerances to show: 40-high left-hand edge, perpendicular to datum A, tolerance zone 0.2 in size Hole axis perpendicular to datum A, tolerance zone 0.2 dia at MMC Center Position # Symmetry # "},{"id":34,"href":"/eecs-16a/11/","title":"11: Locationing \u0026 Trilateration","section":"EECS 16A","content":" \\(\\) Positioning Systems # Just read Note 21.1-2\nVectors # Inner Products # The Euclidean inner product between two vectors $\\vec u, \\vec v$ is defined as\u0026hellip; $$\\langle \\vec u, \\vec v \\rangle \\equiv \\vec u \\cdot \\vec v \\equiv \\vec u^T \\vec v$$ $$\\dots = \\begin{bmatrix} v_1 v_2 \\dots v_n \\end{bmatrix}\\begin{bmatrix} u_1\\\\\\ u_2\\\\\\ \\vdots \\\\\\ u_n \\end{bmatrix}$$ $$\\dots = v_1 u_1 + v_2 u_2 + \\dots v_n u_n$$ $$\\dots = \\sum_{i=1}^n v_i u_i$$ Naming In physics, the inner product is called dot product; $\\vec u \\cdot \\vec v$ Scalar product is also occasionally used because it produces a scalar output Properties # In general, if $\\mathbb{V}$ is a real vector space$^{[1]}$, we say that the mapping $\\vec u, \\vec v \\in \\mathbb{V} \\to \\langle \\vec u, \\vec v \\rangle \\in \\mathbb{R}$ is an inner product iff it satisfies the following properties:\n1. Symmetry: $\\langle \\vec u, \\vec v \\rangle = \\langle \\vec v, \\vec u \\rangle$ for all $\\vec u, \\vec v \\in \\mathbb{V}$ # 2. Linearity: # Homogeneity: $\\langle \\gamma \\vec u, \\vec v \\rangle = \\gamma \\langle \\vec u, \\vec v \\rangle$ Super position: $\\langle \\vec u + \\vec w, \\vec v \\rangle = \\langle \\vec u, \\vec v \\rangle + \\langle \\vec w, \\vec v \\rangle$ for $\\vec w \\in \\mathbb{V}, \\gamma \\in \\mathbb{R}$ 3. Positive-definiteness: $\\langle \\vec v, \\vec v \\rangle \\geq 0$ with equality iff $\\vec v = \\vec 0$ # $^{[1]}$In 16A we do not want to think about complex numbers so we tend to have $\\vec u, \\vec v \\in \\mathbb{R}^n$\nGeometric Interpretation # The inner product of vectors two vectors is their magnitudes multiplied by the angle between them $$\\langle \\vec u, \\vec v \\rangle = \\Vert \\vec u \\Vert \\Vert \\vec v \\Vert \\cdot \\cos \\theta$$\nProof on page 6 The inner product does not depend on the coordinate system the vectors are in\u0026ndash; it only depends on the relative angle between these vectors and their length. Note that we cannot just look at the value of the inner product $\\vec u, \\vec v$ in making the judgement about the vectors’ similarity, due to the scaling property Making the vectors 10 times longer/shorter doesn’t make them any more or less aligned with each other! What we can do is normalize the vectors \u0026ndash; maintain direction and set magnitude to 1 E.x. $\\hat v = \\frac{\\vec v}{\\Vert \\vec v \\Vert}$ \u0026ndash; the $\\hat{ }$ symbol indicates a unit vector (magnitude = 1) Nice derivation on page 108 Special Operations # Motivation: The act of computing an inner product is very simple computationally; it’s just a few additions and multiplications, so computers are highly optimized for computing inner products. Therefore, it is useful to represent other common operations in terms of inner products.\nFor $\\vec v \\in \\mathbb{R}^n$\nSum of Components: $\\langle \\vec 1, \\vec v \\rangle = v_0 + v_1 + \\dots + v_n$ Average: $\\langle \\hat n^{-1}, \\vec v \\rangle = \\frac{v_0}{\\hat n} + \\frac{v_1}{\\hat n} + \\dots + \\frac{v_n}{\\hat n} = \\frac{v_0 + \\dots + v_n}{n}$ Sum of Squares: $\\langle \\vec v, \\vec v \\rangle = v_0^2 + v_1^2 + \\dots + v_n^2$ Selective Sum: $\\langle \\vec e_2 + \\vec e_5 + \\dots + e_n, \\vec v \\rangle = v_2 + v_5 + \\dots v_n$ Orthogonal Vectors # \u003e Two vectors $\\vec v, \\vec u \\in \\mathbb{R}^n$ are **orthogonal** if their inner product is zero, i.e. $\\langle \\vec v, \\vec u \\rangle = 0$ - [Orthogonality](https://en.wikipedia.org/wiki/Orthogonality) can be thought of [perpendicularity](https://en.wikipedia.org/wiki/Perpendicular) to higher dimensions than two/three - Note that the [standard unit vectors](https://en.wikipedia.org/wiki/Standard_basis) are _always_ orthogonal to each other. - E.x. orthogonal vectors in $\\mathbb{R}^2$ to the right: ![](/docs/eecs-16a/11/ortho.png) Norms # The Euclidean Norm (or 2-norm) of a vector represents the vector’s length, or magnitude. Defined as $\\Vert \\vec v \\Vert = \\sqrt{v_1^2 + \\dots v_n^2} = \\sqrt{\\langle \\vec v, \\vec v \\rangle}$ where the inner product on the right is the Euclidean inner product\nThe norm of a vector is the magnitude This corresponds to the usual notion of distance in $\\mathbb{R}^2, \\mathbb{R}^3$ The set of points with equal Euclidean norm is a circle in $\\mathbb{R}^2$ or a sphere in $\\mathbb{R}^3$ Aside: More generally, any choice of inner product will give rise to a corresponding norm via defining $\\Vert \\vec v \\Vert := \\sqrt{ \\langle \\vec v, \\vec v \\rangle}$ Properties # For $\\vec v, u \\in \\mathbb{R}^2$\u0026hellip;\n1. Non-negativity: $\\Vert \\vec v \\Vert \\geq 0$ # 2. Zero Vector: $\\Vert \\vec v \\Vert = 0 \\iff \\vec v = \\vec 0$ # 3. Scalar Multiplication: $\\Vert \\gamma \\vec v \\Vert = \\vert \\gamma \\vert \\Vert \\vec v \\Vert$ # 4. Triangle Inequality: $\\Vert \\vec v + \\vec u \\Vert \\leq \\Vert \\vec v \\Vert + \\Vert \\vec u \\Vert$ # Cauchy-Schwarz Inequality # \u003e $$\\vert \\langle \\vec v, \\vec u \\rangle \\vert \\leq \\Vert \\vec v \\Vert \\Vert \\vec u \\Vert$$ We can prove this knowing $\\vert \\cos \\theta \\vert \\leq 1$: $$\\vert \\langle \\vec v, \\vec u \\rangle \\vert = \\big\\vert \\Vert \\vec u \\Vert \\Vert \\vec u \\Vert \\cdot \\cos \\theta \\big\\vert $$ $$\\vert \\langle \\vec v, \\vec u \\rangle \\vert = \\Vert \\vec u \\Vert \\Vert \\vec u \\Vert \\cdot \\big\\vert\\cos \\theta \\big\\vert $$ $$\\therefore \\vert \\langle \\vec v, \\vec u \\rangle \\vert \\leq \\Vert \\vec u \\Vert \\Vert \\vec u \\Vert $$ Projections # The vector projection of $\\vec x$ onto $\\vec y$ \u0026mdash; $\\text{proj}_{\\vec y}\\vec x$ \u0026mdash; refers to the component of $\\vec x$ that is aligned in the same direction as $\\vec y$\u0026ndash; or exactly opposite; it helps to imagine a line going through $\\vec y$ By definition, we see that $\\text{proj}_{\\vec y}\\vec x \\in \\text{Span} \\{\\vec y \\}$ If the projection is zero, then the vectors are orthogonal \u0026ndash; there is no component of $\\vec y$ that is aligned with $\\vec x$ - We can break up $\\vec x$ into it's parallel and perpendicular components to $\\vec y$, $\\vec x_\\parallel, \\vec x_\\perp$ - The length of the parallel component $\\Vert \\vec x_\\parallel \\Vert$ gives the _scalar_ projection of $\\vec x$ onto $\\vec y$ $$\\cos \\theta = \\frac{\\langle \\vec x, \\vec y \\rangle}{\\Vert \\vec x \\Vert \\Vert \\vec y \\Vert}$$ $$\\therefore \\text{comp}\\_{\\vec{y}} \\vec x = \\Vert \\vec x_\\parallel \\Vert = \\cos\\theta \\Vert \\vec x \\Vert$$ $$\\dots = \\frac{\\langle \\vec x, \\vec y\\rangle}{\\Vert \\vec y \\Vert} $$ - This is the scalar projection, which we can give direction by multiplying it by $\\hat y$ ![Dot Product](/docs/eecs-16a/11/proj.png) $$\\text{proj}_{\\vec y}\\vec x = ( \\text{comp}_{\\vec{y}} \\vec x)\\hat y = \\left( \\frac{\\langle \\vec x, \\vec y\\rangle}{\\Vert \\vec y \\Vert}\\right) \\frac{\\vec y}{\\Vert \\vec y \\Vert} = \\frac{\\langle \\vec x, \\vec y\\rangle}{\\Vert \\vec y \\Vert ^2} \\vec y = \\frac{\\langle \\vec x, \\vec y\\rangle}{\\langle \\vec y, \\vec y\\rangle} \\vec y$$\nThis new, unique vector is closest to $\\vec x$ as measured by the norm \u0026ndash; page 9 The above only uses generic properties of the inner product, and does not need to the specific choice of the Euclidean inner product to work out. See also: Math 53 12.3: Projections Trilateration # [_I'm on a journey to the center of three_](https://youtu.be/ILxKidrD3K8?t=57) - We know the locations of the beacons $\\vec a_1,\\vec a_2,\\vec a_3$ - We know the distances $d_1,d_2,d_3$ - We want to find the position of $\\vec x$ ![](/docs/eecs-16a/11/tri.png) --- - These two equations are linear in $\\vec x$, so we can then stick them into a matrix - This system can be solved for a location - Notice that three circles uniquely define a point in 2D; this argument extends in 3D to four spheres, 4D to five hyper-spheres, etc. $$\\Vert \\vec x - \\vec a_1 \\Vert^2 = d_1^2$$ $$\\Vert \\vec x - \\vec a_2 \\Vert^2 = d_2^2$$ $$\\Vert \\vec x - \\vec a_3 \\Vert^2 = d_3^2$$ $$\\equiv$$ $$(\\vec x - \\vec a_i)^T (\\vec x - \\vec a_i) = d_i^2$$ $$\\equiv$$ $$\\vec x^T \\vec x - \\vec x^T\\vec a_i -\\vec a_i^T\\vec x + \\vec a_i^T \\vec a_i - = d_i^2$$ $$\\equiv$$ $$\\Vert \\vec x \\Vert^2 - 2 \\langle \\vec x, \\vec a_i \\rangle + \\Vert \\vec a_i \\Vert^2 = d_i^2$$ \u003e We have **squared terms** (not linear!) involving unknown variable $\\vec x$ --- \u003e We'll subtract equation 1 from equation 2, and separately again from equation 3. $$2 (\\vec a_1 - \\vec a_2)^T \\vec x = \\Vert \\vec a_1 \\Vert^2 - \\Vert \\vec a_2 \\Vert^2 - d_1^2 + d_2^2$$ $$2 (\\vec a_1 - \\vec a_3)^T \\vec x = \\Vert \\vec a_1 \\Vert^2 - \\Vert \\vec a_3 \\Vert^2 - d_1^2 + d_3^2$$ $$\\equiv$$ $$\\begin{bmatrix} 2 (\\vec a_1 - \\vec a_2)^T \\\\\\ 2 (\\vec a_1 - \\vec a_3)^T \\\\\\ \\end{bmatrix}\\vec x = \\begin{bmatrix} \\Vert \\vec a_1 \\Vert^2 - \\Vert \\vec a_2 \\Vert^2 - d_1^2 + d_2^2 \\\\\\ \\Vert \\vec a_1 \\Vert^2 - \\Vert \\vec a_3 \\Vert^2 - d_1^2 + d_3^2 \\\\\\ \\end{bmatrix}$$ Signals # Signal: a message that contains information as a function of, in this class, time \u0026ndash; can also be a function of space (i.e. an image)\nDiscrete-time Signal: defined at specific points in time (for example, every minute) \u0026ndash; can represent as a list of numbers Continuous-Time Signal: defined over all time \u0026ndash; not focused on in 16A We can represent a discrete-time signal as a list of numbers, and thus as a vector where each element is the value at a single time point Every element of the vector represents the signal value at one timestep. We’ll use the notation $s[k]$ to represent the $k$-th element of the vector where initial element is at $k = 0$. E.x. in the signal $\\vec s$ above, $s[0] = 0$, $s[1] = 1$, etc.\nCross-Correlation # \u003e **Cross-correlation:** Measure of the similarity between two signals $\\vec x$ and $\\vec y$ based on the inner product. $$\\text{corr}_{\\vec x} ( \\vec y) [k] = \\sum^{\\infty}\\_{i=-\\infty} x[i] y[i−k]$$ $$\\dots = \\left\\langle \\vec x, \\vec y^{(k)} \\right\\rangle$$ - $\\vec x, \\vec y$: input signals - $\\text{corr} _{\\vec x} ( \\vec y) [k]$: $k$-th element of their cross-correlation - We typically iterate over $[-l, L+l]$ - $L, l$ The larger and smaller signal lengths, respectively - $x[n], y[n] = 0$ for any $n$ that they are not defined for - When the inner product is large, $\\vec x, \\vec y$ are more similar, and when it’s small, they are more different. - The cross-correlation checks the inner product at all relative shifts between the signals, so it tells us how similar two signals are at every shift. - **Autocorrelation**: a correlation between a signal and itself - Tells us how similar a signal is to all shifts of itself. - Not commutative: $\\text{corr}_{\\vec x} ( \\vec y) \\neq \\text{corr}\\_{\\vec y} ( \\vec x)$ - Aside: [convolution](https://en.wikipedia.org/wiki/Convolution) is an operation similar to correlation but commutative - [Convolutional Neural Network](https://en.wikipedia.org/wiki/Convolutional_neural_network) - Aside: [Circular Correlation](https://eecs16a.org/EECS16ACompendiumOfNotesAndPracticeProblems.pdf#page=111) E.x. for $\\vec s_1 = \\begin{bmatrix}1 \\ 3 \\ 2\\end{bmatrix}^T$, $\\vec s_2 = \\begin{bmatrix}2 \\ 1\\end{bmatrix}^T$: $\\text{corr}_{\\vec s_1} ( \\vec s_2) [0] = (1)(2) + (3)(1) + (2)(0) = 5$ Using numpy: numpy.correlate([1, 3, 2], [2, 1], ‘full’) "},{"id":35,"href":"/eecs-16a/12/","title":"12-13: Least Squares \u0026 ML","section":"EECS 16A","content":" \\(\\) Least Squares # Motivation # We want to find an approximate solution \u0026ndash; one that satisfies all the given equations/information as closely as possible to\u0026hellip; Minimize the impact of noise/errors Solve overdetermined systems \u0026ndash; we\u0026rsquo;ll often be collecting abundant information, thus we have more equations than unknowns Applications: Least squares is the fundamental idea behind data fitting and machine learning In data (curve) fitting, we find lines or curves that best match the data In machine learning, we use a best-fit curve to make predictions about new, unseen data. What # The goal of least squares is to minimize the error vector's magnitude (norm) -- the square of each of it's components: $$\\Vert \\vec e \\Vert = \\sqrt{\\sum_{i=1}^n e_i^2 }$$ With $m$ measurements (equations) and $n$ unknowns; $m \u0026gt; n$ $\\text{col}(A)$ is an $n$-dimensional subspace within the larger $m$-dimensional space that $\\vec b$ lies in That is, $\\vec b$ cannot be exactly reached by $A\\vec x$ - $\\vec x$: Best-guess that minimizes $\\Vert \\vec e \\Vert$ - $\\vec x \\in \\mathbb{R}^{n}$ - $\\vec e = \\vec b - A\\vec x = \\vec b - \\hat x$: Error vector - $\\vec e \\in \\mathbb{R}^{n}$ - We want to find $\\vec x$ where $\\vec e \\perp \\text{col}(A)$ - $\\vec b$: Actual, observed values - $\\vec b \\in \\mathbb{R}^{m}$ - $\\hat x = A \\vec x = A (A^T A)^{-1} A^T \\vec b$: Predicted values - $A \\in \\mathbb{R}^{m \\times n}; A\\vec x, \\hat x \\in \\mathbb{R}^{m}$ - Can be thought of a linear combination of the columns of $A$, with $\\vec x$ acting as weights Proof # We know from the last section that the projection of $\\vec a$ onto $\\vec b$ results in a vector within the span of $\\vec b$ that is closest and orthogonal to $\\vec a$ - So we'll project $\\vec b$ onto $\\text{col}(A)$ to find the smallest possible $\\vec e$ - That is, we know that $\\vec e \\perp \\text{col}(A)$ $\\Longrightarrow \\vec e \\perp \\vec a_i $ for each column of $A$ so we can write: $$\\langle \\vec a_i, \\vec e \\rangle = 0$$ $$\\langle \\vec a_i, \\vec b - A\\vec x \\rangle = 0$$ $$\\vec a_i^T (\\vec b - A\\vec x) = 0$$ $$\\therefore A^T (\\vec b - A \\vec x) = \\vec 0$$ - Then solving for $\\vec x$ in terms of the known $A$ and $\\vec b$: $$A^T (\\vec b - A \\vec x) = \\vec 0$$ $$A^T \\vec b - A^T A \\vec x = \\vec 0$$ $$A^T \\vec b = A^T A \\vec x$$ $$ \\therefore \\vec x = (A^T A )^{-1} A^T \\vec b$$ Theorems # Theorem 23.1 # Vector $\\vec e$ is orthogonal to every vector in the column space of $A$ iff it is orthogonal to each of the columns $\\vec a_i$ that form the basis of its column space\n- If $\\vec e$ is orthogonal to every vector in the column space of $A$, then it is orthogonal to each of the $\\vec a_i$, as each of the $\\vec a_i$ are in the column space of $A$ too - Now, we will try to prove the converse: consider an arbitrary vector $\\vec v \\in \\text{span}(A)$-- by definition, we know that there exist coefficients $\\alpha_i$ such that we can express $\\vec v = \\sum_{i=1}^m \\alpha_i \\vec a_i$ - We also know that $\\vec e$ is orthogonal to each $\\vec a_i$; that is $\\langle \\vec e, \\vec a_i \\rangle = 0$ - We wish to show that $\\vec{e}$ is orthogonal to $\\vec{v}$ too: $$\\langle\\vec{e},\\vec{v}_i \\rangle = \\left\\langle \\vec{e}, \\sum\\_{i=1}^m \\alpha_i \\vec a_i \\right\\rangle$$ $$\\dots = \\sum \\left\\langle \\vec{e}, \\alpha_i \\vec a_i \\right\\rangle$$ $$\\dots = \\sum \\alpha_i \\left\\langle \\vec{e}, \\vec a_i \\right\\rangle$$ $$\\dots = 0$$ That is, if $\\vec e$ is orthogonal to all the basis vectors of a subspace, it is orthogonal to every vector in that subspace as well! Theorem 23.2 # $\\text{Null}(A^TA) = \\text{Null}(A)$ even when $A$ has a nontrivial nullspace\n- Consider an arbitrary $\\vec v \\in \\text{Null}(A^T A)$-- by definition, we have $$A^T A \\vec v = \\vec 0$$ $$\\vec v^T (A^T A \\vec v) = \\vec v^T (\\vec 0)$$ $$(A \\vec v)^T (A \\vec v) = 0$$ $$\\langle A \\vec v, A \\vec v \\rangle = \\Vert A\\vec v \\Vert ^2 = 0$$ - Thus, it is clear that $A \\vec v = 0$, so $\\vec v \\in \\text{Null}(A)$ - That is, $\\text{Null}(A^T A) \\subseteq \\text{Null}(A)$ - Consider an arbitrary vector $\\vec v' \\in \\text{Null}(A)$-- pre-multiplying by $A^T$ we have that... $$A \\vec v' = \\vec 0$$ $$A^T A \\vec v' = \\vec 0$$ - Therefore $\\vec v' \\in \\text{Null}(A^T A)$ - That is, $\\text{Null}(A) \\subseteq \\text{Null}(A^T A)$ - Combining this with the prior statement, we find our desired $\\text{Null}(A) = \\text{Null}(A^T A)$ "},{"id":36,"href":"/math-53/12/","title":"12: Vectors \u0026 Geometry of Space","section":"Math 53","content":" 12.1 3D Coordinate Systems # Right hand rule: Index point to .$x$, thumb to .$z$, and write through .$y$ If you have point .$P(a,b,c)$ and drop a perpendicular dot on the .$xy$-plane at .$a,b,0$, you now have a projection of .$P$ onto the .$xy$-plane The distance .$|P_1 P_2|$ between two points .$P_1(x_1, y_1, z_1)$ and .$P_2(x_2, y_2, z_2)$ is $$|P_1 P_2| = \\sqrt{(x_2-x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2}$$ We can define the equation for a sphere with a center at .$C(h,k,l)$ and radius .$r$ as $$(x-h)^2 + (y-k)^2 + (z-l)^2 = r^2$$ 12.2 Vectors # Written as .$\\overrightarrow{AB}$ Has initial point .$A$ at the tail and the a terminal point .$B$ at the tip If the initial point .$A$ is at .$(x_1, y_1, z_1)$ and terminal point .$B$ is at .$(x_2, y_2, z_2)$, then we can write .$\\overrightarrow{AB} = \\langle x_2 - x_1, y_2 - y_1, z_2 - z_1\\rangle$ Vectors with the same length/magnitude are called equivalent or equal, despite not necessarily having the same initial/termination points Vector addition (order doesn\u0026rsquo;t matter) $$ \\overrightarrow{AC} = \\overrightarrow{AB} + \\overrightarrow{BC} = \\overrightarrow{BC} + \\overrightarrow{AB}$$ $$ \\vec u - \\vec v = \\vec u + (- \\vec v)$$ $$ \\vec a + (\\vec b + \\vec c) = (\\vec a + \\vec b) + \\vec c$$ Vector multiplication Given scalar .$c$ and vector .$\\vec v$, .$c\\cdot\\vec v$ is like .$\\vec v$ but with length changed by a factor of .$\\Vert c\\Vert$ If .$c\u0026lt;0$, then the vector is flipped around $$c\\cdot\\vec v = \\langle cv_x, cv_y, cv_z\\rangle$$ Magnitude for .$\\vec a = \\langle a_x, a_y, a_z \\rangle$: $$ \\Vert \\vec a \\Vert = \\sqrt{a_x^2 + a_y^2 + a_z^3}$$ Unit vector Has length of one If .$\\vec a \\neq 0$ then the unit vector .$\\vec u$ in the same direction as .$\\vec a$ is: $$\\vec u = \\frac{\\vec a}{\\Vert \\vec a \\Vert} = \\frac{1}{\\Vert \\vec a \\Vert} \\vec a$$ Notice that .$\\frac{1}{\\Vert \\vec a \\Vert}$ is a scalar 12.3 Dot Product # The dot product measures the extent which two vectors are parallel to one another Two vectors are perpendicular/orthogonal .$\\perp$ (.$90^\\circ$ from one another) iff the dot product is 0 .$\\vec a \\cdot \\vec b$ is the length of .$\\vec a$ times the scalar projection of .$\\vec b$ onto .$\\vec a$ Notice that the dot product gives a scalar $$\\langle a_1, a_2, a_3 \\rangle \\cdot \\langle b_1, b_2, b_3 \\rangle = a_1b_1 + a_2b_2 + a_3b_3$$ $$\\vec a \\cdot (\\vec b + \\vec c) = \\vec a \\cdot \\vec b + \\vec a\\cdot \\vec c$$ $$ \\vec a \\cdot \\vec a = \\Vert \\vec a \\Vert ^2$$ $$ \\vec a \\cdot \\vec b = \\vec b \\cdot \\vec a $$ $$ (c \\vec a) \\cdot \\vec b = c (\\vec a \\cdot \\vec b) = \\vec a \\cdot (c \\vec b)$$ $$\\vec a \\cdot \\vec b = \\Vert\\vec a\\Vert\\ \\Vert\\vec b\\Vert \\cos \\theta$$ $$\\Vert\\vec a - \\vec b \\Vert^2 = \\Vert\\vec a\\Vert^2+\\Vert\\vec b\\Vert^2 - 2\\Vert\\vec a\\Vert \\Vert\\vec b\\Vert \\cos\\theta\\ $$ $$... = \\Vert\\vec a\\Vert\\ \\Vert\\vec b\\Vert \\cos \\theta$$ $$\\cos\\theta = \\frac{\\vec a \\cdot \\vec b}{\\Vert\\vec a\\Vert\\ \\Vert\\vec b\\Vert}$$ $$\\cos \\theta = \\frac{\\vec a}{\\Vert \\vec a \\Vert} \\cdot \\frac{\\vec b}{\\Vert \\vec b \\Vert} \\Longrightarrow \\cos^{-1}\\bigg(\\frac{\\vec a}{\\Vert \\vec a \\Vert} \\cdot \\frac{\\vec b}{\\Vert \\vec b \\Vert} \\bigg) = \\theta $$ Direction Vectors # The direction angles of a nonzero vector .$\\vec a$ are the .$\\alpha, \\beta, \\gamma$ that a makes with the positive .$x,y,z$-axes respectively $$\\cos\\alpha = \\frac{\\vec a \\cdot \\vec i}{\\Vert \\vec a \\Vert \\Vert \\vec i \\Vert} = \\frac{a_1}{\\Vert \\vec a \\Vert}$$ $$\\vec a = \\Vert \\vec a \\Vert \\langle \\cos \\alpha, \\cos \\beta, \\cos \\gamma \\rangle$$ Projections # Scalar projection of .$\\vec b$ onto .$\\vec a$: $$\\text{comp}_\\vec a\\vec b = \\frac{\\vec a\\cdot\\vec b}{\\Vert\\vec a\\Vert}$$ Vector projection of .$\\vec b$ onto .$\\vec a$: $$\\text{proj}_\\vec a\\vec b = \\bigg(\\frac{\\vec a\\cdot\\vec b}{\\Vert\\vec a\\Vert}\\bigg)\\frac{\\vec a}{\\Vert\\vec a\\Vert} = \\frac{\\vec a\\cdot\\vec b}{\\Vert\\vec a\\Vert^2}\\vec a$$ 12.4 Cross Product # The cross product measures how orthogonal two vectors are Therefore, .$(\\vec a \\times \\vec b) \\cdot \\vec b = 0$ because measures how similar (close to .$0^\\circ$) two vectors are and cross product outputs a vector orthogonal (.$90^\\circ$ to both .$\\vec a, \\vec b$) Two nonzero vectors are only parallel iff their cross product is zero The magnitude is also the area of a parallelogram formed by the two vectors We can find the volume of the 3D parallelogram formed by three vectors with the following equation: $$\\vec a \\cdot (\\vec b \\times \\vec c) = (\\vec a \\times \\vec b) \\cdot \\vec c$$ Realize that if the resulting area is .$0$, then all of the points exist on the same plane Notice that the cross product gives a vector that is orthogonal to both original vectors Direction is determined with the right-hand rule We can also calculate the determinant with the unit vectors .$\\langle \\hat i, \\hat j, \\hat k \\rangle$to find the cross product $$\\langle a_1, a_2, a_3 \\rangle \\times \\langle b_1, b_2, b_3 \\rangle = \\langle a_2b_3 - a_3 b_2, -(a1_b3 - a_3 b_1), a_1b_2 - a_2 b_1 \\rangle$$ $$\\vec a \\times \\vec b = \\Vert \\vec a \\Vert \\Vert \\vec b \\Vert \\sin\\theta$$ $$(\\vec a \\times \\vec b) \\times \\vec c \\neq \\vec a \\times (\\vec b \\times \\vec c) \\Longrightarrow \\vec a \\times (\\vec b \\times \\vec c) = (\\vec a \\cdot \\vec c) \\vec b - (\\vec a \\cdot \\vec b ) \\vec c$$ $$\\vec a \\times \\vec b \\neq \\vec b \\times \\vec b \\Longrightarrow \\vec a \\times \\vec b = - \\vec b \\times \\vec a$$ $$(c \\vec a) \\times \\vec b = c(\\vec a \\times \\vec b) = \\vec a \\times (c \\vec b)$$ $$\\vec a \\times (\\vec b + \\vec c) = \\vec a \\times \\vec b + \\vec a \\times \\vec c$$ $$(\\vec a + \\vec b) \\times \\vec c = \\vec a \\times \\vec c + \\vec b \\times \\vec c$$ $$\\Vert \\vec a \\times \\vec b \\Vert ^2 = \\Vert \\vec a \\Vert^2 \\Vert \\vec b \\Vert^2 - (\\vec a \\cdot \\vec b)^2 = \\Vert \\vec a \\Vert^2 \\Vert \\vec b \\Vert^2 \\sin^2 \\theta$$ $$\u0026hellip; \\Longrightarrow \\Vert \\vec a \\times \\vec b \\Vert \\Vert \\vec a \\Vert \\Vert \\vec b \\Vert \\sin \\theta$$ 12.5 Equation of Lines and Planes # Line # If given a point .$P_0 (x_0, y_0, z_0)$ and a vector .$\\vec v = \\langle a,b,c \\rangle$ that passes through said point (parallel), we can write a line equation as: $$\\langle x, y, z \\rangle = P_0 + t \\vec v = \\langle x_0 + ta, y_0 +tb, z_0 + tc \\rangle;\\ \\ t \\in \\mathbb{R}$$ We can then isolate .$t$ to find the symmetric equation of the line $$ t = \\frac{x-x_0}{a} = \\frac{y-y_0}{b} = \\frac{z-z_0}{c} $$ And we can extrapolate this to write an equation we can use to verify if two points are on a line: $$ t = \\frac{x-x_0}{x_1-x_0} = \\frac{y-y_0}{y_1-y_0} = \\frac{z-z_0}{z_1-z_0} $$ Note: If we have no change in an axis (such as .$x$), then .$x_1-x_0$ is zero. Therefore, we can write .$x = x_0$ (because we know it never changes) and the other relations for .$y$ and .$z$ still work We can also write our original equation in vector form as $$\\vec r(t) = \\vec r_0 + t\\vec v$$ Which we can use to write a specific line between point .$A$ and .$B$ from .$t \\in [0,1]$ as $$\\overrightarrow{AB} = \\langle x_1 - x_0, y_1 - y_0, z_1 - z_0 \\rangle$$ $$r(t) = \\vec A(1-t) + \\vec B(t)$$ Two vectors are equal iff corresponding components are equal 3D Lines can be parallel (same direction vector), intersect at one point (.$r_1 = r_2\\ @\\ t_1, t_2$), or skew (not intersecting nor parallel \u0026ndash; not possible in 2D) Planes # Planes need a point and direction Point .$P_0 (x_0, y_0, z_0)$ is trivial; a plane is a set of various points Direction is described by the normal vector .$\\vec n = \\langle a,b,c \\rangle$; only one normal unit vector per plane Given three points .$P_1, P_2, P_3$ on the plane, we can write two vectors .$\\vec a = \\overrightarrow{P_1 P_2}, \\vec b = \\overrightarrow{P_1, P_3}$ as we can find the normal vector as .$\\vec n = \\vec a \\times \\vec b$ Knowing this, we can write a vector equation: $$ \\vec n \\cdot \\overrightarrow{P_0 P} = 0$$ $$ \\vec n \\cdot (\\vec r - \\vec r_0) = 0$$ This can also be parameterized as both the scalar and linear equation respectively: $$a(x-x_0) + b(y-y_0) + c(z-z_0) = 0$$ $$ax + yz + cz + d = 0$$ Planes are parallel if their normal vectors are parallel Otherwise, they intersect and form a straight line Common Questions # Intersection point(s) of plane and parametric curve Given parametric curve .$C = \\langle \\alpha + a\\cdot t, \\beta + b\\cdot t, \\gamma + c \\cdot t \\rangle$ and plane equation .$P = x + y + z + d = 0$ \u0026hellip; Plug in each component of .$C$ as .$x,y,z$ in the .$P$ equation Solve for .$t$(s), then plug (it/them) into the prior equation to get intersection point(s) Angle between planes Given two planes with .$\\vec n_1, \\vec n_2$ respectively Use .$\\theta = \\cos^{-1}\\Big(\\frac{\\vec n_1 \\cdot \\vec n_2}{\\Vert \\vec n_1 \\Vert \\Vert \\vec n_2 \\Vert}\\Big)$ to find .$\\theta$ Angle between parametric lines that intercept at point .$P_3$ Given parametric equations .$L_1 = P_1 + t\\vec v_1$ and .$L_2 = P_2 + s\\vec v_2$ Find the .$t_3$ and .$s_3$ for when .$L_1 = P_3$ and .$L_2 = P_3$ (point of intersection) Use .$\\theta = \\cos^{-1}\\Big(\\frac{\\vec v_1\u0026rsquo;(t_3) \\cdot \\vec v_2\u0026rsquo;(s_3)}{\\Vert \\vec v_1\u0026rsquo;(t_3) \\Vert \\Vert \\vec v_2\u0026rsquo;(s_3) \\Vert}\\Big)$ to find .$\\theta$ Intersection of two lines: .$L_1: \\langle x_1, y_1, z_1 \\rangle + t \\cdot \\langle a_1, b_1, c_1\\rangle; L_2: \\langle x_2, y_2, z_2 \\rangle + s \\cdot \\langle a_2, b_2, c_2 \\rangle;$ First, check if they are parallel by checking if the directions of the two lines are scalar multiples of one another. Second, check if they intersect by setting the two parametric equations equal to one another: .$x_1 + t a_1 = x_2 + s a_2; y_1 + t b_1 = y_2 + s b_2; z_1 + t c_1 = z_2 + s c_2$ If an equation exists (that is, there is a valid .$t$ and .$s$) then they intersect at .$L_1(t)$ or .$L_2(s)$ Intersection line .$L$ of two planes Set one of the 3D variables to zero (e.x. .$z = 0$) to find where the two planes intersect the remaining plane (in this case the .$z$ plane) We find the intersection point .$P (\\alpha, \\beta, 0)$ by solving when our plane equations in the prior equation are equal Since the line .$L$ is orthogonal to both planes\u0026rsquo; normal vectors, our direction vector is .$\\vec v = n_1 \\times n_2 = \\langle a,b,c \\rangle$ We can then plug in everything into the symmetric equation: .$\\frac{x-\\alpha}{a} = \\frac{y-\\beta}{b} = \\frac{z-0}{c}$ Distance from point to plane Given point .$P_1(x_1, y_1, z_1)$ and plane .$ax+by+cz+d = 0$ $$D = \\Vert \\text{comp}_{\\vec n}{\\vec b} \\Vert = \\frac{\\vert ax_1 + by_1 + cz_1 +d\\vert}{\\sqrt{a^2 + b^2 + c^2}}$$ Distance from skew line to skew line Given .$L_1 = \\langle x_1, y_1, z_1 \\rangle + t \\vec v_1$ and .$L_2 = \u0026hellip;$ Find the plane containing .$L_2$ that is parallel to .$L_1$. .$P_3 = \\langle x- x_2, y - y_2, z - z_2 \\rangle \\cdot (v_1 \\times v_2)$ Find the .$D$istance from .$x_1, y_1, z_1$ on .$L_1$ to the plane .$P_3$ above $$D = \\frac{\\vert a_3 x_1 + b_3 y_1 + c_3 z_1 +d\\vert}{\\sqrt{a_3^2 + b_3^2 + c_3^2}}$$ Distance from point to line Given line .$L = \\langle x_0, y_0, z_0 \\rangle + \\langle a, b, c \\rangle$ and point .$P = \\langle P_x, P_y, P_z \\rangle$ Write a distance equation as .$D^2 = ((x_0 + ta) - P_x)^2 + ((y_0 + tb) - P_y)^2 + ((z_0 + tc) - P_z)^2$ Find the minimum value of .$t$ and plug in into the equation above and find .$D$ (but not .$D^2$!) 12.6 Cylinders and Quadratic Surfaces # Traces # Cross sections of a surface found by taking a three-variable equation and setting one of the equations variables equal to a constant. Help us visualize 3D curves by thinking about them from different axis $$z = \\frac{x^2}{4} + \\frac{y^2}{9} \\Longrightarrow k = \\frac{x^2}{4} + \\frac{y^2}{9}$$ $$... \\Longrightarrow z = \\frac{x^2}{4} + \\frac{k^2}{9}$$ In the left example, for every .$z$ value we have a ellipse In the right example, we have a parabola for every .$y$ value Cylinder # A cylinder is a surface that consists of all rulings that at parallel to a given line that passes through a given plane curve Two variable equation in 3D space E.x. .$y =\\sin x, z = x^2$ Quadratic Surfaces # A quadric surface is the graph of a second-degree equation with three variables Two standard forms (when centered about origin): $$Ax^2 + By^2 + Cz^2 + J = 0$$ $$Ax^2 + By^2 + Iz = 0$$ "},{"id":37,"href":"/math-53/13/","title":"13: Vector Functions","section":"Math 53","content":" 13.1 Vector Functions and Space Curves # Vector Functions # We can write a vector function as $$\\vec r(t) = \\langle f(t), g(t), h(t) \\rangle = f(t) \\hat i + g(t) \\hat j + h(t) \\hat k$$ The domain of .$\\vec r$ consists of all values of .$t$ for which each of the terms are defined The limit of a vector function is $$\\lim_{t\\to a} \\vec r(t) = \\big\\langle \\lim_{t\\to a} f(t), \\lim_{t\\to a} g(t), \\lim_{t\\to a} h(t) \\big\\rangle$$ .$\\vec r$ is continuous at time .$a$ if .$\\lim_{t\\to a} \\vec r(t) = \\vec r(a)$ Space Curve # The set .$C$ of all points defined by a vector function .$\\vec r$ over interval .$I$ is called a space curve. Think of .$C$ as being traced out by a moving particle whose position follows .$\\vec r$ Space curves are parametrized by a vector function but isn\u0026rsquo;t necessarily that vector function! E.x. .$\\vec r(t) \\langle \\cos t, \\sin t, t \\rangle \\neq \\vec q(t) = \\langle \\cos 3t, \\sin 3t, 3t \\rangle$ Space curves exist on the same point, but don\u0026rsquo;t grow at the same rate 13.2 Derivatives and Integrals of Vector Functions # Derivatives # $$\\frac{d\\vec r}{dt} = \\vec r\u0026rsquo;(t) = \\lim_{h \\to 0} \\frac{\\vec r(t+h) - r(t)}{h}$$ $$\u0026hellip; = \\big\\langle f\u0026rsquo;(t), g\u0026rsquo;(t), h\u0026rsquo;(t) \\big\\rangle$$\nNote that the last equation only works if each component is differentiable The direction is the tangent line and the magnitude is the rate at which the particle is moving at that point If we just want the tangent line, we can write the unit tangent vector: $$\\vec T(t) = \\frac{\\vec r\u0026rsquo;(t)}{\\Vert \\vec r \u0026rsquo; (t) \\Vert}$$ Differentiation rules (notice .$f(t)$ is a scalar function) $$ \\frac{d}{dt} \\big[f(t) \\vec u(t) \\big] = f\u0026rsquo;(t) \\vec u(t) + f(t) \\vec u\u0026rsquo;(t)$$ $$ \\frac{d}{dt}\\big[\\vec u(t) \\cdot \\vec v(t)\\big] = \\vec u\u0026rsquo;(t) \\cdot \\vec v(t) + \\vec u(t) \\cdot \\vec v\u0026rsquo;(t) $$ $$ \\frac{d}{dt} \\big[\\vec u(t) \\times \\vec v(t)\\big] = \\vec u\u0026rsquo; (t) \\times \\vec v(t) + \\vec u(t) + \\vec v\u0026rsquo;(t)$$ $$ \\frac{d}{dt} \\big[ \\vec u(f(t)) \\big] = f\u0026rsquo;(t) \\vec u\u0026rsquo; (f(t))$$ Integrals # Let .$\\vec r (t) = \\langle f(t), g(t), h(t) \\rangle$, then $$\\int_a^b \\vec r(t)\\ dt = \\bigg\\langle \\int_a^b f(t)\\ dt, \\int_a^b g(t) \\ dt, \\int_a^b h(t)\\ dt \\bigg\\rangle$$ Fundamental theorem: If .$\\vec R(t)$ is an anti-derivative of .$\\vec r(t)$, (i.e. .$\\vec R\u0026rsquo;(t) = \\vec r(t)$), then $$ \\int_a^b \\vec r(t) \\ dt = \\Big[\\vec R(t)\\Big]_a^b = \\vec R(b) - \\vec R(a)$$ "},{"id":38,"href":"/math-53/14/","title":"14: Partial Derivatives","section":"Math 53","content":" 14.1 Functions of Several Variables # In the real world, most things don\u0026rsquo;t depend on a single variable Temperature may depend on the .$(x,y)$ (latitude/longitude) position Volume of a cylinder depends on radius .$r$ and height .$h$: .$V =\\pi r^2 h$ Formal Definition: A function .$f$ of two variables is a rule that assigns to each ordered pair of real numbers .$(x,y)$ in a set .$D$ a unique real number denoted by .$f(x,y)$. The set .$D$ is the domain of .$f$ and its range is the set of values that .$f$ takes on, that is, .$\\{f(x,y)\\ |\\ (x,y) \\in D \\}$. E.x. for .$f(x,y) = \\frac{\\sqrt{x+y+1}}{x-1}$, the domain is .$D = \\{(x,y)\\ |\\ x + y + 1 \\geq 0, x \\neq 1\\}$ which can be graphed with a solid line following .$y =-x-1$ with a dotted line at .$x = 1$ E.x. for .$f(x,y) = x\\ln(y^2-x)$, the domain is .$D =\\{(x,y)\\ |\\ x\u0026lt;y^2\\}$. This can be graphed with a dotted line following the curve .$x = y^2$ For the equation .$z = f(x,y)$, .$x,y$ are the independent variables and .$z$ is the dependent variable \u0026ndash; similar to single variable equations We can visualize functions of two variables (i.e .$f(x,y)$) by graphing them in 3D as .$(x,y,f(x,y))$ We can then write level curves for the function by setting .$f(x,y) = k$ for some .$k$onstant in the range of .$f$. This will result in a graph similar to a Topographic map **Level Curve:** The level curves of a function .$f$ of two variables are the curves with equations .$f(x,y) = k$, where .$k$ is a constant (in the range of .$f$). 14.2 Limits and Continuity # Limits # **Vector Limit:** Let .$f$ be a function of two variables whose domain .$D$ includes points arbitrarily close to .$(a, b)$. Then we say that the **limit of** .$f(x, y)$ **as** .$(x, y)$ **approaches** .$a, b.$ is .$L$ and we write $$\\lim_{(x,y)\\to(a,b)} f(x,y) = L$$ if for every number .$\\varepsilon \u003c 0$ there is a corresponding number .$\\delta \u003c 0$ such that if .$(x, y) \\in D$ and .$0 \u003c \\sqrt{(x-a)^2 + (y-b)^2} \u003c \\delta$ then .$\\vert f(x,y) - L \\vert \u003c \\varepsilon$ Notice that .$\\vert f(x,y) - L \\vert$ is the distance between the numbers .$f(x, y)$ and .$L$, and .$\\sqrt{(x-a)^2 + (y-b)^2}$ is the distance between the point .$(x, y)$ and the point .$(a, b)$. If .$f(x,y) \\to L_1$ as .$(x,y) \\to (a,b)$ along a path .$C_1$ and .$f(x,y) \\to L_2$ as .$(x,y) \\to (a,b)$ along a path .$C_2$, where .$L_1 \\neq L_2$, then .$\\lim_{(x,y)\\to(a,b)} f(x,y)$, does not exist. We can test this by setting .$x$ and .$y$ to various different values (e.x. .$x = 0, y = 0, x = y, \u0026hellip;,$ etc) Continuity # A function .$f$ of two variables is called continuous at .$(a,b)$ if $$\\lim_{(x,y)\\to (a,b)} f(x,y) = f(a,b)$$ We say .$f$ is continuous on .$D$ if .$f$ is continuous at every point .$(a,b)$ in .$D$. That is, we need the limit to exist ands for .$f(a,b)$ to be defined Continuous functions: .$x,y, c, \\text{ trig (on domain)}$ Arithmetic, composition, exponent all preserve continuity (on domain!) Dividing doesn\u0026rsquo;t necessarily preserve continuity 14.3 Partial Derivatives # If .$f$ is a function of two variables, its **partial derivatives** are the functions .$f_x$ and .$f_y$ defined by $$f_x(x,y) = \\frac{\\delta f}{\\delta x} = \\lim_{h\\to0} \\frac{f(x+h,y)-f(x,y)}{h}$$ $$f_y(x,y) = \\frac{\\delta f}{\\delta y} = \\lim_{h\\to0} \\frac{f(x,y+h)-f(x,y)}{h}$$ Notice we use .$\\delta$ instead of .$d$ for partial derivatives These can be written at a single point .$(a,b)$ with respect to .$x$ and .$y$ by treating the remaining variables as a constant $$f_x(a,b) = g\u0026rsquo;(a); \\ \\ \\ g(x) = f(x,b)$$ $$f_y(a,b) = h\u0026rsquo;(b); \\ \\ \\ h(y) = f(a,y)$$ Which can be extrapolated for 3 (or more) variables: $$f_z(a,b,c) = k\u0026rsquo;(c); \\ \\ \\ k(z) = f(a,b,z)$$ Higher Derivatives # Just like regular derivatives, we can do many partial derivatives For example, the following are second partial derivatives of .$z = f(x,y)$: $$(f_x)_x = f_{xx} = \\frac{\\delta }{\\delta x}\\bigg(\\frac{\\delta f}{\\delta x}\\bigg) = \\frac{\\delta^2f}{\\delta x^2}$$ $$(f_x)_y = f_{xy} = \\frac{\\delta }{\\delta y}\\bigg(\\frac{\\delta f}{\\delta x}\\bigg) = \\frac{\\delta^2f}{\\delta y \\delta x}$$ $$(f_y)_x = f_{yx} = \\frac{\\delta }{\\delta x}\\bigg(\\frac{\\delta f}{\\delta y}\\bigg) = \\frac{\\delta^2f}{\\delta x \\delta y}$$ $$(f_y)_y = f_{yy} = \\frac{\\delta }{\\delta y}\\bigg(\\frac{\\delta f}{\\delta y}\\bigg) = \\frac{\\delta^2f}{\\delta y^2}$$ **Clairaut's Theorem** Suppose .$f$ is defined on a disk .$D$ that contains the point .$(a,b)$. If the functions .$f_{xy}$ and .$f_{yx}$ are both continuous on .$D$, then $$f_{xy}(a,b) = f_{yx}(a,b)$$ Partial Differential Equations # In the sciences, we typically want to find how a system changes with respect to multiple variables Partial derivatives occur in partial differential equations, e.x Laplace\u0026rsquo;s Equation: $$ \\frac{\\delta^2 u}{\\delta x^2} + \\frac{\\delta^2 u}{\\delta y^2} = 0$$ Solutions to Laplace\u0026rsquo;s are always harmonic functions, such as .$u = e^x \\sin(y)$ 14.4 Tangent Planes and Linear Approximations # Tangent Planes # Tangent planes are to surfaces as tangent lines are to curves Tangent planes contain both the partial derivative lines w.r.t .$x$ and .$y$ All we need to know to write a tangent plane is a point .$(a,b)$ and direction of the two partial derivatives .$\\langle 1,0, f_x(a,b)\\rangle, \\langle 0,1, f_y(a,b)\\rangle$ Direction vector can be found with .$\\langle 1,0, f_x(a,b)\\rangle \\times \\langle 0,1, f_y(a,b)\\rangle = \\langle -f_x, -f_y, 1 \\rangle$ which we can dot with .$\\langle x-x_0, y-y_0, z-f(x_0,y_0) \\rangle$ Suppose .$f$ has continuous partial derivatives. An equation of the tangent plane to the surface .$z = f(x, y)$ at the point .$P(x_0,y_0,z_0)$ is $$z-f(x_0, y_0) = f_x(x_0,y_0)(x-x_0) + f_y(x_0, y_0)(y-y_0)$$ Linear Approximations # As we get very close to the surface, then the tangent plane (at point .$(a,b)$) looks more and more like the surface Thus, we can use it to for making approximations when we are near near .$(a,b)$ If .$z = f(x,y)$, then .$f$ is _differentiable_ at .$(a,b)$ if .$\\Delta z$ can be expressed in the form $$\\Delta z = f_x(a,b)\\Delta x + f_y(a,b)\\Delta y + \\varepsilon_1 \\Delta x + \\varepsilon_2 \\Delta y$$ where the error terms, .$\\varepsilon_1$ and .$\\varepsilon_2 \\to 0$ as .$(\\Delta x, \\Delta y) \\to (0,0)$ and the other terms are the linearization of the function. Rewriting this, we can use the given .$f(x,y)$ to write the linear approximation which is an estimate for point/state at .$f(a,b)$ $$f(x,y) \\approx f(a,b) + f_x(a,b) (x-a) + f_y(a,b)(y-b)$$ We can similarly define the 3D linear approximation, increment of .$w$, and differential .$dw$ as: $$f(x,y,z) \\approx f(a,b,c) + f_x(a,b,c) (x-a) + f_y(a,b,c)(y-b) + f_z(a,b,c) (z-c)$$ $$\\Delta w = f(x+\\Delta x, y + \\Delta y, z + \\Delta z) - f(x,y,z)$$ $$dw = \\frac{\\delta w}{\\delta x}dx + \\frac{\\delta w}{\\delta y}dy + \\frac{\\delta w}{\\delta z}dz$$ Differentials # With one variable functions, i.e. .$y = f(x)$, we defined the differential .$dx$ to be independent so we had to write .$dy$ as .$dy = f\u0026rsquo;(x)\\ dx$ Given a differentiable function of two variables, i.e. .$z = f(x,y)$, we know both .$dx$ and .$dy$ are independent so we write: $$dz = f_x(x,y)\\ dx + f_y(x,y)\\ dy = \\frac{\\delta z}{\\delta x}dx + \\frac{\\delta z}{\\delta y}dy$$ If the partial derivatives .$f_x$ and .$f_y$ exist near .$(a,b)$ and are continuous at .$(a,b)$, then .$f$ is differentiable at .$(a,b)$. 14.5 Chain Rule # Chain Rule # Suppose that .$z = f(g_1 (x_1,\\_{\\dots}, x_m), g_2 (x_1,_{\\dots}, x_m), g_n (x_1,\\_{\\dots}, x_m))$ is a differentiable function of the .$n$ variables .$g_1,\\_{\\dots}, g_n$ and is .$g_j$ is a differentiable function of the .$m$ variables .$x_1,\\_{\\dots}, x_m$. Then .$z$ is a function of .$x_1,\\_{\\dots}, x_m$ and $$ \\frac{\\delta f}{\\delta x_i} = \\frac{\\delta f}{\\delta g_1} \\frac{\\delta g_1}{\\delta x_i} + \\frac{\\delta f}{\\delta g_2} \\frac{\\delta g_2}{\\delta x_i} + \\dots + \\frac{\\delta f}{\\delta g_m} \\frac{\\delta g_m}{\\delta x_i}$$ for each .$i = 1,2,\\dots,m$ Implicit Differentiation # If .$F(x,y) = 0$ defines .$y$ implicitly as a function of .$x$ (that is, .$y = f(x)$, where .$F(x,f(x))= 0$ for all .$x$ in the domain of .$f$), then $$ \\frac{dy}{dx} = - \\frac{\\frac{\\delta F}{\\delta x}}{ \\frac{\\delta F}{\\delta y}} = - \\frac{F_x}{F_y}$$\nIf .$F(x,y,z) = 0$ defines .$z$ implicitly as a function of .$x,y$, then\n$$ \\frac{dz}{dx} = - \\frac{\\frac{\\delta F}{\\delta x}}{ \\frac{\\delta F}{\\delta z}} = - \\frac{F_x}{F_z};\\ \\ \\frac{dz}{dy} = - \\frac{\\frac{\\delta F}{\\delta y}}{ \\frac{\\delta F}{\\delta z}} = - \\frac{F_y}{F_z}$$\n14.6 Directional Derivatives and the Gradient Vector # Directional Derivatives # **Direction Derivative** For function .$f$ at .$(x_0, y_0)$ in the direction of **unit vector** .$\\hat u = \\langle a, b \\rangle$ is $$D_{\\hat u} f(x_0, y_0) = \\lim_{h\\to 0} \\frac{f(x_0 + ha, y_0 + hb) - f(x_0, y_0)}{h} = $$ $$\\dots = \\nabla f \\cdot \\hat u = f_x (x,y) a + f_y (x,y) b$$ if the limit exists (for the former) and if .$f$ is a differentiable function of .$x$ and .$y$ (for the latter) That is, .$\\hat u = \\hat i = \\langle 1, 0 \\rangle$ for .$D_\\hat{i} = f_x$ and .$\\hat u = \\hat j = \\langle 0, 1 \\rangle$ for .$D_\\hat{j} = f_y$ Differentiability is important because it means that as you approach the surface very closely, it looks more and more like the tangent plane. Directional derivatives can be thought of as the slope of the tangent line at a given point This definition can be extrapolated to (three variables/higher dimensions) trivially, shown below with gradient vectors Gradient Vector # **Gradient:** If .$f$ is a function of variable .$x,y,z$, then the gradient of .$f$ is the vector function .$\\nabla f$ defined by $$\\nabla f(x,y,z) = \\big\\langle f_x(x,y,z), f_y (x,y,z), f_z (x,y,z) \\big\\rangle = \\frac{\\delta f}{\\delta x}\\hat i + \\frac{\\delta f}{\\delta y}\\hat j + \\frac{\\delta f}{\\delta z}\\hat k$$ We can now use the gradient to re-write our directional derivative equation as $$D_{\\hat u} f(x,y,z,\\dots) = \\nabla f(x,y,z,\\dots) \\cdot \\hat u$$ We can re-write this using the definition of the dot product as $$D_{\\hat u} f(x,y,z,\\dots) = \\Vert \\nabla f \\Vert \\Vert \\hat u \\Vert \\cos\\theta =\\Vert \\nabla f \\Vert \\cos\\theta $$ Maximizing the Directional Derivative # Suppose .$f$ is a differentiable function of two or three variables. The maximum value of the directional derivatives .$D_\\hat{u} f(\\vec x)$ is .$\\Vert \\nabla f(\\vec x ) \\Vert$ and it occurs when .$\\hat u$ has the same direction as the gradient vector .$\\nabla f(\\vec x)$ We can see from the definition above that since the max of .$\\cos\\theta$ is .$1$ when .$\\theta = 0$, therefore the max of the directional derivative occurs at the same angle (when .$\\hat u$ has the same direction of .$\\nabla f$ ) TL;DR: .$D_\\hat{u} f(\\vec x)$ is maximized if .$\\vec u = \\frac{\\nabla f}{\\Vert \\nabla f \\Vert}\\bigg\\vert_\\vec{p}$ at point .$\\vec p$ Tangent Planes to Level Surfaces # If .$f(x,y) = k$ is a curve, then .$F(x,y,z) = k$ is a surface Let .$\\vec r(t)$ be a space curve on the surface .$F(x,y,z) = k$ Let .$\\vec r(t_0) = \\langle x_0, y_0, z_0 \\rangle$ for some .$t_0$ (at some time, the space curve passes through some point which is on the surface) We know .$F(\\vec r(t)) = k$, thus, using the chain rule: $$0 = \\frac{\\delta F}{\\delta x} \\frac{\\delta x}{\\delta t} + \\frac{\\delta F}{\\delta y} \\frac{\\delta y}{\\delta t} + \\frac{\\delta F}{\\delta z} \\frac{\\delta z}{\\delta t} = \\nabla F(x_0, y_0, z_0) \\cdot (\\vec r(t_0))\u0026rsquo;$$ The gradient vector at .$P$, .$F(x_0, y_0, z_0)$, is perpendicular to the tangent vector .$\\vec r\u0026rsquo;(t)$ to any curve .$C$ on .$S$ that passes through .$P$ In English: The direction of the gradient is always perpendicular to the level surface at every point We can then define the tangent plane to the level surface .$F(x,y,z) = k$ at .$P(x_0, y_0, z_0)$ as the plane that passes through .$P$ and has normal vector .$\\nabla F(x_0, y_0, z_0)$: $$\\nabla F\\big\\vert_{(x_0, y_0, z_0)} \\cdot \\langle x-x_0, y-y_0, z-z_0 \\rangle = 0$$ We can also write this in the symmetric equation form: $$\\frac{x-x_0}{F_x(x_0, y_0, z_0)} = \\frac{y-y_0}{F_y(x_0, y_0, z_0)} = \\frac{z-z_0}{F_z(x_0, y_0, z_0)}$$ 14.7 Maximum and Minimum Values # Critical Points # A function of two variables has a **local maximum** at .$(a,b)$ if .$f(x,y) \\leq f(a,b)$ when .$(x,y)$ is near .$(a,b)$ [This means that for .$f(x,y) \\leq f(a,b)$ for all points .$(x,y)$ in some disk with center .$(a,b)$.] The number .$f(a,b)$ is called a local maximum _value_. If .$f(x,y) \\geq f(a,b)$ when .$(x,y)$ is near .$(a,b)$, then .$f$ has a **local minimum** at .$(a,b)$ and .$(x,y)$ is a local minimum _value_. If the inequalities above hold for all points .$(x,y)$ in the domain of .$f$, then .$f$ has an absolute maximum (or absolute minimum) at .$(a,b)$ If .$f$ has a local maximum or minimum at .$(a,b)$ and the first-order partial derivatives of .$f$ exist there, then .$f_x(a,b) = 0$ and .$f_y(a,b) = 0$. If the graph of .$f$ has a tangent plane at a local maximum or minimum, then the tangent plane must be horizontal .$(a,b)$ is a Critical Point of .$f$ if .$f_x(a,b) = 0$ and .$f_y(a,b) = 0$, or if one of these partial derivatives does not exist Thus, if .$f$ has a local maximum or minimum at .$(a,b)$, then .$(a,b)$ is a critical point of .$f$ In other words, at a critical point, a function could have a local maximum or a local minimum or neither (saddle point). **Second Derivatives Test:** Suppose the second partial derivatives of .$f$ are continuous on a disk with center .$(a, b)$, and suppose that .$f_x(a, b) = 0$ and .$f_y(a, b) = 0$ (that is, .$(a, b)$ is a critical point of .$f$ ). Let $$D = D(a, b) = \\begin{vmatrix}f_{xx} \u0026 f_{xy}\\\\\\ f_{yx} \u0026 f_{yy}\\end{vmatrix} = f_{xx}(a, b) f_{yy}(a, b) - (f_{xy}(a, b))^2$$ - If .$D \u003e 0$ and .$f_{xx}(a, b) \u003e 0$ (or .$f_{yy}(a, b) \u003e 0$), then .$f(a, b)$ is a local minimum. - If .$D \u003e 0$ and .$f_{xx}(a, b) \u003c 0$ (or .$f_{yy}(a, b) \u003c 0$), then .$f(a, b)$ is a local maximum. - If .$D \u003c 0$, then .$f(a, b)$ is a saddle point - If .$D = 0$, the test gives no information: .$f$ could be any of the above Note that in the first two tests, it\u0026rsquo;s implied that .$f_{xx}$ and .$f_{yy}$ have the same sign The determinant is a Hessian matrix Extreme Points # - Just as a closed interval contains its endpoints, a **closed set** in .$\\mathbb{R}^2$ is one that contains all its boundary points. - For instance, the disk .$D = \\\\{(x,y) \\vert x^2 + y^2 \\leq 1 \\\\}$ is a closed set because it contains all of its boundary points (which are the points on the circle .$r = 1$) - But if even one point on the boundary curve were omitted, the set would not be closed - A **bounded set** in .$\\mathbb{R}^2$ is one that is contained within some disk -- it is finite in extent ![Sets](/docs/math-53/imgs/sets.png) **Extreme Value Theorem for Functions of Two Variables:** If .$f$ is continuous on a closed, bounded set .$D$ in .$\\mathbb{R}^2$, then .$f$ attains an absolute maximum value .$f(x_1, y_1)$ and an absolute minimum value .$f(x_2, y_2)$ at some points .$(x_1, y_1)$ and .$(x_2, y_2)$ in .$D$. If .$f$ has an extreme value at .$(x_1, y_1)$, then .$(x_1, y_1)$ is either a critical point of .$f$ or a boundary point of .$d$. To find the absolute maximum and minimum values of a continuous function .$f$ on a closed, bounded set .$D$: Find the values of .$f$ at the critical points of .$f$ in .$D$. Find the extreme values of .$f$ on the boundary of .$D$. The largest of the values from steps 1 and 2 is the absolute maximum value; the smallest of these values is the absolute minimum value. 14.8 Lagrange Multipliers # We use Lagrange Multipliers to find critical points of a surface .$f$ given some constraining surface .$g$ **Method of Lagrange Multipliers** To find the maximum and minimum values of .$f(x,y,z)$ subject to the constraint .$g(x,y,z) = k$ [assuming that these extreme values exist and .$\\nabla \\neq 0$ on the surface .$g(x,y,z) = k$]: - Find all values of .$x, y, z$, and .$\\lambda$ such that $$\\nabla f(x,y,z) = \\lambda \\nabla g(x,y,z)$$ $$g(x,y,z) = k$$ - Evaluate .$f$ at all the points .$(x, y, z)$ that result from the first step. The largest of these values is the maximum value of .$f$; the smallest is the minimum value of .$f$. We can decompose the first equation and use the second equation to get $$f_x = \\lambda g_x;\\ \\ f_y = \\lambda g_y;\\ \\ f_z = \\lambda g_z;\\ \\ g(x,y,z) = k$$ Notice we don\u0026rsquo;t care what .$\\lambda$ is, only that it exists Two Constraints # We can use Lagrange multipliers for two constraints .$f$ and .$g$ too: $$\\nabla f(x_0, y_0, z_0) = \\lambda \\nabla g(x_0, y_0, z_0) + \\mu \\nabla h(x_0, y_0, z_0)$$ Likewise, we can decompose the equation above to get the following five equations: 1. $$f_x = \\lambda g_x + \\mu h_x$$ 2. $$f_y = \\lambda g_y + \\mu h_y$$ 3. $$f_z = \\lambda g_z + \\mu h_z$$ 4. $$g(x,y,z) = k$$ 5. $$h(x,y,z) = c$$ ![Two Constraints](/docs/math-53/imgs/two-constr.png) "},{"id":39,"href":"/math-53/15/","title":"15: Multiple Integrals","section":"Math 53","content":" 15.1 Double Integrals over Rectangles # We describe closed rectangles in the form .$R = [a,b] \\times [c,b] = \\{(x,y) \\in \\mathbb{R}^2 \\vert a \\leq x \\leq b, c \\leq y \\leq d\\}$ Then we can write the solid .$S$ that lies above .$R$ as .$S = \\{(x,y,z) \\in \\mathbb{R}^3 \\vert 0 \\leq z \\leq f(x,y), (x,y) \\in R\\}$ To find the volume of this surface, we take a double integral $$V = \\iint_R f(x,y)\\ dA$$ **Fubini's Theorem:** If .$f$ is continuous on the rectangle .$R = \\\\{(x,y) \\vert a \\leq x \\leq b, c \\leq y \\leq d\\\\}$, then $$\\iint_R f(x,y)\\ dA = \\int_a^b \\int_c^d f(x,y)\\ dy\\ dx = \\int_c^d \\int_a^b f(x,y)\\ dx\\ dy$$ More generally, this is true if we assume that .$f$ is bounded on .$R$, .$f$ is discontinuous only on a finite number of smooth curves, and the iterated integrals exist. Average Value # In the 2D case we could write the average as $$f_\\text{avg} = \\frac{1}{b-a} \\int_a^b f(x) dx$$ For 3D, instead of dividing by the change in just .$y$ (which was .$b-a$), we divide over the total area: $$f_\\text{avg} = \\frac{1}{A(R)}\\iint_R f(x,y)\\ dA$$ 15.2 Double Integrals over General Regions # Type I # If .$f$ is continuous on a type I region .$D$ such that $$D = \\\\{(x,y)\\ \\vert\\ a \\leq x \\leq b,\\ g_1(x) \\leq y \\leq g_2(x)\\ \\\\}$$ then $$\\int_D f(x,y)\\ dA = \\int_a^b \\int_{g_1(x)}^{g_2(x)} f(x,y)\\ dy\\ dx$$ Type II # If .$f$ is continuous on a type II region .$D$ such that $$D = \\\\{(x,y)\\ \\vert\\ c \\leq y \\leq d,\\ h_1(y) \\leq x \\leq h_2(y)\\ \\\\}$$ then $$\\int_D f(x,y)\\ dA = \\int_c^d \\int_{h_1(y)}^{h_2(y)} f(x,y)\\ dx\\ dy$$ Properties of Double Integrals # $$\\iint_D \\Big[ f(x,y) + g(x,y)\\Big]\\ dA = \\iint_{D} f(x,y)\\ dA + \\iint_{D} g(x,y)\\ dA$$ $$\\iint_D c\\cdot f(x,y)\\ dA = c \\iint_D f(x,y)\\ dA\\ \\text{ where $c$ is a constant}$$ $$\\iint_D f(x,y)\\ dA \\geq \\iint_D g(x,y)\\ dA \\ \\text{ if $f(x,y) \\geq g(x,y)$ for all $(x,y) \\in D$}$$ $$\\iint_D f(x,y)\\ dA = \\iint_{D_1} f(x,y)\\ dA + \\iint_{D_2} f(x,y)\\ dA\\ \\text{ for $D = D_1 \\cup D_2$}$$ $$mA(D) \\leq \\iint_D f(x,y)\\ dA \\leq MA(D)$$ If .$m \\leq f(x,y) \\leq M$ for all .$(x,y) \\in D$ 15.3 Double Integrals in Polar Coordinates # Recall that we can convert cartesian to polar with the following equations: $$r^2 = x^2 +y^2$$ $$x = r\\cos\\theta$$ $$y = r\\sin\\theta$$ - We multiply .$r$ because an \"infinitesimal\" polar rectangle as an ordinary rectangle with dimensions .$r\\ d\\theta$ and .$dr$ and therefore has area .$dA = r\\ dr\\ d\\theta$ - That is, the further out the polar rectangle is (the larger the .$r$), the larger the area of that rectangle is (this scale is .$\\propto r$) ![Polar r factor](/docs/math-53/imgs/polar-mult.png) If .$f$ is continuous on a polar region of the form $$D = \\\\{(r,\\theta)\\ \\vert\\ \\alpha \\leq \\theta \\leq \\beta, h_1(\\theta) \\leq r \\leq h_2(\\theta) \\\\}$$ then $$\\iint_D f(x,y)\\ dA = \\int_\\alpha^\\beta \\int_{h_1(\\theta}^{h_2(\\theta)} r \\cdot f(r\\cos\\theta, r\\sin\\theta)\\ dr\\ d\\theta$$ 15.5 Surface Area # The area of the surface with equation .$z = f(x,y), (x,y) \\in D$, where .$f_x$ and .$f_y$ are continuous, is $$A(S) = \\iint_D \\sqrt{\\big[f_x(x,y)\\big]^2 + \\big[f_y(x,y)\\big]^2 + 1}\\ dA$$ Notice the similarities between the SA function and the line integral function, .$L = \\int_a^b \\sqrt{1 + \\big( \\frac{dy}{dx} \\big)^2}\\ dx$ 15.6 Triple Integrals # Fubini's Theorem for Triple Integrals If f is continuous on the rectangular box B − fa, bg 3 fc, dg 3 fr, sg, then $$\\iiint_B f(x,y,z)\\ dV = \\int_r^s\\int_c^d\\int_a^b f(x,y,z)\\ dx\\ dy\\ dz$$ The iterated integral on the right side of Fubini\u0026rsquo;s Theorem means that we integrate first with respect to .$x$ (keeping .$y$ and .$z$ fixed), then we integrate with respect to .$y$ (keeping .$z$ fixed), and finally we integrate with respect to .$z$. Note that if .$f$ is separable this just becomes the product of three single-dimensional integrals, or one two-dimensional integral and two one-dimensional integrals. Fubini\u0026rsquo;s theorem still applies. Type 1 # $$\\iiint_E f(x,y,z)\\ dV$ = \\iint_D \\bigg[\\int_{u_1(x,y)}^{u_2(x,y)}f(x,y,z)\\ dz\\bigg]\\ dA$$\nType I # $$\\dots = \\int_a^b \\int_{g_1(x)}^{g_2(x)} \\int_{u_1(x,y)}^\\{u_2(x,y)}f(x,y,z)\\ dz\\ dx\\ dy$$ Type II # $$\\dots = \\int_c^d \\int_{h_1(y)}^{h_2(y)} \\int_{u_1(x,y)}^\\{u_2(x,y)}f(x,y,z)\\ dz\\ dy\\ dx$$ Type 2 # $$\\iiint_E f(x,y,z)\\ dV$ = \\iint_D \\bigg[\\int_{u_1(y,z)}^{u_2(y,z)}f(x,y,z)\\ dx\\bigg]\\ dA$$\nType 3 # $$\\iiint_E f(x,y,z)\\ dV$ = \\iint_D \\bigg[\\int_{u_1(x,z)}^{u_2(x,z)}f(x,y,z)\\ dy\\bigg]\\ dA$$\n15.7 Triple Integrals in Cylindrical Coordinates # Cylindrical to Cartesian # $$x = r\\cos\\theta$$ $$y = r\\sin\\theta$$ $$z = z$$ Cartesian to Cylindrical # $$r^2 = x^2 + y^2$$ $$\\tan\\theta = \\frac{y}{x}$$ $$z = z$$ - Now we deal with integration in cylindrical coordinates. - We have .$dV = dx\\ dy\\ dz$ - Since .$z$ is the same, .$dz$ is the same. However, we can convert .$dx, dy$ to .$r\\ dr, dθ.$ since it is the same transformation as in polar coordinates. - Thus the volume element in cylindrical coordinates is .$dV = r\\ dr\\ dθ\\ dz$. ![](/docs/math-53/imgs/cyl-v.png) $$\\iiint_D f(x,y,z) dx\\ dy\\ dz = \\iiint_D f(r\\cos\\theta, r\\sin\\theta, z)\\cdot r\\ dr\\ d\\theta\\ dz$$ $$\\dots = \\int_\\alpha^\\beta \\int_{h_1(\\theta)}^{h_2(\\theta)} \\int_{u_1(r\\cos\\theta, r\\sin\\theta)}^{u_2(r\\cos\\theta, r\\sin\\theta)} f(r\\cos\\theta, r\\sin\\theta, z)\\cdot r\\ dz\\ dr\\ d\\theta$$ 15.8 Triple Integrals in Spherical Coordinates # - Spherical Coordinates map .$(x,y,z) \\Longrightarrow (\\rho, \\theta, \\phi)$ - .$\\rho$ is the distance between the origin and point; .$\\rho \\geq 0$ - .$\\theta$ is the angle on the .$xy$ plane; .$\\theta \\in [0, 2\\pi]$ - .$\\phi$ is the angle between the .$z$ axis and the .$xy$ plane; .$\\phi \\in [0, \\pi]$ - We only need to consider half the sphere; the other half is already counted by the varying .$\\theta$. ![](/docs/math-53/imgs/sph.png) Spherical to Cartesian # $$x =\\rho \\sin \\phi \\cos \\theta$$ $$y =\\rho \\sin \\phi \\sin \\theta$$ $$z =\\rho \\cos \\phi$$ Cylindrical to Spherical # $$x =\\rho \\sin \\phi$$ $$\\theta = \\theta$$ $$z =\\rho \\cos \\phi$$ Cartesian to Spherical # $$\\rho = \\sqrt{x^2 + y^2 + z^2}$$ $$\\tan \\theta = \\frac{y}{x}$$ $$\\tan \\phi = \\frac{z}{\\sqrt{x^2 + y^2}}$$ $$\\iiint_E f(x,y,z)\\ dV = \\dots$$ $$\\dots = \\int_c^d \\int_\\alpha^\\beta \\int_a^b f(\\rho\\sin\\phi\\cos\\theta, \\rho\\sin\\phi\\sin\\theta, \\rho\\cos\\phi) \\cdot \\rho^2 \\sin\\phi\\ d\\rho\\ d\\theta\\ d\\phi$$ - We have the volume element .$dV = dx\\ dy\\ dz$. By converting to cylindrical coordinates and doing some algebraic conversions we have .$dV = \\rho^2 \\sin\\phi d\\rho\\ d\\theta\\ d\\phi$: ![](/docs/math-53/imgs/sph-v.png) 15.9 Change of Variable in Multiple Integrals # We\u0026rsquo;ve done .$u$-sub before in single variable, as well as cartesian .$\\iff$ polar .$\\iff$ spherical in multivariable More generally, we can consider a change of variables that is given by a transformation .$T$ from the .$uv$-plane to the .$xy$-plane: .$T(u,v) = (x,y)$ where .$x = g(u,v), y = h(u,v)$ .$x,y$ must be differentiable in .$S$ We usually assume that .$T$ is a .$C^1$ transformation: .$g$ and .$h$ have continuous first-order partial derivatives A transformation .$T$ is really just a function whose domain and range are both subsets of .$\\mathbb{R}^2$ If .$T(u_1, v_1 = (x_1, y_1)$, then the point .$(x_1,y_1)$ is called the image of the point .$(u_1, v_1)$ That is, .$T$ transforms .$S$ into a region .$R$ in the .$xy$-plane called the image of .$S$, consisting of the images of all points in .$S$ If no two points have the same image, .$T$ is called one-to-one ( wiki) If .$T$ is a one-to-one transformation, then it has an inverse transformation .$T^{-1}$ from the .$xy$-plane to the .$uv$-plane + it may be possible to solve for .$u$ and .$v$ in terms of .$x$ and .$y$: .$u = G(x,y), v = H(x,y)$ If not one-to-one, then the transformation would \u0026ldquo;fold\u0026rdquo; over itself \u0026ndash; we would double-count some amount of area This change in variable affects the size of the region (the area/integral) The vector .$\\vec r (u, v) = g(u, v) \\hat i + h(u, v) \\hat j$ is the position vector of the image of the point .$(u, v)$. - The tangent vector at .$(x_0, y_0)$ to the image curve of the lower side (.$v = v_0$) of .$S$: $$\\vec r_v = \\frac{\\delta x}{\\delta v} \\hat i + \\frac{\\delta y}{\\delta v} \\hat j$$ - Similarly, the tangent vector at .$(x_0, y_0)$ to the image curve of the left side (.$u = u_0$) of .$S$: $$\\vec r_u = \\frac{\\delta x}{\\delta u} \\hat i + \\frac{\\delta y}{\\delta u} \\hat j$$ - We can then find the area by calculating the cross product: $$\\vec r_u \\times \\vec r_v = \\begin{vmatrix} \\frac{\\delta x}{\\delta u} \u0026 \\frac{\\delta x}{\\delta v} \\\\\\ \\frac{\\delta y}{\\delta u} \u0026 \\frac{\\delta y}{\\delta v} \\end{vmatrix}$$ $$\\dots = \\frac{\\delta (x,y)}{\\delta (u,v)} = \\frac{\\delta x}{\\delta u} \\frac{\\delta y}{\\delta v} - \\frac{\\delta x}{\\delta v}\\frac{\\delta y}{\\delta u}$$ - This is the **Jacobian** of the transformation .$T$ given by .$x = g(u,v)$ and .$y = h(u,v)$ ![](/docs/math-53/imgs/jacob.png) Formally, Suppose that .$T$ is a .$C^1$ transformation whose Jacobian is nonzero and that .$T$ maps a region .$S$ in the .$uv$-plane onto a region .$R$ in the .$xy$-plane. Suppose that .$f$ is continuous on .$R$ and that .$R$ and .$S$ are type I or type II plane regions. Suppose also that .$T$ is one-to-one, except perhaps on the boundary of .$S$. Then, $$\\iint_R f(x,y) dA = \\iint_S f(x(u,v), y(u,v)) \\Bigg\\vert \\frac{\\delta (x,y)}{\\delta (u,v)} \\Bigg\\vert\\ du\\ dv$$ That is, .$dA = \\Bigg\\vert \\frac{\\delta (x,y)}{\\delta (u,v)} \\Bigg\\vert\\ du\\ dv$ ## General Solving Steps 1. Write down transformations (.$x$ and .$y$ in terms of .$u$ and .$v$) 2. Find the Jacobian 3. Rewrite the equations with .$u$ and .$v$ 4. Sketch the new region + find new bounds 5. Integrate on the new field with Jacobian Triple Integrals # We can also let .$T$ be a transformation that maps a region .$S$ in .$uvw$-space onto a region .$R$ in .$xyz$-space by means of the equations: $$x = g(u,v,w)$$ $$y = h(u,v,w)$$ $$z = k(u,v,w)$$ Then, the Jacobian is a .$3 \\times 3$ determinant: $$ \\frac{\\delta (x,y,z)}{\\delta (u,v,w)} = \\begin{vmatrix} \\frac{\\delta x}{\\delta u} \u0026amp; \\frac{\\delta x}{\\delta v} \u0026amp; \\frac{\\delta x}{\\delta w} \\\\ \\frac{\\delta y}{\\delta u} \u0026amp; \\frac{\\delta y}{\\delta v} \u0026amp; \\frac{\\delta y}{\\delta w} \\\\ \\frac{\\delta z}{\\delta u} \u0026amp; \\frac{\\delta z}{\\delta v} \u0026amp; \\frac{\\delta z}{\\delta w} \\end{vmatrix} = dA$$ "},{"id":40,"href":"/math-53/16/","title":"16: Vector Calculus","section":"Math 53","content":" 16.1 Vector Fields # A vector field in .$\\mathbb{R}^3$ is a function .$\\vec F$ on region .$E \\in \\mathbb{R}^3$ that assigns each point .$(x,y,z)$ a vector .$F(x,y,z)$ .$\\vec F$ is made up of component function: .$\\vec F(x,y,z) = \\langle P(x,y,z)\\hat i, Q(x,y,z) \\hat j, R(x,y,z) \\hat k\\rangle$ .$\\vec F$ is continuos iff its component vectors are continuos .$\\vec F$ is conservative (path taken doesn\u0026rsquo;t change work) iff potential function .$f(x,y,z)$ is a partial of .$\\vec F$ $$\\vec F = \\nabla f$$ Notice that the gradient lines are always perpendicular to the level sets If the function .$f$ is differentiable, .$\\nabla f$ at a point is either zero or perpendicular to the level set of .$f$ at that point. That is, that the gradient of a function is called a gradient field which is always conservative (the fundamental theorem of calculus for line integrals) Conversely, a (continuous) conservative vector field is always the gradient of a function 16.2 Line Integrals # We know that the distance (length) normally is .$L = \\int_a^b \\sqrt{(dx/dt)^2 + (dy/dt)^2}\\ dt$ Over a vector field, we can think of the function being the density of the line (or height of particle). Therefore, we say .$ds = \\int_a^b \\sqrt{(dx/dt)^2 + (dy/dt)^2}\\ dt$ and can write $$\\int_C f(x,y) ds = \\int_a^bf(x(t), y(t)) \\cdot \\sqrt{\\bigg(\\frac{dx}{dt}\\bigg)^2 + \\bigg(\\frac{dy}{dt}\\bigg)^2} dt$$ and for 3D in a slightly different form: $$\\int_a^b f (\\vec r (t) ) \\vert \\vec r\u0026rsquo;(t) \\vert \\Longrightarrow \\int_a^b f(x(t), y(t), z(t)) \\cdot \\sqrt{x\u0026rsquo;(t)^2 + y\u0026rsquo;(t)^2 + z\u0026rsquo;(t)^2} dt$$ We can write .$\\vec a \\to \\vec b$ as .$(1-t)\\vec a + t\\vec b$ with .$t\\in[0,1]$ Just like usual, we can break up un-integrable smooth curves, i.e $$\\int_a^z f (x,y) = \\int_a^b f_1(x,y) + \\int_b^c f_2(x,y) + \\dots \\int_{\\dots}^z f_n(x,y)$$ wrt variable # Opposed to the line integrals on .$f$ along .$C$ with respect to .$x$ both and .$y$, we can write line integral with respect to arc length as follows:\n$$\\int_C f(x,y) dx = \\int_a^b f(x(t), y(t)) \\cdot y\u0026rsquo;(t) dt$$ $$\\int_C f(x,y) dy = \\int_a^b f(x(t), y(t)) \\cdot x\u0026rsquo;(t) dt$$\nIt frequently happens that line integrals with respect to .$x$ and .$y$ occur together which we abbr as\n$$\\int_C P(x,y)\\ dx + \\int_C Q(x,y)\\ dy = \\int_C P(x,y)\\ dx + Q(x,y)\\ dy$$\nOrientation # When we parameterize a curve, we give it a direction Positive: Enclosed region .$D$ is always on the left as we traverse curve .$C$ (counter-clockwise) Negative: Enclosed region .$D$ is always on the right as we traverse curve .$C$ (clockwise) The orientation represents the direction of the line The positive direction corresponding to increasing values of the parameter .$t$ Doesn\u0026rsquo;t matter for regular line integrals: .$\\int_C f(x,y) ds = \\int_C f(x,y) ds$ Deals with distance, .$ds$, which doesn\u0026rsquo;t depend on direction Does matter for field line integrals: .$\\int_C f(x,y) dx \\neq \\int_C f(x,y) dy$ Deals with displacement, .$dx/dy$, which depends on direction Let .$\\vec F$ be a continuous vector field defined on a smooth curve .$C$ given by a vector function .$\\vec r(t), t\\in[a,b]$. Then the line integral of .$\\vec F$ along .$C$ is $$W = \\int_C \\vec F \\cdot d\\vec r = \\int_a^b \\vec F ( \\vec r (t) ) \\cdot (\\vec r (t))'\\ dt = \\int_C \\vec F \\cdot \\vec T\\ ds$$ - .$\\vec T(x,y,z)$ is the unit tangent vector at the point .$(x,y,z)$ on .$C$ - .$\\vec F \\cdot \\vec T = \\vec F(x,y,z) \\cdot \\vec T(x,y,z)$ This equation says that work is the line integral with respect to arc length of the tangential component of the force. Then, for a non-conservative force i.e .$F = \\langle P(x,y,z), Q(x,y,z), R(x,y,z) \\rangle$ $$W = \\int_a^b P(\\vec r(t)) \\cdot x\u0026rsquo;(t) + Q(\\vec r(t)) \\cdot y\u0026rsquo;(t) + R(\\vec r(t)) \\cdot z\u0026rsquo;(t)$$ $$ \\Longrightarrow \\int_C P\\ dx + Q\\ dy + R\\ dz$$ If we flip the curve\u0026hellip; - ...and integrate with respect to just .$x$ or .$y$ then the value flips: $$\\int_{-C}f(x,y)\\ dx = - \\int_C f(x,y)\\ dx$$ - Since .$\\Delta x$ and .$\\Delta y$ change sign when we reverse the orientation of .$C$. - ...and integrate with respect to arc length, the value of the line integral does not change when we reverse the orientation of the curve: $$\\int_{-C}f(x,y)\\ ds = \\int_C f(x,y)\\ ds$$ - This is because .$\\Delta s$ is always positive. 16.3 Fundamental Thm for Line Integrals # Let .$C$ be a smooth curve given by the vector function .$\\vec r (t), t\\in[a,b]$. Let .$f$ be a differentiable function of two or three variables whose gradient vector .$\\nabla f$ is continuous on .$C$. Then $$\\int_C \\nabla f \\cdot d\\vec r =\\int_C \\vec F \\cdot d\\vec r = f(\\vec r(b) ) f(\\vec r(a))$$ Independence of Path # Suppose .$C_1$ and .$C_2$ are two piecewise-smooth curves (which are called paths) that have the same initial point .$A$ and terminal point .$B$. Therefore, .$\\int_{C_1} \\nabla f \\cdot d\\vec r = \\int_{C_2} \\nabla f \\cdot d\\vec r$ whenever .$\\nabla f$ is continuous In other words, line integrals of conservative vector fields are independent of path (they only depend on the start and end points) Plane Curves # .$\\int_C \\vec F \\cdot d\\vec r$ is independent of path in .$D$ iff .$\\int_C \\vec F \\cdot d\\vec r = 0$ for every **closed** path .$C$ in .$D$ - **Closed:** A curve with the same end and start points: .$\\vec r(b) = \\vec r(a)$ - That is, only vector fields that are independent of path are conservative. ![Closed Curve](/docs/math-53/imgs/closed-curve.png) Space Curves # Suppose .$\\vec F$ is a vector field that is continuous on an **open connected** region .$D$. If .$\\int_C \\vec F \\cdot d\\vec r$ is _independent_ of path in .$D$, then .$\\vec F$ is a conservative vector field on .$D$; that is, there exists a function .$f$ such that .$\\nabla f = \\vec F$. - **Open:** For every point .$P$ in .$D$ there is a disk with center .$P$ that lies entirely in .$D$. (So .$D$ doesn't contain any of its boundary points.) - **Connected:** Any two points in .$D$ can be joined by a path that lies in .$D$. $$$$ ![](/docs/math-53/imgs/path-d.png) ![Curves](/docs/math-53/imgs/curves.png) ![Regions](/docs/math-53/imgs/regions.png) - If .$\\vec F (x,y) = P(x,y) \\hat i + Q(x,y) \\hat j$ is a conservative vector field, where .$P$ and .$Q$ have continuous first-order partial derivatives on a domain .$D$, then throughout .$D$ we have $$ \\frac{\\delta P}{\\delta y} = \\frac{\\delta Q}{\\delta x}$$ - The converse of the theorem above is true on only **simple curves**: curves that don't intersect itself anywhere between its endpoints - A **simply-connected** region in the plane is a connected region .$D$ such that every simple closed curve in .$D$ encloses only points that are in .$D$ - Intuitively speaking, a simply-connected region contains no hole and can't consist of two separate pieces. .$\\vec F = \\langle P, Q \\rangle$ is a *conservative* vector field on an open *simply-connected* region .$D$ iff both .$P$ and .$Q$ have continuous first-order partial derivatives and $$ \\frac{\\delta P}{\\delta y} = \\frac{\\delta Q}{\\delta x} \\text{ throughout } D$$ 16.4 Green\u0026rsquo;s Theorem # **Green's Theorem:** Let .$C$ be a *positively oriented*, piecewise-smooth, *simple closed* curve in the plane and let .$D$ be the region bounded by .$C$. If .$P$ and .$Q$ have continuous partial derivatives on an *open region* that contains .$D$, then $$\\int_C \\vec F \\cdot d\\vec r = \\oint_C P\\ dx + Q\\ dy = \\iint_D \\bigg(\\frac{\\delta Q}{\\delta x} - \\frac{\\delta P}{\\delta y}\\bigg) dA$$ - .$dA = dx\\ dy = r \\cdot dr\\ d\\theta = \\dots$ - .$\\vec F(x,y) = \\langle P(x,y), Q(x,y)\\rangle$ - .$\\oint$ implies an integral over a closed curve The proof (for Green\u0026rsquo;s thm + remaining sections) is (are) too much for me to write out here, the book does a good job One important takeaway is the the shape doesn\u0026rsquo;t have to be \u0026ldquo;nice\u0026rdquo; \u0026ndash; we can break up any shape into parts that are either Type I or II. Even though we will have overlapping lines, they cancel one another out (leaving only the boundaries) because of orientation Green\u0026rsquo;s Theorem should be regarded as the counterpart of the Fundamental Theorem of Calculus for double integrals Recall the Fundamental Theorem of Calculus is .$\\int_a^b F\u0026rsquo;(x)\\ dx = F(b) - F(a)$ In both cases there is an integral involving derivatives (.$F\u0026rsquo;, \\delta Q/\\delta x, \\delta P/\\delta y$) on the left side of the equation. And in both cases the right side involves the values of the original functions (.$F, Q, P$) only on the boundary of the domain. (In the one-dimensional case, the domain is an interval .$[a,b]$ whose boundary consists of just two points, .$a$ and .$b$.) Application: Finding Area # Since the area of .$D$ is .$\\iint_D 1 dA$, we wish to choose .$P$ and .$Q$ so that $$ \\frac{\\delta Q}{\\delta x} - \\frac{\\delta P}{\\delta y} = 1$$ Some examples of .$P/Q$ combos are $$P(x,y)= 0$$ $$Q(x,y)= x$$ $$A = \\oint_C x\\ dy$$ $$P(x,y)=-y$$ $$Q(x,y)= 0$$ $$A = -\\oint_C y\\ dx$$ $$P(x,y)=-y/2$$ $$Q(x,y)= x/2$$ $$A = \\frac{1}{2} \\oint_C x\\ dy - y\\ dx$$ Planimeters (a measuring instrument used to determine the area of an arbitrary two-dimensional shape) is an example of an application of Green Theorem We can also use Green\u0026rsquo;s to prove our last equation found in 16.3: $$\\oint_C \\vec F \\cdot d \\vec r = \\oint_C P\\ dx + Q\\ dy = \\iint_R \\bigg( \\frac{\\delta Q}{\\delta x} - \\frac{\\delta P}{\\delta y}\\bigg)\\ dA = \\iint_R 0\\ dA = 0$$ A curve that is not simple crosses itself at one or more points and can be broken up into a number of simple curves. We have shown that the line integrals of .$\\vec F$ around these simple curves are all .$0$ and, adding these integrals, we see that .$\\int_C \\vec F \\cdot d\\vec r = 0$ for any closed curve .$C$. Therefore .$\\int_C \\vec F \\cdot d\\vec r$ is independent of path in .$D$. It follows that .$F$ is a conservative vector field.\n16.5 Curl and Divergence # Recall that .$\\nabla = \\langle \\frac{\\delta}{\\delta x} \\frac{\\delta}{\\delta y} \\frac{\\delta}{\\delta z} \\rangle$ 3b1b video going over this section Curl # Vector of the rotation caused by the field at a given point $$\\nabla \\times \\vec F(x,y,z) = \\begin{bmatrix}\\hat i \u0026amp; \\hat j \u0026amp; \\hat k\\\\ \\frac{\\delta}{\\delta x} \u0026amp; \\frac{\\delta}{\\delta y} \u0026amp; \\frac{\\delta}{\\delta z}\\\\ P \u0026amp; Q \u0026amp; R\\end{bmatrix} = \\dots $$ If .$\\vec F$ is conservative then .$\\text{curl($\\vec F$) = 0}$ We know if .$\\vec F$ is conservative then .$\\vec F = \\nabla f$ for some .$f(x,y,z)$ Crossing .$\\nabla F$ with .$\\nabla$ we get .$\\langle \\frac{\\delta^2 f}{\\delta y \\delta z} - \\frac{\\delta^2 f}{\\delta z \\delta y}, \\dots \\rangle = \\langle 0, 0,0 \\rangle$ Divergence # If .$\\vec F (x,y,z)$ is the velocity of a fluid (or gas), then .$\\text{div}(\\vec F (x,y,z))$ represents the net rate of change (wrt time) of the mass of fluid (or gas) flowing from the point .$(x,y,z)$ per unit volume. In other words, .$\\text{div}(\\vec F (x,y,z))$ measures the tendency of the fluid to diverge from the point .$(x,y,z)$. If .$\\text{div}(\\vec F (x,y,z)) = 0$, then .$F$ is said to be incompressible. Scalar of the amount of \u0026ldquo;flow\u0026rdquo; at a given point \u0026ndash; how much does the field expand/contract at a given point? $$\\nabla \\cdot \\vec F(x,y,z) = \\langle \\frac{\\delta}{\\delta x} \\frac{\\delta}{\\delta y} \\frac{\\delta}{\\delta z} \\rangle \\cdot \\langle P, Q, R \\rangle$$ Fun fact: .$\\text{(div(curl($\\vec F$)))} = \\nabla \\cdot (\\nabla \\times \\vec F)= 0$ We can use this fact to find if there exists a vector field .$\\vec G$ such that .$\\text{curl($\\vec G$)} = \\vec H$ because .$\\text{div(curl($\\vec G$))} = \\text{div($\\vec H$)} = 0$ Vector Form of Green\u0026rsquo;s # $$\\oint_C \\vec F \\cdot d \\vec r = \\iint_D \\text{(curl ($\\vec F$))} \\cdot \\hat k\\ dA = \\bigg( \\frac{\\delta Q}{\\delta x} - \\frac{\\delta P}{\\delta y} \\bigg) \\hat k$$\n- This equation expresses the line integral of the tangential component of .$\\vec F$ along .$C$ as the double integral of the vertical component of .$\\text{curl($\\vec F$)}$ over the region .$D$ enclosed by .$C$. ![](/docs/math-53/imgs/green-tan.png) We can write this using the normal component of .$\\vec F$ too: With .$\\vec r(t) = \\langle x(t), y(t) \\rangle; t \\in [a,b]$ Recall the unit tangent vector: .$\\vec T(t) = \\frac{1}{\\vert \\vec r \u0026rsquo; (t) \\vert} \\langle x\u0026rsquo;(t), y\u0026rsquo;(t) \\rangle$ The outward unit normal vector to .$C$ is given by .$\\vec n (t) = \\frac{1}{\\vert \\vec r \u0026rsquo; (t) \\vert} \\langle y\u0026rsquo;(t), -x\u0026rsquo;(t) \\rangle$ We can then evaluate $$\\oint_C \\vec F \\cdot \\vec n\\ ds = \\int_a^b (\\vec F \\cdot \\vec n)(t) \\vert \\vec r\u0026rsquo;(t) \\vert\\ dt = \\iint_D \\bigg( \\frac{\\delta P}{\\delta x} - \\frac{\\delta Q}{\\delta y} \\bigg)\\ dA = \\iint_D \\text{div $\\vec F (x,y)$}\\ dA$$ This says that the line integral of the normal component of .$\\vec F$ along .$C$ is equal to the double integral of the divergence of .$\\vec F$ over the region .$D$ enclosed by .$C$. 16.6 Parametric Surfaces and Their Area # Parametric Surfaces # Just like how we can describe curves with single parameter (variable) function .$\\vec r(t)$, we can describe surfaces with a vector function .$\\vec r(u,v) = \\langle x(u,v), y(u,v), z(u,v) \\rangle$ .$\\vec r(u,v)$ is called a vector-valued function defined on a region .$D$ in the .$uv$-plane .$x,y,z$ are the component functions of .$\\vec r$, each of which have domain .$D$ In general, a surface given as the graph of a function of .$x$ and .$y$, that is, with an equation of the form .$z = f(x,y)$, can always be regarded as a parametric surface by taking .$x$ and .$y$ as parameters and writing the parametric equations as .$x = x; y = y; z = f(x,y)$ E.x. the plane with point .$(x_0, y_0, z_0)$ and vectors .$\\langle a,b,c \\rangle$ .$\\langle \\alpha,\\beta,\\gamma \\rangle$ is .$\\vec r(u,v) = \\langle x_0, y_0, z_0 \\rangle + u\\langle a,b,c \\rangle + v\\langle \\alpha,\\beta,\\gamma \\rangle$ or .$0 = (\\langle x - x_0, y - y_0, z - z_0 \\rangle) \\cdot (\\langle a,b,c \\rangle \\times \\langle \\alpha,\\beta,\\gamma \\rangle)$ Surfaces of Revolution # ![](/docs/math-53/imgs/param-rev.png) - We can write surfaces of revolution as parametric equations too - Consider surface .$S$ obtained by rotating the curve .$y = f(x)$ about the .$x$-axis (with .$f(x) \\geq 0$) - Therefore, we get the following parameterization: $$x = x$$ $$y = f(x)\\cos\\theta$$ $$z = f(x)\\sin\\theta$$ Tangent Planes # Employing the same method as before, we can find the tangent plane to a param surface .$S$ by finding the initial point and the normal vector Given some parameterization .$\\vec r(u,v) = \\langle x(u,v), y(u,v), x(u,v) \\rangle$ and initial point .$P_0 = (x_0, y_0)$\u0026hellip; Find point .$P_0$ by setting .$x(u,v) = x_0, y(u,v) = y_0, \\dots$ and solving for .$u_0,v_0$ Find normal vector .$\\vec n$ by deriving to get, then cross, the parameterization: .$\\vec n = \\vec r_u \\times \\vec r_v$ If the normal vector isn\u0026rsquo;t zero, the tangent plane is at .$\\vec n (u_0, v_0)$ If it is, then the surface .$S$ isn\u0026rsquo;t smooth (it is at a \u0026ldquo;corner\u0026rdquo;) The tangent plane can then be expressed as $$(\\vec r_u \\times \\vec r_v)_{(u_0, v_0)} \\cdot (\\langle x,y,z \\rangle - \\langle x_0, y_0, z_0 \\rangle)$$ Surface Area # The image of the subrectangle .$R_{ij}$ is the patch .$S_{ij}$.\nRecall that the magnitude of the cross product is the area of a parallelogram formed by two vectors We can think of this as the jacobian of the transformation If a smooth parametric surface .$S$ is given by the equation $$\\vec r(u,v) = \\langle x(u,v), y(u,v), z(u,v) \\rangle; (u,v) \\in D$$ and .$S$ is covered just once as .$(u,v)$ ranges throughout the parameter domain .$D$, then the surface area of .$S$ is $$A(S) = \\iint_D \\vert \\vec r_u \\times \\vec r_v \\vert\\ dA$$ where $$\\vec r_u = \\langle \\frac{\\delta x}{\\delta u}, \\frac{\\delta y}{\\delta u}, \\frac{\\delta z}{\\delta u} \\rangle; \\vec r_v = \\langle \\frac{\\delta x}{\\delta v}, \\frac{\\delta y}{\\delta v}, \\frac{\\delta z}{\\delta v} \\rangle$$ Surface Area of the Graph of a Function # For the special case of a surface .$S$ with equation .$z = f(x,y)$, where .$(x,y)$ lies in .$D$ and .$f$ has continuous partial derivatives, we take .$x$ and .$y$ as parameters. That is, the parametric equations are .$x = x; y = y; z = f(x,y)$ Therefore .$\\vec r_x = \\langle 1, 0, \\frac{\\delta f}{\\delta x} \\rangle; \\vec r_y = \\langle 0, 1, \\frac{\\delta f}{\\delta y};$ and .$\\vec n = \\sqrt{1 + \\frac{\\delta f}{\\delta x}^2 + \\frac{\\delta f}{\\delta y}^2}$ Thus, the surface area becomes $$A(S) = \\iint_D \\sqrt{1 + \\frac{\\delta f}{\\delta x}^2 + \\frac{\\delta f}{\\delta y}^2}\\ dA$$ Notice the similarity between the surface area formula above and the arc length formula 16.7 Surface Integral # Surface Integral # The relationship between surface integrals and surface area is much the same as the relationship between line integrals and arc length. The arc length is a line integral where the density (or weight) function .$f(x,y,z) = 1$ That is, .$\\int_C f(x,y,z)\\ ds = \\int_a^b f(\\vec r(t)) \\vert \\vec r\u0026rsquo;(t) \\vert$ Similarly, the surface area is found taking the surface integral with density function .$f(x,y,z) = 1$ That is, .$\\iint_S 1\\ dS = \\iint_D \\vert \\vec r_u \\times \\vec r_v \\vert\\ dA = A(S)$ If we define .$\\vec r(u,v) = \\langle x(u,v), y(u,v), z(u,v) \\rangle; (u,v) \\in D$ $$\\iint_S f(x,y,z)\\ dS = \\iint_D f(\\vec r(u,v)) \\vert \\vec r_u \\times \\vec r_v \\vert\\ dA$$ Graphs of Functions # Any surface .$S$ with equation .$z = g(x,y)$ can be regarded as a parametric surface with parametric equations $$x = x$$ $$y = y$$ $$z = g(x,y)$$ Thus, $$\\vec r_x = \\bigg\\langle 1, 0, \\frac{\\delta g}{\\delta x}\\bigg\\rangle$$ $$\\vec r_y = \\bigg\\langle 0, 1, \\frac{\\delta g}{\\delta y}\\bigg\\rangle$$ $$\\vec r_x \\times \\vec r_y = \\bigg\\langle -\\frac{\\delta g}{\\delta x}, -\\frac{\\delta g}{\\delta y}, 1\\bigg\\rangle$$ $$\\vec n = \\sqrt{\\bigg(\\frac{\\delta z}{\\delta x}\\bigg)^2 + \\bigg(\\frac{\\delta z}{\\delta y}\\bigg)^2 + 1}$$ Therefore, $$\\iint_S f(x,y,z)\\ dS = \\iint_D f(x,y,g(x,y)) \\sqrt{\\bigg(\\frac{\\delta z}{\\delta x}\\bigg)^2 + \\bigg(\\frac{\\delta z}{\\delta y}\\bigg)^2 + 1}\\ dA$$ Similar formulas apply when it is more convenient to project .$S$ onto the .$yz$-plane or .$xz$-plane. Oriented Surfaces # With the exception of the Möbius strip, most surfaces are two-sided, meaning they\u0026rsquo;re Orientable surfaces We start with a surface .$S$ that has a tangent plane at every point .$(x,y,z)$ on .$S$ (except at any boundary point). There are two unit normal vectors .$\\hat n_1$ and .$\\hat n_2 = -\\vec n_1$ at .$(x,y,z)$ If it is possible to choose a unit normal vector .$\\hat n$ at every such point .$(x,y,z)$ so that .$\\hat n$ varies continuously over .$S$, then .$S$ is called an oriented surface - The choice of .$\\hat n$ provides .$S$ with an **orientation**. - There are two possible orientations for any orientable surface - For a closed surface, the positive orientation has the normal vectors pointing outward and vis-versa ![](/docs/math-53/imgs/orientation-dir.png) If .$S$ is a smooth orientable surface given in parametric form by a vector function .$\\vec r (u,v)$ then it is automatically supplied with the orientation of the unit normal vector $$\\hat n = \\frac{\\vec r_u \\times \\vec r_v}{\\vert \\vec r_u \\times \\vec r_v \\vert}$$ E.x., going back to a surface .$z = g(x,y)$ given as the graph of .$g$, the normal unit vector is $$\\hat n = \\frac{\\big\\langle -\\frac{\\delta g}{\\delta x}, -\\frac{\\delta g}{\\delta y}, 1\\big\\rangle}{\\sqrt{\\big(\\frac{\\delta z}{\\delta x}\\big)^2 + \\big(\\frac{\\delta z}{\\delta y}\\big)^2 + 1}}$$ Since the .$\\hat k$-component is positive, this gives the upward orientation of the surface. Surface Integrals of Vector Fields (Flux) # If .$\\vec F$ is a continuous vector field defined on an oriented surface .$S$ with unit normal vector .$\\hat n$, then the surface integral of .$\\vec F$ over .$S$ is $$\\iint_S \\vec F \\cdot d\\vec S = \\iint_S \\vec F \\cdot \\hat n \\ dS = \\iint_D \\vec F \\cdot (\\vec r_u \\times \\vec r_v)\\ dA$$ This integral is also called the **flux** of .$\\vec F$ across .$S$. In words, the surface integral of a vector field .$\\vec F$ over .$S$ is equal to the surface integral of its normal component over .$S$ (as previously defined). We can apply this to fluids: Imagine a fluid with density .$\\rho (x,y,z)$ and velocity field .$\\vec v (x,y,z)$ flowing through .$S$. Think of .$S$ as an imaginary surface that doesn\u0026rsquo;t impede the fluid flow, like a fishing net across a stream. Then the rate of flow (mass per unit time) per unit area is .$\\vec F = \\vec v \\rho$ The flux can be interpreted physically as the rate of flow through .$S$. 16.8 Stokes\u0026rsquo; Theorem # Just as Green\u0026rsquo;s Theorem relates a double integral over a plane region .$D$ to a line integral around its plane boundary curve, Stokes\u0026rsquo; Theorem relates a surface integral over surface .$S$ to a line integral around the boundary curve of .$S$ (which is a space curve) **Stokes' Theorem:** Let .$S$ be an oriented piecewise-smooth surface that is bounded by a simple, closed, piecewise-smooth boundary curve .$C$ with positive orientation. Let .$\\vec F$ be a vector field whose components have continuous partial derivatives on an open region in .$\\mathbb{R}^3$ that contains .$S$. Then $$\\int_C \\vec F \\cdot d \\vec r = \\iint_S \\text{curl } \\vec F \\cdot d\\vec S$$ In words, Stokes\u0026rsquo; Theorem says that the line integral around the boundary curve of .$S$ (some curve.$C$) of the tangential component of .$\\vec F$ is equal to the surface integral over .$S$ of the normal component of the curl of .$F$ This is since $$\\int_C \\vec F \\cdot d \\vec r = \\int_C \\vec F \\cdot \\vec T\\ ds \\ \\ \\ \\text{ and }\\ \\ \\iint_S \\text{curl } \\vec F \\cdot d\\vec S = \\iint_S \\text{curl } \\vec F \\cdot \\hat n\\ dS$$ 16.9 Divergence Theorem # **Divergence Theorem:** Let .$E$ be a simple solid region and .$S$ be the boundary surface of .$E$, given with positive (outward) orientation. Let .$\\vec F$ be a vector field whose component functions have continuous partial derivatives on an open region that contains .$E$. Then $$\\iint_S \\vec F \\cdot d\\vec S = \\iiint_E \\text{div } \\vec F\\ dV$$ In words, we can say that the Divergence Theorem says that (under the given conditions) the flux of .$\\vec F$ across the boundary surface of .$E$ is equal to the triple integral of the divergence of .$\\vec F$ over .$E$. "},{"id":41,"href":"/physics-7b/17/","title":"17: Temperature, Thermal Expansion, \u0026 Ideal Gas Law","section":"Physics 7B","content":" 17.1: Atomic Theory # Atoms are the smallest unit of matter Atomic unit: .$\\text{u} = 1.66\\cdot 10^{-27}$ kg E.x. Hydrogen weighs .$1.0078 \\text{u}$ Molecular mass of a compound is the sum of the particles (atoms) in the compound Terms # Element: Substance that cannot be broken down into smaller substances (gold) Molecule: Group of atoms held together by covalent bonds Compound: Substance made from atoms combined in specific ratios Brownian Motion # Random movement seen in pollen/dust, as well as atoms Using Brownian motion, Einstein found the size of an atom to be .$10^{-10}$ meters Forces # Atoms and molecules exert an (electric) attractive force on one another by default If an atom/molecule gets too close to another, they exert a repelling force on one another Matter states: Solid: Atoms held in matrix formation by strong attractive forces. Atoms vibrate around their mean position Liquid: Force between atoms is weaker so atoms move more rapidly within Gas: Atom attractive forces are so weak compared to their kinetic energy that they move randomly If two atoms collide, the attractive force is so weak that they may just bounce off one another 17.2: Temperature and Thermometers # Matter property changes under different temperatures Sidewalks expand under the sun Electric resistance increases with heat Lightbulb filament glows Thermometers Types # Originally used alcohol which expands linearly with heat (water doesn\u0026rsquo;t) Bimetalic strips bend at slightly different rates under heat Electronic thermometers measure resistance change and often have digital screens Scales # Fahrenheit: Water freezes at 32 and boils at 212 deg Celsius: Water freezes at 0 and boils at 100 deg Kelvin: Celsius + 273.15K. Written without degree sign. Absolute = 0K Conversions: $$T(^\\circ C) = \\frac{5}{9}(T(^\\circ F)-32)$$ $$T(^\\circ F) = \\frac{9}{5}(T(^\\circ C)) + 32$$ Different materials expand at different rates ro we use constant-volume thermos because it\u0026rsquo;s pressure linearly relates to the temperature 17.3 0th Law of Thermodynamics # If objects .$A$ and .$B$ are at equilibrium with object .$C$ , then .$A$ and .$B$ are also at equilibrium with one another Systems naturally reach equilibrium over time Thermal Expansion # Most materials expand when heated Expansion amount depends on the material Equations (assuming a constant volume .$V$ ) Linear Expansion: .$\\alpha$ is the coefficient of linear expansion and depends on the material with units .$(^\\circ C)^{-1}$ $$\\Delta l \\approxeq \\alpha l_0 \\cdot \\Delta T$$ $$l_i + \\Delta l = l_f = l_i ( 1 + \\alpha\\Delta T)$$ $$\\frac{dl}{dT} = \\alpha(T)\\cdot l$$ If .$\\Delta T$ is too large such that the temperature dependence of .$\\alpha$ is too large, we can do the following: $$\\int_{l_i}^{l_f} \\frac{1}{l}dl = \\int_{T_i}^{T_f} \\alpha(T) dT$$ Volume Expansion: $$\\beta = \\frac{1}{V} \\frac{dV}{dT}$$ $$V_f \\approxeq V_0 ( 1 + \\beta\\Delta T)$$ .$\\beta \\approx 3\\cdot\\alpha$ = coefficient of volume expansion. Coefficient of expansion varies at extremely high heats so it only works with small .$\\Delta T$ \u0026rsquo;s Materials must be isotropic (have same expansion properties in all directions) for us to say .$\\alpha \\approx 3\\cdot\\beta$ (Linear) expansion doesn\u0026rsquo;t exist for gas or liquids because they have no fixed space like solids. Weird water property .$0 - 4 ^\\circ C$ : Water increases in density .$\\rho^+\\Longrightarrow$ decreases in volume .$V^-$ .$4^\\circ C +$ : Water acts \u0026ldquo;normally\u0026rdquo;: increase in volume .$V$ proportional to temperature .$T$ This explains why pipes burst when frozen and why ice cubes float 17.5 Thermal Stresses # When the ends a solid (rod) are fixed (such as in beams), temperature changes induce thermal stress due to the clamp limiting expansion/contraction Process Steps: Beam tries to expand/contract by .$\\Delta l$ Mount reacts with an opposite reactive force, keeping it at it\u0026rsquo;s original length: $$\\Delta l = \\frac{1}{E} \\cdot \\frac{F}{A} \\cdot l_0$$ where .$E$ is Young\u0026rsquo;s modulus for the material. We can also re-write for stress: $$\\frac{F}{A} = \\Delta l \\cdot E \\cdot \\frac{1}{l_0} = (\\alpha l_0 \\Delta T) E \\cdot \\frac{1}{l_0} = \\alpha E \\Delta T$$ 17.6 Gas Laws and Absolute Temperature # Equation at State describes how pressure varies with Temperature, Number of Particles (Molecules), and Volume State is the physical condition of a system Equilibrium State: .$T, N, \\\u0026amp;\\ V = \\text{Constant}$ Laws # Assume that gasses aren\u0026rsquo;t too dense (so .$P \\sim$ atmospheric pressure) and that they aren\u0026rsquo;t close to liquefaction (boiling) point either (for oxygen, this is .$~183^\\circ \\text{C}$.) ![Ideal Gas Law Relation Equation](/docs/physics-7b/imgs/ideal.png) - **[Boyle's Law](https://en.wikipedia.org/wiki/Boyle's_law)** - .$V \\propto P^{-1}$ [Constant Temperature] - .$P$ is absolute, not gauge, pressure - Alternatively, .$PV =$ const or .$P_1V_1 = P_2V_2$ - **[Charles's Law](https://en.wikipedia.org/wiki/Charles%27s_law)** - .$V \\propto T$ [Constant Pressure] - Alternatively, .$\\frac{V_1}{T_1} = \\frac{V_2}{T_2}$ - **[Gay Lussac's Law](https://en.wikipedia.org/wiki/Gay-Lussac%27s_law)** - .$P \\propto T$ [Constant Volume] - Alternatively, .$\\frac{P_1}{T_1} = \\frac{P_2}{T_2}$ 17.7 Ideal Gas Law # $$PV = nRT = n k_B N_a T = N k_B T$$ .$P$ is the pressure of the gas [Pascals] .$V$ is the volume of the gas [Cubic Meters] .$T$ is the absolute temperature of the gas [Kelvins] .$N$ is the number of molecules of gas - .$n$ is the amount of substance of gas (number of moles) \\[Moles] - .$R$ is the ideal, or universal, gas constant, equal to .$k_B \\cdot N_a = 8.314 \\frac{J}{K\\cdot \\text{mol}}$ - Using mass of a gas, different gasses have different proportionality constants - So we used number of moles, in which case .$R$ becomes the constant for all gasses - .$k_B $ is the [Boltzmann constant](https://en.wikipedia.org/wiki/Boltzmann_constant) - Relates the average relative kinetic energy of particles in a gas with the thermodynamic temperature of the gas - .$N_a$ is the [Avogadro constant](https://en.wikipedia.org/wiki/Avogadro_constant) - The number of particles that are contained in one mole of gas - .$n = N/N_A$ This equation is Ideal in that the equation only works for gasses around atmospheric pressure and not excessive temperatures Moles # Mole is the SI unit for amount of substance 1 mole = Number of particles in .$\\text{12g}$ of Carbon 1 mole = Number of grams of a substance numerically equal to the molar mass $$n \\text{(moles)} = \\frac{\\text{mass (grams)}}{\\text{molecular mass (g/mol)}}$$ 17.8 Problem Solving with .$PV = nRT$ # STP: Standard Temperature and Pressure # .$T = 273 \\text{K}$ .$P = 1.00 \\text{atm} = 1.013\\cdot10^5 \\text{N/m}^2 = 101.3 \\text{kPA}$ .$1 \\text{mol of ideal gas} = 22.4\\text{L}$ in volume If P is in liters and V is in atm, then we can use .$R = 0.0821 \\frac{\\text{L} \\cdot \\text{atm}}{\\text{mol} \\cdot \\text{K}}$ Since .$n$ and .$R$ are constants, we can say: $$\\frac{P_1 V_1}{T_1} = \\frac{P_2 V_2}{T_2}$$ 17.9 Ideal Gas with Avogadro\u0026rsquo;s Number # Avogadro\u0026rsquo;s hypothesis: Equal volume of gas with the same .$P$ and .$T$ have an equal .$n$ umber of particles (molecules) .$N_a$ is avogadro\u0026rsquo;s number: the number of particles that are contained in one mole of gas (or one gram of hydrogen). .$N_a = 6.022 \\cdot 10^{23}\\ \\text{particles/mole}$ Therefore, if .$N$ is the number of molecules of a gas sample and .$n$ is the number of moles, then $$N = n\\cdot N_A \\Longrightarrow n = \\frac{N}{N_A} \\Longrightarrow PV = \\frac{N}{N_A}RT = Nk_B T$$ where .$k_B $ is Boltzmann\u0026rsquo;s constant .$\\frac{R}{N_A} = 1.38 \\cdot 10^{-23} \\frac{\\text{J}}{\\text{K}}$ 17.10 Ideal Gas Temperature # - _Triple point_: A precise temperature and pressure where the three phases (gas, liquid, and solid) of a substance can coexist in thermodynamic equilibrium. - .$P_3 = 4.88\\ \\text{torr};\\ T_3 = 0.01^\\circ C$ for water - Ideal Gas, constant volume: $$T = (273.16 K)\\bigg(\\frac{P}{P_3}\\bigg)$$ - Constant volume: $$T = (273.16 K)\\lim_{P_3 \\to 0}\\bigg(\\frac{P}{P_3}\\bigg)$$ \u003e![Phase Diagram](/docs/physics-7b/imgs/phase-diagram.png) \u003eA typical phase diagram. The solid green line applies to most substances; the dashed green line gives the anomalous behavior of water. For more see [18.4](18.md/#vapor-pressure) "},{"id":42,"href":"/docs/cheatsheets/","title":"Cheatsheet PDFs","section":"Docs","content":"Consider visiting the OCF to archive your own crib sheets.\nIn hindsight, I would have used darker pencil graphite (i.e. 3B) earlier.\n"},{"id":43,"href":"/physics-7b/18/","title":"18: Kinetic Theory of Gases","section":"Physics 7B","content":" 18.1 Ideal Gas Laws and Molecular Interpolation # Ideal Gas Law Assumptions # There are a large number of molecules, .$N$, each of mass .$m$ that move in random directions at random speeds Molecules are, on average, sufficiently far away from one another (separation .$\\gg$ diameter) Molecules obey classical mechanics so .$KE \\gg PE$ when colliding Collisions are perfectly elastic Micro and Macroscopic views related through Energy # In a system with .$N$ molecules each of mass .$m$ and average speed .$\\bar{v}^2$ (also denoted as .$\\langle v^2 \\rangle$), we can combine the ideal gas law with the .$\\overline{KE}$ equation: $$\\overline{K} = \\frac{1}{2} m \\bar{v}^2 = \\frac{3}{2}k_B T$$ This shows .$\\overline{KE} \\propto T$ which makes sense intuitively; cold = slow particle motion E.x: A container is filled with a light and heavy molecule. Which has a greater speed? The lighter molecules do because they are less massive. And since the system\u0026rsquo;s internal energy .$E_{\\text{int}} = N \\cdot \\overline{K}$ then we can write an important .$PV$ relation + find the gas.$E_{\\text{int}}$: $$T = \\frac{\\frac{1}{2} m\\bar{v}^2}{\\frac{3}{2}k_B} = \\frac{2}{3} \\cdot \\frac{E_{\\text{int}}}{N k_B} \\Longrightarrow PV = \\frac{2}{3}E_{\\text{int}}$$ $$E_{\\text{int}} = N\\cdot \\frac{1}{2}m\\bar{v}^2 \\Longrightarrow PV = \\frac{Nm}{3}\\bar{v}^2 $$ Which shows us that .$(P,V)$ is a representation of (kinetic) energy! We can think of any point on a .$PV$ diagram in terms of energy Absolute 0 # Before, we said .$T = 0K$ exists when .$P = 0$\nNow we can also see that .$KE = 0$ when .$T = 0$ as well. This would mean that at absolute 0, there is no particle movement\nWe can then write an equation for the root-mean-square (or RMS): $$\\overline{K} = \\frac{3}{2}k_B T \\Longrightarrow \\frac{1}{2}m\\bar{v}^2 = \\frac{3}{2}k_B T;\\ v_{\\text{rms}} = \\sqrt{\\bar{v}^2} = \\sqrt{3k_B\\frac{T}{m}} = \\sqrt{3 R\\frac{T}{M}} $$ $$\\bar v ^2 = \\frac{1}{N}\\sum_i^N n_i v_i^2 \\Longrightarrow v_{\\text{rms}} = \\frac{1}{\\sqrt N} \\sqrt{\\int_0^\\infty n(v)\\cdot v^2 dv} $$\nThis is the typical velocity of particles that make up the gas/liquid .$M$ is the molar mass of the gas [kilograms per mole] .$v_{\\text{rms}}$ is also called the thermal velocity, .$v_{\\text{th}}$ Fun fact: Less than 1% of particles of particles exceed .$v_{\\text{rms}}$ Example problems: If a sample is quasistatically shrunk to half it\u0026rsquo;s original volume with no change in pressure, the new root-mean-square speed is .$1/\\sqrt{2}$ times the original rms speed If we double the root-mean-square speed (thermal speed) of the molecules of a gas, then its temperature must increase by a factor of 4 18.2 Distribution of Molecular Speeds # ![Maxwell Distribution](/docs/physics-7b/imgs/maxwell-distribution.gif) $$f(v) = 4\\pi N \\bigg( \\frac{m}{2 \\pi k_B T}\\bigg)^{3/2} v^2 e^{ -\\frac{1}{2} \\cdot \\frac{mv^2}{k_B T}}$$ Recognize that .$f(v) \\propto T^{-3/2}, v^2$ and exponentially .$\\propto KE/T$ If .$T$ increases, so does .$KE$ and .$v$ thus variance .$\\sigma^2$ increases and the distribution becomes \u0026ldquo;stretched\u0026rdquo; (lower max, thicker tail) Spread of important values (.$v_p, v_{\\text{avg}}, \\text{etc.}$) are spread out further from one another Area stays constant (always equal to .$N$) .$f(v)\\ dv$ represents the number of molecules with .$v \\in [v, v+dv]$ That is, .$\\int_0^\\infty f(v) dv = N$ .$\\sigma^2$ is the variance, or standard deviation squared, which can be found from the equation .$\\langle v^2 \\rangle - \\langle v \\rangle ^2$ Chemical Reactions Some reactions only occur at a certain energy levels (activation energy) Warmer conditions lead to faster moving particles which have energy That\u0026rsquo;s why reaction speed .$\\propto$ temperature Important Values # $$v_p = 1.41 \\sqrt{k_B\\frac{T}{m}}$$ $$v_{\\text{avg}} = 1.60 \\sqrt{k_B\\frac{T}{m}}$$ $$v_{\\text{rms}} = \\sqrt{3 k_B \\frac{T}{m}}$$ Notice how .$v \\propto m^{-1/2}$, which explains why it\u0026rsquo;s easier for lighter particles to escape earth\u0026rsquo;s atmosphere! 18.3 Real Gases and Phase Changes # (a) Each curve represents the relationship between .$P$ and .$V$ at a fixed temperature; the upper curves are at higher temperatures. The lower curves are not hyperbolas, because the gas is no longer an ideal gas. (b) An expanded portion of the diagram for low temperatures, where the phase can change from a gas to a liquid.\nPhase changes can only be explained if we\u0026rsquo;re considering the behavior of a real \u0026ndash; not ideal \u0026ndash; gas This is because phase changes involve intermolecular bonds which we only factor in when considering real gases At high enough pressures, gases take up less volume than expected. This effect is magnified with lower temperatures At lower temperatures, the .$PE$ attractive forces between particles aren\u0026rsquo;t negligible with respect to .$KE$ At the critical points (when .$PV$ curve is horizontal), gases may no longer change to liquid under any pressure This point varies by substance Gas below the critical point is vapor Gas above the critical point is just gas Sublimation: When substance changes from solid to gas, skipping liquefaction step Ideal gases would have a straight line along a .$PV/nRT \\text{ vs } P$ graph Real gases vary don\u0026rsquo;t follow this line and deviate from it proportional to their molecule size and weight (resulting in higher .$a$ and .$b$ values respectively \u0026ndash; see 18.5) 18.4 Vapor, Pressure, and Humidity (not covered) # Evaporation # Molecules in liquid are held tightly together with intermolecular attractive forces (covalent hydrogen bonds) Some molecules may momentarily leave the liquid if their velocity is fast enough If velocity isn\u0026rsquo;t too large, then the particle will be pulled back to the liquid surface If velocity is large enough, then the particle will break the intermolecular bonds and leave the liquid to enter their gas form Low probability of occurring Because .$v_{\\text{particle}} \\propto T$, the .$\\text{evaporation rate} \\propto T$ As fast moving (thus hot) particles leave the liquid, the liquid\u0026rsquo;s temperature decreases That is, evaporation is a cooling process Vapor Pressure # A typical phase diagram. The solid green line applies to most substances; the dashed green line gives the anomalous behavior of water - Green line = SL Line; transition between solid .$\\iff$ liquid (melting/freezing) - Red line = SV; transition between solid .$\\iff$ vapor (sublimation/deposition) - Blue line = LV; transition between liquid .$\\iff$ vapor (vaporizing/condensing) ![Phase Change Graph](/docs/physics-7b/imgs/phase-diagram.png) When evaporation particles go from gas to liquid, it\u0026rsquo;s called condensation The number of particles in vapor increases until the rate of particles condensing is equal to the number of particles becoming vapor (equilibrium!) When this state is reached, the space above the water is considered saturated Pressure of vapor saturation is called (saturated) vapor pressure Saturated Vapor Pressure varies with the volume of container If volume above the liquid was reduced, then the density would increase so particles would condense back to liquid Assuming .$T$ is constant, vapor pressure would stay constant too Since at high temperatures there are more particles (entering/already in) the vapor phase, higher pressure is required for equilibrium When the volume is large, it\u0026rsquo;s likely that all the liquid evaporates before equilibrium Boiling # Boiling occurs when saturated vapor pressure equals external pressure Bubbling forms as temperature approaches boiling temperature If the pressure in the bubbles are less than the external pressure, the bubbles are crushed Otherwise, bubbles are able to rise to surface Boiling point is proportional to pressure Lower pressure = lower temperature required for boiling point Partial Pressure and Humidity # In gases composed of multiple other gases, the total pressure is the sum of all partial pressures for each of other sub gas Partial Pressure is the pressure a single gas would exert by itself The partial pressure of water in the air can be as low as zero and vary up to a maximum equal to the saturated vapor pressure (of water at the given temperature) Relative Humidity: ratio of partial pressure of water vapor to the saturated vapor pressure at a given temperature $$\\text{Relative Humidity} = \\frac{\\text{partial pressure of }H_2O}{\\text{saturated vapor pressure of }H_2O} \\cdot 100\\%$$ Super Saturation: .$P_{\\text{partial}} \u0026gt; P_{\\text{saturated vapor pressure}}$ Happens when temperature decreases Excess water condenses as dew / mist 18.5 Van der Waals Equation of State # Microscopic (molecular) view accounts for\u0026hellip;\nFinite size of molecules (before we assumed separation .$\\gg$ diameter, ignoring density) Since gas particles aren\u0026rsquo;t negligible in size, we can\u0026rsquo;t use all of our volume Particles are solid spheres that can\u0026rsquo;t get closer than .$2r$ to one another That means .$V$ is over-estimated: .$V_{\\text{real}} \u0026lt; V_{\\text{ideal}}$ Lower volume mean more collisions, leading to pressure being higher than estimated with the ideal gas law: .$P_{\\text{real}} \u0026gt; P_{\\text{ideal}}$ The unavailable volume due to particles, .$b$, depends on the .$n$umber of moles $$ P(V-nb) = nRT \\Longrightarrow P\\bigg(\\frac{V}{n} - b\\bigg) = RT\\ \\ \\ \\big[\\text{Clausius Equation of State}\\big]$$ Where .$b$ is the volume consumed by 1 mol of gas with the units .$\\text{V/mols}$ Forces between molecules (before we assumed that forces only played an effect in collisions) At low .$T$, electric attractive forces aren\u0026rsquo;t 0 Particles towards the edge are slowed down by the other particles attractive forces For that reason, our pressure is lower than estimated with the ideal gas law: .$P_{\\text{real}} \u0026lt; P_{\\text{ideal}}$ On the contrary, with higher temperatures gases appear more ideal because .$KE$ is greater than the intermolecular .$PE$ \u0026ldquo;Slow down\u0026rdquo; is proportional to the gas density M ore dense means more molecules means more intermolecular forces Pressure reduced by the following equation where .$n/V$ is the gas density and .$a$ is a constant unique to the gas that measures the attractive forces between particles $$ a\\bigg( \\frac{n}{V}\\bigg)^2$$ .$a \\propto m$ and boiling point because the lower the boiling point, the less energy is required to break the internal bonds Thus, we can rewrite the ideal gas law with the last two equations as $$ \\bigg(P+ \\frac{a}{(V/n)^2}\\bigg)\\bigg(\\frac{V}{n} - b\\bigg) = RT \\ \\ \\big[\\text{Van der Waals Eq of State}\\big]$$ Note that these equations aren\u0026rsquo;t accurate in all cases, but they\u0026rsquo;re the best generalization we can do and they show the relation With low densities, .$a\\big/(V/n)^2 \\ll P$ and .$b \\ll V/n$ so Van der Waals equation reduces to the ideal gas law 18.6 Mean Free Path # Molecules bump into each other a lot which slow them down Mean free path: Average distance between collisions is proportional to .$\\rho ^{-1}, r^{-1}$ $$l_m = \\frac{1}{4\\pi \\sqrt{2}r^2 (N/V)}$$ 18.7 Diffusion (not covered) # Particles diffuse from high to low concentrations until equilibrium is reached (when .$\\rho$ is constant throughout) Given a tube with a cross section area .$A$, two concentrations, .$C_1$ and .$C_2$, separated by .$\\Delta x$, we can write the rate of diffusion, .$J$, as $$J = DA \\frac{C_1 - C_2}{\\Delta x} = DA \\frac{dC}{dx} \\ \\ \\text{[Fick\u0026rsquo;s Law]}$$ .$D$ is the diffusion constant Varies with temperature, viscosity, and particle size "},{"id":44,"href":"/physics-7b/19/","title":"19: Heat \u0026 First Law of Thermo","section":"Physics 7B","content":" \\(\\) 19.1 Heat as Energy Transfer # Units # - Heat unit is calorie (cal) - The amount of heat needed to raise the temperature of 1 gram of water by 1 celsius $$4.186 \\text{ J} = 1 \\text{ cal}$$ - Kilocalorie (kcal, Calorie) is more common - Amount of heat needed to raise 1 kg of water by 1 celsius $$4.186 \\text{ kJ} = 1 \\text{ kcal}$$ - British system of units has British thermal units (Btu) - One Btu is the heat needed to raise the temperature of 1 lb of water by 1 Fahrenheit $$1 \\text{ Btu} = 0.252 \\text{ kcal} = 1056 \\text{ J}$$ - Gas companies use the unit therm: .$10^5 \\text{ Btu}$ Heat # Heat is energy transferred from one object to another because of a difference in temperature. Energy transfers from hot to cold object until equilibrium The SI units for heat is the joule: this is because heat is a form of energy! 19.2 Internal Energy # Internal Energy: The sum of all the energy of all the molecules in an object Sometimes called thermal energy Difference between Temp, Heat, and Internal Energy # Temperature is the average kinetic energy of all of the molecules Internal energy is the sum of the energy of all of the molecules E.x. Two equal-mass iron ingots could the same temperature as a single ingot, but the two would have double the internal energy Heat refers to the transfer of energy from one object to another due to a difference in temperatures Direction of transfer depends on temperature, not internal energy E.x. .$50\\text{ g}$ of .$30^\\circ\\text{ C}$ water mixed with .$200 \\text{ g}$ of .$25^\\circ \\text{ C}$ water results with heat transferring from the smaller sample with less internal energy to the larger sample with more internal energy. Calculating Internal Energy # Internal energy is the sum of all the translational kinetic energy of the molecules in a monatomic gas Monatomic: Gas with one atom per molecule We can re-write this as the average KE per molecule times the total number of molecules, .$N$ $$E_{\\text{int}} = N \\bigg(\\frac{1}{2}m\\bar{v}^2\\bigg) = \\frac{3}{2}Nk_B T = \\frac{3}{2}nRT$$ We can see that internal energy for a monatomic gas depends only on the temperature and number of moles If a gas isn\u0026rsquo;t monatomic, then we need to consider the rotational and vibrational energy of the molecules Non-monatomic gasses result in a internal energy at a given temperature compared to a monatomic The internal energy of real gases depends mainly on temperature There are some exceptions of gases depending on pressure and volume as well Internal energy of liquids and solids is more complex It includes electric potential energy of the chemical bonds 19.3 Specific Heat # Amount of heat required to change the temperature of a material is found with the following: $$\\Delta Q = mc \\Delta T$$ .$c$ specific heat capacity that depends on the material .$[\\text{J}/(\\text{C}^\\circ\\text{ kg})]$ For water at .$15 ^\\circ \\text{ C}$ and constant pressure .$1 \\text{atm}$, .$c = 4168 \\text{ J}/(\\text{C}^\\circ\\text{ kg}) = 1.00 \\text{ kcal}/(\\text{C}^\\circ \\text{ kg})$ .$c$ does vary to some extent with temperature (and slightly pressure), but for small .$\\Delta T$ we can say .$c$ is a constant Relative to other materials/substances, water has a high specific heat capacity 19.4 Calorimetry # Types of Systems # System: Any (set of) object(s) we choose to consider Closed System: Mass is constant, but energy may be exchanged within environment Isolated: If no energy in any form passes across its boundaries We idealize systems to be closed systems, which is rare in the real world Heat will flow from hot to cold region of system until equilibrium We can assume that no energy is lost; heat lost in one part = heat gained in another part or .$\\Sigma Q = 0$ Open System: Mass and energy may enter/leave Calorimeter # Calorimetry: Quantitative measure of heat exchange Calorimeter tend to have insulation so that no heat is exchanged with the surrounding air Often use thermometer to measure change the temperature E.x. a substance sample will be heated up, measured, then quickly placed inside cool water of calorimeter The heat lost from the sample will be gained by the water and the calorimeter cup Measuring final temperature of the mixture lets us calculate the specific heat Assume that small masses like the thermometer/stirrer are negligible 19.5 Latent Heat # Change of Phase: When a material changes from solid to liquid or liquid to gas. A certain energy is required for a phase change During phase changes, temperature stops increasing and all energy goes into the phase change Latent heat is lost during phase change (often in the form of heat) Heat of fusion .$L_F$: Heat required to change .$1.0 \\text{ kg}$ of a substance from solid to liquid state Heat fusion of water is .$79.7 \\text{kcal/kg} = 333 \\text{kJ/kg}$ Heat of Vaporization .$L_V$: Heat required to change a substance from liquid to vapor phase Heat vaporization is .$539 \\text{kcal/kg} = 2260 \\text{kJ/kg}$ Heat involved in the phase change depends on the mass and latent heat: $$\\Delta Q = mL$$ Therefore, when considering the change in a system involving heating a substance to a phase change (e.g. boiling at temperature .$T$), we can write: $$\\Delta Q_{\\text{total}} = m_L c \\Delta T + m_S L$$ .$m_L$ is the total mass of the substance before the phase change (e.x. initial mass of substance, don\u0026rsquo;t subtract amount that vaporized) .$m_S$ is the mass of the substance that underwent a phase change (e.x. mass that vaporized) Evaporation # Heat of Vaporization of water increases slightly with a decrease in Temperature At .$20^\\circ \\text{ C}$, it\u0026rsquo;s .$585 \\text{ kcal/kg}$ When liquid evaporates, the remaining liquid cools because the heat/energy comes from the water itself Therefore, internal energy decreases with evaporation Kinetic Theory of Latent Heats # At melting point, the latent heat of fusion doesn\u0026rsquo;t increase the average KE / temperature Rather, the energy goes into overcoming the PE associated with the forces between the molecules Once the molecules in a solid are broken from there lattice formation, they can freely roll over one another as a liquid More energy is required for liquid to gas phase because the average distance between the molecules is greatly increased The larger the distance that the molecules have to be separated, the more work has to be done to pull them apart 19.6 First Law of Thermo # Heat and work are different Heat is the transfer of energy due to a difference in temperature \u0026ndash; hot/cold bath around gas chamber Work is the transfer of energy not due to a temperature difference \u0026ndash; piston applying force to a gas Internal energy and temperature are both proportional to heat and work though with the First law equation: $$\\Delta E_{\\text{int}} = Q - W = E_{\\text{int, 2}} - E_{\\text{int, 1}} \\ \\ \\ \\text{[First Law of Thermo.]}$$ - .$W$ is net **work done by** the system - Work done *by* system is .$\\texttt{+}$ - Work done *on* the system is .$\\texttt{-}$ - Gas expands .$\\Longrightarrow$ sys looses energy - .$Q$ is net **heat added** to the system - Heat *added* is .$\\texttt{+}$ - Heat *lost* is .$\\texttt{-}$ - Gas is heated .$\\Longrightarrow$ sys gains energy .$Q$ and .$W$ are not state variables in that a static state doesn\u0026rsquo;t have \u0026ldquo;heat\u0026rdquo; or \u0026ldquo;work\u0026rdquo; \u0026ndash; only when the system changes through thermodynamic process can we measure heat/work. This is unlike .$P, V, T$ and .$E_{\\text{int}}$ which are state variables (can be measured at all states) We can also extend the first law to include systems that have KE and PE: $$\\Delta K + \\Delta U + \\Delta E_{\\text{int}} = Q - W = E_{\\text{int, 2}} - E_{\\text{int, 1}}$$ 19.7 Thermodynamic Process and the 1st Law # Isothermal Process (.$\\Delta T = 0$) # When temperature is constant, .$PV$ is constant too Each label of points in the graph above represent the systems states (it\u0026rsquo;s pressure and temperatures) Isotherms: curves in PV diagram At a lower temperature, an isothermal process would be represented by the isotherm .$A\u0026rsquo;B'$ We also assume that the container is a heat reservoir: a body whose mass is so big that the temperature doesn\u0026rsquo;t change when heat is exchanged We increase internal energy by doing work, such as by decreasing the volume of the container with by applying a force to a piston over some distance We assume that expansion/compression is quasistatic: we decrease the volume slow enough that we can consider it a series of equilibrium states all at the same temperature E.x. if we started with state .$A$ and added heat .$Q$ to the system, the system would reach point .$B$ If .$T$ remain constant, the volume will expand, both doing work .$W$ on the environment and decreasing the .$P$ We know .$E_\\text{int} = \\frac{3}{2}nR\\Delta T$, and since .$\\Delta T = 0 \\Longrightarrow E_\\text{int} = 0$ Thus, .$E_\\text{int} = Q - W \\Longrightarrow W = Q$ $$$$ $$$$ $$W = \\int_{V_A}^{V_B} P \\ dV$$ $$... = nRT \\int_{V_A}^{V_B} \\frac{dV}{V}$$ $$... = nRT \\ln{\\frac{V_B}{V_A}}$$ ![Isothermal Work](/docs/physics-7b/imgs/iso-work.png) Adiabatic Process (.$\\Delta Q = 0$) # No heat allowed to flow in our out of system. This can happen if\u0026hellip; Process happens so quickly that heat, a slow process, has no time to flow in/out E.x. a combustion engine happens quickly it\u0026rsquo;s nearly adiabatic System is well insulated If a system experiences an adiabatic process slowly, it will look similar to curve .$AC$ Since .$Q = 0 \\Longrightarrow \\Delta E_\\text{int} = -W$ In a reverse processes represented by .$CA$ (adiabatic compression), work is done on the gas so .$E_\\text{int}$ and .$T$ rise ![Adiabatic vs Isothermal](/docs/physics-7b/imgs/adia-v-iso.png) $$$$ $$$$ $$W = \\int_{V_A}^{V_B} P \\ dV$$ $$... = P_A V_A ^\\gamma \\int_{V_A}^{V_B} \\frac{1}{V^\\gamma}\\ dV$$ $$... = \\frac{P_A V_A - P_B V_B}{1-\\gamma}$$ 19.9 Adiabatic Expansions # The .$PV$ curve for adiabatic expansion (.$Q = 0$) is slightly less steep than isothermal processes (.$\\Delta T = 0$) This means that for the same change in volume, the pressure will be greater in adiabatic processes Therefore, the temperature of a gas must drop in adiabatic expansion and rise in adiabatic compression Likewise, if during an adiabatic process the volume increases then the internal energy must decrease We can relate .$P$ and .$V$ for a quasistatic expansion / compression with $$PV^\\gamma = \\text{[constant] for } \\gamma = \\frac{C_P}{C_V} = 1 + \\frac{R}{C_V}$$ \u0026hellip;which can also be written as the following (with .$d$ = degrees of freedom) $$T_A^{C_V/R} V_A = T_B^{C_V/R} V_B$$ $$C_V = \\frac{d}{2}R$$ $$C_P = \\frac{d+2}{2}R$$ $$\\gamma = \\frac{d+2}{d}$$ Free Expansion # A type of adiabatic process where gas is allowed to expand in a volume without doing any work Must be done with insulated containers so that no heat is able to flow in/out; .$Q = 0$ No work is done either because no object is moved; .$W = 0$ Thus, .$\\Delta E_\\text{int} = 0$ and .$\\Delta T = 0$ In reality, we see temperature slightly drops meaning internal energy does depend on pressure or volume as well as temperature. Isobaric and Isovolumetric .$(\\Delta P = 0, \\Delta V = 0)$ # Isobaric: .$\\Delta P = 0 \\Longrightarrow Q = \\Delta E_\\text{int} + W = \\Delta E_\\text{int} + P\\Delta V$. The heat transferred to the system does work, but also changes the internal energy of the system Isovolumetric: .$\\Delta V = 0 \\Longrightarrow W = 0 \\Longrightarrow Q = \\Delta E_\\text{int}$. The thermodynamic process is the addition or removal of heat. First law of thermo holds for both of these processes $$$$ $$$$ $$W_{\\text{Isovol.}} = 0$$ $$W_{\\text{Isobaric}} = \\int_{V_A}^{V_B} P \\ dV$$ $$... = P \\Delta V$$ $$... = P_B(V_B - V_A)$$ $$... = nRT_B(1 - \\frac{V_A}{V_B})$$ ![Isobaric and Isovolumetric Work](/docs/physics-7b/imgs/iso-bar-vol-work.png) Work done in volume changes .$(\\Delta V \\neq 0)$ # For quasistatic processes: $$dW = \\vec{F} \\cdot d\\vec{l} = PA d\\vec{l} = P\\ dV \\ \\ \\ \\text{(1)}$$ $$W = \\int dW = \\int_{V_A}^{V_B} P\\ dV \\ \\ \\ \\text{(2)}$$ .$\\text{(1)}$ Where .$F = PA$ is the force the gas exerts on the piston and .$d\\vec{l}$ is the (small) distance the piston moves .$\\text{(2)}$ This shows that the work done is the area under the .$PV$ curve This equations are valid for work done in any volume change (solid, liquids, gas) .$W$ (and even .$Q$) depends on the initial and final states and also on the process (or path) 19.8 Molar Specific Heats for Gases and Equipartition of Energy # Molar Specific Heat # Specific heat for gases depends heavily on the process and how it\u0026rsquo;s carried out Specific heat for constant pressure and constant volume vary We use molar specific heat for gases: .$C_V$ and .$C_P$ which are defined as the heat required to raise .$1 \\text{ mol}$ of gas by .$1^\\circ \\text{ C}$ at a constant volume or pressure respectively. We then use .$n$ instead of .$m$ in our heat equations: $$\\Delta Q = nC_V \\Delta T = mc_V \\Delta T\\ \\ \\ \\text{[Constant Volume]}$$ $$\\Delta Q = nC_P \\Delta T = mc_P \\Delta T\\ \\ \\ \\text{[Constant Pressure]}$$ which we can then relate to the specific heat with .$M$ as the molecular mass of the gas, .$m/n$ in grams/mol: $$C_V = Mc_V$$ $$C_p = Mc_p$$ In a heating process, when .$\\Delta V = 0$ then the heat added, .$Q_V$ goes entirely into internal energy: .$Q_V = \\Delta E_\\text{int}$ However, when pressure is constant work is done. Thus, heat added, .$Q_P$, goes towards increasing internal energy and work: .$W = P\\Delta V$ Therefore, more heat is needed for a constant pressure system: .$Q_P = \\Delta E_\\text{int} + P\\Delta V$ Since .$\\Delta E_\\text{int}$ is the same for both processes, we can write .$Q_P - Q_V = P \\Delta V$ With an ideal gas, we know .$V = nRT/P$ so .$\\Delta V = nR\\Delta T/P$ which we can combine with the prior equations to get: $$nC_P\\Delta T - nC_V \\Delta T = P\\bigg(\\frac{nR\\Delta T}{P}\\bigg) \\Longrightarrow C_P - C_V = R$$ We can also relate internal energy to molar specific heat for gases at constant volumes: $$\\Delta E_\\text{int} = Q_V \\Longrightarrow \\frac{\\text{[Deg. of Freedom]}}{2}nRT = nC_V\\Delta T \\Longrightarrow C_V = \\frac{3}{2}R$$ We can then plug in our new value for .$C_V$ into the second to last equation .$C_P - C_V = R$ to get .$C_P = \\frac{5}{2}R$ for a monatomic gas. We can also combine our equations to write a relation between internal energy and temperature again: $$\\Delta E_\\text{int} = nC_V \\Delta T$$ Equipartition of Energy # Degrees of Freedom: The number of independent ways a molecule can posses energy Degrees of freedom depend on the temperature At low temperatures, the only degree of freedom is from translational .$KE$ Starting after .$0K$ Diatomic gas: .$C_V = \\frac{3}{2}R$ (3 for each axis) Sum of .$\\frac{1}{2}m \\langle v_x, v_y, v_z \\rangle$ At \u0026ldquo;regular\u0026rdquo; temperatures, the molecules posses rotation energy Around .$50K$ Diatomic gas: .$C_V = \\frac{5}{2}R$ Sum of .$\\frac{1}{2}I \\langle 0, \\omega_y, \\omega_z \\rangle$ (since it\u0026rsquo;s rotating about .$\\hat x$ meaning .$E_{\\text{rotational, }x}) = 0$ At higher temperatures, the molecules gain energy associated with their vibrations: Around .$1000K$ One from KE of the molecules vibrating back and forth: .$\\frac{1}{2}mv_{\\text{COM}}^2$ The second from PE of the vibrational motion (think of this as a spring\u0026rsquo;s PE): .$\\frac{1}{2}kx^2$ Solids: The molar temperature of solids at high temperatures is close to .$3R$. At high temperatures, there are six degrees of freedom: three from vibrational KE in the .$x, y,$ and .$z$ axis and three more from spring PE in the same axis Some of these degrees of freedom aren\u0026rsquo;t active at lower temperatures Principle of Equipartition of Energy: Energy is shared equally among degrees of freedom and each degrees has energy .$\\frac{1}{2}k_B T$ Thus, for a particle with three degrees of freedom (such as a monatomic gas) .$C_V = \\frac{3}{2}R$ Diatomic gases have five degrees so they have .$C_V = \\frac{5}{2}R = 4.97 \\text{ cal/(mol K)}$ and have .$E_\\text{int} = N(\\frac{5}{2}k_B T) = n C_V \\Delta T = \\frac{5}{2}nRT$ where .$n$ is the number of moles and .$N$ is the number of molecules 19.10 Heat Transfer # Conduction # Heat transfer by contact Conduction can be visualized thinking of molecular collisions The hot end of an object has fast moving molecules These molecules bump into other molecules, transferring them some of their own KE This keeps repeating down the object Free electrons are the primary source of these collisions Heat conduction only occurs when there is a difference in temperatures Heat conduction rate is proportional to the difference in temperatures: $$\\frac{\\Delta Q}{\\Delta t} = - kA\\frac{T_1 - T_2}{l}$$ Where .$A$ is the cross section area, .$l$ is the distance between the two ends, and .$k$ is a constant called thermal conductivity that depends on the material Good insulator / poor thermal conductors have a low .$k$ Metals have .$k\u0026gt;1$ Wood, plastics have small .$k$s Building materials sometimes list the thermal resistance, .$R$, which is equal to .$R = \\frac{l}{k}$ where .$l$ is the material\u0026rsquo;s thickness Larger .$R$ means better insulation If .$k$ or .$A$ isn\u0026rsquo;t constant, we consider a small thickness: $$ \\frac{dQ}{dt} = -kA \\frac{dT}{dx}$$ .$\\frac{T_1 - T_2}{l} \\text{ and } \\frac{dT}{dx}$ are called the temperature gradients We have a negative sign in the equation above because the direction of heat flow is opposite to the temperature gradient A steady system state is reached when heat flow through each layer of an object is equal Convection # Heat flow by movement of mass Convection involves heat flowing by the bulk movement of molecules from one place to another Whereas conduction involved molecules/electrons moving over small distances, convection involves the movement of a large number of molecules over a long distance Natural Convection occurs in systems where a cold substance (air, water) is warmed and subsequently expands, decreasing density and thus rising Warm fluid/gases are less dense, thus they rise compared to colder fluid/gas Radiation # Whereas conduction and convection require a medium, radiation doesn\u0026rsquo;t The sun\u0026rsquo;s rays are a form of heat and travel through (nearly empty) space Radiation of the sun\u0026rsquo;s rays arrive on a clear day at a rate around .$1000 \\text{W/m}^2$ Most of the time radiation consists of electromagnetic waves, but infrared (IR) wavelengths are responsible for heating Earth The rate at which energy leaves a radiation object, .$Q/t$, is $$ \\frac{\\Delta Q}{\\Delta t} \\varepsilon \\sigma A T^4$$ .$\\varepsilon$ is called emissivity. Between 0 and 1 Characteristic of the surface of the radiating material Black surfaces close to one, shiny metal surfaces close to zero Depends slightly on the temperature of the material A good absorber is also a good emitter A black tee shirt gets very hot because it absorbs nearly all the radiation that hits it .$\\sigma$ is the Stefan-Boltzmann constant: .$\\sigma = 5.67 \\cdot 10^{-8} \\text{ W/(m}^2 \\text{K}^4\\text{)}$ Objects also absorb heat of surrounding objects. This net heat flow can be found by $$ \\frac{\\Delta Q}{\\Delta t} \\varepsilon \\sigma A (T_1^4 - T_2^4)$$ Where .$T_1$ is the object\u0026rsquo;s temperature and .$T_2$ is the surrounding environment\u0026rsquo;s temperature .$T_1 \u0026gt; T_2$: net flow of heat is from object to the surroundings .$T_1 \u0026lt; T_2$: net flow of heat is from surroundings into object, raising the object temperature "},{"id":45,"href":"/docs/cs-194/","title":"CS194","section":"Docs","content":" Redirecting to cs194.mehvix.com\u0026hellip; # "},{"id":46,"href":"/physics-7b/20/","title":"20: Second Law of Thermo","section":"Physics 7B","content":" 20.1 Intro # Second law states that systems only increase in entropy over time That is, most systems are on directional E.x. mixing salt and pepper together result in an mixture. No matter how much you keep mixing it, they won\u0026rsquo;t naturally separate and return to the initial state even though it follows first law of thermo (conserving energy) (Specific) Second Law of Thermo Heat can flow spontaneously from a hot object to a cold object; heat will not flow spontaneously from a cold object to a hot object.\n20.2 Heat Engines # Heat Engine: Any device that changes thermal energy into mechanical work, such as steam or car engine Show importance in developing the second law of thermo Mechanical energy can only be obtained from thermal energy when heat is allowed to flow from high temp to low temp During this process, some of the heat can be transformed to mechanical work Heat engines run in a repeating cycle: the system returns repeatedly to its starting point and thus can run continuously - In each cycle .$\\Delta E_{\\text{int}} = 0$ because it returns to the initial state - Thus, heat input .$Q_H$ at a .$T_H$ is partly transformed into work .$W$ and partly exhausted as heat .$Q_L$ at .$T_L$ - By conservation of energy, .$Q_H = W+Q_L$. - **Operating Temperatures**: The high and low temperatures, .$T_H, T_L$ - .$Q_H, Q_L, W \u003e 0$ ![Heat Engine](/docs/physics-7b/imgs/engine.png) Change in temperature is required for a change in pressure Gas exhaust is cooled to a lower temperature and condensed so that the exhaust pressure is less than intake pressure Thus, the work the piston must do on the gas to expel it is less than the work done by the gas on the piston during the intake 20.3 (Ir)reversible Processes; Carnot Engine # Carnot engine is ideal: doesn\u0026rsquo;t take into account turbulence in gas, friction, etc. Consist of four processes done in a cycle Isothermal expansion (.$\\Delta T = 0$) with the addition of heat .$Q_H$ along path .$ab$ at temperature .$T_H$ Adiabatic expansion (.$Q = 0$) lowering temperature to .$T_L$ along path .$bc$ Isothermal compression (.$\\Delta T = 0$) leads to heat .$Q_L$ flowing out along path .$cd$ Adiabatic compression (.$Q = 0$) occurs path .$da$, returning to temperature .$T_H$ Each process is reversible; that is, each occurs infinitely slowly so that the process could be considered a series of equilibrium states Real processes are irreversible Work done in a cycle is proportional to area enclosed by the curve representing the cycle on a .$PV$ diagram (.$abcd$) Efficiency is given by .$e = 1-\\frac{Q_L}{Q_H} \\Longrightarrow e_{\\text{ideal}} = 1 - \\frac{T_L}{T_H}$ Carnot\u0026rsquo;s Theorem: All reversible engines operating between the same two constant temperatures .$T_H$ and .$T_L$ have the same efficiency. Any irreversible engine operating between the same two fixed temperatures will have an efficiency less than this.\nOnly at absolute zero would 100% efficiency be reachable. But getting to absolute zero is a practical (as well as theoretical) impossibility Kelvin-Planck statement of the second law of thermodynamics: no device is possible whose sole effect is to transform a given amount of heat completely into work.\n20.4 Refrigerators, AC, Heat Pumps # - Refrigerators, air conditioners, and heat pumps are just the reverse of heat engines - Each transfer heat ouf of a cool environments into a warm environment - A perfect fridge (no work required to take heat from low temp to high temp) is impossible \u003e No device is possible whose sole effect is to transfer heat from one region at a temperature .$T_L$ into a second region at a higher temperature .$T_H$ (_Clausius statement_) ![Fridge](/docs/physics-7b/imgs/fridge.png) Coefficient of Performance (COP): .$\\text{COP} = \\frac{Q_L}{W}$\nThe more heat .$Q_L$ removed from a fridge for a given amount of work, the more efficient it is Energy is conserved, so we can write .$Q_L + W = Q_H$ or .$W = Q_H-Q_L$ We can then write .$\\text{COP} = \\frac{Q_L}{W} = \\frac{Q_L}{Q_H-Q_L} \\Longrightarrow \\text{COP}_{\\text{ideal}} = \\frac{T_L}{T_H-T_L}$ Heat pump\nElectric motor does work .$W$ to take heat .$Q_L$ from outside at low temperature and delivers heat .$Q_H$ to inside at a hot temperature Whereas fridges cool (remove .$Q_L$), heat pumps heat (deliver .$Q_H$) Thus, COP uses .$Q_H$ instead of .$Q_L$: .$\\text{COP} = \\frac{Q_H}{W}$ COP is greater than 1 because .$W+Q_L = Q_H$ 20.5 Entropy # Entropy, unlike heat, is a state variable and measures the (dis)order of a system When heat is added to a system by a reversible process then change in entropy is $$\\Delta S = \\frac{Q}{T} \\ \\ \\text{[Constant T]} \\Longrightarrow dS = \\frac{dQ}{T} \\ \\ \\text{[Non-const T]}$$ The change of entropy between two states doesn\u0026rsquo;t depend on the process. Thus, $$\\Delta S = S_b - S_a = \\int_a^b dS = \\int_a^b \\frac{dQ}{T}$$ 20.6 Entropy and Second Law # In an isolated system with two objects that eventually reach equilibrium, we can write the change (increase) in entropy as $$\\Delta S = \\Delta S_H + \\Delta S_L = - \\frac{Q}{T_{HM}} + \\frac{Q}{T_{LM}}$$ .$T_{HM}$ is the average temperature between .$T_H$ and .$T_M$ where .$T_M$ is the average between .$T_H$ and .$T_L$ E.x. if .$T_H = 0^\\circ C, T_L = 0^\\circ C$, then .$T_M = 4^\\circ C$ so .$T_{HM} = 6^\\circ C$ and .$T_{LM} = 2^\\circ C$. Also, we use .$Q = mc \\Delta T$ to find heat and use half .$T_{M}$ (in this case .$4^\\circ C$) for .$\\Delta T$ Since .$T_{HM} \u0026gt; T_{LM}, \\Delta S \u0026gt; 0$ is always true While one system may decrease in entropy, the other one always increases more so net always increases For adiabatic processes, we know .$dQ = dW = P dV$, thus $$\\Delta S_\\text{gas} = \\int \\frac{dQ}{T} = \\frac{1}{T} \\int_{V_1}^{V_2} P\\ dV$$ and since we know through the idea gas law that .$P = nRT/V$ so $$\u0026hellip;= \\frac{1}{T} \\int_{V_1}^{V_2} \\frac{nRT}{V}\\ dV = nR \\ \\ln \\bigg(\\frac{V_2}{V_1}\\bigg)$$ 20.7 Order to Disorder (not covered) # If we say that entropy is a measure of (dis)order in a system, we can write the second law as Natural processes tend to move toward a state of greater disorder\nWhen ice melts to water at 0°C, the entropy of the water increases. Intuitively, we can think of solid water, ice, as being more ordered than the less orderly fluid state which can flow all over the place. This change from order to disorder can be seen more clearly from the molecular point of view: the orderly arrangement of water molecules in an ice crystal has changed to the disorderly and somewhat random motion of the molecules in the fluid state. When a hot substance is put in contact with a cold substance, heat flows from the high temperature to the low until the two substances reach the same intermediate temperature. At the beginning of the process we can distinguish two classes of molecules: those with a high average kinetic energy (the hot object), and those with a low average kinetic energy (the cooler object). After the process in which heat flows, all the molecules are in one class with the same average kinetic energy; we no longer have the more orderly arrangement of molecules in two classes \u0026ndash; Order has gone to disorder Furthermore, the separate hot and cold objects could serve as the hot and cold-temperature regions of a heat engine, and thus could be used to obtain useful work. But once the two objects are put in contact and reach the same temperature, no work can be obtained. Disorder has increased, because a system that has the ability to perform work must surely be considered to have a higher order than a system no longer able to do work. When a stone falls to the ground, its macroscopic kinetic energy is transformed to thermal energy. Thermal energy is associated with the disorderly random motion of molecules, but the molecules in the falling stone all have the same velocity downward in addition to their own random velocities. Thus, the more orderly kinetic energy of the stone as a whole (which could do useful work) is changed to disordered thermal energy when the stone strikes the ground. Disorder increases in this process, as it does in all processes that occur in nature. 20.8 Unavailability of Energy; Heat Death (not covered) # In any natural process, some energy becomes unavailable to do useful work\nThat is, as time goes on, both energy is degraded and entropy increases A rock that falls to the ground could instead used it\u0026rsquo;s energy towards useful work versus exerting kinetic/thermal energy while falling Two separate hot and cold objects could serves as the high and low temperature regions for a heat engine (obtaining useful work). Instead, if the tow objects are put in contact with one another, they\u0026rsquo;ll eventually reach the same uniform temperature and not be able to do any work. Heat Death: All energy of the universe degrades into thermal energy Very far out Scientists are unsure whether this is inevitable or whether we can even extrapolate the 2nd law to the scale of our universe 20.9 Statistical Interpretation of Entropy/2nd (not covered) # We can only realistically observe macrostates and not microstates However, we can make inferences about microstates with probabilities Each microstate is equally probable of occurring Thus, the number of microstates that give the same macrostate correspond to the relative probability of that macrostate occurring The most probable state of a gas is one in which the molecules take up the whole spaces and move about randomly (in a maxwell distribution) At the same time, the very orderly arrangement of all molecules located in one corner of the room and all moving with the same velocity is extremely unlikely Therefore, the probability is directly related to the disorder and hence entropy of the system The most probably state is the one with greatest entropy or greatest disorder and randomness It\u0026rsquo;s also the macrostate that corresponds to the most microstates The netropy of a system in a given macro state can be written as: $$ S = k \\ \\ln\\mathscr{W}$$ .$k$ is the Boltzmann\u0026rsquo;s constant and .$\\mathscr{W}$ is the number of microstates corresponding to the given macrostate That is, .$\\mathscr{W}$ is proportional to the probability of occurrence of that state .$\\mathscr{W}$ is also called the thermodynamic probability or the disorder parameter 20.10 Thermo Temperature; Third Law (not covered) # Ideal Carnot Cycles always have the ratio $$\\frac{Q_L}{Q_H} = \\frac{T_L}{T_H}$$ Note that this relation doesn\u0026rsquo;t depend on the working substance, thus it can server as the basis for the Kelvin scale The closer a temperature is to abs zero, the more difficult it is to reduce the temp further Third Law: It is not possible to reach absolute zero in any finite number of processes\nThus, since .$e = 1 - \\frac{T_L}{T_H}$ and because .$T_L$ can\u0026rsquo;t ever be zero then 100% efficiency is never possible "},{"id":47,"href":"/physics-7b/21/","title":"21: Electric Charges \u0026 Fields","section":"Physics 7B","content":" 21.1 Static Electricity; Electric Charge and its Conservation # \u0026ldquo;Charged\u0026rdquo; objects posses a net electric charge Unlike charges attract; like charges repel Charges on glass are positive, charges on plastic is negative Law of Conservation of Electric Charge: Whenever a certain amount of charge is produced in one object, an equal amount of the opposite type of charge is produced in another object Charges cannot be destroyed or created E.x. a plastic ruler is rubbed with a paper towel. The plastic acquires a negative charge and the towel obtains an equal positive charge In other words, the net amount of electric charge produced in any process is zero: .$\\Sigma Q = 0$ 21.2 Electric Charge in the Atom # Atoms are made up of positive nucleus surrounded by at least one negatively charged electron. Inside the nucleus are protons which are positively charged and neutrons which have no charge The charges of electrons and protons are equal in magnitude E.x. neutral atoms with no charge contain an equal number of protons and electrons When an atom gains a charge (by losing/gaining electrons), it then has a net charge and is called an ion Neutral objects have a net charge of zero Over time, objects left alone with a charge tend to lose their charge This is because over time, electrons are exchanged with water molecules in the air Water molecules are polar: They are neutral, their charges aren\u0026rsquo;t equally distributed Thus, on rainy days it\u0026rsquo;s harder for an object to maintain a charge for too long 21.3 Insulators and Conductors # Conductor: Material that allow charge to flow between objects Metals tend to be good conductors Electrons (charges) are relatively lose: can move freely within metal, but can\u0026rsquo;t leave easily Called free or conduction electrons Insulator: Opposite of conductors; don\u0026rsquo;t easily allow a flow of charge Most materials other than metals tend to be good insulators Notably rubber and wood Electrons are bound very tightly to the nuclei Almost no free electrons Semiconductors: Somewhere between the two former Silicon, germanium Less free electrons than a conductor, but more than an insulator 21.4 Induced Charge; Electroscope # Conduction: Charge transfer by physical contact E.x. a positively charged metal rod touches a neutral metal rod. Free electrons from the neutral rod will then flow (transfer) to the charged rod, leaving the formerly neutral rod now slightly positively charged Induction: Charge distribution altered by bringing two objects close, but not touching Unlike conduction, induction doesn\u0026rsquo;t alter the net charge of objects when the inducer is taken away However, induction can redistribute the existing charges on the induced object Grounded Objects Objects can be ground to the earth with a conducting wire The earth is very large and can conduct, so it easily accepts/gives up electrons Therefore, when an object is induced by another charged object, the original objects will become charged If the wire is ever cut when the object is under induction, the charge will stay in the object Electroscope - .$\\vec F \\propto \\text{angle of deflection}$ - .$y$-axis: .$F_{T1} \\sin \\theta_1 = F_{21}$ - .$x$-axis: .$F_{T1} \\cos \\theta_0 = m_1 g$ - .$F_{21} = m_1 g \\tan \\theta_1 \\approx m_1 g \\theta_1$ - .$F_{21} = - F_{12}$ ([Newton's Third](https://en.wikipedia.org/wiki/Newton's_laws_of_motion#Newton's_third_law)) .$ \\Longrightarrow \\theta_1/\\theta_2 = m_2/m_1$ - .$d = l (\\theta_1 + \\theta_2)$ ![Forces Diagram](/docs/physics-7b/imgs/electroscope-diag1.png) ![Distance](/docs/physics-7b/imgs/electroscope-diag2.png) 21.5 Coulomb\u0026rsquo;s Law # **Coulomb's Law:** $$E_\\text{source} = k \\frac{Q_\\text{source}}{r^2} \\Longrightarrow F = EQ = \\bigg(k \\frac{Q_1}{r^2}\\bigg) (Q_2) = k\\frac{Q_1 Q_2}{r^2}$$ where .$k$ is a constant equal to .$\\frac{1}{4\\pi\\varepsilon_0} = 8.988 \\cdot 10^9 \\text{ N m$^2$/C$^2$}$ Very similar to universal gravitation equation However\u0026hellip; .$F_C$ can repel, whereas .$F_G$ is always attractive .$F_C$ only acts on charged objects, whereas .$F_G$ acts on neutral objects too .$F_G/F_C \\approx 10^{-40} \\Longrightarrow F_C \\gg F_G$ The coulomb (.$\\text{C}$) is the SI unit for charge Properties of Coulomb Force: It can be attractive and repulsive It is not a contact force Inversely proportional to .$r^2$ Proportional to amount of charge .$Q$ The smallest charge we\u0026rsquo;ve observed is the elementary charge: .$e = 1.6022 \\cdot 10^{-19} \\text{ C}$ Electrons have a charge equal to .$-e$ Protons have a charge equal to .$+e = -Q_\\text{electron}$ Charges are Quantized That is, all charges are multiples of .$e$ Since electrons are elementary particles, by definition they can\u0026rsquo;t be divided. .$k$ can also be written as .$\\frac{1}{4\\pi\\varepsilon_0}$ .$\\varepsilon_0$ is called the permittivity of free space .$\\varepsilon_0 = \\frac{1}{4\\pi k} = 8.85 \\cdot 10^{-12} \\text{C$^2$/N m$^2$}$ 21.6 Electric Field # Electric fields extend outward from every charge and permeates all of space $$\\overrightarrow E = \\lim_{q\\to0}\\frac{\\overrightarrow F}{q} \\Longrightarrow \\overrightarrow F = q \\overrightarrow E$$ .$q$ is a positive charge .$\\overrightarrow F$ is the forces the field exserts on .$q$ Has units newtons per coulomb (.$\\text{N/C}$) We can combine this with Coulomb\u0026rsquo;s law to get $$\\overrightarrow E = \\frac{kqQ/r^2}{q} = k \\frac{Q}{r^2} = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r^2}$$ We see that .$\\overrightarrow E$ is independent of the non-source particle .$q$ .$Q$ is the particle that is responsible for the field in the first place An electric field at a given point is the sum of all other electric fields that act on that point $$\\overrightarrow E = \\overrightarrow E_1 + \\overrightarrow E_2 + \u0026hellip;$$ 21.7 Electric Field Calculations for Continuous Charge Distributions # We can extend our previous definition to calculus as $$\\overrightarrow E = \\int d \\overrightarrow E = k \\int \\frac{1}{r^2}\\ dq = \\frac{1}{4\\pi\\varepsilon_0} \\int \\frac{1}{r^2}\\ dq$$ .$dq = \\lambda\\ dl \\text{ (line)} = \\sigma\\ dA \\text{ (disk)} = \\rho\\ dV \\text{ (sphere)}$ **Calculating field generated by a continuous charge distribution** 1. Draw an arbitrary \"piece\" of charge distribution; don't choose a special point such as the end or exact middle. The piece should be infinitesimally long and/or wide. Thus, its length or width will be something like .$dx$ or .$ds$ 2. Write an expression for .$dq$, the corresponding infinitesimal charge of that piece in terms of .$dx$ or .$ds$ or whatever. Recall .$dq = \\frac{\\text{total charge}}{\\text{total length}} \\times \\text{(tiny length of piece)}$ 3. Using Coulomb's law, find the infinitesimal electric field at that point of interest (e.x. some point .$P$) generated by the piece chosen in step 1. When necessary, break .$d\\vec E$ into components, .$dE_x$ and .$dE_y$ 4. Integrate .$dE_x$ or .$dE_y$ over the whole charge distribution to obtain the total electric field in the .$x$ or .$y$ direction respectively When solving problems, it\u0026rsquo;s a good idea to use symmetry, check charge direction, and (when applicable) use bounds of .$r \\in [0, \\infty]$ We can write equation for an infinite plane holding a uniform surface charge density .$\\sigma$ $$2A \\cdot \\overrightarrow E = \\frac{\\sigma A}{\\varepsilon_0} \\Longrightarrow \\overrightarrow E = \\frac{\\sigma}{2\\varepsilon_0}$$ This also applies in the case where a charge is close to an infinite surface (so that the distance to the surface is much greater than the distance to the edges) In the case where there are two oppositely charged sheets parallel to one another, the field is .$\\vec E = \\frac{\\sigma}{\\varepsilon_0}$ since there are two charges creating the field The case involving an infinitely long wire can be written generally as $$\\overrightarrow E \\cdot 2\\pi RL = \\frac{\\lambda L}{\\varepsilon_0} \\Longrightarrow \\overrightarrow E = \\frac{\\lambda}{2\\pi\\varepsilon_0 \\cdot r}$$ .$r$ is the distance from a particle to the wire 21.8 Field Lines # - To visualize electric fields, we draw **electric field lines** or **lines of force** - Three properties of Electric Field Lines: 1. Electric field lines **indicate the direction of the electric field**; the field points are in the direction tangent to the field line at any point -- see point .$P$ in .$\\text{(a)}$ 2. The lines are drawn so that the magnitude of the electric field, .$E$, is proportional to the number of lines crossing unit area perpendicular to the lines (i.e. a circle 'hugging' a point charge). **The closer together the lines, the stronger the field.** 3. Electric field lines start on positive charges and end on negative charges; and **the number starting or ending is proportional to the magnitude of the charge**. - .$\\text{Density} = \\frac{\\text{number of lines crossing surface}}{\\text{area surface}}$ - .$\\text{1 Coulomb} = \\frac{1}{\\varepsilon_0} \\cdot \\text{ lines}$ - .$\\therefore \\text{Density} = \\frac{q}{\\varepsilon_0 4\\pi r^2} \\Longrightarrow \\vec E$ - In the case of two oppositely charged parallel \u0026 equally spaces plates -- such as case .$\\text{(d)}$ -- we can write the field as $$\\overrightarrow E =\\text{const.} = \\frac{\\sigma}{\\varepsilon_0}=\\frac{Q}{\\varepsilon_0 A}$$ - .$Q =\\sigma A$ is the charge on one plate of area .$A$ - Field lines never cross because it wouldn't make sense for an electric field to have two directions at the same point. Electric Dipole # A combination of two equal but opposite charges next to one another \u0026ndash; see .$(\\text{a})$ above Dipole Moment is when represented by vector .$\\vec{p}$ of magnitude .$Ql$ Molecules that have dipole moments are called polar molecules ![Dipole](/docs/physics-7b/imgs/dipole.png) - A dipole in a uniform electric field feels no net force, but does have a net torque (unless .$\\vec p \\parallel \\vec E$) - If .$\\vec p \\not \\parallel \\vec E$, .$W =\\int_{\\theta_1}^{\\theta_2} \\tau d\\theta$ where .$\\tau = -\\vec p\\vec E\\sin\\theta = \\vec p \\times \\vec E$ - Simplifies to .$W =\\vec p\\vec E(\\cos\\theta_2 - \\cos\\theta_1)$ - Thus, work/torque is most at .$\\theta = 90^\\circ$ or .$180^\\circ$ depending on .$\\vec E$ direction - Pay attention to right hand rule when solving - If .$r \\gg l \\Longrightarrow \\overrightarrow E \\propto 1/r^3$ 21.9 Electric Fields and Conductors # The static electric field inside a conductor is zero (in static situations where electrons have had time to stop moving) For that reason, any net charge on a conductor distributes itself on the surface Charges inside conductors act as if the conductor isn\u0026rsquo;t there All the electric field lines just outside a charged conductor are perpendicular to the surface 21.10 Motion of Charged Particle # Vector Form of Forces $$\\overrightarrow F_{12} = k \\frac{q_1 q_2}{r^2} \\cdot \\widehat r_{21}$$ Notation: .$\\overrightarrow F_{12}$ means force on .$q_1$ by .$q_2$ since .$q_2$ is the source charge .$\\widehat r_{21} = - \\widehat r_{12} \\Longrightarrow \\overrightarrow F_{12} = -\\overrightarrow F_{21}$ Direction If .$q_1 q_2 \u0026gt; 0$ (same sign, repulse), then the force and unitary vectors both point away from the two charges ![Same Signs 12](/docs/physics-7b/imgs/repel-12.png) ![Same Signs 21](/docs/physics-7b/imgs/repel-21.png) If .$q_1 q_2 \u0026lt; 0$ (opposite sign, attract), then the force vector points towards the two charges and the unitary direction vector still points away from the two charges ![Opposite Signs 12](/docs/physics-7b/imgs/attractive-12.png) ![Opposite Signs 21](/docs/physics-7b/imgs/attractive-21.png) Superposition Principle In a system considering multiple (3+) charges, forces acting on .$q_1$ by .$q_2$ (.$F_{12}$) is independent from whether other charges are present Total forces acting on .$Q_1$ can be written as .$\\overrightarrow F = \\overrightarrow F_{12} + \\overrightarrow F_{13} + \\dots$ Remember to break down the vectors into .$x/y$ components when adding them E.x. .$F_{1x} = F_{12x} + F_{13x} + \\dots$ Realize that the axis are arbitrary .$\\theta = \\tan^{-1}\\Big(\\frac{F_x}{F_y}\\Big)$ Charges in Fields Charge moving with .$\\vec v$ that is parallel to uniform field .$\\overrightarrow E$ .$\\overrightarrow F = q \\overrightarrow E = m \\vec a \\Longrightarrow a_x = \\frac{q}{m}\\overrightarrow E = \\text{const.}$ .$\\vec v = \\sqrt{2a_x \\vec d} = \\sqrt{\\frac{2q}{m}\\overrightarrow E_x \\vec d}$ Charge moving with .$\\vec v$ that is orthogonal to uniform field .$\\overrightarrow E$ Similar to projectile in gravitational field: .$\\vec g \\sim \\overrightarrow E$ .$\\overrightarrow F_x = 0 \\Longrightarrow v_{x2} = v_{x1};\\ \\ a_x = 0$ .$\\overrightarrow F_y = q \\overrightarrow E = m a_y;\\ \\ a_y = \\vec a = \\frac{q}{m}\\overrightarrow E = \\text{const.}$ .$y(t) = \\frac{1}{2} \\frac{q\\overrightarrow E}{m}t^2$ 21.11 Electric Dipoles # Notes for this chapter are under 21.8 \u0026ndash; Electric Dipole "},{"id":48,"href":"/physics-7b/22/","title":"22: Flux \u0026 Gauss's Law","section":"Physics 7B","content":" 22.1 Electric Flux # Electric Flux: Electric field that passes through a given area E.x. for a uniform field .$\\vec E$ passing through an area .$A$ at angle .$\\theta$ between the field direction and line perpendicular to the area, the flux is defined as $$\\Phi_\\vec{E} = \\vec E_\\perp A = \\vec EA_\\perp = \\vec E A \\cos \\theta = \\vec E \\cdot \\vec A$$ The .$N$umber of field lines passing through unit area perpendicular to the field .$A_\\perp$ is proportional to the magnitude of the field .$\\vec E$ $$\\vec E \\propto N/A_\\perp \\Longrightarrow N \\propto \\vec EA_\\perp = \\Phi_\\vec{E}$$ For non-uniform fields: We divide up the surface into .$n$ small elements of surface whose areas are .$dA$ where .$dA$ is small enough (1) to be considered flat and (2) so .$E$ varies so little it can considered uniform $$\\Phi_\\vec{E} = \\oint_A \\vec E \\cdot d\\vec A$$ If .$\\Phi \u0026gt; 0$, flux is entering the volume and .$\\Phi \u0026lt; 0$ is flux leaving Direction: - For closed surfaces, .$\\vec A$ points outwards from the enclosed volume, so flux is positive - Further, .$\\theta$ (angle between .$d\\vec A$ and .$E$) should always be, for electric field... - Leaving the volume: Less than .$\\pi/2$ (so .$\\cos\\theta \u003e 0$) and .$\\Phi \u003e 0$) - Entering the volume: Greater than .$\\pi/2$ (so .$\\cos\\theta \u003c 0$ and .$\\Phi \u003c 0$) ![Flux Direction](/docs/physics-7b/imgs/flux-dir.png) Net Flux In the example above, every line that enters also leaves so .$\\Phi = 0$ meaning there is no net flux into or out of the enclosed surface Flux will only be nonzero if one of more lines start or end within the surface \u003e Flux through .$A_1$ is positive, .$A_2$ is negative ![Dipole Flux](/docs/physics-7b/imgs/dipole-flux.png) \u003e Net flux through .$A$ is negative ![Negative Flux](/docs/physics-7b/imgs/neg-flux.png) 22.2 Gauss\u0026rsquo;s Law # Gauss\u0026rsquo;s Law: We can relate flux through a surface and net charge enclosed within said surface by $$\\Phi = \\oint \\vec E \\cdot d\\vec A = \\frac{Q_\\text{enclosed}}{\\varepsilon_0}$$\nThis tells us the difference between the input and output flux of the electric field over any surface is due to charge within that surface. This is because we defined .$1 \\text{ Coulomb} = \\varepsilon_0^{-1} \\text{ field lines}$ Notice that it doesn\u0026rsquo;t matter the distribution of the charge inside the surface A charge outside the chosen surface may affect the position of the electric field lines, but it won\u0026rsquo;t affect the number of lines entering of leaving the surface Irregular Surfaces: ![Irregular vs Regular Surface](/docs/physics-7b/imgs/gauss-areas.png) - Since flux is proportional to the flux lines passing in/out, and the number of lines is the same for .$A_1$ and .$A_2$, so $$\\oint_{A_1} \\vec E \\cdot d \\vec A = \\oint_{A_2} \\vec E \\cdot d \\vec A = \\frac{Q}{\\varepsilon_0}$$ - Therefore, this is true for _any_ surface surrounding a single point charge .$Q$ The superposition principle from last chapter also applies to Gauss\u0026rsquo;s law: The total field .$\\vec E$ is equal to the sum of the fields due to each separate charge: $$\\oint \\vec E_i \\cdot d \\vec A = \\oint \\Big(\\Sigma \\vec E_i \\Big) \\cdot d \\vec A = \\sum \\frac{Q_i}{\\varepsilon_0} = \\frac{Q_\\text{enclosed}}{\\varepsilon_0}$$\n22.3 Applications of Gauss\u0026rsquo;s # **Gauss's Law to calculate electric fields** 1. Using symmetry and intuition, draw the electric field lines. 2. Enclose all or part of the charge distribution with a Gaussian surface. The electric field should have the same strength at all points on (at least part of) the surface. 3. Apply Gauss's law: .$\\Phi_\\vec{E} = \\oint \\vec E \\cdot d\\vec A = \\frac{Q_\\text{enclosed}}{\\varepsilon_0}$. If .$E$ is constant over (part of) the Gaussian surface, you can pull it outside the integral. This simplification is what allows you to solve for the field. - Recall .$Q_\\text{enclosed} = \\frac{\\text{(total charge)}}{\\text{(total area)}}\\times \\text{(area enclosed by Gaussian surface)}$ - If you can't pull .$E$ outside the flux integral, then Gauss's law don't work! Use the continuous charge distribution strategy from the [prior chapter](21.md#217-electric-field-calculations-for-continuous-charge-distributions). Uniformly Charged Solid Spherical Conductor # - **Charge Outside:** - .$\\vec E$ will have the same magnitude at all points along the surface .$A_1$ - Since .$\\vec E$ is always orthogonal to the surface, the cosine is always .$1$ $$\\Longrightarrow E = \\frac{1}{4\\pi\\varepsilon_0}\\frac{Q}{r^2}$$ - We see that the field outside is as if all of the charge was from a single point - **Charge Inside:** - .$\\vec E$ will have the same magnitude at all points along the surface .$A_2$ - Thus, .$Q = 0$ because the charge inside the surface .$A_2$ is zero - Hence, .$E = 0$ for .$r \u003c r_0$ - Initial radius is .$r_0$; outside radius is .$r$ - Enclosed charge has charge .$Q$ ![Hollow Shell](/docs/physics-7b/imgs/hollow-charge.png) - This result is the same for both hollow and solid spheres because all the charge would lie in a thin layer at the surface. If .$Q \\neq 0$, current would flow inside the conductor which would build up charge on the exterior of the conductor. This charge would oppose the field, ultimately (in a few nanoseconds for a metal) canceling the field to zero. Solid Sphere of Charge # - Charge .$Q$ is distributed uniformly throughout a nonconducting sphere of radius .$r_0$ ![Solid Charge](/docs/physics-7b/imgs/solid-charge.png) ![Field vs Distance](/docs/physics-7b/imgs/e-r.png) - **Charge Outside:** - Same rational as before, $$\\oint \\vec E \\cdot d\\vec A = E (4\\pi r^2) = \\frac{Q}{\\varepsilon_0}$$ $$\\Longrightarrow E = \\frac{1}{4\\pi\\varepsilon_0}\\frac{Q}{r^2}$$ - Again, the field outside is the same as for a point charge in center of sphere - **Charge Inside:** $$\\oint \\vec E \\cdot d\\vec A = E (4\\pi r^2) = \\frac{Q_{\\text{enclosed in }A_2}}{\\varepsilon_0}$$ - Since .$Q_{\\text{enclosed...}} \\neq Q$, we define the charge density .$\\rho_E$ as the charge per unit volume (.$dQ/dV$) which is constant - We can then write $$Q_{\\text{enclosed}} = Q \\cdot \\frac{\\frac{4}{3}\\pi r^3 \\rho_E}{\\frac{4}{3}\\pi r_0^3 \\rho_E} = Q\\cdot \\frac{r^3}{r^3_0}$$ $$ \\Longrightarrow E = \\frac{1}{4\\pi\\varepsilon_0}\\frac{Q}{r_0^3}r$$ $$$$ "},{"id":49,"href":"/physics-7b/23/","title":"23: Electric Potential","section":"Physics 7B","content":" 23.1 Electric Potential Energy and Difference # PE can only be defined for conservative forces That is, work done by said force is independent of the path taken Coulomb\u0026rsquo;s Law is conservative because the dependence on position is conservative Hence, we define .$\\Delta U = -W$ with .$\\Delta U = U_b - U_a$ is for a situation where a point charge .$q$ moves from point .$a$ to point .$b$ This is equal to negative work, .$-W = -\\vec F d = -(q\\vec E) d$ (for a uniform .$\\vec E$) 23.2 Relation between Electric Potential and Field # Electric Potential: Electric PE per unit charge, such as for a charge at point .$a$ $$V_a = \\frac{U_a}{q}$$ We only really care about difference though, which is defined as $$V_{ba} = \\Delta V = \\frac{U_b - U_a}{q} = - \\frac{W_{ba}}{q}$$ We can now also define PE in terms of electric potential: $$\\Delta U = U_b - U_a = q(V_b - V_a) = qV_{ba}$$ Electric potential difference is a measure of how much energy an electric charge can acquire in a given situation. Since energy is the ability to do work, the electric potential difference is also a measure of how much work a given charge can do. The exact amount of energy or work depends both on the potential difference and on the charge. If a positive charge is free, it will tend to move from high to low potential Inverse for opposite charge 23.3 Potential due to Point Charges # $$\\Delta U = U_b - U_a = - \\int_a^b \\vec F \\cdot d \\vec l$$\n.$dl$ is an infinitesimal increment of displacement along the path from .$a$ to .$b$ Keep in mind that .$\\vec F$ must be conservative Thus the integral can be taken along any path from point .$a$ to point .$b$. Knowing .$\\vec E = \\vec F / q$ and .$V_{ba} = (U_b - U_a) / q$, we can write the electric potential equation as\u0026hellip; ![Particle Through Field](/docs/physics-7b/imgs/pe-field.png) $$V_{ba} = V_b - V_a = - \\int_a^b \\vec E \\cdot d \\vec l$$ $$V_{ba, \\text{uniform $\\vec E$}} = -E\\int_a^b d\\vec l = -Ed$$ ...where .$d$ is the distance of a straight line from point .$a$ to .$b$ Charged Conducting Sphere # ### 1. Electric Potential **Outside** Sphere - We know .$\\vec E = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r^2}$ for outside a conducting sphere (.$r \u003e r_0$) - Therefore, we can write $$V_{ba} = - \\int_{r_a}^{r_b} \\vec E \\cdot d \\vec l = - \\frac{Q}{4\\pi\\varepsilon_0}\\int_{r_a}^{r_b} \\frac{dr}{r^2}$$ $$\\dots = \\frac{Q}{4\\pi\\varepsilon_0} \\bigg(\\frac{1}{r_b} - \\frac{1}{r_a}\\bigg)$$ $$\\dots = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r} \\text{ [$r_b = \\infty$]}$$ ![V and E versus radius](/docs/physics-7b/imgs/v-graph.png) ### 2. Electric Potential **On** Sphere - From .$(a)$, as .$r$ approaches .$r_0$, we see $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r_0}$$ at the surface of the sphere. This makes sense because the charge is distributed on the surface of the sphere. ### 3. Electric Potential **Inside** Sphere - Inside the conductor, .$\\vec E = 0$ - Therefore, there is no change in .$\\vec E$ from .$0$ to .$r_0$ (or any point within the conductor) gives zero change in .$V$ - Hence, within the conductor, .$V$ is a constant: $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r_0}$$ Thus, the whole conductor, not just its surface, is at this same potential. We can also generalize the first case to the electric potential .$r$ from a single point charge .$Q$ Coulomb potential # The potential outside a uniformly charged sphere is the same as if all the charge were concentrated at its center \u003e The potential near a positive charge is large, and it decreases toward zero at very large distances ![V vs R (positive)](/docs/physics-7b/imgs/v-r-pos.png) \u003e For a negative charge, the potential is negative and increases toward zero at large distances ![V vs R (negative)](/docs/physics-7b/imgs/v-r-neg.png) 23.4 Potential due to Any Charge Distribution # If .$\\vec E$ is a function of position (or otherwise unknown), we can find .$V$ by calculating the potential due to the many tiny charges that make up .$\\vec E$: $$V = \\frac{1}{4\\pi\\varepsilon_0} \\int \\frac{dq}{r}$$ where .$r$ is the distance from a tiny element of charge .$dq$ to the point where .$V$ is being determined 23.5 Equipotential Lines and Surfaces # The electric potential can be represented by drawing equipotential lines, or, in three dimensions, equipotential surfaces An equipotential surface has all points at the same potential. That is, the potential difference between any two points on the surface is zero Thus, no work is required to move a charge from one point on the surface to another. Equipotential surfaces are perpendicular to the electric field (field lines) For a positive point charge, the equipotential surface with the largest potential is closest to the positive charge Unlike electric field lines, which start and end on electric charges, equipotential lines/surfaces are always continuous and never end \u003eElectric field lines and equipotential surfaces for a point charge. ![Equipotential Lines -- Point](/docs/physics-7b/imgs/v-lines-point.png) \u003eEquipotential lines (green, dashed) are always perpendicular to the electric field lines (solid red) shown here for two equal but oppositely charged particles (an electric dipole). ![Equipotential Lines -- Dipole](/docs/physics-7b/imgs/v-lines-dipole.png) 23.6 Potential Due to Dipole (Moment) # $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r} + \\frac{1}{4\\pi\\varepsilon_0} \\frac{(-Q)}{(r+\\Delta r)} = \\frac{Q}{4\\pi\\varepsilon_0} \\frac{\\Delta r}{r(r + \\Delta r)}$$\n.$r$ is the distance from (some arbitrary point) .$P$ to the positive charge and .$r + \\Delta r$ is the distance to the negative charge - If .$r \\gg l$, then .$r \\gg \\Delta r \\approx l \\cos \\theta$ so we can neglect .$\\Delta r$ $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Ql \\cos\\theta}{r^2} = \\frac{1}{4\\pi\\varepsilon_0} \\frac{p \\cos\\theta}{r^2} $$ - Notice the potential decreases .$\\propto r^2$, whereas for a single point charge the potential decreases .$\\propto r$ - It is not surprising that the potential should fall off faster for a dipole: - When you are far from a dipole, the two equal but opposite charges appear so close together as to tend to neutralize each other ![Dipole Figure](/docs/physics-7b/imgs/v-dipole.png) 23.7 .$\\vec E$ Determined from .$V$ # We know that .$V_b - V_a = - \\int_a^b \\vec E \\cdot d\\vec l$, which we can write in differential form as .$dV = -\\vec E \\cdot d\\vec l = - E_l dl$. This can be written as $$E_l = - \\frac{dV}{dl}$$ .$dV$ is the tiny difference in potential between two points a distance .$dl$ apart, and .$E_l$ is the component of the electric field in the direction of the tiny displacement .$d\\vec l$ This is called the gradient of .$V$ in a particular direction: The general case is $$\\vec E = - \\nabla \\vec V = - \\bigg\\langle \\frac{\\delta V}{\\delta x}, \\frac{\\delta V}{\\delta y}, \\frac{\\delta V}{\\delta z} \\bigg\\rangle$$ This states that the electric field points \u0026ldquo;downhill\u0026rdquo; towards lower voltages (where there is lower potential) 23.8 Electrostatic PE; The Electron Volt # The electric potential and energy potential due to one point charge .$Q_1$ on another point charge .$Q_2$ separated by .$r_{12}$ are $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q_1}{r_{12}}$$ $$U = Q_2 V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q_1 Q_2}{r_{12}}$$ The PE is the negative work needed to separate the two charges to infinity. For three points, we can use the superposition principle like we have prior to write $$U = \\frac{1}{4\\pi\\varepsilon_0}\\bigg( \\frac{Q_1 Q_2}{r_{12}}+ \\frac{Q_1 Q_3}{r_{13}} + \\frac{Q_2 Q_3}{r_{23}} \\bigg)$$ Electron Volt # Joules are a very large unit for dealing with energy of the electron scale; as such, the electron volt (.$eV$) is often used One electron volt is the energy acquired by a particle carrying a charge .$e$ (the magnitude of an electron) as a result of moving through a potential difference of .$1 V$ $$1 \\text{ eV} = 1.6022 \\cdot 10^{-19} \\text{ J}$$ E.x., an electron (charge .$e = 1.6\\cdot10^{-19}$) that accelerates through a potential difference of .$1000 \\text{ V}$ will lose .$1000 \\text{ eV}$ of potential energy and gain .$1000 \\text{ eV}$ of kinetic energy 23.9 Digital; Binary Numbers; Signal Voltage (not covered) # Batteries and wall sockets provide a steady supply voltage as power Signal voltage provide/carry information Analog signal voltage has voltage that varies continuously (i.e .$\\sin$) Digital signals are more complicated and encode information, often in binary Bytes have 8 bits which allow .$2^8 = 256$ numbers Digital signals are transmitted at some rate (bit-rate) given in .$\\text{Mb/s}$ - Analog to digital converters, ADCs, convert analog signals to boxy digital waves - The difference between the original continuous and it's digital approximation is called the **quantization error / loss** - This error varies by primarily: 1. **Resolution** or **bit depth** which is the number of bits for the voltage of each sample 2. **Sampling rate** which is the number of times per second the original analog voltage is measured (sampled) - E.x., CDs are sampled at .$44.1 \\text{ kHz}$ with a bit depth of .$16 \\text{ bits per sample}$ \u003eThe red analog sine wave, which is at a 100-Hz frequency (1 wavelength is done in 0.010 s), has been converted to a 2-bit (4 level) digital signal (blue). ![ADC](/docs/physics-7b/imgs/adc.png) Digital Signals Digital to Analog, DACs, exist too because some appliances require an analog signal Digital signals can be compressed: Repeated information can be reduced so that less memory (bits) is needed Fun fact: Bit is the contraction of \u0026ldquo;binary digit\u0026rdquo;, leaving out the 8 letters between Digital signals are more resistant from noise, which badly corrupts analog signals Any electronic signal involves electric charges whose electric field can affect charges in another nearby signal External fields, as from high voltage wires, motors, or fluorescent lamps, can produce noise Thermal noise refers to random motion of electrons, much like the “thermal motion” of the molecules in a gas Moving electrons can be affected by the medium (wire, etc.), altering the signal "},{"id":50,"href":"/physics-7b/24/","title":"24: Capacitance, Dielectrics, Electric Energy Storage","section":"Physics 7B","content":" 24.1 Capacitors # Capacitors are devices that store an electric charge Normally consists of two conducting objects; plates, sheets When a voltage is applied, the two plates become charged: one positive, one negative Conductors are placed near one another, but not touching This distance is typically due to an insulator between sheets Capacitors are typically rolled so that they take up less room Two main use cases Storing energy for later use; e.x. camera flash Block surges of charge and energy to protect circuits The amount of charge .$Q$ acquired by each plate is proportional to .$V$: The potential difference of the two plates (Volts) .$C$: The constant capacitance of the capacitor (Coulombs per volt, farad) $$Q = CV$$ 24.2 Determination of Capacitance # In the real world, capacitance is determined experimentally by using the prior equations For ideal cases where the sheets are separated by a vacuum or air, however, we can use the following equations For a parallel-plate capacitor where .$A$ is the area of each plate and .$d$ is the distance between plates: $$E = \\frac{\\sigma}{\\varepsilon_0} = \\frac{Q}{\\varepsilon_0 A}$$ We also know this because .$E = \\sigma / \\varepsilon_0$ and .$\\sigma = Q/A$ Since .$V = \\int E\\ dl = \\frac{Qd}{\\varepsilon_0 A}$, we can relate it to .$C$ as $$C = \\frac{Q}{V} = \\varepsilon_0 \\cdot \\frac{A}{d}$$ **Capacitance-finding strategy** 1. Assign an arbitrary charge .$\\pm q$ to the two plates. 2. Using Gauss's law or other techniques, calculate the electric field between these two plates 3. From that electric field, calculate the potential difference between the plates, .$V = -\\int \\vec E \\cdot d \\vec s$ 4. Calculate the capacitance using .$C = q/V$. The arbitrary charge .$q$ from (1) should cancel out. 24.3 Capacitors in Series and Parallel # Series # The current/charge on each capacitor has the same magnitude: $$Q = Q_1 = Q_2 = \\dots$$ The total voltage across all capacitors is sumo of the voltage drops of the individual components: $$V = V_1 + V_2 + \\dots = I(R_1 + R_2 + \\dots)$$ And since .$V = Q/C$, capacitance is then $$\\frac{Q}{C_\\text{eq}} = \\frac{Q}{C_1} + \\frac{Q}{C_2} + \\dots \\Longrightarrow \\frac{1}{C_\\text{eq}} = \\frac{1}{C_1} + \\frac{1}{C_2} + \\dots $$ Notice that the equivalence capacitance is smaller than the smallest contributing capacitance Parallel # The total current/charge is the sum of the currents flowing through each component $$Q = Q_1 + Q_2 + \\dots = V (R^{-1}_1 + R^{-1}_2 + \\dots)$$ Voltage (potential difference) is the same across all paths/capacitors $$V = V_1 = V_2 = \\dots$$ Therefore, we can use .$V = Q/C$ to write the equivalent capacitance as $$Q = C_1 V + C_2 V + \\dots$$ $$Q = C_\\text{eq} V = (C_1 + \\dots)V \\Longrightarrow C_\\text{eq} = C_1 + \\dots$$ The net effect of connecting capacitors in parallel is to increase the capacitance Makes sense: We\u0026rsquo;re essentially increasing area of the plates The overall working voltage is always limited by the smallest working voltage of an individual capacitor. 24.4 Storage of Electric Energy # The energy stored in a capacitor is equal to the work done to charge it. Initially, an uncharged capacitor requires no work to move the first few bits of charge As more charge is stored, more work is needed to add more charge of the same sign because of the electric repulsion That is, the more charge already on a plate, the more work required to add additional charge Since we know .$dW = V\\ dq$ and .$V = q/C$, we can write the work needed to store charge .$Q$ as $$W = \\int_0^Q V\\ dq = \\frac{1}{C}\\int_0^Q q \\ dq = \\frac{1}{2} \\frac{Q^2}{C}$$ Since .$U = W$ and .$Q = CV$, we can write the energy stored in a capacitor with charges .$+Q$ and .$-Q$ on its two conductors as $$U = \\frac{1}{2} \\frac{Q^2}{C} = \\frac{1}{2}CV^2 = \\frac{1}{2}QV$$ It is useful to think of the energy stored in a capacitor as being stored in the electric field between the plates. E.x. lets find the energy stored in a parallel-plate capacitor in terms of the electric field We know for two close parallel plates we can find the potential difference as .$V = Ed$ where .$d$ is distance between plates We also know .$C = \\varepsilon_0 A/d$ for parallel plate capacitors, thus we can write $$U = \\frac{1}{2}CV^2 = \\frac{1}{2}\\bigg(\\frac{\\varepsilon_0 A}{d}\\bigg)(E^2 d^2) = \\frac{1}{2} \\varepsilon_0 E^2 Ad$$ We can recognize .$Ad$ as the volume between the plates where .$E$ exists If we divide both sides of by this volume, we can an equation for the energy density .$u$: $$u = \\frac{\\text{energy}}{\\text{volume}} = \\frac{1}{2}\\varepsilon_0 E^2$$ Thus, electric energy stored per unit volume in any region of space is proportional to the square of the electric field We proved this with parallel plates, but this can be shown for any region with an electric field 24.5 Dielectrics # Dielectrics are the insulating material sheet placed between conductors They serve to Because they don\u0026rsquo;t break down, they allow electric charge to flow as easily as air so higher voltages can be applied without charge passing across the gap Allow the plates to be placed closer together without touching, allowing an increased capacitance because the thickness .$d$ is smaller Dielectrics increase the capacitance by a factor .$K$ (known as the dielectric constant) $$C = KC_0$$ .$C_0$ is the capacitance when the space is a vacuum/air .$C$ is the capacitance with the dielectric filling the space For parallel-plate capacitors, we use .$C = Q/V = \\varepsilon_0 A/d$ and .$C = KC_0$ $$C = K \\varepsilon_0 \\frac{A}{d}$$ Energy density also changes with a dielectric as $$u = \\frac{1}{2}K \\varepsilon_0 E^2 = \\frac{1}{2}\\varepsilon E^2$$ Likewise, .$E$ and .$V$ are both also altered: With no dielectric, the field is .$E_0 = \\frac{V_0}{d}$ where .$V_0$ is the potential difference If the capacitor is isolated (i.e. not connected to a battery) so that the charge stays constant, potential difference drops: .$V = V_0/K$ Therefore, .$E = \\frac{V}{d} = \\frac{V_0}{Kd} = \\frac{E_0}{K}$ .$\\varepsilon$ is the permittivity of the dielectric material defined as .$\\varepsilon = K \\varepsilon_0$ "},{"id":51,"href":"/docs/cogsci-c100/","title":"CogSci C100","section":"Docs","content":" "},{"id":52,"href":"/docs/eecs-126/","title":"EECS 126","section":"Docs","content":" I did not take digital notes, but can vouch for these below. Aryan Jain\u0026rsquo;s 126 Notes \u0026ndash; backup Alec Li\u0026rsquo;s 126 Notes \u0026ndash; backup Sinho Chewi\u0026rsquo;s Probability Notes "},{"id":53,"href":"/physics-7b/25/","title":"25: Electric Current and Resistance","section":"Physics 7B","content":" 25.1 The Electric Battery # Batteries produce electricity by transforming chemical energy into electric energy Simple battery (cells) contain two plates or rods of dissimilar metals called electrodes The portion of rods outside of the solution are called the terminals Anode: The positive electrode Cathode: The negative electrode These electrodes are emersed in the electrolyte: a solution such as a dilute acid **Chemical Process:** 1. The acid dissolve the zinc electrode, causing zinc atoms to leave two electrons behind on the electrode and enters the solution as a positive ion. The zinc electrode thus acquires a _negative charge_. 2. Then the electrolyte becomes positively charged and can pull electrons off the carbon electrode. Thus the carbon electrode becomes _positively charged_. 3. Because there is an opposite charge on the two electrodes, there is a _potential difference_ between the two terminals. ![Battery](/docs/physics-7b/imgs/battery.png) When a battery isn\u0026rsquo;t connected, only a small amount of zinc is dissolved The zinc electrode becomes increasingly negative Thus, any new positive zinc ions produced are attracted back to the electrode That is, if a charge is allowed to flow then the zinc can dissolve The voltage depends ot the electrodes\u0026rsquo; material and their relative ability to give up electrons 25.2 Electric Current # - When a circuit is formed, charge can move (flow) through the wires from one terminal to the other - Any flow of charge is called an **electric current** - Flow can only occur on a continuos conducting path (a complete circuit) - If there's any break, our circuit is called an open circuit and no current flows - The symbol for battery is the following: ![Battery Symbol](/docs/physics-7b/imgs/battery-symb.png) \u003eConventional current from .$+$ to .$-$ is equivalent to a negative electron flow from .$-$ to .$+$ ![Flow Direction](/docs/physics-7b/imgs/flow-direction.gif) Current in a wire is defined as the net amount of charge that passes through the wire\u0026rsquo;s full cross section at any point in time: $$\\bar I = \\frac{\\Delta Q}{\\Delta t} \\Longrightarrow I = \\frac{dQ}{dt}$$ Current is measured in coulombs per second; ampere (amp): .$\\text{1 A = 1 C/s}$ 25.3 Ohm\u0026rsquo;s Law: Resistance and Resistors # For a current to exist, there must be a potential difference (e.g. between the terminals of a battery) That is, the current is proportional to the potential difference: $$I \\propto V$$ E.x., a wire connected to a .$6V$ battery results in a current twice that of a .$3V$ battery The current depends on the resistance that the wires offers The electron flow is impeded partly due to the atoms in the wire .$R$ is this proportionality factor between voltage and current Thus, we get Ohm\u0026rsquo;s Law: $$V = IR$$ Ohm\u0026rsquo;s law only works for when .$R$ is a constant, i.e a metal conductor In reality, .$R$ isn\u0026rsquo;t constant if temperature changes much Materials that follow Ohm\u0026rsquo;s law are labeled as \u0026ldquo;ohmic\u0026rdquo; Resistance has the units/notation .$\\text{1 $\\Omega$ = 1 V/A}$ Resistors are used to limit/control the current in a circuit toolbox.mehvix.com/resistor As a current passes through a resistor, the charge/current stays the same but the electric potential decreases **Clarifications of Behavior** - Current's magnitude depends on that device's resistance - Can be though of as the \"response\" to the voltage: increases if voltage increases or resistance decreases - Current is constant -- it's energy so it cannot be destroyed by components and it's not created by a battery - Resistance is a property of the device/wire - Voltage is external to the wire of device -- it's applied across the two ends of the wire - Batteries maintain a constant potential difference -- act as a source of voltage 25.4 Resistivity # Resistivity has experimentally been found as $$R = \\rho \\frac{l}{A}$$ .$\\rho$ is the resistivity (constant of proportionality) and depends on the material Has units .$\\Omega \\cdot \\text{m = V/A $\\cdot $ m}$ .$l$ is the wire length .$A$ is the cross-section area The reciprocal of resistivity is conductivity: .$\\sigma = \\rho^{-1}$ Temperature # Resistivity varies (generally increasing) with temperature $$\\rho_T = \\rho_0 = \\bigg[ 1+ \\alpha (T-T_0)\\bigg]$$ .$\\rho_0$ is the resistivity at some reference temperature .$T_0$ (i.e .$0^\\circ \\text{ C}$) .$\\rho_T$ is the new resistivity at the current (higher) temperature .$T$ .$\\alpha$ is the temperature coefficient of resistivity that depends on material Note that the temperature coefficient for semiconductors can be negative. At higher temperatures, some of the electrons that are normally not free in a semiconductor can become free and contribute to the current. Thus, the resistance of a semiconductor can decrease with an increase in temperature. 25.5 Electric Power # Electric energy is transformed into thermal energy (and light) in stove burners, toasters, etc. The current creates collisions between the moving electrons and the atoms in the wire That is, the KE from the wire\u0026rsquo;s atoms increases meaning the temperature increases too $$P = \\frac{dU}{dt} = \\frac{dq}{dt}\\cdot V$$ This is because energy is transformed when a tiny charge .$dq$ moves through a potential difference .$V$ is .$dU = V\\ dq$ The charge that flows per second, .$dq/dt$, is the electric current .$I$: $$P = IV = I^2 R = \\frac{V^2}{R}$$ The SI unit for power is the watt: .$\\text{1 W = 1 J/s}$ We get the last two equations by plugging in .$V = IR$ 25.7 Alternating Current # When a battery is connected to a circuit, the current moves steadily in one direction (DC: Direct Current) Electric generators at power plants produce AC: alternating current Reverses direction many times per second and is commonly sinusoidal $$V = V_0 \\sin(2\\pi ft) = V_0 \\sin(\\omega t)$$ .$\\omega$ = .$2\\pi f$ .$f$ is the frequency: number of complete oscillations per second Commonly .$\\text{60 Hz}$ in NA Potential .$V$ oscillates between .$\\pm V_0$, the peak voltage Current equation still works: $$I = \\frac{V}{R} = \\frac{V_0}{R}\\sin\\omega t = I_0 \\sin\\omega t$$ .$I_0 = V_0/R$ is the peak current Avg current is 0; it\u0026rsquo;s positive and negative for an equal amount of time Doesn\u0026rsquo;t mean that no heat is created or no power is needed Electrons are still moving though! Power is also consistent $$P = I^2R = I_0^2 R \\sin\\omega t = \\frac{V_0^2}{R} \\sin\\omega t$$ Power is always positive because current is squared Since the .$\\sin\\dots$ oscillates between 1 and 0, the average power is $$\\overline P = \\frac{1}{2}I_0^2R = \\frac{1}{2} \\frac{V_0^2}{R}$$ This can also be calculated by using the RMS values for .$I$ and .$V$ $$I_\\text{rms} = \\sqrt{\\overline I^2} = \\frac{I_0}{\\sqrt{2}} \\approx 0.707 I_0$$ $$V_\\text{rms} = \\sqrt{\\overline V^2} = \\frac{V_0}{\\sqrt{2}} \\approx 0.707 V_0$$ $$\\dots \\Longrightarrow \\overline P = I_\\text{rms} V_\\text{rms} = I_\\text{rms}^2 R = \\frac{V_\\text{rms}^2}{R}$$ Fun fact: we can use the rms of a value to find the peak of it, e.x. $$V_0 = \\sqrt{2} V_\\text{rms}$$ Keep in mind that this is the average power. Instantaneous power varies from .$0$ to .$2\\overline P$ 25.8 Microscopic View of Current # We\u0026rsquo;ve seen that electric current can be carried by negatively charged electrons in metal wires, and that in liquid solutions current can also be carried by positive and/or negatively charged ions When a potential difference is applied to the two ends of a wire, the direction of the electric field .$\\vec E$ is parallel to the walls of the wire This field within the conducting wire does not contradict our earlier result that .$\\vec E = 0$ inside a conductor in the electrostatic case, as we are no longer dealing with the static case. That is, charges are free to move in a conductor, and hence can move under the action of the electric field. If all the charges are at rest, then .$\\vec E = 0$ Current Density # Current density, .$\\vec j$, is the current per area $$j = \\frac{I}{A} \\Longrightarrow I = \\int \\vec j \\cdot d \\vec A$$ .$I$ is the current through the whole surface .$d\\vec A$ is an element of surface area over which the integration is taken Direction of the density is the same direction as .$\\vec E$ \u0026ndash; the direction that a positive charge would move Drift Speed # Inside a wire, we can imagine the free electrons as moving about randomly at high speeds, bouncing off the metal atoms of the wire Somewhat like the molecules of a gas When an electric field exists in the wire the electrons feel a force and initially begin to accelerate but they soon reach a more or less steady average speed, known as their drift speed .$v_d$ Collisions with atoms in the wire keep them from accelerating further The drift speed is normally very much smaller than the electrons\u0026rsquo; average random speed inside the metal wire Black zagged line represents the motion of an electron in a metal wire due to an electric field. The field .$\\vec E$ gives electrons in random motion a net drift velocity .$\\vec v_d$. Its direction (the net charge flow) is in the opposite direction of .$\\vec E$ because electrons have a negative charge and .$\\vec F = q \\vec E$ We can relate drift speed with the macroscopic view: In some time, the electrons travel (the average) distance .$l = v_d \\Delta t$ In that same time, electrons in volume .$V = Al = A v_d \\Delta t$ pass through area .$A$ of the wire If there are .$n$ free electrons each of charge .$-e$ per unit volume, then the total electrons is .$N = nV$ Thus, the charge is $$\\Delta Q = \\text{(number of charges, $N$)$\\times$(charge per particle, $-e$)}$$ $$\\dots = (nV)(-e) = -(nAv_d\\Delta T)(e)$$ We can then easily find the current (density): $$I = \\frac{\\Delta Q}{\\Delta t} = -neAv_d$$ $$j = \\frac{I}{A} = -nev_d$$ Notice that the negative sign indicates that the direction of (positive) current flow is opposite to the drift speed of electrons. Field inside a Wire # Voltage can be written in terms of microscopic values (in addition to the macro: .$V = IR$) Recall that resistance is related to density by .$R = \\rho \\frac{l}{A}$ We can then write .$V$, .$I$ and .$j$ as $$V = El = IR = (jA)\\bigg(\\rho \\frac{l}{A}\\bigg) = j \\rho l$$ $$I = jA$$ $$j = \\frac{1}{\\rho}E = \\sigma E$$ .$\\sigma$ is the conductivity of the wire .$\\rho, \\sigma$ do not vary with .$V$ and thus neither .$E$ We can then write the microscopic statement of Ohm\u0026rsquo;s Law: $$\\vec j = \\sigma \\vec E = \\frac{\\vec E}{\\rho}$$ 25.9 Superconductivity # At very low temperatures, the resistivity of certain metals and certain compounds or alloys becomes zero Materials in such a state are said to be superconducting In general, superconductors become superconducting only below a certain transition (critical) temperature, .$T_C$ "},{"id":54,"href":"/docs/anthro-c12ac/","title":"Anthro C12AC","section":"Docs","content":" Anthropocene # The time when human activity began to have an influence on (global) landscape due to our use of fire Large subject used in a range of fields \u0026ndash; no single definition Defining feature: combustion of carbon and greenhouse gases Ice core measurement technique As ice forms, methane and CO2 get trapped along with ash/dust/pollen which scientists can measure by coring Ice can be dated so we can compare these variables so we can see change in greenhouse gases over time Beginning is disputed Industrial revolution (1780s) Most popular among scholars Atomic Testing (1940s) The isotopic by-products of bomb testing provide a distinctive marker horizon in ice cores, ocean and lake sediments, and soils Stages idea: Includes vital events such as forest cutting and grassland conversion: the two largest spatial transformations of Earth\u0026rsquo;s surface in human history 1.8 million years ago: When fire was discovered 6000-4000s years ago: With neolithic agriculture 1780s: Industrial revolution Identifying fire requirements: Evidence of temporal or spatial changes in fire activity and vegetation Demonstration that these changes are not predicted by climate parameters alone Temporal/spatial coincidence between fire regime changes and changes in the human record Pyrogeography # History of the variation of fire activity over space and time at the landscape scale in different regions of the world Pyrogeography started in Silurian period when plant life began Fire requirements: 13% Oxygen in a normal environment and 30% Oxygen in damp vegetation. Fires are a selection force in the evolution of plants Four phases for Pyrogeography # 1. Natural Biospheric Fire \u0026ndash; Natural Fire Regime # (Potential) start date for pyrogeography During Silurian and Devonian Periods (440-400 HYA) Natural fire regime started during this period because it was the first time that the fire triangle came together Fire triangle: Ignition Source: (Since beginning) Natural ignition from lightening (most common), volcanoes, (rarely) falling rock sparks These natural sources tend to only begin fires in the dry season Lightening is most common in mountain regions (over a costal region) Oxygen Source: (Cambrian period) Atmospheric Oxygen (from photosynthetic plants) leads to appearance of photosynthetic organisms Fuel Source: (Silurian and Devonian Periods) Enough terrestrial plants in ecosystems to acts as fuel During this time, natural fire regimes evolved As coal became more common (Carboniferous period), fires did too Started long time ago, before humans and dinosaurs 2. Wildland Anthropogenic Fire \u0026ndash; Hunter/Gatherer Fire Regime # When people began acting as the ignition source Primarily used fire for domestic cases Heating, cooking, warmth, etc. When people move to a new land Major changes in fauna, vegetation, and fires (charcoal) People seem to bring fire with them as they migrate Start dates 40 ka for Australia 90% of fauna went extinct Lots of evidence of fire 45 ka for Highland New Guinea 50 ka for lowland Borneo 20 ka for the Americas Extinctions of many animals and vegetation Debate: are these because of natural process like climate change (ice age -\u0026gt; post ice age?) or do people play a large role Native Perspective \u0026ndash; Indigenous people have been here since time began When did humans actually discover fire? # Defining the bridge between phase one and two is difficult Definition problems Do we ask when did (modern humans / hominin ancestors) develop the ability to control and utilize fire? We also need to distinguish between (1) controlling / utilizing fire and (2) being able to start a fire on a whim Archeological problems Fire exists naturally, so we can\u0026rsquo;t assume all fire evidence is from human action Other natural processes can look like fire (e.g. staining by minerals in soil, oxidation causing reddish patches) Combustion of natural objects (e.g. bushes) can leave charcoal which looks like a human hearth Additionally, evidence of a hearth doesn\u0026rsquo;t mean that humans started/controlled fire Provides a single snapshot, has little temporal depth Archaeological Record Analysis In the field: Observation and collection of materials Study the geology of the site In the lab: Microscopic analysis to see if there was burning If so, could the location of the sample been transported after combustion? Further, how does the history of the burned object associate with cultural items How long has fire been controlled? # Europe: Strong evidence of 400,000 - 300,000 years ago Western Asia: One established case from 780,000 years ago. Other sites are similar to Europe Africa: Claims have been made for a cave site that shows fire around 1.5-1.6 million years ago Note that opportunistic use of fire could have happened much earlier Eg. lighting a torch from a natural-starting forest fire 3. Agriculture Anthropogenic Fire \u0026ndash; Agricultural Fire Regime # Required fire to alter the natural vegetation from perennial-dominated to annual-dominated landscapes. People preferred to live in fire-prone places because the burning provides advantages for hunting, foraging, cultivating, and livestock herding 4. Industrial and Domestic Anthropogenic Fire \u0026ndash; Industrial Fire Regime # Low-severity surface fire regimes are being replaced with low-frequency, high-intensity crown fires that are outside the historical range of variability for these ecosystems Western US: forests have also experienced an increase in hazardous fuels due to highly effective fire suppression policy that excluded fires for much of the 20th century Eastern US: Fire suppression has shifted oak and pine woodlands to mesophytic hardwoods consequently reducing flammability and fire activity Globally: urban areas have steadily expanded into wildland areas Producing more ignition sources (arson and accidental) Exposing more people to wildfire Key Factors in Fire Regimes (Discussion 8-30) # Frequency The interval of fire occurrences E.x. every four years Area Size, distribution, location Ground fires (primarily dead plants) vs crown (burning upper canopy of living trees) Crown fires areas are more difficult to manage because controlled burns still damage natural resources Severity How destructive a fire is (high mortality = high severity) Change in dominant species / change in ecosystem Quantifiable by how much soil on the ground is visible Seasonality How the season affects fires May or may not be annual May arise due to weather conditions Ex. Annual to decadal cycles of drying conditions Interactions General activity on the landscape leading to different fire outcomes Droughts leading to stress on fuels Beatles eating bark, making trees more vulnerable Fire suppression leading to less severe fires Climate change making fires more severe Biodiversity and Fire as a Selective Variable in Evolution # C4 grass Spread during seasonal climate in the tertiary period (when fires became more common) Fires lead to woodlands and created environments favorable to C4 grasslands Since C4 is high flammability, it would have produced a feedback process that further increased fire activity, Thus maintaining the grassland-dominated landscape This process is similar to the one currently maintaining many of our savannas Plant attributes Heat shock Certain species have seeds that will open with heat Not exclusive to fire; correlated with soil heat too Smoke Highly selective and specific to fire Smoke is a mixture of specific chemicals unique to itself Note that plants become resistant to certain fire regimes, not necessarily all Changes in fire regime can kill off fire resistant plants Even small differences in the deployment of fire outside of natural lightning strikes can alter patterns of forest succession, fuel availability, and seasonality of ignitions Fires Relating to Evolution # Beneficial Attributes Cooking hypothesis Key claim: Fire + cooking started with the Homo erectus. As such, humans have evolved around a cooked diet that they can\u0026rsquo;t live without Led to fitness advantage More energy + nutrient from food, enabling body and brain size increase Detoxing effect Increase digestibility of all food Cooking takes time, leading to social development Distribution of tasks among group: (collection, preparation, even stealing) Cooking accounts for reduction in jaw, tooth size (due to softer food), stomach, and digestive system size There is no evidence of modern human societies existing without cooked food Counterpoints: It\u0026rsquo;s still unclear that Homo erectus controlled fire There are some sites that show no example of cooking: e.g. Neanderthal sites in cold climates Energetic effects aren\u0026rsquo;t well quantified Digestive evolution may not have been linear; other adaptations related to fire occurred after Homo erectus Protection benefits at night (especially versus the alternative: sleeping in trees) Allowed much better vision in caves Enables cave art Evidence that some hominids could use fire to morph certain woods into tools (e.g. digging sticks, hafted spears) Allowed humans to colonize colder environments Increase prey abundances, maintain mosaic landscapes, and increase pyrodiversity and succession stage heterogeneity Social bonding Led to camp fires Allows people to stay up later Fire could be used as a story telling enhancer, means to pass on history, culture, etc. Provides a sense of intimacy and openness Opportunity for music Fire-stick farming clearing ground for human habitats facilitating travel killing vermin, hunting regenerating plant food sources for both humans and livestock warfare among tribes Woody, closed-canopy shrublands were opened up or entirely displaced Led to spread of fast-growing annual species that provided greater seed resources, travel, and hunting and planting opportunities Ex. CA land was only used for agriculture after burnings, which led to many other alien plants spreading too Reductions in arboreal cover and woody understory have the most potential to enhance erosion Reshaping of landscapes has posed problems for ecologists trying to understand contemporary landscape patterns Overview of Fires in California # Conflagrating California\n~54% of CA ecosystems depend on fire The remaining ecosystems that aren\u0026rsquo;t too extreme for fires (so not deserts, stony summits, wetlands, etc.) are fire adapted \u0026ldquo;Fire season is 13 months\u0026rdquo;\nCA has a diverse ecosystem; each site is similar to another one elsewhere though What sets CA apart is the scale and intensity of it\u0026rsquo;s fires CA\u0026rsquo;s fires are unique in that they lead national discourse Texas views the US as France views the EUnion \u0026ndash; a canvas to project it\u0026rsquo;s ideals Alaska view the US as a source of subsidies. It\u0026rsquo;s isolated and treated almost as a commonwealth. California shares sizes, political isolation, and sense of selfhood with the aforementioned. Unlike AL, it has a strong and wide economy Unlike TX, it has been independent but not secessionist and, while CA and TX both have strong cultures, CA doesn\u0026rsquo;t project its Importance - 1/9 Americans live in CA - 8th largest economy - Social uses 1/2 the national fire budget - Source (and testing ground) of new firefighting technology \u0026ldquo;CA is like the rest of the US, just more so\u0026rdquo;\nTwo CA North and south Sierra and Seacoast Rich and poor Scrubland, megalopolis, \u0026amp; wilderness Lowest and highest elevation in nation (Mount Whitney @ 14,500 ft and Death Valley @ -280 ft) Sierra Nevada is analogous to NoCal Big tilt Highest in SE and slants lower to N + W Mostly timber More frequent fires Transverse Range is analogous to SoCal Big Kink Highest in E, bends sharp W then trails to pacific and N Mostly bush More intense fires 56% of ppl live on 8% of land CA is a national innovator Created geological survey in 1860 Created Board of Forestry in 1885 Set standard for fire control Light-burning controversy Pro-burn: Frontier practices (the Indian way of forest management) Advocated for regular burning montane woods and lowlands NoCal Pro-protection Use govt to prevent\\fight fires SoCal National issue debated in CA 1923: Light-burning anathematized Leopold report, Wilderness Act, and Tall Timbers fire ecology conferences Began in 1962 Aimed to transform fire control into fire management Good for conservation + private land owners who wanted traditional working landscapes Loggers and ranchers started moving out at this time Didn\u0026rsquo;t target urban areas Urban Areas Used fire suppression CA to spawn as AK to wilderness\nFires in SoCal rained embers onto cities SoCal retaliated w larger firefighting force New Practices Operation Firestop: Transform tech into operational programs 1956: Aerial tankers used to drop retardant on firelines 1961: Specialty fire crews expanded nationally 1963: Forest Service opened Western Fire Lab to coordinate fire suppression w air attacks 1970: Organized SoCal fire agencies towards common practices Area Specialty Florida: Prescribed fire N Rockies: Management over back countries (So)Cal: Fire suppression Land management in Cali was synonymous to fire management, thus fire suppression As CA grew, the motivation for fire suppression was primarily economical This lead to divisive debates of suppression vs let-burn When there were flames, it was fight or flight Many fire ideas spread from CA Often transformed and simplified Fires are especially susceptible due to Scioecological Systems (SES) History of fires suppression Climate change More extreme fire weather Expanding development Droughts Difficult to predict future fire regimes well Changes in human behavior can amplify, but tend to cancel out climatic effects on fire regimes For example, humans alter through changing land use, ignitions, fuel conditions, or fire suppression Fire activity is influenced by climate variability More (less) fire occurred in dry (wet) and warm (cool) years, and high-fire years were preceded by moist and sometimes cool conditions 1\u0026ndash;4 y earlier. (Sierra Nevada) fire-regime shifts correlate to SES changes, not shifts in climate. Are best bet is to look at history and see how fire regimes changed from past changes in socioeconomic variables Climate increased fire activity on a large-scale after Native American depopulation reduced the buffering effect of due to their burnings Sierra Nevada tribes were hunter-gatherers who used sophisticated burning practices to manage resources The fire index nearly doubled after depopulation Later Euro-American settlement and fire suppression buffered fire activity from temperature increases Logging, fire suppression, livestock increase (grazing effects) The overall sensitivity of fire regimes to low-frequency temperature variation is related to temperature-driven vegetation changes that alter fuel structure and fuel type Peopling of North America # Traditional Perspective \u0026ndash; Clovis First Model 13,000 ka, there was an ice-free corridor that opened up and let people come to north America People from Asia follow herds of megafauna across Bering Strait ( Beringia) We have found kill sites across America Butchered mammoth, horses, bison, ground sloths, etc. New Thoughts about Peopling of Americas: Multiple Migrations of People 20,000-40,000 years ago Coastal Migration Model: Use Boats to Come to Americas from Asia Some travels may not have been successful which is why there is less evidence for this theory Based on: Evidence sophisticated cultures Art, pottery, (primitive) technology, etc. Evidence of maritime seafaring at early date (Australia, New Guinea, Japan) People follow the Kelp Highway Maritime Kelp forests very productive (food source) Kelp Highway went along Pacific Rim Peopling of California # Earliest well dated sites in CA (13,000-10,000 BP) [Based on radio carbon dates]\nSites located in SoCal: Channel Islands, South Coast These Islands have always been separated by water so we know people had boats relatively early Find Evidence of Shell Middens\nContain shell, fish, other maritime foods Have evidence of tools for kelp + technology Big Game Kill Sites rare in California Dietary Differences (Midwest/Plains vs California) Perhaps because of dietary differences Suggests different groups of people, so potentially different groups of migrants Major Changes observed on Channel Islands\nChanges in Fauna (Pygmy Mammoths) Changes in Flora Evidence of Fires! Debate about what caused these changes\nDue to\u0026hellip; Climate Change Climate change at end of Ice Age Mega herbivores died after ice age, increasing fuel sources (vegetation) which we can see with charcoal signatures Causes warming + drying (leading to fire) Changes in vegetation and animals because they couldn\u0026rsquo;t adapt Comet Newest theory Estimated that 5km comet hit earth somewhere We\u0026rsquo;ve found comet-diamonds and various sites that have chemical signatures potentially from a comet Cloud from comet would have affected photo-synthetic processes, killing plants + animals People People may have over-hunted animals May have brought fire with them Potentially due to multiple reasons Kent thinks it\u0026rsquo;s likely climate change + people Concluding Points\nClearly people knew about fire from earliest times Very Sophisticated Maritime Peoples (Kent\u0026rsquo;s opinion) Early for early anthropogenic Influenced fire regimes from earliest times Implications: the Holocene Epoch in CA (last 10,000 years); you cannot assume That only Natural Fire Regimes existed Must consider the influence of people Historical Fire Records in California # Methods # Key Question: What methods can we use to get historical information on fires? 1. Coring Lakes # Annual layers are laid down in some lakes Realistically you can date to around fifty years of accuracy This samples have deeper temporal depth vs other methods We can also radiocarbon date these samples to determine the time period What to sample Charcoal present is indicates fire Larger particle tend to travel small distances Smaller particles can travel much longer distances Some plants may be easier/harder to identify than others Pollen analysis can give you knowledge on what (wind pollinated) plants were common at the time in that area Provides broad perspective of vegetation over time Pollen can travel far, so resolution isn\u0026rsquo;t great Phytoliths Tiny particles formed in many plants They don\u0026rsquo;t break down \u0026ndash; can stay in soil for hundreds to thousands of years! Can be used to identify plant species Cons: Not all plants produce them; overrepresented in grasses 2. Coring Trees # You basically jab a metal straw into a tree and get a sample of the tree Doesn\u0026rsquo;t harm tree, tree naturally patches the hole itself These sample contain rings Give us age and growth rate of the tree Growth increase in rings can allude to neighboring trees being killed Dead neighboring trees means less canopy blocking sunshine and less trees competing for nutrients Multiple samples can give us an overview of a landscape Do we see a multi-age forest? Do we see synchrony in growth rate? Crossdating: To identify events, we compare the sample\u0026rsquo;s tree rings to those of other \u0026ldquo;regular\u0026rdquo; trees in different areas at the same time Note that the example above is a rare occurrence 3. Fire Scars # Fire scars occur when fire kills part of the cambium below bark, leaving a wound The scar itself takes ~10 years to show up Multiple dated wounds allude to multiple fire occurrences You can also get the seasonality too Spring trees have warmer water so the scars are lighter in color Fall/winter trees have slower cell movement, so the scars are darker (this is called \u0026ldquo;latewood\u0026rdquo;) Therefore, how deep the scar is in the wood corresponds to the season the fire occurred Use crossdating for high accuracy and precision Pines, White oaks, Sequoia, Redwood, Incense, and Cedars are all good trees to take samples from Wedges: You can take wedges from the tree to get access to the ring view Both living and dead wood samples can be dated Pines, redwood, cedar, giant sequoia are all rot resistant thus good species to sample You ideally want to cut a thin wedge that has a large surface area and includes center of tree Downsides Trees heal covering up scars or scars are in an exposed cavity that can be seen Problem when fire interval \u0026lt; 10 years (such as cultural burnings) Most of the time fires aren\u0026rsquo;t severe enough to scare deeply enough and if they do scar, it\u0026rsquo;s feint Only 5% of trees sampled scarred in Sierra Nevada Fire scars have a finite lifespan (tree lifespan) Paints picture only of a certain plant in the landscape Fire History Study Sierra Nevada # Two large sampling areas, one north and south Sierra Nevada Systematic fire history sample in mixed conifer forests Important confluence of at least 3 Tribes: Sierra Miwok, Yokut, and Western Mono. Burned extensively for multiple objectives This periodic burning limited severity of fires Fire area did not exceed 1500 ha in any year. Approximately 50% of area This is tiny compared to the scale of other fires in California! Area burned in California # Before 1800 Lightning fire Indian burning Burned most of grasslands, wetlands, oak woodlands, some forests 4.5 million acres/yr. burned Costal California Today # Large area: scotia to Morro bay Very diverse vegetation type From mixed conifer to costal prairie Fire regimes depend on vegetation, thus they\u0026rsquo;re diverse Likewise, some regions don\u0026rsquo;t consider burning at all and only do suppression whereas others use burnings frequently General ignition sources At higher mountains, lighting ignition occurs (still rare, however) At lower elevations / costal areas, human ignition is the main sources Looking at history, we see that Indian fires dominated for thousands of years Sudden oak death (SOD) in Tanoak Forest Invasive pathogen in Marin Country Dead trees increase the severity of fires Prescribed fire periods Done in fall if not drying to damage trees Trees are in dormant phase, less damaging Done in spring if trying to control/limit Wet spring conditions are easier to manage Location Types # Costal Prairie Interval: Short Frequent fires critical to killing shrubs/trees Therefore, due to human intervention douglas-fir and shrublands have began to take over prairies Source: Indian Type: high \u0026ndash; removes overstory of grass Size: Small to moderate Coast Redwood Severity: low Have thick, adapted bark Interval: Short up to 1880\u0026rsquo;s Size: Small to moderate Source: Indian burnings Can re-sprout after fires Redwoods are very fire and rot resistant so many contain information about fires Difficult to date because the asynchronous ring structure California Annual Grasslands Interval: Short Interval needs to be short so that shrubs don\u0026rsquo;t come in Practicing fire suppression/exclusion results in quick spreading, non-fire resistant plants like douglas-firs taking over Severity: high \u0026ndash; removes overstory of grass Size: Moderate to Large Non-native plants dominate today, very different Human intervention lead to overgrazing and drought which enhanced ability for mediterranean plants to prosper It\u0026rsquo;s hard to go back and restore to native ecosystem state Coastal Scrub \u0026ndash; Coyote Bush (Oakland hills) Interval: Moderate Severity: High Size: Moderate Source: Indian burnings for diverse objectives Oak Woodlands, Mixed Oak Woodland Severity: Low Have thick, adapted bark Frequency: High Size: Small Naturally dense Very dense nowadays due to lack of Indian burnings Dense locations are less productive than managed and open areas Mosaic of vegetation patches created that limit fire spread Chaparral Interval: Low-Moderate Frequent burnings can lead to (invasive) grassland conversion (especially in SoCal) Many other \u0026ldquo;fire follower\u0026rdquo; species begin growing after fires too Severity: High Very volatile even in spring (non-dry conditions) Size: Moderate to high Stand replacing regime 30-75 yr. interval Crown fire adapted High intensity burns Climate driven Droughts Low fuel moistures Foehn winds \u0026ndash; Winds from east that are generally dry and warm Fire scars \u0026ndash; not common Knobcone Pine Severity: High - High severity required to activate seeds Interval: Moderate to long Size: Moderate to large Overstory tends to burn completely Douglas-fir in North Coast Severity: Moderate Not adapted for fire (have thin bark) Interval: Low to moderate Size: Moderate Changed from fire exclusion, harvesting, and fire suppression Native Californians # Long-History of Human Occupation in CA Archaeological Evidence: 13,000 years or more Evidence for multiple immigrations from both sea and land to California Diverse composition of people Native communities are still in California 110+ recognized tribes today in CA We can learn from them now about how they treated fire over history 80-100 languages spoken between all tribes Evidence for multiple immigration waves The concentration of native communities is most dense North of Mexico Packed Landscapes: Many Tribes (Tribelets) or Small Nations 100-1000 people make up polities Mostly small Tribal territories Crowded Landscapes Complex Societies Village Communities have Elaborate Ritual and Political Organizations Different people would specialize in different areas Food Storage (Granaries) Sophisticated Material Culture: Baskets, Shell Beads, etc. Non-Agrarian People No formal agriculture practices outside SE CA Sustainer primarily by hunting/gathering (use of wild plants and gatherers) Adjacent Areas \u0026ndash; neighboring people would grow corn, beans, squash but Indians chose not to practice agriculture Perception about Non-Agrarian people Changed over time (Falsely) Seen initially as passive foragers that minimal impact to environment Indigenous Stewards of Land and Sea # Better way of describing CA Indians (compared to hunter gatherers) Indians worked/work as Active Agents to Augment Environmental Productivity and Diversity Seascape Stewardship: Various ways Native people enhanced the productivity and sustainability of shellfish populations and fisheries Landscape Stewardship: Anthropological Rethinking back to 1940s, picks up steam in 1970s, 1980s that culminates with Anderson 2005 publication Various Methods Employed in Landscape Management Practices: Transplanting Water Diversion Pruning/Coppicing Weeding/Tillage Sowing/Broadcasting Seeds All for the purpose of enhancing productivity of natural plants/animals Most Important: Anthropogenic or Cultural Burning was the key method of stewardship Long History in California (Channel Islands)? Mediterranean Climate is Fire Enabler Wet cool winters lead to high plant production Dry and drought-ful summers provide a dry, extensive fuel base Native Californians realized that fire was a natural occurrence and learned to live with fire Reasoning for Cultural Burnings (Landscape scale) Fires Control Insects/Pests Remove Detritus, clean-up landscape Allows light through which leads to healthy growth Open Pathways Use Fire to Hunt Game (driving animals into traps/valleys) and Insects Produce Straight Stems for cordage, baskets Augment Growth/Diversity of Plants and Animals in Territory Grasslands and other plants may have deeper roots which make them more difficult to kill Increases productivity of nutrient rich plants that animals eat Deer heard sizes are correlated with burnings Stimulate Growth of broad spectrum of economic resources Through burning in Patchy Mosaics How Areas Were Burned Instigate fire regimes with frequent, small, low-intensity surface burns Seasonality of burning very important to minimize risk of catastrophic fires Additionally, risk reduced by reduce fuel loads + creating fuel breaks Burn to increase productivity and stimulate growth of broad spectrum of economic resources Notably shrubs with berries, oak woodlands, coniferous Intentionally create Patchy Mosaics Increase quantity, diversity and sustainability of key plants and animals Different environments benefit from different style burnings resulting in checkerboard-esque patterns Used for foods, medicines, and raw materials Minimize risk of catastrophic fires due to reduced fuel loads and fire breaks Burn areas contained by natural rivers/hills/ridges/basalt flows Implications of Cultural Burning Not Pristine Wilderness, but Managed Anthropogenic Landscape \u0026ndash; you have to take into account Indians when looking at CA\u0026rsquo;s landscape You can\u0026rsquo;t do restoration without bringing in people Now, because of a lack of recent cultural burnings, some habitats are struggling Controversy regarding cultural burnings # Some argue that cultural fires were small in size, near villages, and had little impact on the larger ecosystem Rather, natural fires best explain these fires Evidence Types tend to be soft; Tribal Oral Traditions have a Short Temporal Depth for cultural burnings Observations limited primarily to last 250 years Limitations arise when primarily referring to Ethnohistoric Sources Ethnohistoric Studies are from (typically Spaniard around 1600-1700) explorers and not trained as anthropologists Accounts tend to be spotty, geographically biased, and not very detailed Sources don\u0026rsquo;t include key fire regime aspects (freq, seasonality, severity, area, synergy) Susceptible to biases, uncertainty, and anecdotes Ethnographic Studies Information is word of mouth history from within the tribe that\u0026rsquo;s passed from one generation to another Recorded by anthropologists Information is very brief/general and lacking in our definition of fire regime now Old archeologists may have viewed Indians as hunter/gatherers (which is wrong!) Colonizers prevented cultural fires (fire exclusion) Fire exclusion is when fire is indirectly removed from the environment E.x. adding livestock removes fuels, reducing/removing fire E.x. Colonizers removing Natives (for reasons other than their cultural burnings) removed fires, changing fire regime Whereas fire suppression is mindful + target specifically at stopping fires E.x. Using firetrucks, airplanes, etc. to stop a fire from spreading E.x laws preventing you from creating fires during the dry season Thus, when we started Ethnographic studies in 1901(ish), we didn\u0026rsquo;t see the history before because current tribes weren\u0026rsquo;t allowed to perform cultural burnings Instead, critics would like to see hard ecological data (fire scars, pollen analysis, charcoal accumulation, phytoliths) Two main reasons to address these criticisms Differential impacts due to colonialism in different spaces and at different times Some areas colonized much earlier than others in the state Central and Souther coast colonized 2.5 centuries ago by Spaniards Others only were colonized during the gold rush) Some tribes subjected to Fire Exclusion/Suppression policies Lacking specific information about when these policies were enacted Tribes colonized during gold rush tend to have more information than those colonized earlier in time Consequently, some tribes have not been able to practice Cultural burning for generations Political Implications Some scholars argue that there is no real evidence that Native people were good stewards of the land Point to times when animals/plants went extinct Consequently, they should not play a special role in decision making Ecological restoration projects today Nor play much of a role in the management of our public Lands today Eco-archaeological Research # - **Eco-archaeological Research:** When we bridge ecological studies with anthropological / archeological studies and native Oral traditions - Tries to tackle Major Challenge of Eco-Archaeological Research: Differentiating Natural Fire Regimes from Anthropogenic Fire Regimes - Compare Expected Fire Regime from Lightning Strikes with Observed Fire Regime Based on multiple lines of evidence ![Lightening Strikes](/docs/anthro-c12ac/imgs/lightening.png) Long-Term Diachronic Approach that Employ Multiple Lines of Evidence: Native Oral Histories/Traditions Ethnohistorical Accounts Ethnographic Studies Ecological Studies of Fire Archaeological Research Other methods Involves Researching with Tribes Two Case Studies # 1. Sierra Nevada Mountains # Difficult to carry out research because of high ignition rate due to lightening being common Hard to differentiate between natural and anthropogenic fires Research done by Linn Gassaway Specifically looks at Yosemite Valley which Home of Southern Sierra Miwok people Utilized Ethnohistory, Ethnography, Archaeology, Dendroecology (Fires Scars) Lightning Fires less Frequent in Valley Floor, more common on mountain peaks Natural Fire Regime in the valley has a Long Interval Between Lightning Ignited Fires Three Basic Findings By Gassaway: Fires more Frequent for prehistoric, protohistoric historic times than expected for Natural Fires Alone Evidence for potential Cultural Burning Still evidence of fire activity in 1800s (When Native peoples were removed) Miwok people still maintaining traditional fire practices? 1890s: Fire frequency reduced when Military takes over administration of Yosemite Valley \u0026ndash; Evidence for Fire Suppression 2. Eco-Archaeological Study of Central Coast of CA # Research done by John Keeley Central Coast great place to do study of Cultural Burning Hypothesis Presented for Strong Likelihood of Cultural Burning Here Low Frequency of Lightning on Coast Natural Fire Return Interval around 50 to 100 Years Greater Bay Area: About 2-5 lightning ignitions per hundred kilometers squared per century Conditions of high frequency (around 5 years) fire interval (cultural burnings) Forests dominated by Douglas fir would be suppressed Redwood (fire adapted) forests would remain dominant, but have a more open understory with less fuel Shrublands would be suppressed and costal parries would take over Conditions of low frequency fire interval (natural) Shrublands and forests would be common Central California Coast Project Amah Mutsun Tribal Band Issues of Food Security and Food Sovereignty Limited Access to Native Foods Do not own much property Tribe has Commitment to Ecological Restoration Want to return indigenous plants and animals to the land Established the Amah Mutsun Land Trust (AMLT) Purpose is to restore natural resources Purpose it to steward lands and waters Return to path of traditional ecological knowledge AMLT working with resource agencies who own much of the land (CA State Parks, BLM, etc.) AMLT also working to purchase land for the tribe Established Native Stewardship Corps Boots on the ground for ecological restoration Amah Mutsun Tribe interested in Collaborative Work Legacy of Colonialism Tribe working with collaborative team to bring Knowledge of indigenous stewardship practices out of dormancy Opportunity to integrate Indigenous Science With Western Science Amah Mutsun work with Team of Scholars from UCB, UCSC, and California State Parks Three components of project Synthesize Previous Work: Ethnohistory, Ethnographic Observations, Tribal Oral, Traditions, Historical Fire Ecology Cuthrell: Early Spanish explorers demonstrate extensive grasslands that must have been maintained through prescribed cultural burnings, as well as established Indigenous burning systems Undertake Field/Lab work—Fire Ecology Studies: Take samples of Fire Scars (Redwoods), Pollen/Charcoal, Phytoliths, Lake Cores Cuthrell: Phytolith Data from soil cores in Quiroste Valley indicate a long term history of grassland vegetation over the last ~1500 years Archaeology Archaeology provides understanding of past cultural practices (e.g., tools, settlements) Emphasis on recovering floral and faunal remains; evidence of kinds of resources harvested; Intersection of Archaeology with Fire Ecology; When we see changes in fire regimes, vegetation \u0026ndash; Do we see changes in kinds of resources harvested As outcome of landscape stewardship? Study number of sites: Middle Holocene (6500-3000 BP) Late Holocene (3000-500 BP) Historical (after 500 BP) Collaborative Field Schools Involves UCB students, faculty State Park Archaeologists, ecologists Amah Mutsun Tribal Band, AMLT Native Stewardship Corps Employ Low Impact Methodology Geophysical survey work (ground penetrating radar) Examples of Sites CA-SCR-7 (6500-4000 BP) CA-SCR-10 (1300-1200 BP) Bolcoff Adobe (1830s-1840s) Recovery of Plant and Animal Remains Excavate Soil Flotation of Soil to Recover Remains Laboratory Analysis Cuthrell: Food remains indicate costal prairie seed foods (which came from prairies) were prominent parts of people\u0026rsquo;s diets during the last 1000+ years. Charcoal from hearth fires indicates fire-compatible trees such as redwood were the primary fuel sources, while fire-vulnerable trees like Douglas firs were not as common Our Findings: Observed fire frequency greater than Expected from Lightning Ignitions Alone Strong evidence of Cultural Burning Extensive Cultural Burning: Begins about 1769-1770 CE Pattern of frequent, low intensity burns for the past 9-10 Centuries; up to Portola Expedition Create Coastal Prairie Environments, Evidence of grasses, clovers, tarweeds, hazelnuts, etc. Also evidence of plant foods being harvested that required frequent fires to maintain Patchwork of fires—burning areas every 1 to 5 years or so \u0026ndash; maintain coastal grassland Work in other areas corroborating our Findings Other Study Areas Coastal Prairies \u0026ndash; extend from California to British Columbia Conclusion Key Point for Rest of Class: How can these Lessons from the Past derived from studies Indigenous Landscape Stewardship Practices be employed today? Colonization of California # Introduction # Maritime Exploration The first real instance of Colonization Happened from 1542-1603 then a long break Spanish Missions, Presidios (forts), Pueblos (civilian settlements) Happened from 1769-1823 Primary goal was to Christianize and Civilize Created large farm areas Recruited thousands of Natives as labourers Select locations where existing towns had reduction policies Reduction policies moved natives into a single village after their land was taken Mexican Missions, Ranchos When Mexico took over CA Happened from 1822-1846 Established huge, private ranches (Ranchos) Ran by natives Generated lots of money Colony Ross Russian Colonization from 1812-1841 Carried out by Russian American Company Hunted sea otters Sold pelts to China Recruit Native Alaskans who served as primary hunters Impact # Native population declines Many deaths due to diseases (some of which hit instantly, some which took time) Violence and warfare between natives and soldiers (Sexual) Abuse of young women Unleashing of Foreign Weeds, Pests (Crosby 2004) Raised range of new foods on large ranches Thousands of cattle changed landscape too by overgrazing Weeds spread aggressively at expense of indigenous plants Land remains changed even today (90% of biomass in grasslands today isn\u0026rsquo;t native) Archaeological Evidence of Spread of Weeds Mission excavations and adobe (mud) bricks Grazing Economy (Dart-Newton, Erlandson 2006) Free-Range Grazing (no fences) In addition to cattle, brought Sheep, Goats, Horses, and Pigs Wild pigs are still an issue today Major impacts to local environments and Native Foods Overgrazing trample indigenous Ecological habitats Help spread weeds Commercial Hunting of Mammals Terrestrial Fur Trade Primarily hunted beaver Pelt used to make hats in Europe Exterminate beavers from Western North America, Northern California Major Impacts for wetland habitats Maritime Fur Trade (Colony Ross) Use Native Alaskan Hunters Very Efficient Harvest primarily Sea Otters Nearly eliminated, otter population still low population today Major Changes to Kelp Forests which impacted Fisheries of California Fire Exclusion (Timbrook) Began in 1793 when the Governor prohibited burning from Natives Explicit Policies Enacted to Stop Native Peoples from Cultural Burning Affected both Native Neophytes and so Called Gentile Indians (not part of missions) Implications # Loss of Traditional Ecological Knowledge (TEK) Amah Mutsun Tribal Band (Lopez 2013) Could not conduct ceremonies, prayer songs Could not Steward the land Unable to pass information to next generation (loss of TEK) Willing to work with archaeologists, fire ecologists \u0026ndash; bring knowledge out of dormancy Working to Restore Landscape Today Chumash People (Timbrook et al 1993) Located around Santa Barbara Ethnohistoric accounts of Native Burning, but largely faded from tribal memory when ethnographic research conducted in 1920-1930s Significant Impact to Local Coastal Environments Increase of Foreign Plants and Animals Decline in Diversity and Quantity of Indigenous Flora and Fauna Decreases Loss of Food Security, Food Sovereignty, Native Medicine, Raw Material, etc. for Natives Many Coastal Tribes Displaced Colonial Invaders take away Native land Especially costal land Major Transformation in California Fire Regimes Cultural Burning on Coast Stopped Coastal Prairies get overrun by woody vegetation quickly Even if grazing kept off shrubs, new grasses would begin growing Some Disturbance keep areas open: Grazing, Colonial Burning? Altered Fire Regimes due to new plant types Timber Owners and Early Use of Fire (10/4) # 1880: Advocates for ‘light burning\u0026rsquo; in California appear \u0026ndash; some thought fire was needed to manage forests Whereas cultural burnings are done for specific intentional reasons, light burning is done for other reasons such as reducing fuel, increasing food for livestock, and other economic reasons That is, cultural burning is a form of light burning 1900: Debate start regarding fire management near Lake Almanor in CA Private forest land owners practiced ‘light burning\u0026rsquo; following early Indian and sheep herder traditions Most foresters dismissed this proposal as mere ‘Paiute Forestry\u0026rsquo; (derogatory term based on an Indian tribe) 1902: H.J. Ostrander attacked ‘protectionist\u0026rsquo; policy of fire control as worse than effective because it allowed fuel to accumulate US National Academy of Science committee on forest reserves urged fire control policy 1908: Gene Tolly: Sierra National Forest Ranger from 1905-1912 and cowboy assigned to range management for USFS Gifford Pinchot: 1st Chief of the USFS Tolly took Gifford on a back country trip through the Sierra National Forest to try and convince him to allow Indian Burning to keep meadows and forests from getting overgrown but Gifford didn\u0026rsquo;t buy it 1910: Sunset magazine was an outlet used for forestry discussion at the time G.L. Hoxie wrote in the magazine to advocated light burning claimed it should not be merely acceptable but made mandatory Made economic, not ecological argument Unfortunately at same time, Great Idaho Fire occurred Burned 3 million acres and killed 85 people. Happened due to drought period with ignitions from lightning, locomotives, and logging Resulted in national debate: Senator Weldon Heyburn (R-Idaho) led effort to disband the USFS so that private land owners could manage their own land Others argued that the newly found US Forest Service (1905) should be expanded so that it could prevent future fires (happened, turns out govt tends to only grow bigger) 1930s: Two experiments were occurring in northeast CA around this time Full Control McCloud River Lumber Company Use trains, hand crews, etc Light Burning Thomas Barlow (T.B.) Walker was raised from Minnesota and ran the Red River Lumber Co. near Lake Almanor Clinton Walker (T.B\u0026rsquo;s son) wrote a letter to the Red River Lumber Company in 1938 (years after he had left the Company) saying: The general condition of the forests when the white man first came into CA was very excellent Then came the foresters from Yale University and put the tourniquet on the forests Would prefer to remove the tourniquet in our timber matters [which] is the lack of fire I requested permission [to burn] from the State Forester and the USFS DuBois. Both refused We proceeded to burn anyway, and Chief Forester Graves came out from Washington and DuBois and many others with cameras and notebooks to get damaging evidence They stayed several days and followed the burning, with comment by Graves that the work was excellent DuBois apologized to me for panning me in the newspapers previously Graves suggested that T.B underwrite a chair of fire protection at Yale University Walker agreed, contributing $100,000 (a huge amount of funding 1900\u0026rsquo;s). Harvey Chapman hired who was huge force in longleaf pine is southeast US Over the next decade trials done across the US, especially in pine belts of the West and South Stuart Show (from Stanford btw) looked for light burning area around Mt. Hough, Claremont, Meadow Valley Country Found a suitable area near Snake Lake Commit data/scientific fraud by adding more fuel: \u0026ldquo;Ed and I did 250 acres alone and, except for the long hitch of work, didn\u0026rsquo;t have any trouble. The only dishonest thing we did was to pile some pine limbwood in big fire scars of a few large pines, with the gratifying result that they burned down and became damage statistics\u0026rdquo;\nDave Rogers already had made up his mind regarding light burnings \u0026ldquo;Went over nonchalantly to reburn Snake Lake (in 1920). It would have been O.K. except that Plumas Supervisor Dave Rogers came out the night of the burn, grabbed a brush burning torch and ended up stringing fire outside the line on two opposite ends. Then he left.\u0026rdquo; \u0026ldquo;You can understand our deep affection for Dave and the Plumas\u0026rdquo;\nThe use of fire in forest management was not given an objective evaluation anywhere in the Western US including Indigenous burning 1940s: Harold Biswell was a professor in the Berkeley Forestry Department from 1947 - 1972 Biswell conducted prescribed fire research in the forests of Georgia from 1942 to 1947 when he was a researcher for the US Forest Service Southern Research Station Began prescribed fire work in Ponderosa pine forests in 1951 (Boggs Mountain near Middletown as well as Teaford Ranch in the Southern Sierra near Bass Lake) Both of these locations were private land because no government agency would let him burn in public land Said in his 1958 paper: \u0026ldquo;At the time the idea of burning was fairly new to me and I looked upon fire as the arch enemy of forests and forestry\u0026rdquo;\nHis 1958 paper showed it was possible to use fire in CA forest management and warned about future problems if fuels were not reduced His conclusions were very controversial at the time His PhD students recall \u0026ldquo;There was little opposition to him burning in grasslands and shrublands, but when he began burning experiments in ponderosa pine forests, active and open criticism of him and his work exploded. He was referred to as \u0026ldquo;Harry the Torch,\u0026rdquo; \u0026ldquo;Burn-Em-Up Biswell,\u0026rdquo; and other derisive names, and not always behind his back\u0026rdquo;\nNo forestry faculty would work with Biswell. UCB Forestry faculty voted to forbid him or his graduate students to work at Blodgett Forest (Scott\u0026rsquo;s Opinion:) At the very least, some UC Berkeley forestry faculty should have worked cooperatively with Biswell to further explore this topic In 1973, he was given the Berkeley Citation, awarded for his contribution to the University of California that \u0026ldquo;go beyond the call of duty and whose achievements exceed the standards of excellence in their fields.\u0026rdquo; He was the first UCB forestry professor to get this award Early Foresters and Fire (10/6) # Some debate, but suppression wins in 1910s However, one exception: Southern US continues to use fire Pre WWII: 1933: Civilian Conservation Corps labor (CCC) used to fight fires Hired many people due to great depression 1935: 10 AM (National) Policy: All fires should be out by 10AM the day after they\u0026rsquo;re detected before conditions that would make fire more severe arise During WWII Firefighting resources (people, machines) tied up with the war Consensus objectors put into fire fighting crews Many were ridiculed but they fought the fire with little technology and overhead Japanese sub fires shell near Santa Barbara Fear of Los Padres NF and others being burned Japanese also launch fire balloons Hundreds hit the US, but they\u0026rsquo;re kept hidden from public Public urged to be careful and fire is connected to the war USFS organizes Cooperative Forest Fire Protection Campaign Fire protection was framed as National Security through public campaigns Huge push to save resource during the war \u0026ldquo;Careless matches aid the Axis\u0026rdquo; \u0026ldquo;Our carelessness, their secret weapon\u0026rdquo; Bambi brought (in 1944) Movie showed terrible fires started by hunters Only on loan from Disney for 1 year Smokey Bear named in 1945 Named after asst. Chief of NYC Fire Dept. 1919-1930 \u0026ndash; \u0026ldquo;Smokey\u0026rdquo; Joe Martin Post WWII Smokey Bear (cont.) \u0026ldquo;Only YOU can prevent forest fires!\u0026rdquo; created in 1947 Canada steals him in 1956. Focus broadened to appeal to children 1950: The \u0026ldquo;Real\u0026rdquo; Deal Las Tablas fire breaks out and a bear cub found almost dead Cub is treated and heals, eventually ends up in D.C. Zoo Still endearing One of most recognized figures in U.S. behind Santa and Mickey Mouse Stamps made (1984) Own zip code (20252) \u0026ndash; you can write him a letter and get a reply Office, Web page, Twitter, Facebook, Instagram, YouTube, etc. Has Smokey\u0026rsquo;s message been TOO successful? Original message was very black and white Colonialism (10/8) # Settler Colonialism In The American # Earlier Colonial Enterprises (1769-1846) # Missionary Colonies: Franciscan Missions \u0026ndash; interested in converting Mercantile Colony: Colony Ross (Fort Ross) \u0026ndash; interested in pelts and profit Common Features to both: Predate Settler Colonialism Involved Few Euro-Americans \u0026ndash; workforce was almost all Native people Self-Contained Agrarian Systems Native people integral to their success Major Outcomes ( 9/27/21 Lecture) Loss of Traditional Ecological Knowledge Significant Environmental Impacts to Coastal CA Many Coastal Tribes Displaced Transformations in Fire Regimes Settler Colonies # Immigration of European/foreign settlers British employed Settler Colonialism in Eastern USA Establish Permanent Residences Predicated on Removal of Indigenous People Employed \u0026ldquo;Logic of Elimination\u0026rdquo; \u0026ndash; Moral Ground for Taking Land Away After American Revolution \u0026ndash; USA Adopts Settler Colony Practices; Manifest Destiny; Millions of people moved westward Key Dates for California: 1840s: Movement of settlers along California, Oregon, Mormon Trails 1846: Mexican-American War, Annexation of CA 1848: Treaty of Guadalupe Hidalgo Gold Rush 1850: California became the 31st State 1869: Transcontinental Railroad Completed 1850s-1870s:Settler Colonialism really takes off Implications Of Settler Colonialism # 1. Genocide (Madley 2016 Reading) # 1846-1870s \u0026ndash; Dark Ages for Native People Extermination of Indians supported by Governors and other Politicians: First Governor Peter Burnett proclaimed \u0026ldquo;War of Extermination\u0026rdquo; Senator John Weller (Governor in 1858) \u0026ndash; \u0026ldquo;White Man Demands Extinction\u0026rdquo; California Legislature passed anti-Indian laws: Legal slavery of Indian Children Bounty Hunters paid by the scalp No rights in Court (couldn\u0026rsquo;t testify against a white person) Vagrancy Laws, etc. California and Federal Government Supported militias \u0026ndash; volunteer companies (Essentially Death Squads) that removed Indians from their lands California and Federal Governments \u0026ndash; allocated over $2 million dollars for this Also diseases, starvation, etc. took a terrible toll on Indians Outcome of Extermination Policies: Native people Decimated, while Colonists Explode in Numbers: - Indian Population: - 1769 = 310,000 - 1846 = 150,000 - 1900 = 15,000 - Settler Colonist Population: - 1850 = 92,597 - 1900 = 1,485,053 2. Reservations # Unlike other Western States, most California Tribes did not have treaties with the Federal Government (as such, tribes cannot practice cultural burnings!) Abysmal Treaty Record in California 1851-1852: 18 Treaties Negotiated with Tribes of California; Proposed Reservation Land of 11,700 sq miles (Anderson 2005 Reading) None of the 18 Treaties Ratified by US Senate even though some Natives already moved Politicians didn\u0026rsquo;t want to give up good agricultural land Subsequent attempts to create Reservation Land \u0026ndash; Not very Successful; 1850s-1870s: Military Reservations 1870s-1900: Federal Funding for Small Land Grants Influence of Helen Hunt Jackson, Her Book, Ramona, very important in Humanitarian movement Fictional book told a love story of an Indian chief which became a best seller and brought attention to the situation 1906-1930: Another period of federal funding for small Land Grants for California Indians but it was all tiny sections of land (called Rancheria lands) 3. Federal Recognition # Discuss Importance of Federal Recognition: Housing, legal assistance, Indian Health, food distribution, child welfare, Indian arts and culture development, fund tribal cultural heritage programs, tribal historic preservation officers, NAGPRA, Indian Gaming Three-Tiered System in California: Gaming Tribes (Fed Recognized) Non-Gaming Tribes (Fed Recognized) Unacknowledged Tribes In California Many Tribes Not Federally Recognized (Unacknowledged Status with Federal Government \u0026ndash; no land or status with feds!) \u0026ndash; Why is this the case? 1851-52: treaties not ratified 1870s-1900s: Award Federal Recognition to tribes with strong continuities with Past; Those that maintained Indian cultural practices over time This was influenced by early anthropologists (i.e. UC Berkeley) Program of \u0026ldquo;Ethnographic Salvage\u0026rdquo; Tended not to work with Tribes who had undergone major transformations, acculturation Discuss Spatial Distribution of Fed Recognized Tribes; Many Unacknowledged Tribes in Former Mission Lands E.x. Ohlone Indians in post-mission times did not disappear 1840s: In East Bay 1860s: Lived at Alisal Rancheria well into 1900s Active Indian community \u0026ndash; inter-marry with other tribes, Hispanics Some Anthropologists claim they were \u0026ldquo;culturally extinct\u0026rdquo; role that early Anthropology Played in Tribes obtaining Federal Recognition, and those that did not (Lightfoot 2005 Reading) 4. Environmental Degradation (Anderson 2005 Reading) # Commodification of Environment Gold Mining, Hydraulic Mining Impacted rivers and lakes Commercial Agriculture and Ranching Drained wetlands Monocropping Commercial Hunting of Game, Birds, Fishing Massive Timber Harvests Clear cut total forests Exploitive \u0026ndash; not forestry Specifically Redwoods, Sierra Nevada Dam Rivers Unleash Plethora of Foreign Plants/Animals Four Outcomes Of Settler Colonialism On Indigenous Landscape Management Practices In California # 1. Fire Prohibition Policies # Initially Directed Against Native People; Racism \u0026ndash; Early Fire Bans Did Not Apply to All Settler Colonists Settlers, Ranchers, and timber companies still burned land Why Natives Signaled out for Ban? Fire Suppression - - Component of Settler Colonialism Strategy to Facilitate the Removal of Natives from their Lands? 2. Minimal Reservation Land Implications for Indigenous Stewardship Practices; # Fewer Restrictions on Indian Trust/Reservation Lands However, Lack of Tribal Lands in California Curtailed ability of tribes to Revitalize Landscape Practices, such as Cultural Burning Compare California with Trust Lands in American Southwest!! 3. Native People Lost Access To Resources From Their Tribal Lands # Major problem for tribes—they were not granted trust land (reservations) AND they had minimal access to resources on Public Lands (California State Parks, BLM, National Park Service, US Forest Service) Until Recently - Tribes not allowed to undertake Stewardship practices on Public Lands no cultural burning no harvesting of foods, medicines, raw materials 4. Conservation Practices: Exclusion Of Native People (Anderson 2005, Johnson 2014 Readings) # Influence of John Muir on Conservation Movement in USA in early 1900s Early debate about conservation practices involving light burning, indigenous stewardship Believed land was cathedral of nature and should be untouched (so no Indian burning!) John Muir: Argued for creations of pristine, natural preserves untouched by people Did not Advocate for Native Stewardship Practices, such as Cultural Burning Conservation Model - - Put Fence Around Property and keep people out Fire Suppression Policies of Settler colonialism One component of broader package of developments that have kept tribes from revitalizing cultural burning until recently Policies of extermination, genocide; poverty, diseases, food shortages; limited sized reservations; many California tribes unacknowledged; massive environmental destruction of tribal lands Upshot of Discussion, up until the 1960s-1970s, Native Californians had little or no land to call their own, minimal tribal land, little access to resources on Public Lands in California for harvesting foods, medicines, raw materials for baskets, etc. Greatly curtailed ability to undertake Indigenous Landscape Stewardship Practices, such as Cultural Burning Outline Fire Suppression Policies of US/CA Governments # Nathanial Kenny wrote an article on the US Fire Service Published in 1956 in National Geographic Argued that at the end of the day, science would be the most crucial role in controlling fires \u0026ldquo;I don\u0026rsquo;t believe that equipment and development alone will show us how to keep having the relatively few big fires… Researchers must let their imaginations soar for answers that today would seem fantastic\u0026rdquo;\nFire Suppression: Begins around 1905 Approximately 80,000 fires/year today 98-99% of all wildland fires out at less than 5 acres in size 95% of area burned today is from 1-2% of the fires that escape initial attack Often occurs in terrible conditions 4.5 million acres once burned in CA Over half Tribal burning \u0026ndash; 10-35% of this area burns today in most years but 2020 will burn this amount for 1st time (Stephens et al. 2007) Size is only one aspect \u0026ndash; what is the fire mortality? what is the distribution? etc. Not just area burned, burn patterns inside Historical data yields insight into controls on forest structure in pine-mixed conifer forests In 1911 photograph and datasets we can see much more sunny forests This is due to more frequent, natural/cultural burnings vs today\u0026rsquo;s fire suppression Kern National Forest Structure and Composition (Stephens et al. 2015) Southern California and Baja Forests (Stephens et al 2003) Drought from 1999-2002 in southern California and northwestern Mexico Only 5 inches of rain one year, driest on record in So Cal mountains another year Fire suppression and past forest harvesting have increased forest density in So Cal (Minnich et al 1995) Native bark beetle population increased because of weaker trees Sierra San Pedro Martir / Northern Baja California Mediterranean climate Annual precipitation averages 24 in Area has been grazed by livestock Similar to southern California and eastern Sierra Nevada Fire suppression begins in 1970, no harvesting SSPM Mission in 1794 severely impacted populations Within the California floristic province Forested area of around 40,000 acres Fire suppression and past forest harvesting have increased forest density (Minnich et al. 1995) Elevation upper plateau 8800 ft 3 large plateaus, Peninsular Mountains Jeffrey pine-mixed conifer forests Similar to souther CA and eastern Sierra Nevada Fire suppression begins in 1970s, no harvesting 3 indigenous cultures used portions of the SSPM outside the winter: Paipai Kiliwa, Nakipa SSPM Mission in 1794 severely impacted populations Mission lasted 8 years due to extreme climate SSPM wildfire July 4, 2003 Started in chaparral below forest Fire burned approximately 600 acres More shrubland than forest burned Largest fire in 20 years Occurred at end of sever drought, 1999-2002 Same drought as in SoCal SoCal drought killed millions of trees w/o fire Only 20% of trees killed Jeffrey pine more dominate after fire, trees and seedlings (less white fir, incense-cedar) Fire was very patchy Directly linked to heterogeneity of forest structure and fuels pre-fire Mortality very low even after 4 year drought and wildfire (Stephens et al. 2008) Incredible forest resilience!! Gives us hope in California To answer Nathanial Kenny \u0026ndash; Fire back, restoration thinning, and stewardship are also key Implications for Local Ecosystems # Changes to Grasslands Encroachment of woody species Pinyon pine-Juniper in Southwest Tallgrass prairie Mountain meadows Coastal Prairies Fire taken out of system Fire return intervals increased Whole ecosystems change Examples from Montana and Arizona Rim Wildfire Largest fire in Sierra Nevada Fifth largest fire in history of CA Ignited August 17, 2013 Total area burned: 270,000 acres (102,000 ha ) Fire effects Very large high severity patches Cost of suppression : $127.2 million Management Response Forest fuel reduction treatments implemented to reduce fire hazards and fire effects Reduction of surface and ladder fuels critical (Agee and Skinner 2005) Example of fuel reduction treatments Research has determined that treatments are effective in reducing potential fire behavior and effects (Fulé et al. 2012) Permanent Backlog: Sierra Nevada 2.9 million acres (60% of FS acreage) will always remain fuel loaded 2/3\u0026rsquo;s of this acreage is pine-dominated and mixed-conifer forest types This is a disaster! Only gets worse with climate change Summary Tree density increased 2-3 times in mixed conifer forests since 1911 Forest change has decreased resiliency Climate change will make this situation worse Need increased fuel reduction treatments and wildfire for resource benefit frequent fire forests - critical California legislation $200 Million/yr. through 2028 Fuel treatments on 1 million acres/yr. by 2025 US Forest Service management plans being revised Best chance in decades to change trajectory Next 1-2 decades absolutely critical Leave options available for future managers We are running out of time!! Leopold and Forest Restoration # Leopold et al. 1963 # Asked to carry out report by US govt Carried out in Yellowstone Took view of the whole ecosystem, not just a single issue Animal populations \u0026lsquo;protected\u0026rsquo; from hunting and habitats \u0026lsquo;protected\u0026rsquo; from wildfire Wolfs (predators) were hunted before so that elk could thrive Elk thrived too much; Elk became hunted because their population grew so high Habitat is not stable that can be set aside and preserved behind a fence Goal of Park Management in the United States Each park be maintained, or where necessary recreated, in the condition when first visited by the white man Wilderness isn\u0026rsquo;t devoid of people; need to consider native stewards A primitive America could be recreated, using skill, judgment, and ecologic sensitivity The forty-niners poured over the Sierra Nevada and found big trees in gigantic magnificence Ground was grass parkland, in springtime carpeted with wildflowers (No mention of indigenous management) Today dog-hair thicket of young trees and mature brush—a direct function of protection from natural fires Is it possible that the primitive open forest could be restored? And if so, how? (Big question even for today) Policies of Park Management Research, not intuition, should form the basis for all management Agency best to study park management is the National Park Service Management without knowledge would be a dangerous policy indeed Methods of Habitat Management Of the methods of manipulating vegetation, controlled use of fire is the most \u0026ldquo;natural\u0026rdquo; and the cheapest and easiest to apply (easy?? Maybe in the 1960\u0026rsquo;s) Forest and chaparral areas protected from fire may require careful advance treatment (Harold Biswell influence?) Trees and mature brush may have to be cut, piled, and burned before ground fire (Harold Biswell did this with his early burning) Once fuel is reduced, periodic burning can be conducted safely and at low expense (Biswell) Against wind and down hill results in slowest and least severe fire conditions \u0026ldquo;We are calling for a set of ecologic skills unknown in this country today\u0026rdquo; (Indigenous?) \u0026ldquo;It will not be done by passive protection alone\u0026rdquo; (Big statement at the time, Still important today) Very powerful ideas included, changes NPS course of action (no Indigenous people though) Sneeuwjagt et al. 2013 # Rick was the head of bushfire and prescribed fire in Western Australia which also has a Mediterranean climate Opportunities for improved fire use and management in California: lessons from Western Australia (WA) Treatment size - Prescribed burn units much larger than those implemented in the US - make ours bigger Burns averaging in excess of 5000 ac, with some as large as 25,000 acres in Western Australia Department of Environment and Conservation (DEC) fire managers take advantage of relatively few burn windows to burn large areas Managers use weekends and nights, if conditions are favorable Have multiple burn plans in place in each region in order react quickly to conditions DEC begins training new seasonal crews on prescribed fires in the spring burning season DEC has responsibility for fire management across all public lands in the state of Western Australia (integrated versus USA system) Impossible to combine the many county, state, and federal agencies of CA under one agency but we need to do better Similar to California, prescribed fire in Western Australia is a contentious issue, particularly some urban residents who not aware of benefits of prescribed fire Indigenous burning not integrated with DEC burning \u0026ndash; rare across Australia at least in 2013 DEC uses a focused outreach effort to the public and politicians \u0026ndash; otherwise, fire program could get cut Fire program severely tested from an escaped prescribed burn in November 2011 that destroyed 32 houses Part of Reason Rick retired The first instance of home loss from a DEC burn in 50 years More stringent risk management assessment of the program occurred Despite community anxiety, support for continuation of extensive prescribed burn program remains high (similar to Florida from home losses 5 years ago) These are mature programs, California is in the beginning and we will need patience and the support from the public and politicians We will have problems: Indigenous fire use could help us move forward Hopefully can learn from them and build a program MT2 Review # Construction of railroad occurred after statehood of CA Colonization from San Fran do San Diego was unique in that it was primarily to set up missions Paiute Forestry was an offensive term that was directed at light burning, calling it \u0026lsquo;primitive\u0026rsquo; because tribes practiced it Stuart Show manipulated data to make burnings look more dangerous Canopy fires Higher severity \u0026ndash; upper trees aren\u0026rsquo;t fire adapted like the base of trees Used to be rare pre-1800s, now more common due to build up of surface fuels Latter fuels allow fire to travel up fuel, up to canopies Clinton Walker was an advocate of light burning There is little short-term economic gain to do fuel treatment CA\u0026rsquo;s first governor (Peter Burnett) supported the Native American protection act and endorsed the war of extermination At least 4.5 million acres were burned annually pre-colonization (1800s) Ron Good claimed that cultural burning was primarily for cultural reasons + increase value of raw materials and increase visibility Harold Biswell was a UCB professor and was an advocate of prescribed burning when it was taboo Was ostracized at the time, but is now recognized Early EU explorer period was different from the Spanish missionary period in that the EUs didn\u0026rsquo;t settle down and instead explored/traded while the Spanish established settlements Gifford Pinchot was very against any kind of burnings 1910 fire occurred in Idaho and led to many advocating for fire suppression Population reversal of CA Indians occurred due to the finishing of the rail road (letting more people in to CA, i.e during the Gold Rush) Essay Question: Settler colonialism differed from earlier Missionary trips in that\u0026hellip; Settler missions went inwards + cared primarily about making money During Missionary trips, Natives were a large part of the workforce and the main purpose to convert them to Christianity Two sides of light burning controversy: Natives encouraged to burn so that there wasn\u0026rsquo;t fuel build up, etc. Foresters who opposed ranchers employing any form of burning, called it Paiute Forestry Settler colonialism impacts Intersection of many invasive plants/animals that radically altered ecosystem (e.x. cattle) Draining of lakes/dams to flood areas (altering ecosystem) and other forms of land modification for the purpose of agriculture Hydrolic mining leading to soil erosion Logging + clear cutting of forests Anderson 2005, settler period Forceful removal \u0026ndash; through raids, violence, giving false land titles, destroying food/water source Extermination (killing) \u0026ndash; Genocide (Benjamin Madley) Assimilation \u0026ndash; Native Children went to school to be whitewashed (re-educated) How to plan for prescribed burning, comparison with Florida # Prescribed fire definition: A wildland fire burning under pre-defined conditions that will accomplish certain planned objectives. Fire is ignited by people by drip torch or helicopter Whereas cultural burnings exist only for cultural reasons Prescribed burner must integrate: Weather (present day and forecast) Weather has strongest correlation with severity of the fire + it can change rapidly Topography Fuels (load, moisture content) Spotting (embers flying across lines) occurs when fuel is very dry Ignition patterns (how fair is put on the ground) Art side \u0026ndash; factor you can control E.x. head fires, backing fires, strip-head fires Crew size and experience, where to assign people Safety (highest priority of all fires) Risk (all fires have risk, goal is to minimize it and have a plan in place to execute if something goes wrong) Prescribed fire is both art and science You can use science, but it ultimately depends on land/weather Biswell did not take measurements His graduate student Jan van Wagtendonk developed prescriptions for his PhD at UCB Southeast USA # Forests, savannas, and grasslands of the southern US, well-established history of fire, whether from lightning, Indigenous ignitions, or Anglo-Europeans Florida, Georgia, Alabama, Carolinas, all have great prescribed burning programs Carried down from tradition Burning used to increase productivity of sap for turpentine, decrease hardwoods in timber lots, enhance grazing forage Became a family tradition Plant adaptations diverse: closed cones, large terminal buds, sprouting, bark thickness Longleaf pine Low intensity, frequent surface fire to reduce competition Thick, corky insulating bark Self-pruning at maturity Large terminal bud Chapman studied \u0026ndash; Yale USFS tried to eliminate but not successful Kobziar et al. (2015) conducted survey of eastern US burners from in 2011 - 2012 Most respondents (75%) were employed by State or Federal forest or wildlife agencies, with the remainder landowners or contractors Fuels reduction primary goal of prescribed burning overall Program continues to be successful Florida burned \u0026gt; 1.2 million acres of forest last year Longleaf pine in \u0026lt;5 year, low intensity, understory, summer, brown rot Big shrub (sand pine) 25-100 year, high intensity, crown, spring or summer, large areas Bald Cypress / tupelo swamp, \u0026gt; 200 years, small area, mixed severity, only during drought Georgia said it surpassed Florida in terms of acres this year Prescribed fire in California - Low - maybe 50,000 acres Brown Administration Bill passed to provide $200 million/yr. for fuels management projects - Apply for grants Continues under Newson Administration and funded through 2028 Goal to increase prescribed fire in CA to 1,000,000 acres/yr by 2025: 500k acres State and Private and 500k acres Federal What is our baseline? Cultural burning combined with Rx fire? Task forces created in State to increase pace and scale of restoration and prescribed fire Public lands managers - limited budget and staffing are impediments, also planning issues We don\u0026rsquo;t have the experience, crews, or political or institutional support in place today for a large program We need to be patient - will take time Managed Wildfire Effects on Water and Forest Health # Fire and Hydrology in Western US Watersheds - Project Starts 2002 Managed Lighting Fire, Increase Forest Resilience Illilouette Creek Basin, Yosemite National Park Fires in occur naturally through lightening here every 9 years 50 years of fire use, 40,000 ac watershed Reburn fires Interactions between adjacent fires Historically open, patchy stands with large trees not everywhere Evidence of small proportions of stand-replacing fire (5-15%) Show and Kotok (1924): \u0026ldquo;…no large fires occur without a certain amount of heat-killing\u0026rdquo; \u0026ldquo;This loss, it should be noted, represents the complete or nearly complete wiping out of small patches of the stand rather than a uniformly distributed loss over the entire area\u0026rdquo; Vegetation Change from Photos: Fires Reduced Forest Area by 22% Wet meadows increased by 200% Dry meadows increased by 200% Shrublands increased by 30% In Yosemite amount of stream water leaving watershed has increased or remained stable since 1974 - modeling study increased by 60 mm Three other control watersheds significantly decreased Flood risk unchanged Soil water increased Lower tree mortality in drought Since fire suppression ended… Runoff ratio increased or stable Duration of spring snowmelt longer Soil water storage increased, less mortality drought Stream discharge up 3-6%, deep storage up Use of lightening ignited wildfires in Yosemite has provided several benefits to forest and water Indigenous fire could complement lightning fire California is water scarce and is experiencing an increasing number of severe wildfires Despite warming climate, managed wildfires in Illilouette promote a healthy watershed Increased streamflow from wildfires will persist in a warming climate Water agencies supportive of bond funding to manage watersheds but not their base budgets - should change 2020 North Complex Fire burned the largest watershed that feeds the largest lake in the State Water Project (Oroville Lake) Next 1-2 decades absolutely critical in California frequent fire forests Optimistic but we must move decisively Case Studies of Cultural Burning # Background On Tribal Revitalization # Timeline 1960s - Watershed time in California 1963 - Leopold Report \u0026ldquo;Wildlife Management in National Parks\u0026rdquo; bring fire back to National Park Service Managed Lightning Fires Prescribed Burning 1960s - Also Time of Native Activism in CA Historical Perspective: By the 1960s tribes facing some real structural challenges: Recovering from Genocide Little land to call their own Consequence of 1851-52 treaties not being ratified Many California tribes not federally recognized Tribes denied access to federal/state lands to harvest plants and animals Fire Prohibition Policies Fire Exclusion - Spanish, Mexican and Russian Colonists Fire Suppression - American period 1890s - Sequoia and Yosemite 1900s - Elsewhere in California Upshot for Tribes: A. Not allowed to implement Indigenous landscape Stewardship practices B. Poor Health of CA Environments Fire Suppression Policies: Major Impacts to indigenous plants and animals fuel loads increase less ecological diversity loss of patchy mosaic Some Native species disappeared fire adverse species take over hydrology affected some ecosystems - become endangered (e.g., coastal prairies) Native Activism # 1960s - Native Activism, part of broader Civil Rights Movement in USA Protest series of issues: discrimination, poverty, unemployment, religious freedom, fair housing, broken treaties, lack of resources Natives not given right to vote until 1924 Snyder Act Some states did not allow Indians to vote until 1950s, 1960s 1968 - Civil Rights Act signed by President Johnson Guaranteed rights to not only African-American, but American Indians 1968 - when American Indian Movement Founded (AIM) Advocate for rights on Native people 1968-1971 - Occupation of Alcatraz Island by tribes Post-1968 - series of protests, demonstrations, marches for American Indian causes Tribal Revitalization In California # Last few decades - major renaissance with Tribes Keep in mind that Tribes still facing many issues Poverty Unemployment - not much of a land base, FAR from urban jobs Addiction issues - alcohol, drugs Health issues, such as diabetes, obesity Gang issues with younger tribal members Still explicit discrimination But despite these lingering problems from colonization Major transformations taking place in many tribal groups Restoration of local habitats \u0026ndash; Crucial part of this process But need to look as this within broader context Tribal revitalization - involves various facets of Native Life TODAY Native Languages Estimated that 80-100 languages spoken in California \u0026ndash; but many languages endangered Legacy of Colonialism Indian Boarding Schools (late 1800s-mid 1900s) Assimilation Policy of US Government Carlisle Boarding School, Pennsylvania Sherman Institute, Riverside, CA \u0026ldquo;Civilize\u0026rdquo; Indian Children away from negative influences of parents, tribes Children forcibly removed from home and sent to Boarding Schools Taught Western ways Speaking Native Languages Forbidden! By mid-1900s - Many Tribes Facing Crisis with Their Languages Only half of Native languages in CA still spoken Leanne Hinton - UC Berkeley 90% of Native Languages in CA may disappear Major Push Today: language training for California tribes The Advocates for Indigenous California Language Survival \u0026ldquo;Breath Of Life\u0026rdquo; workshop Program on Berkeley campus provides training to Indians studying/learning endangered languages historic linguistic tapes and information in Linguistics Dept, Bancroft Library, Hearst Museum of Anthropology Tribal scholars relearn how to speak dormant languages (Mutsun, Chochenyo Languages) Revitalization Of Native Ceremonies, Dances Many groups involved in reviving spiritual practices Healers, Indian doctors, spiritual specialists Create active dance groups, e.x. Su Su Shinal Kashia Pomo Close Relationship of California Indian religions with Environment Resurgence Of Native Craftspeople Resurgence of Native Crafts Ron Goode - soapstone artifacts woodcarving - Northwest Coast Acorn spoons, boxes, Basket Weaving Premier basket makers in world Baskets served many purposes in Indian households Challenges for Indian Basket Making by 1980s - only a few active weavers Led to Establishment of California Indian Basket Weaver Association host gatherings, workshops more than 650 weavers today! Major Advocate for Indigenous Landscape Stewardship Practices! Great Interest In Native Foodways Traditional menus, traditional foods acorn mush, salmon \u0026ndash; but also seaweed, tar weed, hazel nuts Pow Wows Tribal food security, food sovereignty Café Ohlone - Bancroft Way - bring to Cal campus All Of These Developments - tied into Native Landscapes and Environments Most tribes interested in ecological restoration of their lands Implementing some form of indigenous landscape management practices Bring Fire Back To Landscape \u0026ndash; Tending The Wild and gaining access to various resources on Public Lands Obtain indigenous foods, medicines, dance regalia, raw materials for crafts Ecological Revitalization # Five Case Studies Of Indigenous Stewardship Practices In California\n1. Fowler et al # Fowler, Catherine S., P. Esteves, G. Goad, B. Helmer and K. Watterson 2003 Caring for the Trees: Restoring Timbisha Shoshone Land Management Practices in Death Valley National Park. Ecological Restoration 21(4):302-306.\nFederally Recognized Tribe working with National Park Service Death Valley National Park Timbisha Shoshone tribe in Southern Deserts Granted federal recognition in 2000 Obtained Trust Lands \u0026ndash; Federal Recognition Right to enter traditional management agreements with Federal Agencies (NPS, BLM) Work out co-management agreement with NPS in Death Valley National Park Co-manage Two Key Resources Honey Mesquite, Single Leaf Pinyon Both used as food, raw materials, etc. Timbisha Shoshone Begin to tend the Mesquite and pine groves in Death Valley Had not been tended in years \u0026ndash; in terrible shape! How Undertake Ecological Revitalization While Tribe used Fire to Tend the Land in the Past Current work - using Fire Surrogate Methods \u0026ndash; hope to use fire in future Define Study Plots - Leave half of plot as control Other Half of Plot - Tended by Tribe Trim lower branches of trees Clear ground of underbrush Open trees to sunlight Challenges Insect infestations Changes in Hydrology 2. Codero-Lamb et al # Codero-Lamb, Julie, Jared Dahl Aldern and Teresa Romero 2018 Bring Back the Good Fires. News from Native California 31 (Spring):14-17.\nNon-Fed Recognized Tribe Work on private property Ecological restoration Southern California Chumash - Santa Barbara Area \u0026ndash; only one of tribes federally recognized Santa Ynez Band of Chumash Mission Indians article about non-federally recognized CHUMASH Aftermath of Thomas Fire in Dec 2017 Strong Commitment To Bring Back Indigenous Landscape Practices Bring back good fires recognize issues of working in Chapparal Environments Paper outline difficulties of doing this when not federally recognized, no tribal land No current agreements with government agencies to burn instead - burn on small patches of private land tiny patches tended by Chumash Burn Protocols based on elders, songs, and Scientific Studies Discuss Frequency Or Timing Of Burns Springs - Annually grasses and shrubs for baskets - every 3 years 10-15 years in chaparral Recognize that they must adjust seasonal timing of burns with CLIMATE CHANGE Strong Advocates for Cultural Burning Important Points: For federal and state to restore environment after years of Fire Suppression Need to incorporate local communities (Tribes) Get Tribes Involved In All Aspects of Projects Must Recognize Tek is Valid Strategic Placement of Tended Lands \u0026ndash; can serve as fuel breaks 3. Karuk and Yurok tribes of Northwest California # Lake, Frank K., and Amy C. Christianson 2019 Indigenous Fire Stewardship. In Encyclopedia of Wildfires and Wildland-Urban Interface (WUI) Fires, edited by Samuel L. Manzello. Springer, Cham. https://doi.org/10.1007/978-3-319-51727-8_225-1. Lake, Frank K., Vita Wright, Penelope Morgan, Mary McFadzen, Dave McWethy and Camille Stevens-Rumann 2017 Returning Fire to the Land: Celebrating Traditional Knowledge and Fire. Journal of Forestry 115(5):343-353. Terence, Malcolm 2016 Unleashing the TREX: Why Officials Think Controlled Burns Can Save California from Wildfire. North Coast Journal ( http://www.northcoastjournal.com/humboldt/unleashing-the-trex/content?oid=4132514.\nFederally Recognized Tribe \u0026ndash; work with Federal Agency (USFS) Frank Lake \u0026ndash; key player in bringing Cultural Burning to California Karuk tribal member and works for USFS well positioned for making a difference publishing widely on cultural burning strong proponent for government agencies, conservation groups to develop collaborative partnerships with Tribes Makes this point in Lake and Christianson 2019 Reading How cultural burning can reduce or mediate impacts of wildfires Important information about burning and stewardship passed down through generations Significance of Traditional Ecological Knowledge (TEK) TEK looks at what works, what doesn\u0026rsquo;t, and how things change over time Important for us to use/employ today in how we can learn to live with fire in California Frank helping to bring cultural burning back to Northwest California burns taking place on\u0026hellip;. Private land (fewer restrictions) Tribal lands \u0026ndash; Yurok have some land USFS lands \u0026ndash; control most of traditional tribal lands in the area Five Points to emphasize in burning in Yurok and Karuk lands # Karuk and Yurok Tribes Different process of colonization than Central/Southern California Later in time - post Gold Rush (1848) which is unique Compared to SoCal, where practices were banned early on, Karuk and Yurok have more recent information E.x. Bill Crook learned from his grandma who practiced burns pre-gold rush Considerable Indigenous Knowledge about Cultural Longer continuation of burning USFS Until fairly recently, have not been receptive to Cultural Burning Until fairly recently Now have Native Californian employees high up in management Can\u0026rsquo;t be about certain people, should be about policy Otherwise, if these key people retire then we\u0026rsquo;re screwed! Signed agreements \u0026ndash; MOUs (Memorandum of Understanding) \u0026ndash; between USFS and Karuk Tribe Government To Government Relations Frank Lake et al. 2017 Reading Importance of developing person-to-person relationships and trust workshops, meetings, importance of communication with tribal leaders Integration of TEK and WS (Western Science) Two Different Ways of Knowing WS: Prescribed Burning More utilitarian approach \u0026ndash; can be tailored to smaller area to achieve specific outcome Emphasize Fuel Reduction Residential Areas (W/U Interface) TEK: Cultural Burning requires a more nuanced, patch-like approach Need to consider specific resources in a generally large area E.x. burn early for short basket shoots and later for longer shoots Frank Lake argues that \u0026hellip; Advocate for integrating TEK with scientific disciplines Use multiple lines of evidence to understand past fire regimes and cultural burning Federal Agencies - need to respect TEK Work collaboratively with tribes \u0026ndash; all phases of projects Need to Provide Sufficient Funding! To maintain partnerships, Cultural Burning Programs Need to follow through and show commitment to tribes 4. North Fork Mono Tribe # Ortiz, Beverly R. 2018 Ron Goode: A Life Lived in Service to Community and Environment. News from Native California 31(3 (Spring):18-26. Goode, Ron W. 2015 Tribal-Traditional Ecological Knowledge. News from Native California Spring 2015:23-28. Long, Jonathan W., Frank K. Lake, Ron W. Goode, and Benrita Mae Burnette 2020 How Traditional Tribal Perspectives Influence Ecosystem Restoration. Ecopsychology 12(2):71-82\nCase Study: Non-federally recognized tribe work on private lands + also develop agreement with USFS North Fork Mono: Major advocates of Cultural Burning Ron\u0026rsquo;s knowledge about Cultural Burning comes from his (grand)parents who continued cultural burnings during fire-suppression years Also works with scientists to teach/learn from them Involves other tribes with work to get range of perspectives Cultural Burning \u0026ndash; tied To Spiritual Practices Tribe\u0026rsquo;s Spiritual Philosophy involves prayers and songs Mother Earth And Creator Began burning on private property his family owns 2003 - began working with USFS in partnership Meadow restoration project in tribal territory Restore meadow and spring Enhance deer grass (for baskets) Long et al 2017 Reading discusses\u0026hellip;. Importance of cultural resources (i.e. plants which can be used as medicine) Archaeology Culturally important plants, etc. Differing opinions with USFS E.x. USFS wants to remove all invasive plants whereas Ron argued to leave a few that the tribe would look over 2017-2021 Has been practicing Cultural Burning on private ranch Near Mariposa (Yosemite National Park) Location is associated with major archeological sites Burn for targeted results, as listed below Specific Reasons for Burning Burn for positive result to affect outcomes of targeted cultural resources More than just fuel reduction (which is a trait of prescribed burning) Ron views Prescribed Burning as Industrial Scale burning Cultural Burning: more NUANCED kind of burning \u0026ndash; burn treatment depends on cultural resources being enhanced Sourberry \u0026ndash; important plant for food and basketry material Pretreatment before burns Prune vegetation Create burn piles Burn small plots Post-Burn \u0026ndash; mix burned soils with water to create a nutritious soil bed Summary thus far\u0026hellip; # Tribes \u0026ndash; need to be treated respectfully Need to establish partnerships in CA Resource agencies, tribes, and researchers Tribes should be involved in decision making concerning fire management strategies For their traditional lands Bring in at the outset of revitalization plans Many tribes working with researchers Recognition of importance of TEK and WS Not mutually exclusive! Brought together Too many regulations in bringing cultural fire back Need to ease up on RED TAPE (based scott) Especially at the Federal level, CA is actually pretty good as far as enabling burning Dealing with Intrusive species Areas overgrown from Fire Suppression E.x Chapparal Need Funding for Proactive Work to Manage Environments Funding for pro-active management Funding for environmental revitalization Funding for eco-system corps Maintain programs over time Possibility of Incorporating Prescribed Burning and Cultural Burning? 5. Amah Mutsun Tribal Band # Hannibal, Mary Ellen 2016 Rekindling the Old Ways: The Amah Mutsun and the Recovery of Traditional Ecological Knowledge Bay Nature April-June 2016:28-35. Lightfoot, Kent G., Rob Q. Cuthrell, Cristie M. Boone, Roger Byrne, Andrea B. Chavez, Laurel Collins, Alicia Cowart, and R. Evett, Fine V.A. Paul, Diane Gifford-Gonzalez, Mark G. Hylkema, Valentin Lopez, Tracy M. Misiewicz and Rachel E. B. Reid 2013 Anthropogenic Burning on the Central California Coast in Late Holocene and Early Historical Times: Findings, Implications, and Future Directions. California Archaeology 5(2):371-390.\nValentin Lopez \u0026ndash; Tribal Chair In Week 5 \u0026ndash; discussed eco-archaeological work that UCB and UCSC Partnering with Amah Mutsun + California State Parks Outlined findings employing different lines of evidence Fire scar analysis Pollen/charcoal (wetland coring) Phytoliths \u0026ndash; tells us the extent of grasslands Archaeology Ethnography, ethnohistory, tribal history Our Findings: Strong evidence of Cultural Burning Observed fire frequency greater than Expected from Lightning Ignitions Alone Extensive Cultural Burning: Begins about 1300-1200 BP Pattern of frequent, low intensity burns for 9-10 Centuries up to Portola Expedition in CE (Common Era) 1769-1770 Create Coastal Prairie Environments, Evidence of grasses, clovers, tarweeds, hazelnuts, etc. Rob Cuthrell talked about this Fire Tenders created a productive, patchy landscape mosaic Burning some patches one to 5 years or so cycle maintain coastal grassland! along with neighboring woodlands, wetlands, and forests with fire-adapted species such as hazelnut, California lilac, and redwood What Are We Doing With These Findings? # Ultimate Goal Of Research Program How lessons from the past can be applicable to contemporary CA? How these finding may be incorporated into ecological revitalization programs That are rooted in the deep history of tribal practices The Amah Mutsun working with California State Parks Co-managing some lands \u0026ndash; Quiroste Valley Cultural Preserve MOUs (Frank Lake) Committed to ecological revitalization Understand limitations of fire suppression Bringing back Native plants and animals that once flourished Based on findings from our eco-archaeological findings Tribe \u0026ndash; interested in bringing back patchy landscape mosaics That includes extensive patches of coastal prairies which have become rare with fire suppression Encroached on by conifer forests and shrublands Val Lopez and Tribe Created Amah Mutsun Land Trust Purpose is to restore lands in their territory Undertake research Support Native Stewardship Corps Boots on the Ground for work How we are doing this: # Select Patches Where we Open up Landscape Involves Removing Problematic Invasives Poison hemlock, milk and Italian thistle, jubata (Pampas Grass) Fuel Reduction Use clippers / chainsaws remove brush and small trees Can be used to make burn piles, biswell-style Few places mechanized removal of overgrowth Where Possible Implement Cultural Burns Begin Process Of Bringing Fire Back Work To Bring Back Culturally Important Plants in Patches Plants used for food, medicines and raw materials Based on Eco-Archaeological Work We have good information about plants recovered Two Ways: Patches selected for revitalization Undertake Integrated Cultural Survey Reason: Ama Mutsun have a spiritual obligation from Creator to use fire to take care of ancestral land Goals: (1) To document, protect, and steward cultural and natural resources, (2) locate areas that may be suitable for landscape revitalization + seed collection Landscape components: (1) Non-biological = archeological sites, natural springs, viewsheds, salmon spawning habitat (2) biological = vegetation type and ethnobotany Stratified survey approach: focus on broad areas of flat land near water Include survey to detect ancestral archaeological sites High density of ethnobotanical and culturally-important vegetation (seed and nut foods, basketry and crafting taxa, hazelnut patches) Grasslands being converted to shrublands Also locate other important cultural resources Food plants, medicinal plants AMLT \u0026ndash; Implemented a Native Nursery and Plant Propagation Program Nursery used to raise thousands of plants identified in eco-arch work Tarweeds, California Brome Grass, California Canary Grass, Red maids, yarrow, etc. After propagated in the greenhouse, they plants are moved outside to field beds where they\u0026rsquo;re then \u0026ldquo;harvested\u0026rdquo; for their seeds Enables us to keep rare plants alive Raise seedlings in nursery Some then planted in fields these provide seeds for restoration We will use these seedlings and seeds in our revitalization efforts In Undertaking This Work Hope To Create Fuel Breaks Open Areas \u0026ndash; where we can slow down fire, may not stop major fire but provide where calfire can better manage major fire! Hope to Construct Patchy Landscape Mosaic across tribal territory And if strategically designed and placed, can address three crucial concerns today: Enhance Quantity And Diversity of Indigenous Plants And Animals Provide Better Food Security For Tribal Members Provide Places for tribal harvesting of native foods, medicines, Dance regalia, raw materials for making baskets, other crafts Create Extensive Fuel Breaks In critical areas on public lands Help minimize risk of major fires Eco-System Stewardship Work in CA # Need to Create New Framework for Caring for our Open Spaces - Active Ecosystem Management - Ecological Revitalization - Need a Separate Stewardship Corps dedicated to this mission - Need to get Tribes and Local Communities Involved! - Marks-Block et al 2021 Reading Discusses why we cannot rely on Fire Suppression people to do ecosystem management Requires Locally Situated Practices No one size or one way to manage landscape of California; Employ Various Treatment Plans Depends on Objectives and Options Anderson and Barbour 2003 Reading Managed Wildfires Simulated Wilderness Management Model Broadscale Prescribed Burning Indigenous Landscape Stewardship Practices Cultural Burning Co-Management of Area Simulated Indigenous Management Model Integration of Industrial-Scale Prescribed Burning with Indigenous Stewardship Practices (Cultural Burning)? Is it possible? Prior to Treatment \u0026ndash; Eco-Archaeological Surveys Integrated Approach outlined by Alec Identify Locations of Archaeological Sites; Identify patches of important Ecological Resources: Plants important to tribes for food, medicines, materials, etc. If enough time, may be possible to do refined Eco-Archaeological study Soil samples, flotation, recover plant/animal remains and associated tools from archaeological contexts Obtain physical remains of plants and animals that tribes harvested Areas with Important Arch/Ecological Resources: May call for additional or different treatments from rest of prescribed burn area Similar to Cultural Resources Management work in Urban Context Some Cases \u0026ndash; Prescribed Burning OK But require additional follow-up treatment Other Cases \u0026ndash; need pre-treatment before Prescribed Burn: treat differently from rest of prescribed burn area Ron Goode \u0026ndash; pruning, vegetation removal around site or patch reduce fuel loads Scott \u0026ndash; San Vicente Redwoods Treat oaks differently than redwoods (different burn treatment) Marks-Block et al 2019 California Hazelnut Experimentation Must Deal with Intrusive Species Need to initiate long-term maintenance commitment to the Landscape Costs! Wildland Urban Interface (WUI) and Camp Fire (11-22) # Kramer et al. 2019\nTwo types of WUI \u0026ndash; Wildland Urban Interface Interface WUI - \u0026ldquo;where houses meet\u0026rdquo;: 🏠🏠🏠🌲🌲🌲 Intermix WUI - \u0026ldquo;where houses mingle\u0026rdquo; (with vegetation): 🏠🌲🏠🌲🏠🌲 - U.S. WUI was large in 2010: - WUI Houses: 43.4 million = 33% of total - Around 10% of US population - Probably has grown in last 10 years - WUI Area: 770,000 km2 = 9.5% of U.S. - Concentrated in West - U.S. WUI grew rapidly from 1990 to 2010: - WUI Houses: 30.8 to 43.4 million -- 41% growth ![](/docs/anthro-c12ac/imgs/wui-map.png) WUI Area: 581,000 to 770,000 km2 \u0026ndash; 33% growth Due primarily due to housing growth (wrt change in vegetation, or both) Destruction in WUI skewed and highly variable Destruction rates ranged between 0% and 100% (averaged 25% for fires with burned buildings) 70% of all destroyed buildings were in the top 20 most destructive fires ![](/docs/anthro-c12ac/imgs/firewise-map.png) - Firewise communities - Communities that have principles for fire - Have evacuation / build material standards - Are well located, but many are reactive only after wildfires - Tends to be run by volunteers -- should aim to try and get more professions / advisors involved CA is a risky place; it\u0026rsquo;s contained\u0026hellip; - 12 of the 20 most destructive fires in US - 46% of buildings threatened by fire in US - 60% of buildings destroyed by fire in US - Fire insurance being cancelled Not all buildings are rebuilt In the US, 23% are rebuilt within 5 years In CA, 35% are rebuilt within 5 years In CA, 72% are rebuilt within 20 years (ranging from 13% to 100%) Big differences between affluent and non-affluent communities \u0026ndash; fire insurance Strong growth within all fire perimeters: 1981 Atlas Creek Fire - 65 homes burned 2017 Atlas Fire - 781 homes burned Extreme growth within Tubbs perimeter: For every home present in 1940, there were 26 homes in 2010 (2600% growth) Lessons from Tubbs Fire: Occurred due to eastern winds that traveled from high to low pressure, coastal areas Going downhill means faster winds thus hotter fires Additionally, winds can speed up as they move through canyons and mountain spaces Leads to reoccurring burned areas People likely won\u0026rsquo;t change behavior if incentives are not established Tubbs was highly destructive, and not the norm, but it also was not an anomaly: 6 of the 10 most destructive fires in CA have occurred since 2000 People are continuing to build in areas where fire risk is high and suppression is difficult Camp Fire \u0026ndash; Butte County Electrical power line started fire which the wind then carried Two ignitions related to power lines 85 people died, \u0026gt;18,000 homes lost over 149,000 acres Most expensive natural disaster in world in 2018 in terms of insured losses Mixture of ponderosa pine forests, woodlands, shrublands 2008 BTU Lighting Complex burned before Worst loss of life in a California wildfire Paradise had practiced evacuating Thought was one of most prepared cities Position of Paradise very hazardous with one road in and out Needs: Better community preparation and forest/woodland management, electrical infrastructure improvements Recommendations: Don\u0026rsquo;t reduce regulations to speed rebuilding Mandate good building codes Provide resources to people beyond a few years \u0026ndash; only 2/3 have rebuilt by 5 years Despite regulations on new building, the best incentive could be from insurance More engagement of public to prepare Australia a Leader in WUI: They have done a much better job of engaging people who live in the WUI Stephens et al. 2009, Gill and Stephens 2009\nIn U.S. mostly done by volunteer groups, better with UC extension employees Prepare, stay, defend, or leave early \u0026ndash; Australia Catastrophic fire danger level with climate change Updated Australia policy after 2009 Black Saturday Fires \u0026ndash; 174 people killed Updated Australia Policy PREPARE your family, home or business \u0026ndash; know your risk from bushfire and have a survival plan ACT on the fire danger ratings - put your preparations into action, do not wait to get message on your phone or tablet SURVIVE by monitoring conditions if a fire starts Know bushfire warning alert levels and what you will do if you are caught in a fire Summary # Exposure of human communities to fire in California is huge Communities need to prepare better for fire \u0026ndash; UC Cooperative Extension program Forest and woodland management could improve conditions \u0026ndash; TEK can assist Chaparral less options Electrical infrastructure needs improvement CA can learn from Australian experience Governor Newson\u0026rsquo;s and California\u0026rsquo;s next move? Class Summary # As an AC class, a major objective of this course is to examine diverse populations relationship to fire in California Today, while most of us fear wildland fires, that has not always been the case; Defining fire regimes for local regions of CA: fire frequency, fire season, fire area, fire severity, interaction with other factors; Scott’s Discussions of fire regimes for different CA ecosystems anthropogenic and natural fire regimes; Long-Term use of fire by Human populations: Important component of human evolution Constructive use of fire over hundreds of thousands of years for cooking, warmth, ceremonial use, etc. people bring fire with them when they colonized new landscapes and places across the globe, including California probably 13,000-15,000 years ago; Historical Fire Ecology: How we study the history of past fire regimes: Coring lakes to obtain charcoal, pollen, phytoliths Coring trees Wedges from trees for fire scar analysis Other lines of evidence employed: ethnohistorical accounts, ethnography, Native histories (oral traditions) Eco-archaeology (flotation to recover plant animal remains from archaeological sites) Cultural Burning in California California Indians have lived here more than 13,000 years Traditionally referred to as “Hunter-Gatherers” in anthropology literature,” but best to Refer to Them as “Resource Managers or Landscape Stewards”; Reasons for anthropogenic fires (control pests, remove detritus, open pathways, hunting, habitat revitalization to facilitate growth of tribal foods, medicines, dance regalia, raw materials) Regular, small-scale burning to enhance productivity, diversity, and sustainability of habitats – produce patchy mosaics Holocene times – California characterized byanthropogenic landscape, not “Pristine Wilderness” Controversy about scale and timing of anthropogenic/cultural burning: Central California – evidence for creation of coastal prairies by people 800-1400 CE (Rob Cuthrell, Valentin Lopez – eco-arch Research); Transformations with Colonialism: Significant impacts of Spanish, Russian, Mexican, and American (settler) colonization: altered fire regimes environmental degradation genocide of Native peoples Loss of land few reservations granted – mostly very small in size many tribes not federally recognized detrimental impacts of fire exclusion and later fire suppression Termination of Indigenous landscape stewardship practices on any major scale, but timing varied across state depending on history of colonization Some loss of Traditional Ecological Knowledge TEK (Val Lopez); The Advent of Fire Suppression: Debate about “Light Burning” in 1880s-early 1900s use of fire by sheep herders and by timber companies establishment of Forest Reserves, USFS (1905) influence of Gifford Pinchot (trained in Europe as discussed by Jameson Karns) Light Burning loses out to total fire suppression influence of 1910 Great Idaho Fire and other factors discussed by Scott fire suppression really develops in WWII and Post-war years Smokey the Bear, etc. Impact of Fire Suppression on local Ecosystems: Fire suppression methods very effective: 98-99% of fires out at less than 5 acres in size Major implications for taking fire out of ecosystem: increase fuel loads (ladder, surface, crown fuels), increase density of vegetation, fewer open areas, vegetation that is more homogeneous, encroachment of shrubs and trees, loss of grasslands, meadows, spring (Scott, Brandon Collins) Post-Suppression Times: Importance of Leopold Report in 1963 for National Parks and otherfederal and state agencies USFS, NPS and others experiment with prescribed burning, managed fires, and various fire proxy methods, including manual thinning, mechanized removal of vegetation, etc. (Jim Agee, Jan van Wagtendonk) In regard to prescribed burning, California nowhere near what Florida does. Much more needs to be done here! Tribal Revitalization in California - important concern of Tribes: Health of Environment, work to bring back Indigenous Stewardship Practices - ecological restoration of Tribal Lands - push to bring Cultural Burningand other stewardship practices back to the land: Five Case studies discussed: Timbisha Shoshone (Death Valley) - Chumash (Santa Barbara) - North Fork Mono Tribe (southern Sierra Nevada Mts.) - Karuk And Yurok Tribes (Northwest California) - Amah Mutsun Tribal Band (Central Coast of California); The Future: Rethinking how we manage open spaces, public lands, wildland/urban Interface in California: Use of Managed Fires where possible (Yosemite Case Study) Need much more prescribed burning to reduce fuel loads, develop fuel breaks, forest restoration, etc. Also employ manual thinning and mechanized vegetation removal when burning not a viable option; Need to bring back Indigenous landscape management practices, including strategic use of Cultural Burning (more nuanced treatment of specific resources) Create partnerships with Tribes and Federal and State Agencies Can we combine prescribed burning and cultural Burning in some areas of California? We think so and are working on it\u0026hellip; Proposal: Establish a Stewardship Corps for California that is dedicated to active ecosystem management Implement programs for training and certifying prescribed burn managers (like Florida) Fund stewardship corps work throughout year (prescribed/cultural burns in winter, spring, late fall) Create local/regional stewardship districts where corps undertakes regular maintenance of the land (like painting the Golden Gate Bridge) \u0026ndash; tailored to specific local ecosystems Composition of stewardship corps would include people from local tribes and members of local communities – create career Opportunities; New policies and regulations: fire insurance, zoning issues (try to decrease further development in Wildland/Urban Interface?) Mandate good building codes to fire-proof homes and surroundings – especially after major fires improve electrical infrastructure of California advocate for more community participation to prepare for fires increase funding for UC Extension to work with communities to better prepare for fires; "},{"id":55,"href":"/physics-7b/26/","title":"26: DC Circuits","section":"Physics 7B","content":" 26.1 EMF and Terminal Voltage # EMF # To have a current, we need an emf (electromotive force) device to transform one type of energy (chemical, mechanical, light) into electric energy The term “electromotive force” is a misnomer: it does not refer to a “force,” which is measured in newtons. To avoid confusion, we use the abbreviation, emf. EMF of the Source: The potential difference between the terminals of a source when no current flows to an external circuit .$\\mathscr{E}$ is used for emf and it\u0026rsquo;s units is (V)olts Batteries # Batteries don\u0026rsquo;t have constant current (it varies with resistance of the circuit) Voltage is nearly constant, but decreases when battery cannot supply charge fast enough to maintain full emf This occurs because the charge must move between/through the electrodes in the battery Additionally, the battery has some internal resistance, .$r$ Batteries are treated as a perfect emf .$\\mathscr{E}$ in a series with a resistor .$r$ The terminal voltage is .$V_\\text{ab} = V_a - V_b$ When a battery is being charged, a current is forced to pass through it; we then have to write .$V_\\text{ab} = \\mathscr{E} + Ir$ When no current is drawn, .$V_\\text{ab} = \\mathscr{E} - Ir$ .$Ir$ comes from the fact that when .$I$ flows from the battery it causes an internal voltage drop .$Ir$ Since .$\\mathscr{E} - Ir = IR \\Longrightarrow \\mathscr{E} = I(R+r)$ for .$R$ as the resistance of the circuit 26.2 Resistors in Series and Parallel # Series # Any charge that passes through one resistor passes through all Hence, the same current .$I$ passes through each too (constant) If this wasn\u0026rsquo;t true, then it would imply the charge was not conserved Voltage from the battery is split between each resistor proportional to .$R$ $$V = V_1 + V_2 + \\dots = I R_1 + I R_2 + \\dots = I(R_1 + R_2 + \\dots)$$ Thus, .$R_\\text{eq} = R_1 + R_2 + \\dots$ Note that when you add more resistance to the circuit\u0026hellip; The current that passes through each resistor decreases The equivalent resistance increases Voltage stays the same since the battery is unaltered Parallel # Current is split from the source path into branches Thus, paths outside of one\u0026rsquo;s branch doesn\u0026rsquo;t impact/interrupt current The current from each branch must equal the total current; i.e $$I = I_1 + I_2 + \\dots$$ Voltage across each resistor is equivalent; $$I_1 = \\frac{V}{R_1}, I_2 = \\frac{V}{R_2}, \\dots \\Longrightarrow I_\\text{eq} = \\frac{V}{R_\\text{eq}}$$ Thus, .$R_\\text{eq}$ is equal to $$ \\frac{1}{R_\\text{eq}} = \\frac{1}{R_1} + \\frac{1}{R_2} + \\dots$$ Note that when you add another resistor to the circuit\u0026hellip; Net resistance goes down Adding another resistor adds another path causing current to decrease Voltage stays the same since the battery is unaltered Consistent with .$R = \\rho l/A$ definition of resistance Series is effectively increasing the length Parallel increases the area through which current flows 26.3 Kirchhoff\u0026rsquo;s Rules # We use Kirchhoff\u0026rsquo;s two rules when circuits get too complex for trivial analysis\n**1. Junction Rule:** At any junction point, the sum of all currents entering the junction must equal the sum of all currents leaving the junction. - That is, what goes out must come back in - Based on conservation of electric charge - Mathematically, $$\\sum_{k=1}^{n} I_k = 0$$ - .$n$ is the total number of branches with currents flowing towards or away from the node. \u003e![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/KCL_-_Kirchhoff%27s_circuit_laws.svg/330px-KCL_-_Kirchhoff%27s_circuit_laws.svg.png) \u003eThe current entering any junction is equal to the current leaving that junction: .$I_2 + I_3 = I_1 + I_4$ **2. Loop Rule:** The sum of the changes in potential around any closed loop of a circuit must be zero. - That is, what goes up must come back down - There is as much up as there is down - At the battery, the gain/loss on each terminal cancel one another along the closed circuit path - Based on conservation of energy - Mathematically, $$\\sum_{k=1}^{n} V_k = 0$$ - .$n$ is the total number of voltages measured. \u003e![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Kirchhoff_voltage_law.svg/300px-Kirchhoff_voltage_law.svg.png) \u003eThe sum of all the voltages around a loop is equal to zero: .$V_1 + V_2 + V_3 + V_4 = 0$ 26.4 EMFs in Series and Parallel; Charging a Battery # - (a) Two similarly arranged batteries in a series sum their voltages; e.x. 3V - (b) Two oppositely arranged batteries in a series subtract their voltages; e.x. 8V - How battery charging works - The 20V source is charging up the 12V battery - Because of it's greater voltage, the 20V is forcing charge back into the 12V - (c) Two batteries in parallel, which if the emfs are the same, can provide more energy when large currents are needed. - Each of the cells in parallel has to produce only a fraction of the total current, so the energy loss due to internal resistance is less than for a single cell - Thus, the batteries will drain less quickly. 26.5 RC Circuits: Resistor \u0026amp; Capacitor in Series # RC Circuits differ in that they have varying current\nCapacitor Charging # \u003e After the switch .$S$ closes in the **RC circuit** shown in (a), the voltage across the capacitor increases with time as shown in (b), and the current through the resistor decreases with time as shown in (c). \u003e - (a) When closed, the current starts flowing through the circuit from the negative terminal through .$R$ and accumulate on the upper plate of the capacitor which creates potential difference equal to .$V_C = Q/C$ - Current is then reduced because of this opposing voltage on the capacitor - (b) Eventually, the potential equals the emf, .$\\mathscr{E}$, and then no current flows and no potential difference across the resistor - Potential difference, .$V_C$, across the capacitor is equal to the charge on it, .$V_C = Q/C$ - Because charge increases with time, so does voltage until this point - The emf .$\\mathscr{E}$ of the battery will equal the sum of the voltage drops across the resistor and the capacitor: $$\\mathscr{E} = IR + \\frac{Q}{C}$$ - .$R$ is total circuit resistance, including battery - .$I$ is current at all points in the circuit at any instant - .$Q$ is the charge of the capacitor at that same instant - Notice: .$\\mathscr{E}, R, C$ are constants, .$Q, I$ are functions of time - (c) As charge builds up on the capacitor, the current decreases exponentially in time with a time constant .$\\tau$ equal to .$RC$ The rate at which charge flows thorough the resistor (.$I = dQ/dT$) is equal to the rate at which charge accumulates on the capacitor: $$ \\mathscr{E} = \\bigg(\\frac{dQ}{dt}\\bigg)R + \\frac{1}{C}Q$$ This can then be used to find an equation of .$Q$: $$ \\Longrightarrow \\frac{dQ}{C\\mathscr{E} - Q} = \\frac{dt}{RC} \\Longrightarrow \\int_0^Q \\frac{dQ}{C\\mathscr{E} - Q} = \\frac{1}{RC}\\int_0^t dt$$ $$ \\Longrightarrow \\ln\\bigg(1 - \\frac{Q}{C \\mathscr{E}}\\bigg) = - \\frac{t}{RC} \\Longrightarrow 1 - \\frac{Q}{C\\mathscr{E}} = e^{-t/RC}$$ $$ \\Longrightarrow Q = C\\mathscr{E}(1-e^{-t/RT}) = Q_0 (1-e^{-t/RT})$$ .$Q_0 = C \\mathscr{E}$ represents the maximum charge on the capacitor .$Q_0 \\neq \\text{charge $(Q)$ at $t = 0$}$ The potential difference across the capacitor is .$V_C = Q/C$ so the maximum value is $$ V_C = \\mathscr{E}(1-e^{-t/RC})$$ .$\\tau = RC$ is the axis units on graph (b) and is aptly called the time constant of the circuit Represents the time required for the capacitor to reach .$(1-e^{-1}) = 0.63 = 63\\text{%}$ of its full charge and voltage Also represents the time for the current to drop to .$1/e \\approx 0.37$ of it\u0026rsquo;s initial value Thus, it measures how quickly the capacitor becomes charged We use this as a measurement since the maximums only occur as we take .$t \\to \\infty$, but these values reach 86% of the way in .$2RC = 2\\tau$, 95% in .$3\\tau$, 98% in .$4\\tau$, so on The current in the circuit at any time can be found by differentiating the following: $$I = \\frac{dQ}{dt} = \\frac{\\mathscr{E}}{R}e^{-t/RC}$$ This is an exponential decay function: when .$t = 0$, the current is largest because there is no charge on the capacitor to impede it That is, .$I = I_0 = \\mathscr{E}/R$ As charge builds up, the current decreases exponentially in time (as shown in (c)) Capacitor Discharging # Now imagine the opposite case; we start fully charged at .$Q_0$ with voltage .$V_0$ and have to discharge through resistance .$R$ The voltage across the resistor at any instant equals that across the capacitor: $$V = IR = \\frac{Q}{C}$$ We can use this to find the functions for both .$Q_0$ and .$V_C$: $$ - \\frac{dQ}{dt} R = \\frac{Q}{C} \\Longrightarrow \\frac{dq}{Q} = - \\frac{dt}{RC}$$ $$ \\ln \\frac{Q}{Q_0} = - (t/RC) \\Longrightarrow Q = Q_0 e^{-t/RC}$$ $$ \\dots \\Longrightarrow V_C = V_0 e^{-t/RC}$$ \u003e For the RC circuit shown in (a), the voltage .$V_C$ across the capacitor decreases with time, as shown in (b), after the switch S is closed at .$t = 0$. The charge on the capacitor follows the same curve because .$Q \\propto V_C$ ![RC Discharge Diagrams](/docs/physics-7b/imgs/rc-discharge.png) $$$$ $$$$ - .$V_0 = Q_0 / C$ is the initial voltage, related to initial charge - We can see the charge on the capacitor, thus the voltage across it, decreases exponentially in time - Current is found to be $$I = - \\frac{dQ}{dt} = \\frac{Q_0}{RC}e^{-t/RC} = I_0 e^{-t/RC}$$ - The charge on the capacitor, the voltage across it, and the current in the resistor all decrease to 37% of their original value in one time constant .$t = \\tau \\ RC$ 26.6 Electric Hazards and Safety (not covered) # Current above .$\\text{1 mA}$ can be felt Current above .$\\text{10 mA}$ cause severe contraction of muscles (may not be able to let go of source) Current above .$\\text{80-100 mA}$ that passes through the torso (passing through the heart for a second) will cause ventricular fibrillation (heart stops pumping blood properly) It\u0026rsquo;s current that harms, even though voltage drives the current The seriousness of a shock depends on the current and thus the applied voltage and the effective resistance of the body More voltage shocks, more current kills Wet skin has resistance of .$10^3 \\Omega$ while dry skin is around .$10^5 \\Omega$ 26.7 Ammeters and Voltmeters: Measurement Affects Quantity Measured (not covered) # Measuring is hard to do both precisely and consistently Ammeters measure current (amps) and voltmeters measure potential difference or voltage (volts) An analog ammeter or voltmeter uses a galvanometer The full scale sensitivity, .$I_m$, is the electric current required to make the needle deflect a full scale; typically .$50 \\mu\\text{A}$ \u003eAn ammeter is a galvanometer in _parallel_ with a **shunt** resistor with low resistance, .$R_\\text{sh}$ ![ammeter](/docs/physics-7b/imgs/ammeter.png) \u003e A voltmeter is a galvanometer in _series_ with a resistor with high resistance, .$R_\\text{ser}$ ![voltmeter](/docs/physics-7b/imgs/voltmeter.png) - (b) Because an ammeter is used to measure the current flowing in the circuit, it must be inserted directly into the circuit, **in series** with the other elements. The smaller its internal resistance, the less it affects the circuit. - (c) A voltmeter is connected “externally,” in parallel with the circuit element across which the voltage is to be measured. It measures the potential difference between two points. Its two wire “leads” (connecting wires) are connected to the two points. - Only .$R_1$ is being measured above ![Measuring](/docs/physics-7b/imgs/measuring.png) If the resistance of a voltmeter is much higher than the resistance of the circuit, it will have little effect and its readings can be more accurate At least to the manufactured precision of the meter, which for analog meters is typically 3% to 4% of full-scale deflection. Sensitivity: The sensitivity of a voltmeter is specified on its face as, for example, .$10,000\\ \\Omega/\\text{V}$. Then on the .$5\\text{V}$ scale, the voltmeter would have a resistance given by .$\\text{(5V)(10,000 $\\Omega$/V) = 50,000 $\\Omega$}$ Even an ammeter can interfere with a circuit, but the effect is minimal if its resistance is much less than that of the circuit as a whole. For both voltmeters and ammeters, the more sensitive the galvanometer, the less effect it will have on the circuit. "},{"id":56,"href":"/physics-7b/27/","title":"27: Magnetism","section":"Physics 7B","content":" 27.1 Magnets and Magnetic Fields # Every magnet has two ends or faces called poles which are where the magnetic field is strongest If a magnet is suspended so it can move freely, one pole will point north Aptly, this side is called the north pole Magnetic poles aren\u0026rsquo;t like electric charge: Positive or negative charge can easily be isolated, but we can never isolate a magnetic pole That is, if you cut a magnet is half you don\u0026rsquo;t obtain isolated north and south poles. Rather, you end up with two new magnets each with north and south poles Ferromagnetic: Materials with a strong magnetic effect i.e. iron, cobalt, nickel, gadolinium Similar to how we picture electric fields around a charge, we can picture magnetic fields surround a magnet Field lines should be drawn so that (1) the direction of the magnetic field is always tangent to a field line everywhere and (2) the number of lines per unit area is proportional to the magnetic field strength (a) Visualizing magnetic field lines around a bar magnet, using iron filings and compass needles. The red end of the bar magnet is its north pole. The N pole of a nearby compass needle points away from the north pole of the magnet. (b) Diagram of magnetic field lines for a bar magnet.\n## Earth's Magnetic Field - Earth's magnetic poles are not exactly through the geographic pole (axis of rotation) - The angular difference between the direction of the compass needle (which points along the magnetic field lines) at any location and true (geographical) north varies between .$0 - 20^\\circ$ with location - Earth's magnetic field at most location is not tangent to earth's surface - **Angle of Dip:** The angle that Earth's magnetic field makes with the horizontal at any point \u003e ![Earth](/docs/physics-7b/imgs/27/poles.png) \u003e The Earth acts like a huge magnet. But its magnetic poles are not at the geographic poles (on the Earth's rotation axis). 27.2 Electric Currents Produce Magnet Fields # (a) Deflection of compass needles near a current-carrying wire, showing the presence and direction of the magnetic field. (b) Iron filings also align along the direction of the magnetic field lines near a straight current-carrying wire. (c) Diagram of the magnetic field lines around an electric current in a straight wire. (d) Right-hand-rule-1 for remembering the direction of the magnetic field: when the thumb points in the direction of the conventional current, the fingers wrapped around the wire point in the direction of the magnetic field. (.$\\vec B$ is the symbol for magnetic field).\n27.3 Force on an Electric Current in a Magnetic Field # By Newton\u0026rsquo;s third law, we can see that a magnet exerts a force on a current-carrying wire The direction of the force is always perpendicular to the direction of the current and also perpendicular to the direction of the magnetic field .$\\vec B$ Use right hand rule! $$dF_\\vec{B} = dq (\\vec v \\times \\vec B) = dq\\bigg(\\frac{d\\vec l}{dt}\\times \\vec B\\bigg) = I (d\\vec l \\times \\vec B)$$ $$\\dots\\ \\vec F = I (\\vec l \\times \\vec B) = I l b \\sin\\theta$$ .$\\vec l$ is the vector whose magnitude is the length of the wire its direction is along the (straight) wire in the direction of the conventional (positive) current We use the last equation if .$\\vec B$ isn\u0026rsquo;t uniform or if the wire doesn\u0026rsquo;t form angle .$\\theta$ with .$\\vec B$ everywhere 27.4 Force on an Electric Charge Moving in a Magnetic Field # Recall, .$N$ particles, each charge .$q$, pass by a given point in time .$t$, they constitute current .$I = N q/t$ Lets say in .$t$ time, a particle charge .$q$ moves distance .$l$ in a magnetic field .$\\vec B$ We know from kinematics that .$\\vec l = \\vec v t$ where .$\\vec v$ is the velocity of the particle Using the 27.3 equation, we can find the force on all of these .$N$ particles as $$\\vec F = I\\vec l \\times \\vec B = (Nq/t)(\\vec v t) \\times \\vec B = Nq\\vec v \\times \\vec B$$ Thus, the force on just one of the .$N$ particles is $$\\vec F = q \\vec v \\times \\vec B = qvB \\sin\\theta$$ Realize that we can save a lot of pain if we know that the magnetic field is uniform in which case .$\\vec F_\\vec{B} = 0$ because the forces on opposite segments (sides) cancel out ## Uniform Field Path \u003e ![Uniform Field](/docs/physics-7b/imgs/27/circular-path.png) \u003e Force exerted by a uniform magnetic field on a moving charged particle (in this case, an electron) produces a circular path. - Notice the field goes into the paper, denoted with .$\\times$ - Because force is always orthogonal to .$\\vec v$, the magnitude of .$\\vec v$ - The centripetal acceleration has magnitude .$a = v^2/r$ - Thus we can derive $$F = ma \\Longrightarrow qvB = m \\frac{v^2}{r}$$ $$\\dots \\Longrightarrow r = \\frac{mv}{qB}$$ - The time .$T$ it takes a particle with charge .$q$ and speed .$v$ to make a revolution is $$T = \\frac{2\\pi\\cdot r}{v} = \\frac{2\\pi m}{qB}$$ $$f = \\frac{1}{T} = \\frac{qB}{2\\pi m}$$ Problem Solving # Magnetic fields are somewhat analogous to the electric fields, but there are several important differences to recall: 1. The force experienced by a charged particle moving in a magnetic field is **orthogonal** to the direction of the magnetic field (and to the direction of the velocity of the particle), whereas the force exerted by an electric field is **parallel** to the direction of the field (and independent of the velocity of the particle). 2. The right hand rule, in its different forms, is intended to help you determine the direction of magnetic field, and the force a field exerts, and/or the directions of electric current or charged particle velocity. The right-hand rules to the right are designed to deal with the “perpendicular” nature of these quantities. With Electric Field # Lorentz Equation: A particle charge .$q$ moving with velocity .$\\vec v$ in the presence of both a magnetic field .$\\vec B$ and electric field .$\\vec E$ experiences a force $$\\vec F = q (\\vec E + \\vec v \\times \\vec B)$$ Realize that the magnetic field cannot alter speed (do work), it can only alter the direction! To change an objects speed, you must apply a force along the objects direction of motion The magnetic field exerts a force on particles moving orthogonal to it Therefore, no work can be done because the particle can only move orthogonal to the magnetic field That being said, realize that this field is responsible for the circular, constant speed, motion This is why earth\u0026rsquo;s magnetic field deflects, but doesn\u0026rsquo;t slow down, charged particles from outer space 27.5 Torque on a Current Loop; Magnetic Dipole Moment # \u003e **Calculating the torque on a current loop in a magnetic field** .$\\vec B$ \u003e \u003e (a) Loop face parallel to .$\\vec B$ field lines; (b) top view; (c) loop makes an angle to .$\\vec B$, reducing the torque since the lever arm is reduced. The vector .$\\vec \\mu$ is the “magnetic moment”. - When an electric current flows in a closed wire loop that's in an external magnetic field, the magnetic force on the current can produce a torque $$\\tau = I aB \\frac{b}{2} + I aB \\frac{b}{2}$$ $$\\dots = IabB$$ - .$A = ab$ is the area of the loop - .$B$ is scalar of the magnetic field - Notice, the vertical (orthogonal) sections of wire experience no force from the magnetic field - If we have a coil of .$N$ loops of wire, the current is then .$NI$ so torque becomes $$\\tau = NIAB$$ - We call .$\\vec \\mu = NI \\vec A$ the **magnetic dipole moment** - The direction of .$\\vec A$ (and thus .$\\vec \\mu$) is defined as perpendicular to the plane of the coil - We can then re-write our torque eq as $$\\vec \\tau = NI \\vec A \\times \\vec B$$ $$\\dots \\vec \\tau = \\vec \\mu \\times \\vec B$$ - Dipoles have some potential energy, found by $$U = \\int \\tau d\\theta = \\int NIAB\\sin\\theta d \\theta$$ $$\\dots = -\\mu B \\cos\\theta = - \\vec \\mu \\cdot \\vec B$$ 27.8 Hall Effect # - When a current-carrying conductor is held fixed in a magnetic field, the field exerts a sideways force on the charge moving in the conductor - E.x, if electrons move to the right in the rectangular conductor, the inward magnetic field will exert a downward force: (a) - This force is .$F_B = -e\\vec v_d \\times \\vec B$ - .$v_d$ is drift velocity - Thus, electrons tend to move towards side .$D$ - This creates a potential difference (called the **Hall emf**), creating field .$\\vec E_H$ - This field exerts force .$e\\vec E_H$ on the moving charge - These forces are equal, that is, $$e E_H = ev_d B$$ $$\\therefore E_H = v_d B$$ - Hall emf is then, asm uniform .$E_H$, $$\\mathscr{E}_H = E_H d = v_d B d$$ - .$d$ is the width of the conductor \u003e \u003e The Hall effect. (a) Negative charges moving to the right as the current. (b) Positive charges moving to the left as the current. 27.9 Mass Spectrometer # Mass spectrometers are used to measure the masses of atoms\nSteps: 1. Ions are produced (by a current or heating) and they pass through slit .$S_1$ 2. Ions then pass through a region with perpendicular electric and magnetic fields. - Here, .$F_E = qE$ is equal to .$F_B = qvB$ - Therefore, .$v = \\frac{E}{B}$ for all ions that pass the slit into .$S_2$; the rest are deflected Entering .$S_2$, there is only magnetic field .$B\u0026rsquo;$ so the ios follow a circular path Newtons second gives us .$F = ma \\Longrightarrow qvB\u0026rsquo; = mv^2/r$ Since we know all terms, we can solve for mass: .$m = \\frac{qB\u0026rsquo;r}{v} = \\frac{qBB\u0026rsquo;r}{E}$ "},{"id":57,"href":"/physics-7b/28/","title":"28: Sources of Magnetic Field","section":"Physics 7B","content":" 28.1 Magnetic Field Due to a Straight Wire # - Magnetic fields due to the electric current in a long straight wire forms circles with the wire at the center - This field is proportional directly with current .$I$ and inversely with distance .$r$: $$B = \\frac{\\mu_0}{2\\pi} \\cdot \\frac{I}{r}$$ - .$\\mu_0 = 4\\pi \\times 10^{-7} \\text{ T$\\cdot$m/A}$ is the [permeability of free space](https://en.wikipedia.org/wiki/Vacuum_permeability) ![Single Wire](/docs/physics-7b/imgs/28/one-wire.png) 28.2 Force between Two Parallel Wires # ![Double Wires](/docs/physics-7b/imgs/28/two-wires.png) - Since current-carrying wires feel a force in magnetic fields, and because current-carrying wires emit magnetic fields, current-carrying wires exert a force on one another - Magnetic field .$B_1$ produced by .$I_1$ is given by $$B_1 = \\frac{\\mu_0}{2\\pi} \\cdot \\frac{I_1}{d}$$ - Parallel currents in the same direction attract while antiparallel repel Using .$F = IlB$ we can write the force .$F_2$ exerted by .$B_1$ on length .$l_2$ carrying .$I_2$ has magnitude: $$F_2 = I_2 l_2 B_1$$ Notice that the force on .$I_1$ is due to the field produced by .$I_1$ Thus, subbing .$B_1$ into the .$F_2$ formula we find the force on length .$l_2$: $$F_2 = \\frac{\\mu_0}{2\\pi} \\cdot \\frac{I_1 I_2}{d}l_2$$ 28.3 Definitions of the Ampere and the Coulomb # One ampere can be defined as that current flowing in each of two long parallel wires exactly 1 m apart, which results in a force of exactly .$2\\times10^{-7}$ N per meter of length of each wire This was the standard we used prior because it is readily reproducible (that is, it\u0026rsquo;s called an operational definition) Coulomb is defined in terms of the ampere being exactly one ampere-second: .$\\text{1 C = A $\\cdot$ s}$ Now we define an ampere ampere by saying it\u0026rsquo;s .$\\text{1 C = A $\\cdot$ s}$ and we know the Coulomb because it\u0026rsquo;s mutually assigned the exact value .$e = 1.60176636 \\times 10^{-19}\\text{ C}$ 28.4 Ampère\u0026rsquo;s Law # - If we don't have a straight line, we use ampere's law given below - We take a infinite tiny segments and dot it with the field at the segment: $$\\oint \\vec B \\cdot d \\vec l = \\mu_0 I_\\text{encl}$$ - Note that .$\\vec B$ in Ampere's law isn't necessarily due only to the current .$I_\\text{encl}$ - As with Gauss's law for the electric field, Ampere's law practical value to calculate the magnetic field is limited, however, mainly to simple or symmetric situations. - Its importance is that it relates the magnetic field to the current in a direct and mathematically elegant way. ![Ampere's Law](/docs/physics-7b/imgs/28/ampere.png) Ampère\u0026rsquo;s law is considered one of the basic laws of electricity and magnetism: It is valid for any situation where the currents and fields are steady and not changing in time, and no magnetic materials are present ## **Problem Solving:** 1. Ampère's law, like Gauss's law, is always a valid statement. But as a calculation tool it is limited mainly to systems with a high degree of symmetry. The first step in applying Ampère's law is to identify useful **symmetry**. 2. Choose an integration path that reflects the symmetry. Search for paths where .$\\vec B$ has constant magnitude along the entire path or along segments of the path. Make sure your integration path passes through the point where you wish to evaluate the magnetic field. 3. Use symmetry to determine the direction of .$\\vec B$ along the integration path. With a smart choice of path, .$\\vec B$ will be either parallel or perpendicular to the path. 4. Determine the enclosed current, .$I_\\text{encl}$. Be careful with signs. Let the fingers of your right hand curl along the direction of .$\\vec B$ so that your thumb shows the direction of positive current. If you have a solid conductor and your integration path does not enclose the full current, you can use the current density (current per unit area) multiplied by the enclosed area. 28.5 Magnetic Field of a Solenoid and a Toroid # Solenoid: A long looping coil of wire carrying a dc current The current in each loop produces a magnetic field The total magnetic field is the sum of the fields due to each loop Direction is determined by the right hand rule $$\\oint \\vec B \\cdot d \\vec l = \\mu_0 NI$$ \u003e **Magnetic field due to a solenoid** \u003e ![Solenoid](/docs/physics-7b/imgs/28/solenoid.png) \u003e (a) a few loosely spaced loops; (b) for many closely spaced loops, the field is nearly uniform. \u003e **Cross-sectional view into a solenoid.** \u003e ![Cross Section of Solenoid](/docs/physics-7b/imgs/28/xsec.png) \u003e The magnetic field inside is straight except at the ends. Red dashed lines indicate the path chosen for use in Ampère's law. .$\\odot$ and .$\\otimes$ are electric current direction (in the wire loops) out of the page and into the page. $$\\int_c^d \\vec B \\cdot d \\vec l = Bl_{cd}$$ With .$n = N/l$ is number of loops per unit length we can simplify to $$B = \\mu_0 nI$$ Now, we see that the field does not depend on position within the solenoid, so .$\\vec B$ is uniform. This is strictly true only for an infinite solenoid, but it is a good approximation for tightly wound real ones for points not close to the ends. 28.6 Biot-Savart Law # - A current .$I$ flowing in any path can be considered as many tiny current elements, such as .$d \\vec l$ - Then, .$d\\vec B$ at any point .$P$ in space due to this element of current is given by **Biot-Savart law:** $$d\\vec B = \\frac{\\mu_0 I}{4\\pi} \\frac{d\\vec l \\times \\hat r}{r^2} = \\frac{\\mu_0 I}{4\\pi} \\frac{dl \\sin\\theta}{r^2}$$ - .$\\vec r$ is the displacement vector from the element .$d \\vec l$ to the point .$P$ - .$\\hat r$ is the unit vector in the direction .$\\vec r$ - .$\\theta$ is the angle between .$d\\vec l$ and .$\\vec r$ \u003e **Biot-Savart Law** \u003e ![Boit-Savart](/docs/physics-7b/imgs/28/biot.png) \u003e The field at P due to current element .$I d\\vec l$ is .$d \\vec B = (\\mu_0 I/4\\pi)(d\\vec l \\times \\hat r/r^2)$ An important difference between the Biot-Savart law and Ampère\u0026rsquo;s law is that the later, .$\\oint \\vec B \\cdot d\\vec l = \\mu_0 I_\\text{encl}$, .$\\vec B$ is not necessarily due only to the current enclosed by the path of integration. But in the Biot-Savart law the field .$d\\vec B$ is due only, and entirely, to the current element .$I d\\vec l$ \u0026ndash; that is, to find the total .$\\vec B$ at any point in space, it is necessary to include all currents. **Biot-Savart strategy for finding a magnetic field** 1. Select some tiny piece of wire .$d \\vec l$ and draw the vector .$\\vec r$ pointing from said piece to the location at which you're finding the magnetic field 2. Using Biot-Savart, calculate the magnitude and direction of the infinitesimal magnetic field .$d\\vec B$ generated by that piece 3. Add up all those magnetic field contributions by integrating over the wire, using vector components if needed. ## Straight Wire $$B = \\frac{\\mu_0 I}{4\\pi}\\int_{y =-\\infty}^{+\\infty} \\frac{dy \\sin\\theta}{r^2}$$ $$dy = dl; r^2 = R^2 + y^2$$ $$dy = \\dots = \\frac{r^2 d\\theta}{R}$$ $$B = \\frac{\\mu_0 I}{4\\pi}\\frac{1}{R}\\cdot \\bigg[-\\cos\\theta\\bigg]_{\\theta = 0}^\\pi $$ $$\\dots = B = \\frac{\\mu_0 I}{2\\pi R}$$ ![Straight Wire](/docs/physics-7b/imgs/28/straight-wire.png) ![1/4 Wire](/docs/physics-7b/imgs/28/wire-forth.png) ## Current Loop $$dB = \\frac{\\mu_0 I dl}{4\\pi r^2}$$ $$d\\vec l \\perp \\vec r; \\vert d\\vec l \\times \\hat r \\vert = dl$$ $$B = \\int dB \\cos \\phi = \\int dB \\frac{R}{r}$$ $$\\dots = \\int dB \\frac{R}{(R^2 + x^2)^{\\frac{1}{2}}}$$ $$\\dots = \\frac{\\mu_0 I}{4\\pi}\\frac{R}{(R^2 + x^2)^{\\frac{3}{2}}} \\bigg[L\\bigg]_{L = 2\\pi R}$$ $$\\dots = \\frac{\\mu_0 I}{2R}$$ ![Current Loop](/docs/physics-7b/imgs/28/current-loop.png) ## Quarter Wire Segment $$dB = \\frac{\\mu_0 I}{4\\pi}dl$$ $$B = \\frac{\\mu_0 I}{4\\pi} \\bigg[L\\bigg]_{L =\\frac{1}{4}\\cdot 2\\pi R}$$ $$\\dots = \\frac{\\mu_0 I}{8 R}$$ ## 28.6.1 Magnetic Dipole Field - Recall that a magnetic dipole is .$\\mu = NIA$ (number of loops, current, and area of coil) - The magnetic field produced by magnetic dipoles is $$B = \\frac{\\mu_0 IR^2}{2(R^2 + x^2)^{\\frac{3}{2}}}$$ - This can be written in tirms of the magnetic dipole .$\\mu = IA = I\\pi R^2$ for one loop: $$B = \\frac{\\mu_0}{2\\pi} \\frac{\\mu}{(R^2 +x^2)^{\\frac{3}{2}}}$$ and at distances far from the loop .$x \\gg R$ this becomes $$B \\approx \\frac{\\mu_0}{2\\pi} \\frac{\\mu}{x^3}$$ ![Circle Field](/docs/physics-7b/imgs/28/loop-field.png) 28.7 Magnetic Field Due to a Single Moving Charge # Realize that Biot-Savart works only when considering constant currents that do not change in time significantly over a significant length of wire Additionally, the law is difficult to confirm experimentally: Particles would shoot out of the field before they (and thus the field) could be measured for any significant .$B$. If .$v$ is slow enough to be measured, .$B$ is small enough it\u0026rsquo;s going to be drowned out by experimental noise From the particles frame, it\u0026rsquo;s at rest (not moving wrt itself). And since it\u0026rsquo;s at rest, it shouldn\u0026rsquo;t create a field. However, it\u0026rsquo;s moving because it\u0026rsquo;s creating a field! Einstein explains this with special relativity Observers in two different reference frames, moving relative to each other, will not observe the same .$\\vec E$ and .$\\vec B$ fields What see from the perspective other than the particle: The magnetic field at one single instant due to a single positive charge .$q$ moving at velocity .$\\vec v$.\n28.8 Magnetic Materials—Ferromagnetism (not covered) # - Magnetic fields are produced by (1) magnets and (2) electric currents - **Ferromagnetism:** Materials that are magnetic - At a small enough resolution (less than 1mm areas!), **domains** exist which behave like tiny magnets -- they have two poles - The more domains that are aligned in one direction, the stronger the magnetic field - These domains can be moved around (through dropping or hammering the magnet) - Heating also reduces magnetism -- increasing temp increases the random thermal motion of atoms - Above the **Curie Temperature** (1043K for iron), a magnet cannot be made at all - As a consequence, at lower temperatures, some materials are magnetic \u003e ![Ferro](/docs/physics-7b/imgs/28/ferro.png) \u003e (a) An unmagnetized piece of iron is made up of domains that are randomly arranged. Each domain is like a tiny magnet; the arrows represent the magnetization direction, with the arrowhead being the N pole. (b) In a magnet, the domains are preferentially aligned in one direction (down in this case), and may be altered in size by the magnetization process. Today, we believe that all magnetic fields come from electric currents Electrons produce a (tiny) magnetic field, as if they and their electric charges were spinning about their own additional axes Realize that while .$\\vec B$ lines form closed loops, .$\\vec E$ lines go from a positive to negative electron 28.9 Electromagnets and Solenoids—Applications (not covered) # Solenoids act like magnets; they have poles (determined by the right hand rule)\nMagnetic field of a solenoid. The north pole of this solenoid, thought of as a magnet, is on the right, and the south pole is on the left.\nIf a piece of iron is placed inside a solenoid, the magnetic field is increased greatly\nThe domains of the iron are aligned by the magnetic field produced by the current; that is, the iron becomes a magnet. This system of the iron-core solenoid is called an electromagnet The resulting magnetic field is the sum of the field due to the solenoid\u0026rsquo;s current and the field due to the iron, and can be hundreds or thousands of times larger than the field due to the current alone - The alloys of iron used in electromagnets acquire and lose their magnetism quite readily when the current is turned on or off, and so are referred to as **“soft iron.”** (It is “soft” only in a magnetic sense.) - Soft iron is usually used in electromagnets so that the field can be turned on and off readily. - Iron that holds its magnetism even when there is no externally applied field is called **“hard iron.”** - Hard iron is used in permanent magnets. - Whether iron is hard or soft depends on heat treatment, type of alloy, and other factors. Sometimes an iron core is not present—the magnetic field then comes only from the current in the wire loops. A large field .$B$ in this case requires a large current .$I$ which produces a large amount of waste heat since .$P = I^2 R$. But if the current-carrying wires are made of superconducting material kept below the transition temperature then very high magnetic fields can be produced, and no electric power is needed to maintain the large current in the superconducting coils. Note that energy is required to refrigerate the coils at the low temperatures where they superconduct. 28.10 Magnetic Fields in Magnetic Materials; Hysteresis (not covered) # The solenoid field is produced just .$n$ loops per unit length is .$B_0 = \\mu_0 n I$ If a solenoid contains a ferromagnetic material (e.x. iron), then we need to consider it\u0026rsquo;s field .$B_M$ produced in our total field calculation: $$\\vec B = \\vec B_0 + \\vec B_M$$ Often, .$B_M \\gg B_0$ We can also write this equation as $$B = \\mu n I$$ .$\\mu$ is the magnetic permeability (not electric dipole moment!) However, while .$\\mu$ is a characteristic of the material, it is not constant for ferromagnetic materials; rather, it depends on the value of the “external field” .$B_0$ .$\\mu \\gg \\mu_0$ for ferromagnetic materials "},{"id":58,"href":"/physics-7b/29/","title":"29: Electromagnetic Induction \u0026 Faraday's Law","section":"Physics 7B","content":" 29–1 Induced EMF # A changing magnetic field induces an emf That is, changing .$\\vec B$, not .$\\vec B$ itself, induces current Constant magnetic fields produce no current in a conductor This process is called electromagnetic induction It doesn\u0026rsquo;t matter if the magnet or coil moves, only that there is relative motion between the two (a) A current is induced when a magnet is moved toward a coil, momentarily increasing the magnetic field through the coil. (b) The induced current is opposite when the magnet is moved away from the coil (.$\\vec B$ decreases). In (c), no current is induced if the magnet does not move relative to the coil. It is the relative motion that counts here: the magnet can be held steady and the coil moved, which also induces an emf.\n29–2 Faraday\u0026rsquo;s Law of Induction; Lenz\u0026rsquo;s Law # EMF is proportional to the rate of change of the magnetic flux .$\\Phi_B$ passing through the circuit or loop with area .$A$ - Given a uniform magnetic field .$\\vec B$ we write $$\\Phi_B = B_\\perp A = BA \\cos\\theta = \\vec B \\cdot \\vec A$$ - For non-uniform fields, we need to integrate: $$\\Phi_B = \\int \\vec B \\cdot d \\vec A$$ The unit of magnetic flux is the tesla-meter, called the weber: .$\\text{1 Wb = 1 T$\\cdot$ m$^2$}$ Faraday\u0026rsquo;s law of induction The emf .$\\mathscr{E}$ induced in a circuit is equal to the rate of change of magnetic flux through the circuit: $$\\mathscr{E} = -N\\frac{d\\Phi_B}{dt}$$ .$N$ is the number of loops closely wrapped so the flux passes through each Lenz\u0026rsquo;s Law A current produced by an induced emf creates a magnetic field that opposes the original change in magnetic flux Faraday\u0026rsquo;s law is negative accordingly Realize that we know have to magnetic fields: The changing magnetic field or flux that induces the current, and The magnetic field produced by the induced current (all currents produce a magnetic field) which opposes the charge in the first Note: The magnetic field created by induced current opposes change in external flux, not necessarily opposing the external field It is important to note that an emf is induced whenever there is a change in flux through the coil \u0026ndash; this can be done in three ways: Changing the magnetic field Changing the area .$A$ of the loop in the field Changing the loop\u0026rsquo;s orientation .$\\theta$ wrt the field ## Problem Solving -- Lenz's Law Lenz's law is used to determine the direction of the (conventional) electric current induced in a loop due to a change in magnetic flux inside the loop. (The loop may already be carrying its own ordinary current.) To produce an induced current you need (1) a closed conducting loop, and (2) an external magnetic flux through the loop that is changing in time. 1. Determine whether the magnetic flux .$\\Phi_B = \\vec B \\cdot \\vec A$ inside the loop is decreasing, increasing, or unchanged. 2. The magnetic field due to the induced current: (a) points in the same direction as the external field if the flux is **decreasing**; (b) points in the opposite direction from the external field if the flux is **increasing**; or (c) is zero if the flux is **not changing**. 3. Once you know the direction of the induced magnetic field, use the right hand rule to find the direction of the induced current that would give this induced .$\\vec B$ 4. Always keep in mind that there are two magnetic fields: (1) an external field whose flux must be changing if it is to induce an electric current, and (2) a magnetic field produced by the induced current. 5. If a wire is already carrying an electric current, the total current while the magnetic field is changing will be the algebraic sum of the original current and the induced current. 29–3 EMF Induced in a Moving Conductor # If a conductor begins to move in a magnetic field, an emf is induced We can use Faraday\u0026rsquo;s law and kinematics to derive an equation: $$\\mathscr{E} = \\frac{d\\Phi_B}{dt} = \\frac{B dA}{dt} = \\frac{B (l\\cdot v\\ dt)}{dt} = Blv$$ .$v$ is the speed of the conductor .$dA = l\\ dx = lv\\ dt$ is the change in area over time .$t$ Be careful! This is a generalization where .$B, l, v$ are mutually perpendicular If they aren\u0026rsquo;t, we use the component of each that are mutually perpendicular An emf induced on a conductor moving ina magnetic field is sometimes called a motional emf We could also derive this using our force eq from ch27: $$\\vec F = q\\vec v \\times \\vec B$$ - When the conductor moves with .$v$, as do its electrons - Since .$\\vec \\perp \\vec B$, each electron feels force .$F = qvB$ - The direction determined by the right hand rule (red) - If the rod is not in contact with the conductor, electrons would collect at the upper end leaving the lower positive - Therefore, there must be an induced emf! - If the rod is in contact with the conductor, the electrons will flow into the conductor and there will be a clockwise current in the loop - To calculate emf, we determine the work .$W$ needed to move a charge .$q$ from one end of the rod to the other against this potential difference: $$W = F \\times d = (qvB) \\times (l)$$ $$\\mathscr{E} = W/q = qvBl/q = Blv$$ \u003e ![EMF Force](/docs/physics-7b/imgs/29/emf-force.png) \u003e (a) A conducting rod is moved to the right on the smooth surface of a U-shaped conductor in a uniform magnetic field .$\\vec B$ that points out of the page. The induced current is clockwise. (b) Force on an electron in the metal rod (moving to the right) is upward due to .$\\vec B$ pointing out of the page. Hence electrons can collect at the top of the rod, leaving .$+$ charge at the bottom. 29–4 Electric Generators # - **Electric generators** produce electricity by transforming mechanical energy into electric energy - Also called **dynamos** - Opposite of what a motor does - Consists of many wires wound around an **armature** that can rotate in a magnetic field - This axel is turned by mechanical means (belt, steam, water falling, etc.) and an emf is induced in the rotating coil - An ac current is thus the _output_ of a generator \u003e An ac generator \u003e ![Generator](/docs/physics-7b/imgs/29/generator.png) Each brush is fixed and presses against a continuous slip ring that rotates with the armature If the armature is rotating clockwise; then, .$\\vec F = q \\vec v \\times \\vec B$ applied to a charged particles in the wire Lenz\u0026rsquo;s law tells us that the (conventional) current in the wire .$b$ on the armature is outwards, towards us, thus, the current is outwards, through brush .$b$ After one-half revolution, wire .$b$ will be where .$a$ is now and the current at .$b$ will be inwards. Thus, the current produced is alternating! If the loop is made to rotate in a uniform field .$\\vec B$ with constant angular velocity .$\\omega$, the emf produced is $$\\mathscr{E} = - \\frac{d\\Phi_B}{dt} = - \\frac{d}{dt}\\int \\vec B \\cdot d \\vec A = -\\frac{d}{dt}\\big[BA\\cos\\theta\\big]$$ .$A$ is the area of the loop .$\\theta$ is the angle between .$\\vec B$ and .$\\vec A$ Since .$\\omega = d\\theta/dt \\Longrightarrow \\theta = \\theta_0 + \\omega t$, we choose .$\\theta_0 = 0$ so $$\\mathscr{E} = - N BA \\frac{d}{dt}(\\cos(\\omega t)) = N BA \\omega \\sin (\\omega t)$$ .$N$ is the number of loops in the rotating coil, assumed to be .$1$ unless stated otherwise Thus, the output wave is sinusoidal Amplitude .$\\mathscr{E}_0 = NBA\\omega$ .$\\mathscr{E}_\\text{rms} = \\frac{\\mathscr{E}_0}{\\sqrt{2}}$ .$f = \\omega / 2\\pi$ .$\\text{60 Hz}$ for USA + Canada, .$\\text{50 Hz}$ for EU - dc generators - Same for ac, except the slip rings are replaced by split-ring commutators (just like a dc motor) - The curve output becomes more smooth by placing a capacitor in parallel with the output - More commonly, is the use of many armature windings - A capacitor tends to store charge and, if the time constant .$RC$ is long enough, helps to smooth out the voltage as shown in the figure to the right. \u003e ![DC Generator](/docs/physics-7b/imgs/29/dc-gen.png) \u003e (a) A dc generator with one set of commutators, and (b) a dc generator with many sets of commutators and windings. 29–6 Transformers and Transmission of Power # Transformer: Device used to increase or decrease an ac voltage Made up of two coils know as the primary and secondary coil Primary is the input, secondary is the output These can be interwoven (with insulated wire); or can be linked by an iron core that\u0026rsquo;s laminated We assume energy losses (in resistance and hysteresis) can be ignored When an ac voltage is applied to the primary coil, the changing magnetic field it produces will induce an ac voltage of the same .$f$requency in the secondary coil However, secondary voltage, .$V_S$, changes according to the number of turns or loops in each coil: $$V_S = N_S \\frac{d\\Phi_B}{dt}$$ .$N_S$ is the number of turns in the secondary coil .$\\Phi_B/dt$ is the rate at which the magnetic flux changes through each coil The input voltage, .$V_P$, is related to this rate too: $$V_P = N_P \\frac{d\\Phi_B}{dt}$$ .$N_P$ is the number of turns in the primary coil This follows because the changing flux produce a back emf, .$N_P\\ d\\Phi_B / dt$, in the primary that exactly balances the applied voltage .$V_P$ This is because of Kirchhoff\u0026rsquo;s rules This is only the case if the resistance of the primary can be ignored (which we assume) Then, we can divide these two equations, assuming little or no flux loss, to find $$\\frac{V_S}{V_P} = \\frac{N_S}{N_P}$$ .$V_S$ and .$V_P$ can be the rms or peak values for both Step-up (.$N_S \u0026gt; N_P$) increase voltage; step-down (.$N_S \u0026lt; N_P$) decrease This is called the transformer equation which tells us how the secondary (output) is related to the primary (input) DC voltages don\u0026rsquo;t work in a transformer because there\u0026rsquo;d be no change in magnetic flux But muh conservation of energy! Power output is essentially the power input since transformers tend to be 99%+ efficient The little amount of energy lost is to heat Since .$P = IV$ and .$P_P \\approx P_S$, we have $$I_P V_P = I_S V_S \\Longrightarrow \\frac{I_S}{I_P} = \\frac{V_S}{V_P} = \\frac{N_P}{N_S}$$ 29–7 A Changing Magnetic Flux Produces an Electric Field # A changing magnetic flux produces an electric field This applies not only to wires and other conductors, but is a general result that applies to any region in space An electric field will be produced (induced) at any point in space where theres is a changing magnetic field These electric fields are not static, as are the electric fields due to electric charges at rest Faraday\u0026rsquo;s Law \u0026ndash; General Form # $$ \\mathscr{E} = \\oint \\vec E \\cdot d \\vec l = - \\frac{d\\Phi_B}{dt}$$\nThe first two terms come from the fact that the emf .$\\mathscr{E}$ induced in a circuit is equal to the work done per unit charge by the electric field This is then combined with the relation of a changing magnetic flux to the the field it produces Forces Due to Changing .$\\vec B$ are non-conservative # Electric field lines produced by a changing magnetic field are continuous; they form closed loops That is, while a conservative force (such as a electrostatic magnetic field) integrated over a line integral is zero .$\\big(\\oint \\vec E_\\text{electrostatic} \\cdot d \\vec l = 0\\big)$, the electric field created by an magnetic field is not zero: .$\\oint \\vec E_\\text{non-static} \\cdot d \\vec l = - \\frac{d\\Phi_B}{dt}$ This implies that forces due to changing magnetic fields are non-conservative and we can\u0026rsquo;t define a potential energy (or even a potential function!) at a given point in space "},{"id":59,"href":"/physics-7b/30/","title":"30: Inductance, Electromagnetic Oscillations, \u0026 AC Circuits","section":"Physics 7B","content":" 30.1 Mutual Inductance # When two wires are near one another, they induce an emf in one another This emf is proportional to the rate of change of the flux passing through it The flux passing through the coil is generated by the other coil\u0026rsquo;s current - If the two coils are held in place then the total flux is proportional to the **mutual inductance** $$M = \\frac{N_2 \\Phi_{21}}{I_1}$$ - .$\\Phi_{21}$ is the total flux passing through coil 2 (induced by the current in coil 1, .$I_1$) - .$M$ depends on “geometric” factors such as the size, shape, number of turns, and relative positions of the two coils, and whether a ferromagnetic material is present - The SI unit for mutual inductance is the Henry; .$\\text{1 H = 1 V$\\cdot$s/A = 1$\\Omega \\cdot$s}$ \u003e ![Mutual Inductance](/docs/physics-7b/imgs/30/mutual.png) \u003e A changing current in one coil will induce a current in the second coil. The emf induced in coil 2 due to a change in current 1 can be written now as $$\\mathscr{E_2} = -N_2 \\frac{d\\Phi_{21}}{dt} = -M \\frac{dI_1}{dt}$$ 30.2 Self-Inductance; Inductors # This concept also applies to isolated coils too When a changing current passes through a coil (or solenoid), a changing magnetic flux is produced inside the coil, and this in turn induces an emf in that same coil. This induced emf opposes the change in flux (Lenz\u0026rsquo;s law). If the current through the coil is increasing, the increasing magnetic flux induces an emf that opposes the original current and tends to retard its increase. If the current is decreasing in the coil, the decreasing flux induces an emf in the same direction as the current, thus tending to maintain the original current. If this inductance (coil) is in a circuit, it thus can provide a source of emf, in addition to any battery present or other sources of emf. Self-inductance .$L$ and the emf it induces is given by $$L = \\frac{N\\Phi_B}{I}$$ $$\\mathscr{E} = -N \\frac{d\\Phi_B}{dt} = -L \\frac{dI}{dt}$$ An ac circuit always contains some inductance, but often it is quite small unless the circuit contains a coil of many loops or turns. A coil that has significant self-inductance .$L$ is called an inductor Inductance can serve a useful purpose in certain circuits, but it\u0026rsquo;s often just a nuisance in a circuit. If inductance is large, the change in the current will be small, and therefore the current itself if it is ac will be small. The greater the inductance, the less the ac current. An inductance thus acts something like a “resistance” to impede the flow of alternating current. Solenoid Self-Inductance # The magnetic field of a solenoid is .$B = \\mu_0 nI$ where .$n = N/l$ Thus, the flux is .$\\Phi_B = BA = \\mu_0 NIA/l$ so we can derive $$L = \\frac{N \\Phi_B}{I} = \\frac{\\mu_0 N^2 A}{l}$$ 30.3 Energy Stored in a Magnetic Field # When an inductor with inductance .$L$ is carrying current .$I$ which is changing at the rate .$dI/dt$, energy is being supplied to the inductor at the rate $$P = I \\mathscr{E} = LI \\frac{dI}{dt}$$ Thus, the work needed to increase the current in an inductor from zero to some .$I$ is $$W = \\int P dt = \\int_0^I LI\\ dI = \\frac{1}{2}LI^2$$ This is also the (potential) energy stored in a conductor when it is carrying current .$I$ Just as the energy stored in a capacitor can be considered to reside in the electric field between its plates, so the energy in an inductor can be considered to be stored in its magnetic field. E.x. the energy stored in a solenoid is $$U = \\frac{1}{2}LI^2 = \\frac{1}{2} \\bigg( \\frac{\\mu_0 N^2 A}{l} \\bigg)\\bigg( \\frac{Bl}{\\mu_0 N}\\bigg)^2 = \\frac{1}{2} \\frac{B^2}{\\mu_0}Al$$ We can think of this energy as residing in the volume enclosed by the windings; .$Al$ Then the energy density (energy per unit volume) is $$u = \\text{energy density} = \\frac{1}{2}\\frac{B^2}{\\mu_0}$$ This equation is analogous to that for an electric field, .$ \\frac{1}{2}ϵE^2$ 30.4 LR Circuits # (a) LR circuit; (b) growth of current when connected to battery.\nAt the instant the switch connecting the battery is closed, the current starts to flow. It is opposed by the induced emf in the inductor because of the changing current. As soon as current starts to flow, there is also a voltage drop across the resistance; .$V = IR$ Hence, the voltage drop across the inductance is reduced and the current increases less rapidly as it approaches .$I_0 = V_0 / R$ as seen in (b) The emfs in the circuit are the battery voltage .$V_0$ and the emf .$\\mathscr{E} = -L (dI/dt)$ in the inductor (which opposes the current) Hence, we can find sum of potential charges around the loop where .$I$ is the current at any instance by using the loop rule: $$V_0 - IR - L \\frac{dI}{dt} = 0 \\Longrightarrow L \\frac{dI}{dt} + RI = V_0$$ We can integrate the later term from .$t = 0, I = 0$ to a later time .$t$ when current is .$I$: $$\\int_0^I \\frac{dI}{V_0 - IR} = \\int_0^t \\frac{1}{L}dt \\Longrightarrow - \\frac{1}{R} \\ln \\bigg( \\frac{V_0 - IR}{V_0} \\bigg) \\frac{t}{L}$$ $$\\dots \\Longrightarrow \\frac{V_0 - IR}{V_0} = e^{- \\frac{Rt}{L}} \\Longrightarrow I = \\frac{V_0}{R}(1-e^{-t/\\tau})$$ .$\\tau = \\frac{L}{R}$ is the time constant: the time required for the current .$I$ to reach 63% of it\u0026rsquo;s maximum value .$V_0/R$ - When the battery is removed from the circuit... - Voltage .$V_0$ becomes zero, so .$L \\frac{dI}{dt} + RI = 0$ - We can integrate this and solve for .$I$ $$\\int_{I_0}^I \\frac{dI}{I} = - \\int_0^t \\frac{R}{L} dt$$ $$\\dots \\Longrightarrow I = I_0 e^{-t/\\tau}$$ - .$\\tau = L/R$ is the time it takes current to decrease to 37% of it's initial ![LC with battery removed](/docs/physics-7b/imgs/30/lr-no-v.png) 30.5 LC Circuits and Electromagnetic Oscillations # Any electric circuit can contain the three basic components: resistance, capacitance, and inductance, in addition to a source of emf. ![](/docs/physics-7b/imgs/30/lc-2.png) - Suppose the adjacent circuit is initially charged so one plate has charge .$Q_0$ and the other .$-Q_0$ and that the potential difference is .$V = Q/C$ - At .$t = 0$ the capacitor immediately begins to discharge. As it does so, the current .$I$ through the inductor increases. We now apply Kirchhoff's loop rule (sum of potential changes around a loop is zero): $$-L \\frac{dI}{dt} + \\frac{Q}{C} = 0$$ Because charge leaves the positive plate on the capacitor to produce the current .$I = dQ/dt$ so we can rewrite the equation as $$\\dots \\Longrightarrow \\frac{d^2 Q}{dt^2} + \\frac{Q}{LC} = 0 \\Longrightarrow Q = Q_0 \\cos(\\omega t + \\phi)$$ .$Q_0$ and .$\\phi$ are constants that depend on the initial conditions .$\\omega t + \\phi$ is in radians. Because we have .$\\phi$, the amplitude isn\u0026rsquo;t .$Q_0$ unless .$\\phi = 0$ .$\\omega = 2\\pi f = \\sqrt{ \\frac{1}{LC} }$ - We can then plug in our sinusoidal equation to find a function for .$I$: $$I = -\\frac{dQ}{dt} = \\omega Q_0 \\sin(\\omega t + \\phi)$$ $$\\dots \\Longrightarrow I_0 \\sin(\\omega t + \\phi)$$ - Energy stored in capacitor: $$U_E = \\frac{1}{2}\\frac{Q^2}{C} = \\frac{Q_0^2}{2C}\\cos^2(\\omega t + \\phi)$$ - Energy stored in magnetic field: $$U_B = \\frac{1}{2}LI^2 = \\frac{Q_0^2}{2C}\\sin^2(\\omega t + \\phi)$$ - Total energy stored: $$U = U_B + U_E = \\frac{Q_0^2}{2C}$$ \u003e ![](/docs/physics-7b/imgs/30/lr-graph.png) \u003e Period: .$T = \\frac{1}{f} = \\frac{2\\pi}{\\omega} = 2\\pi \\sqrt{LC}$ "},{"id":60,"href":"/docs/asamst-20a/","title":"Frank's ASAMST 20A","section":"Docs","content":" Week 1 (January 18 \u0026amp; 20): Introduction to the course. History, Memory, and Racialization # Reading: Tataki, Strangers from a Different Shore, Preface and Ch. 1: “From a Different Shore.”\nWhat is Asian American Studies?\nPanethnicity \u0026ldquo;pan\u0026rdquo; - a conglomeration \u0026ldquo;ethnicity\u0026rdquo; - belonging to a social group Panethnic identity example: Asian American Panethnicity Cultural Literacy One\u0026rsquo;s competency about their implicit biases Reading:\nAngel Island versus Ellis Island Angel Island was the west coast immigration entry point for people coming from the west (mainly Asian migration) Ellis Island was the entry point for many immigrrants from the east (mainly European) \u0026ldquo;Multiculuralism was a find of fear and optimism around how we are a very mixed country and what binds us together is this appreciation of different ethnic backgrounds, but we also assimilate under some cultural practice/viewpoint\u0026rdquo; - Michael Chang\nRon Tataki on Multiculturalism (side note - \u0026ldquo;Reasonable minds may differ\u0026rdquo;)\nWhat is \u0026ldquo;epistemology\u0026rdquo;: Theory of knowledge. Asks the question: \u0026ldquo;How do you know what you know?\u0026rdquo;\nRace is socially constructed\nThrough history socio-econmic, labor, and capital conflicts Any type of social norm is dependent upon contestation between people in the majority and minority. The power is asymmetric: Majority \u0026gt; Minority. Cultual Literacy\nIn studying Asian American history we are learning to understand how we have come to understand American history. What are the source we have been taught? What are the viewpoints presented in the curriculum we have been taught as history? How do we believe in cultural literacy, in that we are literate in a diverse range of viewpoints representing the true multicultural background of the United States? Arthur Schlesinger\u0026rsquo;s The Disuniting of America: Reflections on a Multicultural Country\nA very different view of multiculturalism: The concern of a \u0026ldquo;breaking apart\u0026rdquo; or \u0026lsquo;Balkanization\u0026rsquo; due to conflicts Association with multiculturalism with ethnic conflict Reassertion of national unity around assimilation paradigm The concern of the \u0026ldquo;race problem.\u0026rdquo; The \u0026ldquo;American Creed\u0026rdquo; Schlesinger on \u0026ldquo;disuniting\u0026rdquo; Two different viewpoints: Ron Tataki and Arthur Schlesinger\nDiscussion Questions:\nTakaki’s formulation of multiculturalism aligns with the concept of diversity, equity and inclusion of the 2000’s. How is Diversity related to multiculturalism? What does the term \u0026ldquo;American Exceptionalism\u0026rdquo; mean to you? Schlesinger was a proponent of “American Exceptionalism” the idea that America has provided safe harbor to many different groups of people. And that here in America, class, and lineage are not important. How do Asian Americans fit into these models of diversity, multiculturalism and \u0026ldquo;American Exceptionalism\u0026rdquo; Asian Americans fastest-growing electorate\nA naturalized citizen = someone who immigrated to the U.S. and gained citizenship “More than 11 million will be able to vote this year, making up nearly 5% of the nation’s eligible voters (for this analysis, U.S. citizens ages 18 and older). They are also the only major racial or ethnic group in which naturalized citizens – rather than the U.S. born – make up a majority of eligible voters, according to a Pew Research Center analysis of Census Bureau data.”\nMany Asian Americans have limited English proficiency image Aliens Ineligible for Citizenship and the 14th Amendment\n1790 Immigrration and Nationality Act (INA): Asian Americans were restricted from naturalized citizenship from 1790 into the 1940s and until the 1950\u0026rsquo;s depending on Asian ethnic groups. At the same time the 14th Amendment was passed in 1867 as an important legal tool against discrimination by state and local governments. Included an important clause stating that states cannot treat people differently on the basis of race (now it includes gender) \u0026ldquo;Simply stated, all persons must be treated equally without regard to their race, color, or national origin.\u0026rdquo;\nLegislation in 1965: Effectively ended the immigration restrictions and quotas against many Asian immigrants. Removed race and national origin as a restriction for naturalization. As you move through the readings\u0026hellip;\nConsider what \u0026ldquo;power\u0026rdquo;, \u0026ldquo;agency\u0026rdquo; and \u0026ldquo;contestation\u0026rdquo; mean in the context of the history that you reading. Those who are constructed in history as \u0026ldquo;minority\u0026rdquo; also have agency while those with majority power must contend with the contestationo of majority control. How did the process occur in the U.S.? What are the legal and socio-cultural institutions and practices that result in a given standard of a moment in time, and in change? Racial Formation\nMichael Omi \u0026amp; Howard Winant, Introduction, Racial Formation in the United States. 2014. HO Dynamic-constantly in flux Reproduction of political interests Aligns with the notion that within a diverse society, there will be multiple stakeholders (different groups and persons bringing forth different interests). The social construction around access to property and citizenship. Race is socially constructed: came out from social contestation, geopolitics, etc. Racial formation theory explains the fluidity of racial categories and the interest and forces that shape them. These pieces provide historical examples of how “white” identity came to be legally constructed through court cases and through the socio-economic forces supporting these legal outcomes. Do the courts drive the outcome? Legal institions? 1690: the brewing slave trade 1790: contestation around what “white” meant. Before the slave trade was active, the primary source of labor was young Irish women. Came as indentured servants (a form of labor in which a person is contracted to work without salary for a specific number of years). Example of instability around what being “white” meant. Sociologists Omi and Winant describe the fluidity of racial constructions over time dependent on political interests and socio-economic forces, as \u0026ldquo;racial formation.\u0026rdquo; What is Omi and Winant\u0026rsquo;s concept of \u0026ldquo;common sense\u0026rdquo;? “Common sense” derives from Italian philosopher and political economist Antonio Gramsci’s theories on asymmetry in political power and the interest conflicts that may emerge as a result. I.e. today’s “Common sense” surrounding gender is that gender is a social construct as opposed to one’s sex. Gramsci wrote about hegemony as in “how does power operate when there is one party that maintains much of the mechanisms of culture and state?” You have agency. A consensus that results from an agreement (not so much voluntary, but through negotiation) What is a \u0026ldquo;Race\u0026rdquo; versus an \u0026ldquo;Ethnicity\u0026rdquo;? Consider the challenge of formally categorizing groups:\nThe U.S. Census Bureau uses the term \u0026ldquo;Hispanis\u0026rdquo; Who are \u0026ldquo;Hispanics\u0026rdquo;? Who ae \u0026ldquo;Latinos\u0026rdquo;? Is \u0026ldquo;Asian AMerican\u0026rdquo; a race descriptor? Is \u0026ldquo;Hmong American\u0026rdquo; a race or an ethnicity descriptor? Taki referred to the popular perception of Asian Americans as:\nModel Minority: A trope that gained traction in the 1960s that stresses the prototypical Asian’s high achievement in socioeconomic status and focuses on their culture to explain their “success”; denies racism and other hardships that are experienced by Asian Americans; comparison between one minority group and another Perpetual Foreigner: stereotype in which naturalized and even native-born citizens are perceived by some members of the majority as foreign because they belong to a minority ethnic or racial group. Twin pillars of how Asian Americans are constructed\nHow do these sterotypes and categories affect cultural and legal outcomes for Asian Americans?\nThe Social Construction of Race\nThe idea that race is socially constructed emerged as a response to the view that race is based on biology What does it mean to say that race is not based on biology? Does it mean that there are no biological or genetic bases to difference? What is the difference between difference and race? Blood quantum: the idea that if you have any drop of African American ancestry, in that jurisdiction/state, you are legally classified as black For whites to maintain racial purity, property, power, and perpetuated the classification/segregation of people on the basis of race Class Question: How has federal jurisdiction driven civil rights protections from the time of early Asian immigrants to the U.S. to the 2020s?\nFor example, the Interstate Commerce Act addressed the problem of railroad monopolies by setting guidelines for how the railroads could do business. Insiders and Outsiders\nAs cited in footnote 4 of the U.S. Supreme Court\u0026rsquo;s Carolene Products the Tainted Milk, case: “prejudice directed against discrete and insular minorities may call for “more searching judicial inquiry.”\nEnsured that former slave-holding states would abide by this 14th amendment that said that African Americans had to have citizenship rights Created a legal authority when the former slave-holding states tried to reinstitute some form of slavery Racial formation construction? Sojourners vs. Immigrants\nLabor and capital interests drove demand for cheap labor during U.S. industrialization Push and Pull\nGeopolitical political economic factors Alienation of Migration Guangdong Chinese Women sang\nDear husband, ever since you sojourned. In a foreign land. I\u0026rsquo;ve lost interest in all matters. All day long, I stay inside the bedroom, My brows knitted; ten thousand Thoughts bring me endless remorse, in Grief, in silence. I cannot fall asleep on my lonely pillow.\n1882 Chinese Exclusion Act\nRacialized labor conflict and competition The main landmark that stems from aliens ineligible for citizenship Agency, Resistance and Contestation\nYick Wo v. Hopkins, USC 1996 Provides the basis for the important legal evidence standard of \u0026ldquo;disparate impact\u0026rdquo; Supreme Court said that San Francisco zoning law is in violation of the 14th Amendment 120,000 Americans of Japanese descent on the Western U.S. seaboard were sent to internment camps. 75% of internees were American citizens by birth.\nWeek 2 (January 25 \u0026amp; 27): The racialization of Asian Americans: contemporary images and historical transformations. # Reading: Okihiro, Common Ground, Preface \u0026amp; Ch. 2: “White and Black.”\nClass Question: Okihiro writes in his preface that his book Common Ground is about the \u0026ldquo;creation of the American character and subject.\u0026rdquo;\nWhat does he mean by that?\nthe social construction of the nation Binaries as convenient cognitive and socio-political constructs\nBinaries offer coherence, especially during times of social upheaval. They preserve rule amidst apparaent chaos, and stability amidst rapid change, such as during the late eighteenth, nineteenth, and twntieth centuries (i.e industrial revolution, enlightenment, romanticism). Those periods of American history occasioned social reconstitutions of geographies, race, gender, sexuality and nationality that helped to define and regulate identities, the state, and the social formation. Break out question: What are some modern-day binaries and what socio-political institutions or relationships and hierarchies do they support?\ngender norms, environmental conservation, wealth inequality What are some binary ideas or myths based on the social construction of an East vs. West divide?\nRudyard Kipling The Ballad of East and West, 1889 Oh, East is East, and West is West, and never the twain shall meet, Till Earth and Sky stand presently at God\u0026rsquo;s great Judgment Seat; But there is neither East nor West, Border, nor Breed, nor Birth, When two strong men stand face to face, though they come from the ends of the earth!\nThese poems pervade our perceptions and are descriptors for historical moments in time. They are important signifiers of binaries Model Minority vs. Perpetual Foreigner\nAre these two poles of the social construction of Asian Americans binary? How do they serve to construct the \u0026ldquo;Asian American subject?\u0026rdquo; Korematsu v. United States\n\u0026ldquo;In response to the Japanese attack on Pearl Harbor during World War II, the U.S. government decided to require Japanese-Americans to move into relocation camps as a matter of national security. President Franklin Roosevelt signed Executive Order 9066 in February 1942, two months after Pearl Harbor. A Japanese-American man living in San Leandro, Fred Korematsu, chose to stay at his residence rather than obey the order to relocate. Korematsu was arrested and convicted of violating the order. He responded by arguing that Executive Order 9066 violated the Fifth Amendment. The Ninth Circuit affirmed Korematsu\u0026rsquo;s conviction.\u0026rdquo; - Oyez\nConclusion: The Court ruled against Korematsu. The Court believed that the decision was valid because it was a necessity amid the danger of espionage and sabotage. Common ground vs. Margins as the Mainstream\nOkihiro writes that his book seeks to reject binaries and to advocate for a \u0026ldquo;open, borderless\u0026rdquo; common ground\u0026quot; versus his prior argument that the mainstream norms, rights, values of America were created by the margins. meaning that the margins create the mainstream. Race Conscious Judicial Review and Black/White Paradigm\nRace relations in the United States have rapidly evolved in recent decades however, race scholars often point to a persistent paradigm that views racial difference primarily through the construction of black and white relations. Binarism and Black White as a paradigm\nOkirhiro says that the American race paradigm views race relations in terms of black and white. Separate but Equal: Plessy v. Ferguson (1896)\nLouisiana\u0026rsquo;s Separate Car Act challenged under the 14th Amendment \u0026ldquo;Louisiana enacted the Separate Car Act, which required separate railway cars for blacks and whites. In 1892, Homer Plessy – who was seven-eighths Caucasian – agreed to participate in a test to challenge the Act. He was solicited by the Comite des Citoyens (Committee of Citizens), a group of New Orleans residents who sought to repeal the Act. They asked Plessy, who was technically black under Louisiana law, to sit in a \u0026ldquo;whites only\u0026rdquo; car of a Louisiana train\u0026hellip;When Plessy was told to vacate the whites-only car, he refused and was arrested\u0026hellip;Plessy was convicted.\u0026rdquo; - Oyez\nConclusion: The Court declared the state law constitutional. In essence, segregation did not constitute unlawful discrimination. Constructive blacks\nLaw scholar Frank Wu argues that our legal system construes \u0026ldquo;racial groups as white, blacks, \u0026ldquo;honorary whites or constructive blacks.\u0026rdquo; What does \u0026ldquo;constructive\u0026rdquo; mean? The legal system has treated Asians, mostly as blacks. Applied the same rules to Asians as they would to Blacks. He says historically, the U.S. legal system has treated Asians mostly as \u0026ldquo;constructive blacks.\u0026rdquo; People v. Hall, 1854 (CA state court attributed black status to Asians in enforcing a statue (passed by a legislative body) prohibiting the testimony of blacks, reasoning that \u0026ldquo;blacks\u0026rdquo; was a generic term for all nonwhites). Gong Lum v. Rice, 1927 (USC upheld segregated public schools for Asians connoting no difference between segregation for blacks to those of the \u0026ldquo;yellow races\u0026rdquo;). 1790 Immigration and Naturalization Act revisited\nHeld that only \u0026ldquo;free white persons\u0026rdquo; of \u0026ldquo;good moral character\u0026rdquo; could become naturalized citizens. After the Civil War, African Americans who were former slaves, gained official citizenship status. Ozawa v. U.S., 1922 (USC ruled Japanese American were not white for naturalization but lauded performance of white middle class attributes such as attending Cal, Church, and speaking English at home) U.S. v. Thind., 1923 (USC ruled Asian Indian Immigrants not white for naturalization, noting that though anthropologists deemed Indians \u0026ldquo;Aryan\u0026rdquo; this was not the same in the common sense understanding of a white person) Racial bar for naturalization not lifted until the Immigration and Naturalization Act of 1952 (McCarran-Walter Act), and abolished the race restriction of the 1790 INA, though it retained a quota system for nationalities and regions. Are Asians White or Black? Do the Right Thing, Spike Lee (1989)\nAsians as \u0026ldquo;Middle Man minority\u0026rdquo; i.e. Your grandparents may have businesses in neighborhoods that are African-American or Latinx that are in the grey-economic zone. Asians as Other Non-Whites: Social construction of race\nSystematic racism vs. Individual discrimination Rapid change in federal position over a matter of months Trump Executive Order on Diversity Biden Executive Order on Diversity Biden Executive Order on Asian Americans The 1992 Los Angeles Uprising/Riots L.A. Burning: The Riots 25 Years Later\nThe filmed video of African American Rodney King beating was probably on of the first \u0026ldquo;viral video\u0026rdquo; of police excessive force with serious consequences for race relations. Days after the videotaped beating of Rodney King, a Korean American grocery shop owner, Soon Ja Dul, shot and killed a 15 year African American who she mistook for stealing, and grabbed her sweater and backpack and Harlins punched her. Soon Ja Dul went behind the counter to retrieve a shotgun and shot Harlins in the back of her head. Following the acquittal in April of 1992, of Los Angeles Police Department officers on trial for the beating, Los Angeles experienced six days of civil unrest that resulted in the burning of many businesses, including those in Korea town which is located in and near historically black neighborhoods. The Harlins killing has also been attributed as contributing to civil unrest that occurred after the acquittal. Sa I Gu Sa I Gu (official full version)\nA very specific view of the 1992 Los Angeles Uprising/Riots from the perspective of (mostly) Korean American women who were shop owners Afterthoughts: Where do the views of the witnesses in this movie sit? Can we square the views of the Korean American witnesses here with one of diversity and equity? What racial tensions or divides might exist here between KA and African Americans? Is this a race issue or a class issue? Is this a race issue or an immigration issue? The Cold War Construction of the Model Minority Myth\nWhat does \u0026ldquo;model minority\u0026rdquo; mean? Why Do We Call Asian Americans The Model Minority? | AJ+ Black/White paradigm: Does the \u0026ldquo;model minority\u0026rdquo; stereotype support the black/white paradigm? How does it support an assimilationist paradigm? Scholar Robert Lee says that the stereotype supports a view of minorities compliance with \u0026ldquo;accommodation\u0026rdquo; to assimilationist and status quo norms rather than militancy. Lee describes this as a \u0026ldquo;disjuncture between the newly articulated ideals of racial egalitarianism and the practice of racial discrimination\u0026rdquo; as evidence by the USC\u0026rsquo;s decisions in the Japanese interment cases. Disjuncture?\nWhat does Lee mean by this disjuncture? How is this supposed \u0026ldquo;disjuncture\u0026rdquo; exemplified by Cold War politics? 1966 NYT\u0026rsquo;s Magazine article on \u0026ldquo;Success Store: Japanese American Style,\u0026rdquo; and in December of that year, \u0026ldquo;Success Story of One Minority in the U.S.\u0026rdquo; At a similar moment, U.S. Senator Daniel Patrick Moynihan published the influential Report on the Black Family (1965) which was an attempty to use data and sociological methods to understand poverty and income inequality in the African American community but which used the term \u0026ldquo;tangle of pathology\u0026rdquo; and referenced single parent families in the African American community as a source of the generational poverty. How are these relevant to this idea of \u0026ldquo;disjuncture\u0026rdquo;? Week 3 (February 1 \u0026amp; 3): U.S.-Asia relations and early immigration. # Discussion topics:\nWere al the national/ethnic groups who are considered \u0026ldquo;white\u0026rdquo; today considered \u0026ldquo;white\u0026rdquo; in the 1800\u0026rsquo;s? What was the connection between a person\u0026rsquo;s labor/class status and their racial identity according ot Tataki? What does it mean to \u0026ldquo;perform\u0026rdquo; a racial identity. Are you just who you are racially? Are race relations in the U.S. based on a black and white framework? How do Asian Americans fit into a black and white framework? How do Asian Americans not fit into a black and white framework? What is legal discrimination? What is \u0026ldquo;disparate impact\u0026rdquo; versus \u0026ldquo;intentional motivation\u0026rdquo; or \u0026ldquo;animus\u0026rdquo;? What is \u0026ldquo;color-blind\u0026rdquo; legla doctrine? Overblown with Hope\nGam Saan = \u0026ldquo;gold mountain\u0026rdquo;\n1848 shortly after the discovery of gold at John Sutter\u0026rsquo;s Mill, a young man in Canton China wrote to his brother in Boston, \u0026ldquo;Good many Americans speak of California. Oh! Very rich country! I hear good many Americans and Europeans go there. Oh! They find hold very quickly, so I hear \u0026hellip; I feel as if I should like to go there very much. I think I shall go to California next summer\u0026rdquo;\nImmigrant Labor\nContract Laborers Emigration brokers representing sugar planters provided \u0026ldquo;free passage\u0026rdquo; where immigrants would sign labor contracts with a planter for 5 years with wages, shelter, food and medical care. Free Laborers A credit-ticket system, a broker lends money to a migrant for the ticket for passage. The migrant would pay off the loan with interest out of his earnings in the U.S. Chung Kun Ai on money lending\n\u0026ldquo;One condition of his loan of $60 was that each borrower was to pay back $120 as soon as he was able to do so. In all, grandfather must have helped 70 young men from our village and nearby villages to migrate to North and South American and also Australia.\u0026rdquo;\nGender and Migrant Labor: Chinese traditional Culture, Labor and Capital Strucutres, Geopolitics, and race\nHow did traditional Chinese culture affect the gender demographics of Chinese labor migrants? the wife was in a subordinate positon the wife served as an incentive for their husband to return Hawaii vs. U.S. Mainland\nHawaii encouraged the husband to bring their families over, whereas the U.S. Mainland (California) only wanted the men. Complexity in Chinese immigrants\nHakka did not practice footbinding Hawaii made some efforts to promote migration of Chinese women. \u0026ldquo;A Race so Different from Our Own\u0026rdquo; - Justice Harlan, dissenting, Plessy v. Ferguson\nSegregation under the law\nCitizenship Rights are the primary pivot for access to recognition by government and thus rights attached to citizenship Segregation upheld only separation but negative status associated with slavery Randall Kennedy on One Drop Rule and the complexity of Black identity Early Segregation Historical Milestones\n1790: Immigration and Naturalization Act 1857: Dred Scott v. Sandford 1862: Emancipation Proclamation Executive Order 1865: Civil War ends 1882: Chinese Exclusion Act 1886: Yick Wo v. Hopkins 1889: Chae Chan Ping v. U.S. 1896: Plessy v. Ferguson Dred Scott v. Stafford (1857)\nThe Court denies citizenship on the basis of deference to the political branches. Pre-Civil War the Supreme Court reified negative status of Blacks Court holds Blacks are not citizens and are thus subject to legislative laws on slaves as chattel (property) Plessy v. Ferguson\nA legal caste system based on race is created on a fiction of separate but equal. Post-Civil War Supreme Court, holds that segregation of African Americans and Whites does not violate the Fourteenth Amendment. Harlan’s Dissent raises the contradiction of assumedly not segregating Chinese who are excluded from naturalized citizenship while segregating of African Americans who “fought for the union.” Yick Wo v. Hopkins\nA theory of evidence for systemic discrimination is created. Supreme Court established disparate\u000boutcome (impact) as basis for establishing racial discrimination. Chae Chan Ping v. United States\nSupreme Court held that Chinese Exclusion Act of 1882, passed while Chinese man was abroad, applied and revoked his re-entry permit) With law the past is always in the present\nWhy is Chae Chan Ping relevant today? Plenary Power Doctrine\n\u0026ldquo;The plenary power doctrine protects the federal government from claims that it is violating an individual\u0026rsquo;s constitutional right to equal protection when it imposes discriminatory burdens on non-US citizens.\u0026rdquo; - CUNY School of Law i.e. Congress has \u0026lsquo;planery power\u0026rsquo; over who can enter and exit the U.S. Demographic Complexity/An Explosion of Immigrants\nAsian Immigrants (incomplete) 370,000 \u0026ldquo;arrivals\u0026rdquo; of Chinese to Hawaii and CA from late 1940\u0026rsquo;s and early 1880\u0026rsquo;s. 1880\u0026rsquo;s to about 1910: 400,000 \u0026ldquo;arrivals\u0026rdquo; of Japnese to Hawaii and the West Coast. 1900-1933: 7,000 \u0026ldquo;arrivals\u0026rdquo; of Korean, 7,000 Asian Indian, 180,000 Filipinos to Hawaii and mainland. European Immigrants 1850-1930: 35 million European immigrants. Geoolitics and Push and Pull\nColonialism and internal instability European colnial involvement American colonial involvement Internal instability in the modern nation-state era Labor and Capital Racialization of Labor allegations of unfair wage and job competition increases. War and internal instability in China\nAnglo-Chinese War of 1856-60 Piracy change against British citizen leading to war Ports and missionaries Taiping Rebellion 1850-1864 Christianized Chinese believing brother of Jesus led rebellion across Central and South China, impacting Guangdong in particular. Estimated 10 million deaths. Inequity at home tied to colonialism pushes and pulls Filipinos out\nSpanish-American War of 1898; and resultant Treaty of Paris resulted in U.S. possession of Phillipines. Takaki writes that Filipino peasants found that the rich rice lands they cultivated were becoming owned by wealthy men, turning them into sharecroppers. Immigration Laws and Challenges\nLabor and Capital As Chan notes, colonial administrators needed cheap physical labor for their projects, thus the migrants to such colonies were disproportionately young men. In the U.S. mainland context this resulted in labor competition with European Americans in particular, in the immediate post-Civil War era. Legal Outcomes The Chinese Exclusion Act triggered a range of challenges by Asian Americans, Chinese in particular early on, supported by funds from co-ethnic organizations such as the Chinatown based Chinese Benevolent Association. Citizenship: Assimilation vs. Segregation\nWhat does the exclusion exeprience of Asian Americans (early Chinese in particular) from citizenship say about the segregation of African Americans and vice versa? A \u0026ldquo;neutral principle\u0026rdquo; in the \u0026ldquo;Rule of Law\u0026rdquo; and the assertion of Fourteenth Amendment protections for Carolene Products \u0026lsquo;discrete and insular minorities\u0026rsquo;\u0026rdquo;\nNeutral Principle \u0026ldquo;Rule of Law\u0026rdquo;: Often stated as a broader checks and balances based principle with strong consideration of the authirity of each branch as well as the limitations on such authority. Historically asserted by the judicial branch to avoid ruling on \u0026ldquo;political\u0026rdquo; questions. Fourteenth Amendment As a tool to remedy discrimination, (specifically race early in U.S. history). Carolene Products\u0026rsquo; asserted view that allegations of discrimination against \u0026ldquo;discrete and insular minorities\u0026rdquo; requires close scrutiny by courts. This lead into the standard applied in Korematsu (1944). The American Federation of Labor\u0026rsquo;s \u0026ldquo;Meat vs. Rice: American Manhood vs. Asiatic Cooliesim\u0026rdquo;\nLabor and Capital Conflict Social Construction of Race, Gender, and Class Close tie between rise of American unionism and trade associations with racialization through Samual Gompers-elected first president of the AFl in 1886. AFK-CIO June 17, 2020 \u0026ldquo;Condemning and Combatting Anti-Asian Racism\u0026rdquo; statement\n\u0026ldquo;As a labor movement, we must acknowledge our own painful past on this and other racial justice issues. In 1882, then-American Federation of Labor (AFL) President Samuel Gompers pushed for the passage of the Chinese Exclusion Act, citing the dangers of \u0026ldquo;Asiatic\u0026rdquo; men in an essay published by the AFL and submitted as Senate testimony. Fear among White workers propelled this legislation, the first to bar an entire race from legslly entering the United States.\nThe \u0026ldquo;Citizenship Clause\u0026rdquo;\nSection 1: \u0026ldquo;All persons born or naturalized in the United States and subject to the jurisdiction thereof, are citizens of the United States and of the State wehrein they reside.\u0026rdquo; The Fourteenth Amendment\u0026rsquo;s \u0026ldquo;Citizenship Clause\u0026rdquo;: Asian American citizenship rights tied again to slavery and citizenship rights\nPrior to the 14th Amendment\u0026rsquo;s passage on June 8. 1866: Dred Scott v. Sandford (1857), triggered federal legislative response with Civil Rights Act of 1866, asserting all persons born in U.S. or naturalized were citizens of U.S. and residence state Wong Kim Ark challenges his citizenship exlcusion 1898. Born in the USA: Wong Kim Ark, 1898 Another Chinese Exlcusion Act Case\nGiven the Chinese Exclusion Act of 1882, was a born in the USA person of Chinese descent a citizen? \u0026ldquo;Because Wong was born in the United States and his parents were not “employed in any diplomatic or official capacity under the Emperor of China,” the Citizenship Clause of the Fourteenth Amendment automatically makes him a U.S. citizen.\u0026rdquo; - Oyez\nDiscussion: Week 4 # Major Themes\nEarly Asian Immigration/Emigration Influx of Asians to the U.S. start during the mid-19th century 370,000 Chinese (early 1840s - late 1940s) 400,000 Japanese (1880s) 7,000 Koreans (early 1900s to mid-1900s) 7,000 Asian Indians (early 1800s) (incomplete) Push and Pull Factors\nBy definition: factors that caused large groups to emigrate out of a country and or immigrate to another country. China Push Economic Instability: First Opium Wars (1839 - 1842) Second Opium Wars (1857 - 1859) Internal instability Taiping Rebellion Natural Disasters: Drought in Henan Province (1847) Flooding of Yangtze River Famine in Guangdong (incomplete) Japan\nPush: Economic instability Pull: Job opportunity (i.e. farming, fishing) Philippines\nPush: Internal Instability (i.e. Spanish-American War of 1898 and the Treaty of Paris) Pull: Economic opportunities (incomplete) U.S. taking advantage of early Asian migrants\nCheap labor and capital mostly men cheap physical labor labor competition with European Americans U.S. - Asia Relations\nIn early 19th century, white nativists spread xenophobic propaganda -\u0026gt; Chinese Exclusion Act First law in the U.S. that barred immigration based on race With World War II, President Roosevelt passed Executive Order 9066 Japanese Americans were incarcerated, many of whom were naturalized citizens Current Event 1: How Covid-19 reignited long-standing xenophobia against Asians (Specifically Chinese)\n\u0026ldquo;Forever Foreigner\u0026rdquo; stereotype persists Anti-Chinese Rhetoric from political leaders fuels the fire Violence rates against Asians rose after Covid-19 hit the US (incomplete) Current Event 2: The Model Minority Myth of Asian-American Workers Today\nMany Asian-Americans in workforce; less in higher positions \u0026ldquo;Bamboo Ceiling\u0026rdquo; - glass ceiling for Asian Americans Model Minority Myth: Asians painted as hardworking, smart and faithful but also deeemed workers who lacked the ambition, creativity and confidence that being a leader requires Where do we go from here? Change the qualities of what someone in leadership looks like Give more positions to Asian-Americans What happens when there are more Asian-Amerians in the workplace? Studies show a better environment Current Event 3: Biden-Harris Administration Advances Equality and Opportunity for Asian American, Native Hawaiian, and Pacific Islander (incomplete)\nAdvancing safety for Asian Americans Combating hate and violence COVID-19 Hate Crimes Act Helps local and state law enforcement accurately report hate crimes to the FBI Helps combat the potential language barrier stopping AAPI community members from reporting hate crimes Research and Education (NSF) Advancing Immigration Reform United States Citizenship Act Promoting naturalization Addressing the backlog for U Visa Petitioners Week 4 (February 8 \u0026amp;10): Chinese in the labor market. The context for exclusion: broad changes in the economy and polity of the United States. # The Context for Exclusion\nLabor and Capital Conflicts Intersectional across, race, class, and gender and situated in geopolitics and a pre-existing domestic race politics Early Segregation Historical Milestones\n1790: Immigration and Naturalization Act 1857: Dred Scott v. Sandford 1862: Emancipation Proclamation Executive Order 1865: Civil War ends; Start of Reconstruction 1868: 14th Amendment 1875: Page Act 1877: End of Reconstruction 1882: Chinese Exclusion Act 1886: Yick Wo v. Hopkins 1889: Chae Chan Ping v. U.S. 1896: Plessy v. Ferguson Revisiting: Citizenship: Assimilation vs. Segregtion\nWhat does the exclusion experience of Asian Americans (early Chinese in particular) from citizenship say about the segregation of African Americans and vice versa? Fourteenth Amendment 1868 Reminder\nAll persons born or naturalized in the United States, and subject to the jurisdiction thereof, are citizens of the United States and of the State wherein they reside. No State shall make or enforce any law which shall abridge the privileges or immunities of citizens of the United States; nor shall any State deprive any person of life, liberty, or property, without due process of law; nor deny to any person within its jurisdiction the equal protection of the laws Where does power lie?\nAgency and contestation by “discrete and insular minorities” Revisiting: A ”neutral principle” in the “Rule of Law” and the assertion of Fourteenth Amendment protections for Carolene Products’ FN 4 ”discrete and insular minorities”\nNeutral Principle \u0026ldquo;Rule of Law\u0026rdquo;: Often stated as a broader checks and balances based principle with strong consideration of the authority of each branch as well as the limitations on such authority. Historically asserted by the judicial branch to avoid ruling on ”political” questions. Fourteenth Amendment As a tool to remedy discrimination, (specifically race early in U.S. history). Carolene Products’ asserted view that allegations of discrimination against “discrete and insular minorities” requires close scrutiny by courts. This lead into the standard developed in Korematsu (1944). What Happened to the Women?\nRace and sex sterotypes; Asian women A long history of Asian American (women) activists\nHow does history socially construct mainstream understandings of what it means to be an Asian American female? Prof. Um and Fujino on Asian American activism: Centering Women as Active Subjects of History\nHune writes that one constructive approach to situating Asian American women in history is to view them “as active participants in history and agents of social change, negotiating complex structures of power” Alternative spaces where agency was exercised\nDominant historiography of Asian women focused on issues of work, control of labor by the husband’s family and immigration restrictions but other reasons explain absence of Chinese and Indian women in the U.S. They had “separate lives” with ties to kin, friends, and their own cultural worlds important to them which has been obscured by the dominant telling of history. Little is known; Focus on the family unit as the \u0026ldquo;normative model\u0026rdquo; of migration should be questioned\nMigration of women along with their men “was the exception rather than the rule” Social Construction of Asian Women as “Orientalized Chinese women as passive victims - of culture and patriarchy.” - Hune writes that little is known about the lives of Cantonese, Punjabi migrant women that is likely because many of our images of these women’s lives come from the nine-tenth century writings of European-American missionaries.\nMale preference cultures in China and Punjab \u0026amp;\u000bDivergent economies of the home counties created complexity for class status of women affecting female migration\nEvolving patriarchal relations at a time when migrants from a range of counties (Shunde, Zhongshan, Panyu and Nanhai) became merchants in the Chinese American community while “Sze Yup migrants were often laborers and domestics.” Chinese women presumptively sex workers\nPage Act of 1875 (Sect. 141, 18 Stat. 477, 3 March 1875) A pre-Chinese Exclusion Act exclusionary law specifically based on gender Chinese women immigration early on; Prostitution as ”yellow slavery”\u000bRace, culture and religion\nPage Act introduced by Representative Horace Page to \u0026ldquo;end the danger of cheap Chinese labor and immoral Chinese women” barring “undesirable” immigrants defined as: Forced laborer East Asian women engaged in prostitution Convicts Immigration review and requirements in Hong Kong Wives vs. Prostitutes\nAmerican consul reviewed background of Chinese women applying for immigration from Hong Kong with document and questions: Photographic Identification Official declaration of purpose of emigration and personal morality statement. Review by hospital staff for character review. A multi-level review process from American consul in HK officials back to American consul day of departure. Questions about who fathers and husbands were. Break out Questions\nWas the Page Act protective of trafficked Chinese women or was it exclusionary? What were the domestic and geopolitical factors that played a role in Chinese female sex workers and concubines? What are the factors that may have driven the concern around \u0026ldquo;yellow slavery\u0026rdquo; Class Question\nHow did political and socio-economic conflicts in Asia affect the migration of South Asians to the U.S.? How did political and socio-economic conflicts in Asia affect the migration of Chinese to the U.S.? Hostility and Conflict; Racism and Nativism\nChan notes 7 types of hostility against Asian Americans: Prejudice: preconceived notions based on stereotypes ~ discrimination Economic Discrimination Political Disenfranchisement: often references voting rights Physical Violence Immigration Exclusion Social Segregation Incarceration Geopolitical Drivers to Negative Stereotypes of Chinese\nChan references Stewart Creighton Miller three groups of Americans who\u0026rsquo;s interactions in China propagated sterotypes of Chinese: Diplomats resenting protocols of Chinese Court Merchants upset on limitations for freedom of trade Missionaries concerned about slow rate of Chinese conversion to Christianity Range of CA law excluding Chinese: Criminal Proceedings Act of 1850\nCriminal Proceedings Act of 1850 (later covered civil as well) exclusing testimony of Blacks, \u0026ldquo;Mulattos\u0026rdquo; and Native Americans. \u0026ldquo;The 14th section of the Act of April 16th, 1850, regulating Criminal Proceedings, provides that \u0026lsquo;No black or mulatto person, or Indian, shall be allowed to give evidence in favor of, or against a white man.\u0026rdquo; People v. Hall. CA. (1854)\nWhite prospector killed Chinese miner. While prosecuted for the murder, on appeal the conviction was overturned on the basis that Native Americans came over the Bering Strait from Asia and therefore were \u0026ldquo;Asiatics.\u0026rdquo; Thus, the 1850 Criminal Proceedings Act Applied to \u0026ldquo;the whole of the Mongolian race.\u0026rdquo; This prohibited all non-Whites from testifying against Whites not changed until the 1870\u0026rsquo;s. Judicial Rationale in People v. Hall\nincomplete Chinese Massacre of 1871 Massacre, Los Angeles\nincomplete Rock Springs MAssacre, September 2, 1885\nRock Springs Utah, massacre, 1885: Union Pacific railroad hired former Chinese railroad workers for coal mining work for less wages than White labor. Labor Organization and Race\nKnights of Labor Mainstream history on labor history often passes over its origins in race and immigration exclusion "},{"id":61,"href":"/math-53/trig/","title":"Trig Identities","section":"Math 53","content":" Reciprocal # $$\\sin(x)=\\frac{1}{\\csc(x)}$$ $$\\cos(x)=\\frac{1}{\\sec(x)}$$ $$\\tan(x)=\\frac{\\sin(x)}{\\cos(x)}=\\frac{1}{\\cot(x)}$$ Pythagorean # $$\\sin^2(x) + \\cos^2(x) = 1$$ $$1+\\tan^2(x) = \\sec^2(x)$$ $$1+\\cot^2(x)=\\csc^2(x)$$ Cofunction # $$\\sin\\Big(\\frac{\\pi}{2}-x\\Big) = \\cos(x)$$ $$\\csc\\Big(\\frac{\\pi}{2}-x\\Big) = \\sec(x)$$ $$\\cos\\Big(\\frac{\\pi}{2}-x\\Big) = \\sin(x)$$ $$\\sec\\Big(\\frac{\\pi}{2}-x\\Big) = \\csc(x)$$ $$\\tan\\Big(\\frac{\\pi}{2}-x\\Big) = \\cot(x)$$ $$\\cot\\Big(\\frac{\\pi}{2}-x\\Big) = \\tan(x)$$ Even/Odd # $$ \\sin(-x) = -\\sin(x)$$ $$ \\csc(-x) = -\\csc(x)$$ $$ \\cos(-x) = \\cos(x)$$ $$ \\sec(-x) = \\sec(x)$$ $$ \\tan(-x) = - \\tan(x)$$ $$ \\cot(-x) = -\\cot(x)$$ Bonus fact: .$\\int_{-A}^A \\text{[odd]}(x)\\ dx = 0$; .$\\int_{-A}^A \\text{[even]}(x)\\ dx = \\int_0^A \\text{[even]}(x)\\ dx$ Sum and Difference # $$ \\sin(u \\pm v) = \\sin(u) \\cdot \\cos(v) \\pm \\cos(u) \\cdot \\sin(v)$$ $$ \\cos(u \\pm v) = \\cos(u) \\cdot \\cos(v) \\pm \\sin(u) \\cdot \\sin(v)$$ $$ \\tan(u \\pm v) = \\frac{\\tan(u) \\pm \\tan(v)}{1 \\mp \\tan(u) \\tan(v)}$$\nDouble-Angle # $$ \\sin(2u) = 2 \\sin(u) \\cos(u)$$ $$ \\cos(2u) = 2 \\cos^2(u) - 1$$ $$ ... = 1- 2 \\sin^2(u) $$ $$ ... = \\cos^2(u) - \\sin^2(u) $$ $$ \\tan(2u) = \\frac{2 \\tan(u)}{1 - \\tan^2(u)}$$ Power Reducing # $$\\sin^2(u) = \\frac{1 - \\cos(2u)}{2}$$ $$\\cos^2(u) = \\frac{1 + \\cos(2u)}{2}$$ $$\\tan^2(u) = \\frac{1 - \\cos(2u)}{1 + \\cos(2u)}$$ Sum-to-Product # $$\\begin{align*} \\sin(u) + \\sin(v) \u0026amp;= 2\\sin\\bigg(\\frac{u + v}{2}\\bigg) \\cos\\bigg(\\frac{u - v}{2}\\bigg) \\\\ \\sin(u) - \\sin(v) \u0026amp;= 2\\cos\\bigg(\\frac{u + v}{2}\\bigg) \\sin\\bigg(\\frac{u - v}{2}\\bigg) \\\\ \\cos(u) + \\cos(v) \u0026amp;= 2\\cos\\bigg(\\frac{u + v}{2}\\bigg) \\cos\\bigg(\\frac{u - v}{2}\\bigg) \\\\ \\cos(u) - \\cos(v) \u0026amp;= -2\\sin\\bigg(\\frac{u + v}{2}\\bigg) \\sin\\bigg(\\frac{u - v}{2}\\bigg) \\end{align*}$$\nProduct-to-Sum # $$\\begin{align*} \\sin(u) \\sin(v) \u0026amp;= \\frac{1}{2}\\Big[\\cos(u - v) - \\cos(u + v)\\Big] \\\\ \\sin(u) \\cos(v) \u0026amp;= \\frac{1}{2}\\Big[\\sin(u + v) + \\sin(u - v)\\Big] \\\\ \\cos(u) \\sin(v) \u0026amp;= \\frac{1}{2}\\Big[\\sin(u + v) - \\sin(u - v)\\Big] \\\\ \\cos(u) \\cos(v) \u0026amp;= \\frac{1}{2}\\Big[\\cos(u - v) + \\cos(u + v)\\Big] \\\\ \\end{align*}$$\n"},{"id":62,"href":"/math-53/trig-calc/","title":"Trig Calculus","section":"Math 53","content":" Derivatives # $$\\begin{align*} \\frac{d}{dx} \\tan(x) \u0026amp;= 1 + \\tan^2(x) = \\sec^2(x) \\\\ \\frac{d}{dx} \\csc(x) \u0026amp;= -\\cot(x) \\cdot \\csc(x) \\\\ \\frac{d}{dx} \\sec(x) \u0026amp;= \\frac{\\sin(x)}{\\cos^2(x)} = \\tan(x) \\cdot \\sec(x) \\\\ \\frac{d}{dx} \\cot(x) \u0026amp;= -\\csc^2(x) \\\\ \\frac{d}{dx} \\log_a(x) \u0026amp;= \\frac{1}{x\\cdot \\ln(a)} \\\\ \\frac{d}{dx} a^u \u0026amp;= a^x \\cdot \\ln (a) du \\\\ \\frac{d}{dx} \\sin^2(x) \u0026amp;= \\sin(2x) \\\\ \\frac{d}{dx} \\cos^2(x) \u0026amp;= -\\sin(2x) \\\\ \\frac{d}{dx} \\tan^2(x) \u0026amp;= 2\\tan(x)\\cdot \\sec^2(x) \\end{align*}$$\nIntegrals # $$\\begin{align*} \\int a^x dx \u0026amp;= \\bigg(\\frac{1}{\\ln(a)}\\bigg) a^x + C \\\\ \\int \\tan(x) dx \u0026amp;= -\\ln\\vert \\cos(x) \\vert + C \\\\ \\int \\tan^2(x) dx \u0026amp;= \\tan(x) - x + C \\\\ \\int \\csc(x) dx \u0026amp;= \\ln\\vert \\csc(x) - \\cot(x)\\vert + C = \\ln \\bigg\\vert \\tan\\bigg(\\frac{x}{2}\\bigg)\\bigg\\vert + C \\\\ \\int \\csc^2(x) dx \u0026amp;= -\\cot(x) + C \\\\ \\int \\sec(x) dx \u0026amp;= -\\ln\\vert \\sec(x) + \\tan(x)\\vert + C \\\\ \\int \\sec^2(x) dx \u0026amp;= \\tan(x) + C \\\\ \\int \\cot(x) dx \u0026amp;= \\ln\\vert \\sin(x) \\vert + C \\\\ \\int \\cot^2(x) dx \u0026amp;= -\\cot(x) - x + C \\\\ \\int \\frac{1}{\\sin(ax)\\cos(ax)} \u0026amp;= \\frac{1}{a} \\ln\\vert\\tan(ax)\\vert + C \\\\ \\int \\frac{1}{x\\sqrt{x^2-a^2}} dx \u0026amp;= \\frac{1}{a} \\sec^{-1}\\bigg( \\frac{\\vert x \\vert}{a}\\bigg) + C \\\\ \\int \\frac{1}{\\sqrt{a^2-x^2}} dx \u0026amp;= \\sin^{-1}\\bigg( \\frac{x}{a} \\bigg) + C \\\\ \\int \\frac{1}{a^2 + x^2} dx \u0026amp;= \\frac{1}{a} \\tan^{-1}\\bigg( \\frac{x}{a} \\bigg) + C \\end{align*}$$\nMany more integrals\nTriangle Sub # $$\\begin{align*} \\sqrt{b^2x^2-a^2} \u0026amp;\\Longrightarrow x = \\frac{a}{b}\\cdot\\sec\\theta; \\theta \\in [0, \\pi/2), (\\pi/2, \\pi] \\\\ \\sqrt{a^2-b^2x^2} \u0026amp;\\Longrightarrow x = \\frac{a}{b}\\cdot\\sin\\theta; \\theta \\in [-\\pi/2, \\pi/2] \\\\ \\sqrt{a^2+b^2x^2} \u0026amp;\\Longrightarrow x = \\frac{a}{b}\\cdot\\tan\\theta; \\theta \\in (-\\pi/2, \\pi/2) \\end{align*}$$\n"},{"id":63,"href":"/ap/huge/","title":"AP Human Geography","section":"AP Notes","content":" The content of these notes are solid, but formatting is not since they're exported from Notion. 🗺️ Unit 1 — Thinking Geographically # Developing Understanding\nThis first unit sets the foundation for the course by teaching students how geographers approach the study of places. Students are encouraged to reflect on the “why of where” to better understand geographic perspectives. Many other high school courses ask students to read and analyze data, but for this course, students also apply a spatial perspective when reading and analyzing qualitative and quantitative data. Students learn the ways information from data sources such as maps, tables, charts, satellite images, and infographics informs policy decisions such as voting redistricting or expanding transportation networks. They also learn about how people influence and are influenced by their environment; the resulting impact on topography, natural resources, and climate; and the differences between and consequences of environmental determinism and possibilism. Finally, students are introduced to the language of geography, learning discipline-specific terminology and applying that language to contemporary, real-world scenarios so they can better study population processes and patterns in the next unit.\nBIG IDEA 1 Patterns and Spatial Organization (PSO)\nWhy do geographers study relationships and patterns among and between places? BIG IDEA 2 Impacts and Interactions (IMP) How do geographers use maps to help them discover patterns and relationships in the world? BIG IDEA 3 Spatial Processes and Societal Change (SPS) How do geographers use a spatial perspective to analyze complex issues and relationships? 1.1 Introduction to Maps # IMP 1A Geographers use maps and data to depict relationships of time, space, and scale.\nLearning Objective: Identify types of maps, the types of information presented in maps, and different kinds of spatial patterns and relationships portrayed in maps. Essential Knowledge: Types of maps include reference maps and thematic maps reference maps Serve to display general features of an area Topographic highway, atlas, etc thematic maps Server to display single type of information Types: graduated circle size of circle conveys quantitative statistic Example dot display pattern, distribution, dispersion of data in an area Example choropleth display an average value of data in an area Example Types of spatial patterns represented on maps include absolute and relative distance and direction, clustering, dispersal, and elevation. maps are a special form of model that depicts information in two dimensions and usually on paper. A model is a simplified generalization of something in real life relative distance (scale) Scale: The ratio between the size of an area on a map and he actual size of that same area on the earth\u0026rsquo;s surface Scale gives a frame of reference Representation Factor (RF): 1 inch : 250,000 feet Verbal: One inch represents 250,000 feet Visual |——————|——————| 0 250,000\u0026rsquo; 500,000' direction absolute direction: north south, compass relative direction: left right, forward backwards, up down based on perspective in certain location clustering + dispersal where groups are (not) centered around density vs concentration: Density is the amount of an object within a certain area concentration is how these objects are distributed. Box A the distribution is dispersed. There is a clear cluster of stars in the upper left corner for Box C. Box B has concentrations in the left and right sides Box D has a cluster (though not as clustered as C) in the middle left and one outlier. elevation Hight from set point, typically water level All maps are selective in information; map projections inevitably distort spatial relationships in shape, area, distance, and direction Maps are 1D representations (projection) of a 2D environment, so they\u0026rsquo;ll inherently have distortion Mercator shape: fairly accurate area: distorts area near north and south pole direction: turns curves into straight lines Goode\u0026rsquo;s shape: accurate area: accurate direction: accurate hard to understand Goode\u0026rsquo;s shape: everything slightly distorted outwards from 0\u0026rsquo; 0' area: accurate direction: accurate 1.2 Geographic Data # IMP 1B Geographers use maps and data to depict relationships of time, space, and scale.\nLearning Objective: Identify different methods of geographic data collection. Essential Knowledge: Data may be gathered in the field by organizations or by individuals. Geospatial technologies include geographic information systems (GIS), satellite navigation systems, remote sensing, and online mapping and visualization. Remote sensing: Record area from a distance People have used cameras with airplanes, kites, hot-air balloons, etc. for many years Nowadays use satellites Useful for any area that would be otherwise be difficult to travel record geographic information systems (GIS) merge mapping software with a database to overlay various data layers on a basic map grid Spatial information can come from written accounts in the form of field observations, media reports, travel narratives, policy documents, personal interviews, landscape analysis, and photographic interpretation. 1.3 The Power of Geographic Data # IMP 1C Geographers use maps and data to depict relationships of time, space, and scale.\nLearning Objective: Explain the geographical effects of decisions made using geographical information. Essential Knowledge: Geospatial and geographical data, including data and satellite imagery, are used at all scales for personal, business and organizational, and governmental decision making purposes. Used to measure climate change pollution spreads of fires military survalliance google maps / personal GPS delivering your packages 1.4 Spatial Concepts # PSO-1 Geographers analyze relationships among and between places to reveal important spatial patterns.\nLearning Objective: Define major geographic concepts that illustrate spatial relationships. Essential Knowledge: Spatial concepts include absolute and relative location, space, place, flows, distance decay, time-space compression, and pattern. location + place (same thing) actual position on earth space area that is occupied by something can refer to physical and cultural objects on the surface of earth relative space is concerned with where something is in relation to something else and changes constantly as interrelationships between people, places, and things change absolute space is a measurable area with definite boundaries site physical location of a place situation location of a place based on its relation to other places flows + patterns trends of relationships(?) distance decay The declining degree of acceptance of an idea or innovation with increasing time and distance from its point of origin or source. Example: The number of phone calls made decreases with distance. Greater number of migrants settled at the edge of the country closer to the country of origin, compared to the number settled on the opposite edge of the country. The diminishing evidence of cultural traits by a group of people, if the explanation clearly shows a link to the fact that due to migration there is less contact between the migrants and their home country. Explanatory factor behind distance decay relationship (e.g., travel cost, information availability). time-space compression (decrease in friction of distance) the increasing sense of connectivity that seems to be bringing people closer together even thought their distances are the same. Space time compression is the solution to distance decay because technology (internet,cell phones) is allowing us to communicate more across longer distances. 1.5 Human–Environmental Interaction # PSO-1 Geographers analyze relationships among and between places to reveal important spatial patterns.\nLearning Objective: Explain how major geographic concepts illustrate spatial relationships Essential Knowledge: Concepts of nature and society include sustainability, natural resources, and land use. sustainability the use of the earths renewable and nonrenewable natural resources in ways that ensure resource availability in the future 3 Pillars Environmental Having Conservation, Nonrenewable and renewable resources and Preservation Social Humans need shelter food and clothing to survive so make resources meet those needs Economic Having natural resources; supply and demand Humans take resources that aren\u0026rsquo;t always needed or they take advantage of the resources that we have. But there is a lot of supply and demand and humans don\u0026rsquo;t know how to balance the resources. natural resources Resources that come directly from Earth Need to be used in moderation if they aren\u0026rsquo;t renewable land use to be sustainable, land has to be used efficiently to get enough value but not worked too hard to the point where it looses nutrients Theories regarding the interaction of the natural environment with human societies have evolved from environmental determinism to possibilism. Environmental determinism : The idea that physical environment caused social development Possibilism: (Replaces Environmental Determinism) The idea that environment may limit some human actions, but people have the ability to adapt to their environment 1.6 Scales of Analysis # PSO-1 Geographers analyze relationships among and between places to reveal important spatial patterns.\nLearning Objective: Define scales of analysis used by geographers. Essential Knowledge: Scales of analysis is how information is clustered global — worldwide regional — groups of states, e.g. North America national — single state, e.g. Wisconsin local — city or town, e.g. Middleton Scale is what infomation is shown Learning Objective: Explain what scales of analysis reveal. Essential Knowledge: Patterns and processes at different scales reveal variations in, and different interpretations of, data. To understand individual, local, regional, national, and global interrelationships, geographers compare and contrasts different scale views. Downsides to large scale 1.7 Regional Analysis # SPS 1 Geographers analyze complex issues and relationships with a distinctively spatial perspective\nLearning Objective: Describe different ways that geographers define regions. Essential Knowledge: Regions are defined on the basis of one or more unifying characteristics or on patterns of activity. A region is an area characterized by similarity or by cohesiveness that sets it apart from other areas. Regions allow us to generalize about a common characteristic so we can better group them A region is an area on the earth identified by two common characteristics: physical and political geography. Physical regions are features such as deserts, mountains, and lakes. Political regions by establishing political boundaries like the borders of countries. Some regions are based on culture (language or religion), while physical geography defines others. Types of regions include formal, functional, and perceptual/vernacular Formal (Uniform) Region with high level of consistency in a certain cultural or physical attribute E.g. Dairying region of North America Political boundaries Tropical Regions Functional (Nodal) A region with a node, sometimes a hearth, surrounded by interconnecting linkages. Usually connections relate to trade, communication, transportation, etc. E.g. Cell towers Newspaper Circulation School District Metropolitan Area Perceptual (Vernacular) A region defined by feelings and prejudices that may or may not be true. A construct of one\u0026rsquo;s mental map E.g. Bible belt South Regional boundaries are transitional and often contested and overlapping. Regions of the world can and do overlap such as the areas of Southeast Asia and Asia. Regions also have transitional boundaries like between North Africa and Sub-Saharan Africa Geographers apply regional analysis at local, national, and global scales There is not total agreement, however, among geographers on how all regions are defined. One geographer may place Chad in the region of North Africa, and another would classify Chad as part of Central Africa. Geographers will also use two different terms to describe the same area; the Middle East and Southwest Asia, for example. 👣 Unit 2 — Population and Migration Patterns and Processes # Developing Understanding\nThis unit addresses the patterns associated with human populations. Populations may increase or decrease as a result of a combination of natural changes (births and deaths) and migration patterns (emigration and immigration). Students examine population distributions at different scales—local, national, regional, and global. Population pyramids demonstrate age-sex structures, revealing the growth or decline of generations and allowing geographers to predict economic needs based on reproductive and aging patterns. Students learn about factors that influence changes in population as well as the long- and short-term effects of those population changes on a place’s economy, culture, and politics. For example, environmental degradation and natural hazards may prompt population redistribution at various scales, which in turn creates new pressures on the environment and on cultural, economic, and political institutions. The study of migration patterns allows students to examine factors contributing to voluntary and forced relocation and the impact of these migrating populations on existing settlements. Combined, the concepts and theories encountered in this unit help students develop connections and transfer their learning in upcoming units to course topics such as cultural patterns, the political organization of space, food production issues, natural resource use, and urban systems.\nBIG IDEA 1 Patterns and Spatial Organization (PSO)\nHow does where and how people live impact global cultural, political, and economic patterns? BIG IDEA 2 Impacts and Interactions (IMP) How does the interplay of environmental, economic, cultural, and political factors influence changes in population? BIG IDEA 3 Spatial Processes and Societal Change (SPS) How do changes in population affect a place’s economy, culture, and politics? 2.1 Population Distribution # PSO-1 Understanding where and how people live is essential to understanding global cultural, political, and economic patterns.\nLearning Objective: Identify the factors that influence the distribution of human populations at different scales. Essential Knowledge: Physical factors (e.g., climate, landforms, water bodies) and human factors (e.g., culture, economics, history, politics) influence the distribution of population. physical: humans avoid areas that are dry too dry to plant food lack water for crops + regular consumption wet + hot combination of rain and heat deplete nutrients from soil typically near equator cold + high altitude to rough for easy transportation to cold for crops places considered too harsh for occupancy have diminished over time people like to go to low-lying areas with fertile soil and temperate climate near a river or ocean is good too cultural: economics history politics Factors that illustrate patterns of population distribution vary according to the scale of analysis. Scale of analysis is the level of detail that a map goes into Demography: study of characteristics of human population, varies according to scale 75% of population live on 5% of land 50% of population live in urban areas Land inhabited called ecumene most extreme cases occur at small scales countries vary in size so aren\u0026rsquo;t great for seeing details, but they\u0026rsquo;re better than state Learning Objective: Define methods geographers use to calculate population density. Essential Knowledge: The three methods for calculating population density are arithmetic, physiological, and agricultural. Artihmetic / crude - all people / all land Physiological - all people / agricultural land Agricultural - all farmers / agricultural land Learning Objective: Explain the differences between and the impact of methods used to calculate population density. Essential Knowledge: The method used to calculate population density reveals different information about the pressure the population exerts on the land. High agricultural density implies that farmers aren\u0026rsquo;t extracting the most value from there land (better farmers need less farmers to fully use there land) Low agricultural density implies farmers are very efficient and probably developed High physiological density implies that there is either little farmland or that agricultural land is being used by more and may reach its output limit sooner than a country that has a lower density High arithmetic density implies there are a lot of people in a small area, aka urbanization 2.2 Consequences of Population Distribution # PSO-2 Understanding where and how people live is essential to understanding global cultural, political, and economic patterns.\nLearning Objective: Explain how population distribution and density affect society and the environment. Essential Knowledge: Population distribution and density affects political, economic, and social processes, including the provision of services such as medical care. redistricting / gerrymandering Results provision of services such as medical care those closer to medical services are more likely be able to use them Population distribution and density affect the environment and natural resources; this is known as carrying capacity carrying capacity — how many people an area can support on a sustained basis sustainability 2.3 Population Composition # PSO-2 Understanding where and how people live is essential to understanding global cultural, political, and economic patterns.\nLearning Objective: Describe elements of population composition used by geographers. Essential Knowledge: Patterns of age structure and sex ratio vary across different regions and may be mapped and analyzed at different scales most extreme cases occur at small scales countries vary in size so aren\u0026rsquo;t great for seeing details, but they\u0026rsquo;re better than state age structure older in retirement areas younger in military / college towns helps predict how much money is needed for social services old and young (dependent) require more money to support sex ratio more male in military training camps Learning Objective: Explain ways that geographers depict and analyze population composition. Essential Knowledge: Population pyramids are used to assess population growth and decline and to predict markets for goods and services. a representation of a country’s population displayed by age and gender groups on a bar graph. Normally shows the % of the total pop in 5-year age brackets with youngest at base of pyramid and oldest at the top. The length of the bar represents the % of total pop in that group. Males on left, females on right. Young population (bulge at bottom) Economic Risks Potential for job shortage Shift in workforce and jobs that target young people Social Increasing demand on support for youth Preschools, parks, etc. Health and Education Have to be prepared for childhood diseases Increase spending on family planning programs Middle (bulge in middle) Economic: Not enough upcoming workers Possible automation People work longer (later retirement) Aging population (bulge at top) Economic Transition to tertiary jobs Income tax burden falls on a shrinking workforce Over 65 expect long term expensive healthcare Strain on pension system with fewer paying in Capital flow from aging countries shifting global economic power Social Risks Migration needed to satisfy labor needs 2.4 Population Dynamics # IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\nLearning Objective: Explain factors that account for contemporary and historical trends in population growth and decline. Essential Knowledge: Demographic factors that determine a population’s growth and decline are fertility, mortality, and migration. fertility crude birth rate (CBR) — total live births in a year for every 1,000 people alive in society infant mortality rate (IMR) — annual number of deaths of infants under 1 year of age compared with number of live births Decrease due to (life expectancy too) total fertility rate (TFR) — average number of children a woman will have throughout her childbearing years (15-49) mortality crude death rate (CDR) — total number of deaths in a year for every 1,000 people alive in society life expectancy — number of years expected for a newborn to live migration Geographers use the rate of natural increase and population-doubling time to explain population growth and decline. Natural increase rate (NIR) — Percentage by which a population grows in a year CBR - CDR = NIR Doubling Time — Number of years needed to double the population (assuming a steady rate of growth), is affected by NIR Social, cultural, political, and economic factors influence fertility, mortality, and migration rates. Social + cultural norms when to get married role of genders political laws anti/pro abortion one child policy (China) 2.5 The Demographic Transition Model # IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\nLearning Objective: Explain theories of population growth and decline. Essential Knowledge: The demographic transition model can be used to explain population change over time. explains the rising and falling of NIR over time in a country no country has ever reverted back to a previous stage Stage 1: Hunter-gatherers, scarcity of food Stage 2: Increase in healthcare, still lots of kids Stage 3: Rural to urban, less kids (due to less space / resources in urban area) Stage 4: Developed, stuff balances out Stage 5: Replacement rate isn\u0026rsquo;t enough to sustain population Reasons for population drop off / decrease The epidemiological transition explains causes of changing death rates. stage 1 — prestillence and famine (high CDR): principal cause of death: infectious and parasitic diseases stage 2 — receding pandemic (rapidly declining CDR) factors such as improved sanitation, nutrition, and medicine stage 3 — degenerative disease (moderately declining CDR) decrease in deaths by infectious diseases, increase in deaths by chronic disorders associated with aging stage 4 — delayed degenerative diseases (low but increasing CDR) death by cardiovascular diseases and cancer delayed because of modern medicine (possible) stage 5 evolution: infectious disease microbes adapt around drugs, new strains form poverty: infectious diseases are more prevalent in poor areas due to unsanitary conditions and inability to afford medicine / treatment increased connections: advancements in transportation, e.g. air travel, increases contact as well as urbanization death rates are high during first, the drop off til they level around stage 4 this is due to increase in education and healthcare, as well as contraceptives Jobs Economic Activities Primary: Production of raw materials or natural resource extraction (e.g., agriculture, mining, energy, timber, fishing) Secondary: Processing or refining of natural resources (e.g., manufacturing finished goods, industry, building construction, assembly, factory work, value-added, blue collar) Tertiary: Provision of services (e.g., healthcare, technology, communications, financial, wholesale and retail trade, transportation, personal, professional, business services, white collar) How these patterns change as courtiers develop 2.6 Malthusian Theory # IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\nLearning Objective: Explain theories of population growth and decline. Essential Knowledge: Malthusian theory and its critiques are used to analyze population change and its consequences. Thomas Malthus - proposed in his Essay on the Principle of Population 1798, that the population grows faster than the food supply. He claimed that while population expanded at a geometric or exponential rate, food supply increased arithmetically or linearly. However, the continued evolution of agriculture has continued to provide the world with an adequate amount of food. The problem now is distribution of food, not the actual production of it. Also, the birth rates declined sharply in the latter part of the 20th century, thus the world population expanded to only 6 billion compared to Malthus’s predicted 10. Neo-Malthusians claim that more LDC’s are in stage 2 of the demographic transition than ever before in history, thus putting a larger strain on the food supply. They also modified Malthus’s theory by stating that the population growth is out-stripping not just food production, but a wide variety of resources, such as oil, natural gas, etc. Critics of Malthus claim that population growth stimulates new technology and that as strain is put on any resource, the inventive human being will simply develop an alternative method once it is economically feasible. 2.7 Population Policies # SPS-2 Changes in population have long- and short-term effects on a place’s economy, culture, and politics.\nLearning Objective: Explain the intent and effects of various population and immigration policies on population size and composition. Essential Knowledge: Types of population policies include those that promote or discourage population growth, such as pronatalist, antinatalist, and immigration policies. countries fearing overpopulation may enact Antinatilist policies, e.g. China\u0026rsquo;s child limit countries fearing dipping below the replacement level, to assure the population continues to replace itself, may enact pronatilist policies, e.g. Scandinavian country\u0026rsquo;s proactive ads, or policy encourage immigration (migration in to the country) 2.8 Women and Demographic Change # SPS-2 Changes in population have long- and short-term effects on a place’s economy, culture, and politics.\nLearning Objective: Explain how the changing role of females has demographic consequences in different parts of the world. Essential Knowledge: Changing social values and access to education, employment, health care, and contraception have reduced fertility rates in most parts of the world. social: women have a say in whether or not they want a child economic: women joining the workforce leaves less time for relationships political roles: women in government can enact laws that better represent what women may need healthcare: higher chance of mother and child surviving contraception less likely for \u0026lsquo;accidents\u0026rsquo; Social status change Changing social, economic, and political roles for females have influenced patterns of fertility, mortality, and migration, as illustrated by Ravenstein’s laws of migration. Ravenstein\u0026rsquo;s Laws: Most migrants move only a short distance. Migration proceeds step by step. There is a process of absorption, whereby people immediately surrounding a rapidly growing town move into it and the gaps they leave are filled by migrants from more distant areas, and so on until the attractive force is spent. Migrants going long distances generally go by preference to one of the great centres of commerce or industry. Each current of migration produces a compensating counter-current. Natives of towns are less migratory than those of rural areas Females are more migratory than males within the kingdom of their birth, but males more frequently venture beyond. Most migrants are adults: families rarely migrate out of their country of birth. Large towns grow more by migration than by natural increase. Migration increases in volume as industries and commerce develop and transport improves. The major direction of migration is from the agricultural areas to the centres of industry and commerce. The major causes of migration are economic. Ravensteins laws aren\u0026rsquo;t scientific Are too specificied E.g. short distance occurs in Africa where most migrations is due to wars, while most migration from China is to the US (long) 2.9 Aging Populations # SPS-2 Changes in population have long- and short-term effects on a place’s economy, culture, and politics.\nLearning Objective: Explain the causes and consequences of an aging population. Essential Knowledge: Population aging is determined by birth and death rates and life expectancy. An aging population has political, social, and economic consequences, including the dependency ratio. dependency ratio: ratio of citizens under 15 or 65 and older to those between age 15 and 65 Gives us an idea of how many workers are needed to support the dependent population If the population is aging: Government spending for adult daycare, nursing homes, and home care social services will increase Government spending for education, child welfare, and health services will decrease Why population is aging Reduced Fertility Improved education of women, more women working, delays in starting families Children are an economic liability in MDCs, too expensive to have several, societal norms (1–2 children) Birth control: cost, availability, accessibility, acceptance, quality More urban societies: less need for children to work on farms Government and private pensions reduce “children as pension” Increased Life Expectancy Improved health care (e.g., medicine, facilities, research/knowledge, personnel, technologies, accessibility) Improved lifestyle (e.g., knowledge of health risks, improved diets, technology, nutrition and exercise) Improved food security/availability Less conflict (e.g., less crime, fewer wars) Improved work conditions (e.g., less physically demanding labor, better safety standards) Improved public health (e.g., sanitation, water supply, housing, standard of living) Improved financial security for elderly (e.g., pensions, care facilities) Improved safety standards (e.g., sports, transportation, building codes) Out-migration of Youth Out-migration of youth for better lifestyle (e.g., jobs, security) 2.1 Causes of Migration # IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\nLearning Objective: Explain how different causal factors encourage migration. Essential Knowledge: Migration is commonly divided into push factors and pull factors. push factors — bad stuff in current location famine war no jobs disease violence hate crime overcrowding pull factors — good stuff somewhere else better jobs lower taxes better climate better schools/social services more room low crime Push/pull factors and intervening opportunities/obstacles can be cultural, demographic, economic, environmental, or political. Intervening obstacle — a feature that hinders migration cultural similar culture to home demographic people tend to like to be around similar people (age, race) economic better jobs environmental distance Distance Decay: Says that migrants try to minimize the friction of distance migrants will be more inclined to move to locations closer to them; they will be less interested in moving longer distances has been on the decline Intervening Opportunity\u0026rsquo;s: Idea that migrants will choose a location closer rather than farther if all other factors are the same related to other reasons (time and money go up farther you have to travel) climate (push + pull) oceans/water rugged terrain (intervening obstacles) political social services no war less corruption age 2.1 Forced and Voluntary Migration # IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\nLearning Objective: Describe types of forced and voluntary migration. Essential Knowledge: Forced migrations include slavery and events that produce refugees, internally displaced persons, and asylum seekers types of migration: Immigrant: person entering another country with intention of living there Emigrant: person who is leaving one country with the intention of living in a different country refugee: A person who flees, is displaced, or is forced to leave his or her home country, often due to religion, ethnicity, race, or political belief Reasons IDP — Internally Displaced Person: A person who is forced out of the home region due to war, political, or social unrest, environmental problems, etc. does not cross any international boarders Types of voluntary migrations include transnational, transhumance, internal, chain, step, guest worker, and rural-to-urban. transnational migration across one or more nation transhumance movement between mountains and lowlands, typically practiced by farmers Cyclic Movement: movement that has a closed route repeated annually or seasonally internal permanent move w/in the same country. Interregional migration move from one region to another within country. e.g. from Middleton to North WI boonies Intraregional migration move within one region within one country. e.g. moving apartments in downtown Madison chain migration migration of people to a certain location because family members (or other contacts), typically of the same nationality, previously migrated there Examples must clearly establish a link/transfer of knowledge between the first group of migrants and subsequent groups OR it should be clear that subsequent migrants are from areas of close proximity to the source area of the early migrants, and that they are migrating to the same destination area. step migration to a distant destination that occurs in stages hard to measure / verify e.g. from farm to nearby village to town to city guest worker legal immigrant who has work visa, usually short term typically take unskilled labor jobs risk of them overstaying typically citizens of poor countries who temporarily obtain dangerous low-paying jobs in MDC’s that the permanent citizens refuse to accept. rural-to-urban migration flow going frow rural to urban areas In LDC’s, the migration trend recently has been rural to urban. In MDC’s, the migration trend has been urban to suburban Counterurbanization — net migration from urban to rural areas. This has been a trend in MDC’s, as improved technologies enable people to live farther from their places of employment and still enjoy all the amenities the city offers. However, in the U.S., counterurbanization has stopped because of poor economic conditions in the rural areas. Once again, the trend is from non-metropolitan to metropolitan areas, only now it is characterized by a move into the suburbs rather than the inner city. 2.1 Effects of Migration # IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\nLearning Objective: Explain historical and contemporary geographic effects of migration. Essential Knowledge: Migration has political, economic, and cultural effects. cultural visually see change in landscape Chinatown, mosques, etc. political potentially controversial hate crimes economic typically beneficial fill unskilled labor jobs Migration transition identified by Wilbur Zelinsky consists of changes in a society comparable to the demographic transition. Stage 1 consists of little migration Stage 2 involves international migration Stages 3 and 4 are characterized by internal migration. brain drain may occur due to human capital theory of migration (states that smart people are the ones to leave and seek better job opportunities) smartest/most talented people leave a country, leaving only stupid people benefitial to both countries in-country gets talented labor and capital out-country gets often gets remittances (payments sent from individuals) Quotas — maximum limits on the number of people who could immigrate to the U.S. from a country in 1 year — may encourage illegal immigrants some countries rely on immigration from other countries to stay above the replacement level of 2.1 to assure the population stays even support those who are dependent (under 15, over 65) Normally shows the % of the total pop in 5-year age brackets with youngest at base of pyramid and oldest at the top. The length of the bar represents the % of total pop in that group. ⚱️ Unit 3 - Cultural Patterns and Processes # Developing Understanding\nThe main focus of this unit is on cultural patterns and processes that create recognized cultural identities. Students consider the physical environment to determine the effects of geographical location and available resources on cultural practices. Visuals representing artifacts, mentifacts and sociofacts all shed light on cultural landscapes and how they change over time. Practice in analyzing images of different places at different times for evidence of their ethnicity, language, religion, gender roles and attitudes, and other cultural attributes builds students’ understanding of cultural patterns and processes. This unit also considers from a temporal and spatial perspective how culture spreads, through traditional forces such as colonialism and imperialism and through contemporary influences such as social media. Rather than emphasize the details of cultural practices associated with specific languages and religions, this unit instead focuses on the distribution of cultural practices and on the causes and effects of their diffusion. For example, students might study the distribution of Chinese versus English languages or the diffusion patterns of religions such as Hinduism and Islam, at local, national, or global scales. An understanding of the diffusion of cultural practices provides a foundation for the study of political patterns and processes in the next unit\nBIG IDEA 1 Patterns and Spatial Organization (PSO)\nHow does where people live and what resources they have access to impact their cultural practices? BIG IDEA 2 Impacts and Interactions (IMP) How does the interaction of people contribute to the spread of cultural practices? BIG IDEA 3 Spatial Processes and Societal Change (SPS) How and why do cultural ideas, practices, and innovations change or disappear over time? 3.1 Introduction to Culture # PSO-3 Cultural practices vary across geographical locations because of physical geography and available resources.\nLearning Objective: Define the characteristics, attitudes, and traits that influence geographers when they study culture. Essential Knowledge: Culture comprises the shared practices, technologies, attitudes, and behaviors transmitted by a society. shared practices teaching style events holidays technologies what side of the road we drive on 120/240 volt outlet attitudes how we treat different genders behaviors how we greet one another Social customs originates at a hearth, a center of innovation. Folk customs tend to have anonymous sources, from unknown dates, through multiple hearths Folk music tells stories or conveys information about daily activities. Isolation promotes cultural diversity as a group’s unique customs develop over several centuries. Therefore, folk culture varies widely from place to place at one time. Since most folk culture deals in some way with the lives and habits of its people, the physical environment in which the people act has a tremendous impact on the culture. pop culture generally has a known originator, normally from MDC’s, and results from more leisure time and more capital. Pop music is written by specific individuals for the purpose of being sold to a large number of people. Cultural traits include such things as food preferences, architecture, and land use. Food: the food we eat daily and the food we experience while traveling around the world all depends upon our location often passed throughout generations brings us together; sharable food in US reflects patterns of migration and what we\u0026rsquo;re capable of growing food also shows if there\u0026rsquo;s any (religious) taboos Low meat consumption in Africa and S Asia due to large Hindu population, which don\u0026rsquo;t eat beef because they believe the cow to be sacred Muslim and Judaism prohibited from eating pork Somali clans restrict the consumption of fish Land use: location determines what foods are grown locally and readily available in a particular region of the world certain states are known for certain foods; Jersey tomatoes, Florida oranges, Georgia peaches Architectural trait reflection of our built land scape can explain what was going on at a given time and what resources were available Cultural relativism and ethnocentrism are different attitudes toward cultural difference. relativism looking at culture objectively / holistically believing nothing is right or wrong ethnocentrism viewing other cultures through your own believing that your culture is the norm / superior pride in heritage, devaluation of other groups 3.2 Cultural Landscapes # PSO-3 Cultural practices vary across geographical locations because of physical geography and available resources.\nLearning Objective: Describe the characteristics of cultural landscapes. Essential Knowledge: Cultural landscapes are combinations physical features, agricultural and practices, religious and linguistic characteristics, evidence of sequent occupancy, and other expressions of culture including traditional and postmodern architecture and land-use patterns. Toponyms reflect leaders / people of power / religious figures / in immigrant\u0026rsquo;s native language Religious impact Religious architecture sacred spaces religious symbols Architecture traditional architecture built for elements that impact the area being built on built with materials (abundantly) available post-modern architecture is designed to descriptive / feats of design Sequent Occupance early societies leave their cultural imprint on a place old fashion architecture old-street\u0026rsquo;s names land surveys — how land was parceled / divided square pattern system long-lot (french) housing reflects cultural identities of those who lived there and environmental constraints \u0026ldquo;The cultural landscape is fashioned from a natural landscape by a cultural group. Culture is the agent, the natural area is the medium, the cultural landscape is the result.\u0026rdquo; - Carl Sauer\nGentrification Positive Impacts Negative Impacts How govt can slow down + rpevent Learning Objective: Explain how landscape features and land and resource use reflect cultural beliefs and identities Essential Knowledge: Attitudes toward ethnicity and gender, including the role of women in the workforce; ethnic neighborhoods; and indigenous communities and lands help shape the use of space in a given society. positive attitudes encourage chain migration can lead to subsections of area with high concentration of a particular ethnicity China town little Mexico generally, women are becoming more equal but there\u0026rsquo;s still progress to be made 3.3 Cultural Patterns # PSO-3 Cultural practices vary across geographical locations because of physical geography and available resources.\nLearning Objective: Cultural practices vary across geographical locations because of physical geography and available resources. Essential Knowledge: Regional patterns of language, religion, and ethnicity contribute to a sense of place, enhance placemaking, and shape the global cultural landscape. language dialects phrases ethnicity immigrants shape neighborhoods china town sense of place link Bilingualism Language, ethnicity, and religion are factors in creating centripetal and centrifugal forces. countries need a stronger centripetal force than centrifugal force to stay intact forces and produce regionalism or dissimilarity between people in the same country centripetal exist in a place and don\u0026rsquo;t move — typically people don\u0026rsquo;t wanna or can\u0026rsquo;t leave while push/pull are actively working centripetal forces — together Centripetal forces unify a state (provide stability, strengthen, bind together, create solidarity). culture regligious acceptance ethnic unity and tolerance social equity economic equity just and fair legal system nationalism history — common heritage centrifugal forces — apart (repel) Centrifugal forces divide a state (lead to balkanization/devolution, disrupt internal order, destabilize, weaken). cultural diversity religious differences language ethnic conflict social injustice nationalism legal restrictions physical features economic stratification “White flight” is the rapid fleeing of whites from the cities as black families emigrate out of the ghettos, or as the ghetto expands. It was encouraged by blockbusting. blockbusting- the real estate practice of scaring whites into selling their homes at low prices by telling them that blacks would soon be moving in and causing property values to fall. The real estate agents then turned around and sold the homes at extremely high prices to blacks that were emigrating from the inner city. Apartheid-the physical separation of different races into different geographic areas, i.e. South Africa. The apartheid laws were repealed in 1991 in South Africa, but many years will be needed to erase the legacy of such racist policies. 3.4 Types of Diffusion # IMP**-3 The in**teraction of people contributes to the spread of cultural practices.\nLearning Objective: Define the types of diffusion. Essential Knowledge: Relocation and expansion — including contagious, hierarchical, and stimulus expansion — are types of diffusion Relocation — hearth moves act of people physically moving takes time, typically slow not everyone is going to absorb it term: person who uses a term moves to a new location and continues to use the term in the new location, OR a form of media, in which a term is used, is relocated to a new place and the term is used in the new location. Example: Spread of Christianity, when people moved and brought it with them expansion — hearth stays same place contagious diseases rapid spread term: an individual uses, or individuals use, the new word and then acquaintances (or those in close proximity to them) begin to use the word as well Example: Hinduism spreading throughout the Indian subcontinent hierarchical intent is to spread selectively term: celebrities start to use the new word and then it spreads to others down the social hierarchy OR people in large cities start to use the word and then the word eventually gets to smaller places or media markets, OR Reverse Hierarchical: minority use of the term spreads up the social ladder to majority group(s). spread by choice, often wealth stimulus innovative idea diffuses from its hearth outward, but the original idea is changed by the new adopters Example: Different Menu items from McDonalds around the world. 3.5 Historical Causes of Diffusion # SPS-3 Cultural ideas, practices, and innovations change or disappear over time.\nLearning Objective: Explain how historical processes impact current cultural patterns. Essential Knowledge: Interactions between and among cultural traits and larger global forces can lead to new forms of cultural expression; for example, creolization and lingua franca. lingua franca a language that is informally agreed upon as the language of business and trade Reasons for US being lingua franca / dominant Historical Globalization creolization mix of languages that form its own language native to some group of people vocab from different language pidgin no ones native language usually result of trading between groups of people who don\u0026rsquo;t share the same language Colonialism, imperialism, and trade helped to shape patterns and practices of culture. Colonialism + imperialism The widespread diffusion of English is thanks, in large part, to the colonial practices of the British trade link 3.6 Contemporary Causes of Diffusion # SPS-3 Cultural ideas, practices, and innovations change or disappear over time.\nLearning Objective: Explain how historical processes impact current cultural patterns. Essential Knowledge: Cultural ideas and practices are socially constructed and change through both small-scale and large-scale processes such as urbanization and globalization. These processes come to bear on culture through media, technological change, politics, economics, and social relationships. sense of place is the special perception we have of a certain place based on our feelings, emotion, and associations with that place. also called distinctive culture Placelessness is he loss of a place\u0026rsquo;s unique favor and identity because of standardizing influence of popular culture and globalization Communication technologies, such as the internet and the time-space convergence, are reshaping and accelerating interactions among people; changing cultural practices, as in the increasing use of English and the loss of indigenous languages; and creating cultural convergence and divergence. the internet has united us more pros easier to share + spread culture english is language of the internet, universal cons culture can be easily judged without full context english is prereq and reducing usage of other languages 3.7 Diffusion of Religion and Language # IMP**-3 The** interaction of people contributes to the spread of cultural practices.\nLearning Objective: Explain what factors lead to the diffusion of universalizing and ethnic religions. Essential Knowledge: Language Language families, languages, dialects, world religions, ethnic cultures, and gender roles diffuse from cultural hearths. Diffusion of language families, including Indo-European, and religious patterns and distributions can be visually represented on maps, in charts and toponyms, and in other representations. Religion Hinduism Hearth: Pakistan in ~2300 BCE Because Hinduism is an ethnic religion it primarily diffused via relocation diffusion to India and Nepal Judaism Hearth: Isreal/Palestine in ~1800 BCE Due to persecution from many countries, Judaism has diffused across many countries but is most prominent in Isreal and the United States now. Christianity Hearth: Jerusalem on 1 AD Christianity largely spread due to conquest throughout much of the Roman Empire, and again later on through colonialism. Now it’s the most practiced religion and is most influential in Europe, the Americas, South Africa, and Australia Islam Hearth: Arabian Peninsula/Saudi Arabia in ~600 CE Spread via conquest and trade, concentrated primarily in the Middle East, North Africa, Southwest Asia, and some portions of Southeast Asia Buddhism Hearth: Nepal in ~500 BCE Missionaries and trade helped diffuse Buddhism, and it’s not found in Southeast and East Asia, India, Sri Lanka, and Tibet Religion can identify, unit, or divide a group of people RELIGION IS ARGUABLY THE MOST VOLITALE OF ALL HUMAN RELATIONS AND THE SOURCE OF MOST VIOLENCE THROUGHOUT HISTORY. EUnion forbid any religious symbols such as crucifixes, crosses, etc. on public school walls and calls them a violation of religious and educational freedom Religion is nearly always suppressed in communist countries. Leaders believe that religion has a tendency to upset stability and therefore ban it altogether, though often they just concrete the people’s religious adherence instead of destroying it. Religions have distinct places of origin from which they diffused to other locations through different processes. Practices and belief systems impacted how widespread the religion diffused. Romans came and pushed out Jews, forcing them to diffuse Many religions spread via trade routes Christian countries tended to have many trade routes, so it spread to a range of areas Islamic countries didn\u0026rsquo;t trade very far outside Africa and Asia (a bit to Europe) Buddhism barely diffused from Asia Universalizing religions, including Christianity, Islam, Buddhism, and Sikhism, are spread through expansion and relocation diffusion. Anyone can become a member of a universalizing religion universalizing religion stories often attempt to explain the mystical and there calendar\u0026rsquo;s main purpose in calendars is to commemorate events in the founder’s life, thus the seasons or weather are not central to the structure Christianity, Buddhism, and Islam are the three main Buddhism and Islam are the universalizing religions that place the most emphasis on identifying shrines/holy places. In universalizing religions, the holy places are generally locations at which memorable events happened in the founder’s life, such as Mecca is in Islam because it is Muhammad’s birthplace. Holy places in ethnic religions are often physical features that are closely tied to the religion (For example, in Hindu one of the most important rituals is the bathing of oneself in the Ganges River.) Members actively proselytize, or seek new converts by sending missionaries through the world to spread their beliefs Excluding Hinduism, this shows diffusion of universalizing religions Ethnic religions, including Hinduism and Judaism, are generally found near the hearth or spread through relocation diffusion. Only really spread from generation to generation Ethnic religious creation stories tend to deal with the physical environment and natural events and typically organize their calendars around the seasons, other natural events, or the physical geography Ethnic religions rarely diffuse, and when they do, it is to a small extent Judaism is an exception in that it has diffused widely throughout the years, mainly because its people have had to flee persecution from many areas in the world. Traditional religions subgroup of ethnic practiced by small groups, typically within a village or tribe 3.8 Effects of Diffusion # SPS-3 The interaction of people contributes to the spread of cultural practices.\nLearning Objective: Explain how the process of diffusion results in changes to the cultural landscape Essential Knowledge: Acculturation, assimilation, syncretism, and multiculturalism are effects of the diffusion of culture. Acculturation process of adopting some of the values, customs, and behaviors of the host culture immigrants may adopt the language and a few other customs of the host group but will retain many distinctive customs assimilation Assimilation is the process whereby individuals or groups of differing ethnic heritage are totally absorbed into the dominant culture of a society. The process of assimilating involves taking on the traits of the dominant culture to such a degree that the assimilating group becomes socially indistinguishable from other members of the society. as we become more assimilated, languages become lost syncretism blending of cultures and ideas from different places multiculturalism grouping of various cultures in a certain area can lead to loss of cultural uniqueness, languages, and general \u0026ldquo;sameness\u0026rdquo; — link 🏛️Unit 4 - Political Patterns and Processes # Developing Understanding\nThis unit addresses the political organization of the world. Building on knowledge of populations and cultural patterns learned in previous units, students examine the contemporary political map and the impact of territoriality on political power and on issues of identity for peoples. Students also look at the different types of political boundaries, how they function, and their scale, as they consider both internal and international boundaries. The interplay of political and cultural influences may cause tensions over boundaries to arise, such as sovereign states making claims on what other states consider to be international waters. Students also examine forms of government and how forces such as devolution may alter the functioning of political units and cause changes to established political boundaries. Separatist and independence movements that challenge the sovereignty of political states may arise from economic and nationalistic forces, as seen in Scotland, Northern Ireland, and Spain. The influence of supranational organizations such as the United Nations or European Union and their role in global affairs presents another challenge to nationalist sovereignty. Student understanding of cultural patterns and processes helps inform their understanding of the consequences of centrifugal and centripetal forces.\nBIG IDEA 1Patterns and Spatial Organization (PSO)\nHow do historical and current events influence political structures around the world? BIG IDEA 2 Impacts and Interactions (IMP) How are balances of power reflected in political boundaries and government power structures? BIG IDEA 3Spatial Processes and Societal Change (SPS) How can political, economic, cultural, or technological changes challenge state sovereignty? 4.1 Introduction to Political Geography # PSO-4 The political organization of space results from historical and current processes, events, and ideas.\nLearning Objective: For world political maps: a. Define the different types of political entities. b. Identify a contemporary example of political entities. Essential Knowledge: Independent states are the primary building blocks of the world political map. Types of political entities include nations, nation-states, stateless nations, multinational states, multistate nations, and autonomous and semiautonomous regions, such as American Indian reservations. state: a country and not a political subdivision within the united states, such as Nevada or Maine has sovereignty, boundaries, and a permanent population nations: unified group of people with a common culture Navajo, Roma nation-states: States in which over 90 percent of the population are the same specific culture or group of people A politically organized area in which nation and state occupy the same space. can act as a centripetal factor to those of the same ethnicity as majority Japan, Iceland, Armenia, Bangladesh, Lesotho stateless nations A nationality that is not represented by a state. multinational states states made up of a two or more ethnic groups United states, Canada, China, Russia, India, Brazil multistate nations country with two or more nationalities within its borders (a nation that exists in multiple states) Kurds, French, Basque Buffer state States that are allowed to exist by neighboring states (to help relieve tension between the neighboring states). Mongolia between China and Russia autonomous a group of people or territory are self-governing, thus not under the control of a higher level of government semiautonomous regions a group of people that have some level of automity, but are still controlled by another entity 4.2 Political Processes # PSO-4 Explain the processes that have shaped contemporary political geography.\nLearning Objective: Explain the processes that have shaped contemporary political geography. Essential Knowledge: The concepts of sovereignty, nation-states, and self-determination shape the contemporary world sovereignty internationally recognized exercise of a country\u0026rsquo;s power over its people and territory nation-states URL self-determination the concept that ethnicities have the right to govern themselves can lead to irredentism Colonialism, imperialism, independence movements, and devolution along national lines have influenced contemporary political boundaries. Colonialism when a group of people impose a set of formal controls by the mother country over its colonies or outside territories Colonizers colonize because of Gold — seek monitary gains at (most of the time) any expense God — want to spread there own religion Glory — clout Effects still present today Social unrest typically speak langauge of colonizers French in Northern Africa, English (British) in Southern Africa boundaries expand that aren\u0026rsquo;t physically connected to mother country imperialism the use of military, cultural domination, and or economic sanctions to gain control of a country and its resources boundaries expand from mother country independence movements can result in section breaking off devolution Quizlet the transition of power from the central government to regional governments in a state is done by Altering of a constitution Experiments on new governmental body Internal Division (Ethnocultural, Economic, or Spatial) results in Creation of an independent state Calls for Autonomy can result in section breaking off 4.3 Political Power and Territoriality # PSO-4 Explain the processes that have shaped contemporary political geography.\nLearning Objective: Describe the concepts of political power and territoriality as used by geographers Essential Knowledge: Political power is expressed geographically as control over people, land, and resources, as illustrated by neocolonialism, shatter belts, and choke points. neocolonialism Refers to the economic control that MDCs are sometimes believed to have over LDCs. Through organizations such as the IMF, the MDCs are able to dictate precisely what LDCs economic policies are, or are able to use their economic subsidies to put LDCs industries out of business. shatter belts an area of instability between regions with opposing political and cultural values choke points A geographical land feature such as a valley or water way narrowing causing a decrease in forces making their way through. Territoriality is the connection of people, their culture, and their economic systems to the land. boundaries are set to connect people with same/similar culture and that want to have an economic relation with one anther Stages of Economic Growth and Core Periphery Model (Core-Periphery) Core Periphery Stages of each Reasons for economic location Core-periphery leads to uneven spatial distribution of economic, political, or cultural power 4.4 Defining Political Boundaries # IMP-4.Political boundaries and divisions of governance, between states and within them, reflect balances of power that have been negotiated or imposed.\nLearning Objective: Define types of political boundaries used by geographers. Essential Knowledge: Types of political boundaries (barriers)include relic, superimposed, subsequent, antecedent, geometric, and consequent boundaries. relic boundary that used to exist, but is no longer active / present You can often still see effects of relic boundary even if they aren\u0026rsquo;t there e.g. great wall of China, East and West Germany superimposed boundary imposed by an outside force may not reflect cultural landscape e.g. treaties, Africa during Colonial era subsequent corresponds to group that is there, often regardless of cultural divide boundary set after the settlements of different groups meet often correspond to ecumene wall impacts consequent boundaries A boundary line that coincides with some cultural divide, such as religion or language. E.g. India antecedent pre-existing; most commonly physical features such as rivers, bays, mountains, desserts can potentially be removed with technology road build across dessert whole through mountain geometric straight lines US-Canada boarder because they aren\u0026rsquo;t visible, can lead to conflict Shapes compact round easy defense and communication prorupted or protruded round with a large extension increases access to resources or water/ports elongated long, narrow difficult communication between areas fragmented two or more areas separated by another country or body of water difficult communication perforated totally surrounds another country can abuse country w trade taxes/tariffs landlocked 4.5 The Function of Political Boundaries # IMP-4. Political boundaries and divisions of governance, between states and within them, reflect balances of power that have been negotiated or imposed.\nLearning Objective: Explain the nature and function of international and internal boundaries. Essential Knowledge: Boundaries are defined, delimited, demarcated, and administered to establish limits of sovereignty, but they are often contested. defined Treaty or legal document delimited Drawn on map in agreement demarcated VISUALLY MARKED walls, posts, fence administered the enforcement \u0026amp; maintaining of a boundary by government who can cross? what goods can cross? demarcated? Political boundaries often coincide with cultural, national, or economic divisions. However, some boundaries are created by demilitarized zones or policy, such as the Berlin Conference. most of the time are made to not piss people / countries off if made by a supranational org Land and maritime boundaries and international agreements can influence national or regional identity and encourage or discourage international or internal interactions and disputes over resources. The United Nations Convention on the Law of the Sea defines the rights and responsibilities of nations in the use of international waters, established territorial seas, and exclusive economic zones. UN came up with these zones EEZ is important because you can tax ships that travel and make money Includes islands too which has put pressure / created conflict at some islands South China Sea UN came in because otherwise it was hard to figure out who owned what area and lead to conflicts 4.6 Internal Boundaries # IMP-4.Political boundaries and divisions of governance, between states and within them, reflect balances of power that have been negotiated or imposed.\nLearning Objective: Explain the nature and function of international and internal boundaries. Essential Knowledge: Voting districts, redistricting, and gerrymandering affect election results at various scales. Voting districts subsections in states specifically for voting redistricting occurs once in every 10 years in US after census goal is to be drawn fairer and group like people often results in gerrymandering gerrymandering redistricting in such a way that it favors a political party 4.7 Forms of Governance # IMP-4.Political boundaries and divisions of governance, between states and within them, reflect balances of power that have been negotiated or imposed.\nLearning Objective: Define federal and unitary states. Essential Knowledge: Forms of governance include unitary states and federal states unitary states most power lies in centralized govt areas far away from central power aren\u0026rsquo;t represented equally can pull a country together federal states most power lies in local govt country is split into states / provinces, typically to group like-people can better represent areas Green = Federal Learning Objective: Explain how federal and unitary states affect spatial organization. Essential Knowledge: Unitary states tend to have a more top-down, centralized form of governance, while federal states have more locally based, dispersed power centers. unitary states focus on central government or big city federal states multiple nodal points stateless compact around a center nodal point small boarders 4.8 Defining Devolutionary Factors # SPS-4.Political, economic, cultural, or technological changes can challenge state sovereignty.\nLearning Objective: Define factors that lead to the devolution of states Essential Knowledge: Factors that can lead to the devolution of states include the division of groups by physical geography, ethnic separatism, ethnic cleansing, terrorism, economic and social problems, and irredentism. physical geography if state is physically separated by land, water, etc. ethnic separatism rise of ethnic groups in a state that want there own statehood ethnic cleansing not genocide genocide = killing people ethnic cleansing is moving certain people out political justification Heartland-rimland theory justified eu colonization during 19th century by claiming EU was the heartland and the surrounding territories comprised of the rimland the heartland was well positioned to dominate the world because of the immense size of its mass. since Russia formed the major part of the heartland, Mackinder (creator of theory) influenced politicians of the day to try to limit Russia\u0026rsquo;s expansion by colonizing territories near Russia tl;dr — Politicians used some crappy justification that aligned with the biases to further there agenda domino thoery once a country became communist, the neighboring countries around it were likely to also become communist terrorism goal is to intimidate or coerce a govt to do the terrorists political or social objective serves to pull country apart economic richer areas can want to split off so that they don\u0026rsquo;t have to pay a majority in taxes to people they don\u0026rsquo;t know/relate to social problems due to differences between cultural groups irredentism the goal of a group of people to want to unit with another group of people who share cultural elements with, but are divided by national boundaries can result in civil wars 4.9 Challenges to Sovereignty # SPS-4.Political, economic, cultural, or technological changes can challenge state sovereignty.\nLearning Objective: Explain how political, economic, cultural, and technological changes challenge state sovereignty. political superimposed boarders can lead to people upset economic area wanting less taxes because they\u0026rsquo;re paying an unequal amount terrorist groups attacking transportation / pipes cultural e.g. one group wanting an official language and another group wanting a different official language Essential Knowledge: Devolution occurs when states fragment into autonomous regions; subnational political territorial units, such as those within Spain, Belgium, Canada, and Nigeria; or when states disintegrate, as happened in Sudan and the former Soviet Union. autonomous regions; subnational political territorial units Link E.g. Spain, Belgium, Canada, and Nigeria disintegrate E.g. Sudan and the former Soviet Union Advances in communication technology have facilitated devolution, supranationalism, and democratization. devolution — link supranationalism easier to connect with similar people and want to join them Political, economic, and/or cultural cooperation among national states to promote shared objectives Tendency for states to give up political power to a higher authority in pursuit of common objectives (political, economic, military, environmental) Venture involving multiple national states (two or more, many, several) with a common goal democratization easier to see how much better it is outside your country with internet Global efforts to address transnational and environmental challenges and to create economies of scale, trade agreements, and military alliances help to further supranationalism. economies of scale trade agreements military alliances Supranational organizations—including the United Nations (UN), North Atlantic Treaty Organization (NATO), European Union (EU), Association of Southeast Asian Nations (ASEAN), Arctic Council, and African Union— can challenge state sovereignty by limiting the economic or political actions of member states. international group which the power and influence of member states transcend national boundaries or interest to share in decision making and vote on issues concerning the collective body member states give up some rights for common good of supranational organziation cooperation should resolve conflict sometimes used for collective defense can make economic stuff easier by opening boarders to member states set standards 4.1 Consequences of Centrifugal and Centripetal Forces # SPS-4.Political, economic, cultural, or technological changes can challenge state sovereignty.\nLearning Objective: Explain how the concepts of centrifugal and centripetal forces apply at the state scale. Essential Knowledge: Centrifugal forces may lead to failed states, uneven development, stateless nations, and ethnic nationalist movements. failed states political body that has disintegrated to a point where basic conditions and responsibilities of a sovereign govt no longer function most LDCs uneven development tend to be poor with corrupt govt stateless nations can serve as a centrifugal factor to state they\u0026rsquo;re in united inside there own area typically grouped by ethnic groups ethnic nationalist movements lead to separation movements riots against govt if not adequately represented Centripetal forces can lead to ethnonationalism, more equitable infrastructure development, and increased cultural cohesion. ethnonationalism nationalism of people with common background / language unites people more equitable infrastructure development increased cultural cohesion 🚜Unit 5 — Agriculture and Rural Land-Use Patterns and Processes # Developing Understanding\nThis unit examines the origins of agriculture and its subsequent diffusion. Students learn about the ways agricultural practices have changed over time as a result of technological innovations, such as equipment mechanization and improvements in transportation that create global markets. In addition, they examine the consequences of agricultural practices such as the use of high-yield seeds and chemicals, revisiting the human–environmental relationships studied in Unit 1. Course emphasis on spatial patterns is evident in this unit as students consider the differences in what foods or resources are produced and where they are produced. These agricultural production regions are impacted by economic and technological forces that increase the size of agricultural operations and the carrying capacity of the land. This has in turn created a global system of agriculture and the interdependence of regions of agricultural consumption and production. Student understanding of this global system of agriculture based on government cooperation lays the foundation for a deeper understanding of economic development in the final unit of the course.\nBIG IDEA 1Patterns and Spatial Organization (PSO)\nHow do a people’s culture and the resources available to them influence how they grow food? BIG IDEA 2 Impacts and Interactions (IMP) How does what people produce and consume vary in different locations? BIG IDEA 3Spatial Processes and Societal Change (SPS) What kind of cultural changes and technological advances have impacted the way people grow and consume food? 5.1 Introduction to Agriculture # PSO 5 Availability of resources and cultural practices influence agricultural practices and land-use patterns.\nLearning Objective: Explain the connection between physical geography and agricultural practices. Essential Knowledge: Agricultural practices are influenced by the physical environment and climatic conditions, such as the Mediterranean climate and tropical climates. During the First Agricultural Revolution: Sarted around 11,000 BC Unknown origins / how it happened (before recording of history) Humans radically changed their behavior: Went from hunting/gather life style to settling in to single areas and cultivating the land, planting crops, and raising animals Agriculture is impacted by: Land — cheap, near market + transportation, good quality soil Labor — cheap, skilled (enough), enough quantity Climate — have to meet requirements of crop, enough rain Mediterranean Agriculture: produces grapes and olives (cash crops), alongside citruses and figs — helps attract tourists, contributes to culture still produce cereals, especially wheat for pasta/bread requires warm year-round climate with lots of sunshine and boardering a sea horticulture: growing fruits, veggies, and flowers Intensive farming practices include market gardening, plantation agriculture, and mixed crop/livestock systems. Land: Small — land isn\u0026rsquo;t cheap so only small portions of high quality land is used High yield (food produced) to feed consumers Location: Closest to market Relies on lots of labor and tech (pesticides, fertilizer, etc.) (Oftentimes) variety of products produced — polyculture Examples: market gardening close to market small scale production of cash crops: fruits, vegetables, and flowers (apples, asparagus, cherries, lettuce, mushrooms, tomatoes) sold directly to local consumers. truck farming: truck means \u0026ldquo;barter\u0026rdquo; or \u0026ldquo;exchange\u0026rdquo;, not a physical truck plantation agriculture (cash crop, cashcrop) highly efficient tend to be established in or near the tropics produce a cash crop mixed crop/livestock systems Both animal and crops are farmed in the same area. Most common form of agriculture in US Crops, like maize and soybeans, are grown primarily to feed animals Utilizes crop rotation: cycles various crops and fields left to fallow (naturally grow over) to allow nutrient replenishing China, India, and SE Asia rely on this type of agriculure to double-crop Fit 2 years of harvest in 1 year Extensive farming practices include shifting cultivation, nomadic herding, and ranching. Land: Large Location: Farther from market — land isn\u0026rsquo;t cheap so it\u0026rsquo;s not that great and far away from market Examples: Shifting cultivation (slash-and-burn) vegetation is cut down and then ignited to make the ground more productive low yield / ineffective occurs in tropics More notes Nomadic herding (animal husbandry) based on herding domesticated animals. can result in desertification low yield, but only needs to support tribe/family Ranching commercial grazing of livestock over an extensive area practiced is semi-arid or arid land, where vegetation is too sparse or the soil to too poor to support crops prominent in later 19th century in the American West; on the decline due to low profit margins — more intensive to go into mono farming 5.2 Settlement Patterns and Survey Methods # PSO 5 Availability of resources and cultural practices influence agricultural practices and land-use patterns.\nLearning Objective: Identify different rural settlement patterns and methods of surveying rural settlements. Essential Knowledge: Specific agricultural practices shape different rural land-use patterns. Rural defined as \u0026lt; 2500 residents, and between 1 and 999 person per square mile 3 factors that affect the pattern of rural setllement: The kind of resource/feature that attracts people to the area (forests, farmlands, fields) The transportation method avaliable at the time of settlement (rivers, roads) Role of government policy, especially the land survey system (metes-and-bonds, long lot, rectangle, etc.) Rural settlement patterns are classified as clustered, dispersed, or linear. clustered A clustered rural settlement typically includes homes, barns, tool sheds, and other farm structures, plus personal services, such as religious structures and schools. dispersed characterized by farmers living on individual farms isolated from neighbors rather than alongside other farmers in the area. linear Linear rural settlements feature buildings clustered along a road, river, or dike to facilitate communications. nucleated a number of families live in close proximity to each other, with fields surrounding the collection of houses and farm buildings (e.g., Asian longhouse) Rural survey methods include metes and bounds, township and range, and long lot. Rectangular survey system Also called the Public Land Survey The system was used by the U.S. Land Office Survey to parcel land west of the Appalacian mountains. The system divides land into a series of rectangular parcels. metes and bounds A system of land surveying east of the Appalachian Mountains (EU) It is a system that relies on descriptions of land ownership and natural features such as streams or trees. township and range rectangular land division scheme designed by Thomas Jefferson grid system Intended to disperse settlers evenly across farmlands of the U.S. interior long lot Distinct regional approach to land surveying found in the Canadian Maritimes, parts of Quebec, Louisiana, and Texas designed to give everyone an equal type of land / soil (one person shouldnt get all poor land / land on a road or river / etc.) Land is divided into narrow parcels stretching back from rivers, roads, or canals. 5.3 Agricultural Origins and Diffusions # SPS 5 Agriculture has changed over time because of cultural diffusion and advances in technology.\nLearning Objective: Identify major centers of domestication of plant sand animals. Essential Knowledge: Early hearths of domestication of plants and animals arose in the Fertile Crescent and several other regions of the world, including the Indus River Valley, Southeast Asia, and Central America. Fertile Crescent (Mesopotamia) — 10,000 years ago 1200 years ago it became good for sedentary agriculture In the Middle East that includes most of Iraq (Known as Mesopotamia in the past), Syria, Lebanon, Israel, and the Nile River basin in Egypt. Huang He (Yellow) Valley — 10,000 years ago Flooding of rivers resulted in people settling near them and using them to farm Barley, wheat, lentils, and olives Diffused west to EU + Central Asia Experienced the Primary Revolution later than in the Fertile Crescent/Mesopotamia Nile River Valley — 8,000 years ago Used crop rotation with lagoons and cereals to reduce salt build up Settlements around Nile Indus River Valley — 4,000 years ago Extended from modern-day northeast Afghanistan to Pakistan and northwest India. Important innovations of this civilization include standardized weights and measures, seal carving, and metallurgy with copper, bronze, lead, and tin. Central America. Uncertain time period, but probably happened last Some scholars estimate 2000 BC, but may go up to the discovery of the Americas by the Europeans because some Native Tribes had not progressed to the First Agricultural Revolution by that time Beans, maize (corn), and cotton Diffused North and South Sub-Saharan Africa Sorghum, yams, milet, and rice 10,000 years ago Diffused south Learning Objective: Explain how plants and animals diffused globally. Essential Knowledge: Patterns of diffusion, such as the Columbian Exchange and the agricultural revolutions, resulted in the global spread of various plants and animals. 5.4 The Second Agricultural Revolution # SPS 5 Agriculture has changed over time because of cultural diffusion and advances in technology.\nLearning Objective: Explain the advances and impacts of the second agricultural revolution. Essential Knowledge: New technology and increased food production in the second agricultural revolution led to better diets, longer life expectancies, and more people available for work in factories. Page 105 in Barron\u0026rsquo;s Occurred in 1700\u0026rsquo;s through 1940\u0026rsquo;s (alongside industrial revolution) Advances: Motors, specifically tractors, which further advanced stuff in the 1930\u0026rsquo;s People used crop rotation instead of letting land grow over Where: Happened in Europe and North America Started with horse-drawn hoes in England Outcomes: Surplus of crops in England diffused through EU People ate healthier because more food was available at lower prices Allowed more people to move to cities which led to industrial revolution women needed less kids for farms Farming changed from family to commercial enterprise (agribusiness) that emphasized single crops and profits Vertical integration (contracts between farmer and purchaser) caused farm outputs to increase by 1990s 5.5 The Green Revolution # SPS 5 Agriculture has changed over time because of cultural diffusion and advances in technology.\nLearning Objective: Explain the consequences of the Green Revolution on food supply and the environment in the developing world. Essential Knowledge: The Green Revolution was characterized in agriculture by the use of high-yield seeds, increased use of chemicals, and mechanized farming Machines have replaced human labor New seeds, chemical pesticides, and fertilizers increased yield MDC often get newest tech first The Green Revolution had positive and negative consequences for both human populations and the environment. Started in mid-1970\u0026rsquo;s when scientists developed hybrid higher-yield seeds and new fertilizers to use alongside them. + New seeds and fertilizers diffused from core to periphery countries to help eradicate hunger + China, India, and SE Asia had rice harvests increase + Decrease land devoted to farms + Less expensive food + Reduce poverty + More consistent yield - Many poor farmers couldn\u0026rsquo;t afford new seeds - Africa couldn\u0026rsquo;t take advantage of seeds (there chief foods are millet, sorghum, yams, and cassavas - Increased irrigation, causing environmental damage - Focus on cash crops - Some soil has lost majority of nutrients due to over use - Biodiversity and native food crops have gone down, increased chance of blight 5.6 Agricultural Production Regions # PSO Availability of resources and cultural practices influence agricultural practices and land-use patterns.\nLearning Objective: Explain how economic forces influence agricultural practices Essential Knowledge: Agricultural production regions are defined by the extent to which they reflect subsistence or commercial practices (monocropping or monoculture). Subsistence vs Commercial: Subsistence is : Food grown for the farmer or farmer’s family/kin Food grown for local consumption for village/community market Food NOT grown for commercial purposes/sold for revenue Monocropping or Monoculture — cultivation of a single crop Occurs in mostly commercial farms in MDCs — US in 1950\u0026rsquo;s minimizes risks — climate, cost of inputs like labor or fertilizer, market demand, etc. maximize profits — choice of crop best suited for growing, potential pricing, etc. Supply and demands influences farmers to raise the crops that have high demands Governments disort market influence by subsidizing certain crops (rice in Japan, milk in US) Intensive and extensive farming practices are determined in part by land costs (bid-rent theory). bid-rent: geographical economic theory: refers to how the price and demand on real estate changes as the distance towards the Central Business District (CBD) increases. intensive agriculture: any kind of agriculture activity that involves effective and efficient use of labor on small plots of land to maximize crop yield extensive agriculture: an agricultural system characterized by low inputs of labor per unit land area 5.7 Spatial Organization of Agriculture # PSO Availability of resources and cultural practices influence agricultural practices and land-use patterns.\nLearning Objective: Explain how economic forces influence agricultural practices. Essential Knowledge: Large-scale commercial agricultural operations are replacing small family farms. Occured during 20th century due to larger profits Further notes Complex commodity chains link production and consumption of agricultural products. Von Thunen Technology has increased economies of scale in the agricultural sector and the carrying capacity of the land. More food leads to people spending less time trying to figure out how to eat and shifting to figuring out how to grow / be smarter Technology has lead to intensive farming that has optimized how we use land 5.8 Von Thünen (Thunen) Model # PSO Availability of resources and cultural practices influence agricultural practices and land-use patterns.\nLearning Objective: Describe how the von Thünen model is used to explain patterns of agricultural production at various scales Essential Knowledge: Von Thünen’s model helps to explain rural land use by emphasizing the importance of transportation costs associated with distance from the market; however, regions of specialty farming do not always conform to von Thünen’s concentric rings. The closer the land is to the city, the more expensive it Because perishable items, e.g. Milk, and difficult to transport items must be grown very closely to their market Milkshed is ring around market where dairy farming occurs Weberian theory Sort of not true with advances in transportation and that all land is able to support it\u0026rsquo;s designated task Forest resources (needed for fuel) could be grown and harvested further out than fruits/veggies from the market Market example with automobiles Grain could be harvested even further out because it could be grown, harvested, and stored easily and cheaply until needed Limitations Livestock then could be raised in the outer ring where cheap, larges pastures were pentiful 5.9 The Global System of Agriculture # PSO Availability of resources and cultural practices influence agricultural practices and land-use patterns.\nLearning Objective: Explain the interdependence among regions of agricultural production and consumption Essential Knowledge: Food and other agricultural products are part of a global supply chain. MDCs tend to have access to best tech and get far ahead compared to LDCs LDCs with land arable for certain foods may be funded by MDCs for a specific product that they (MDCs) can\u0026rsquo;t produce Some countries have become highly dependent on one or more export commodities. Country\u0026rsquo;s that have a monopoly on foods can exploit other countries that depend on them If there\u0026rsquo;s a pest+drought+other issue that stops production of producer country from making food, then all dependents are screwed too The main elements of global food distribution networks are affected by political relationships, infrastructure, and patterns of world trade. Tariffs can screw over trade agreements Country\u0026rsquo;s with more infrastructure are more likely to receive investment because its key to exporting goods Core-periphery model applies to agriculture 5.1 Consequences of Agricultural Practices # IMP Agricultural production and consumption patterns vary in different locations, presenting different environmental, social, economic, and cultural opportunities and challenges.\nLearning Objective: Explain how agricultural practices have environmental and societal consequences. Essential Knowledge: Environmental effects of agricultural land use include pollution, land cover change, desertification, soil salinization, and conservation efforts. pollution land cover change desertification overgrazing leads to land being perminent damage to land via erosion of unprotected topsoils soil salinization conservation efforts For rice farming For rice farming For mechanization / wheat farming Agricultural practices—including slash and burn, terraces, irrigation, deforestation, draining wetlands, shifting cultivation, and pastoral nomadism—alter the landscape. terraces creating an embankment (a terrance) at a right angle to sloping land in order to allow water to soak into the soil rather than move down the slope, taking the soil with it irrigation more efficient, developed to keep up with population demand deforestation plantation farming mainly specialize in 1-2 crops mostly in tropics, Latin America, Africa, some Asia Mostly produce prodcuts for sale is MDCs Intensive subsistence with wet rice dominant High agricultural density — lots of farmers, little land must produce enough food for family or small village wet rice: field prep: plow flooding: rain, river, or irrigation transplanting: rice seedling grow on dry land then moveod to flooded field to grow harvest: by hand double cropping: finishing 2 harvests in 1 year Intensive subsistence with wet rice NOT dominant climate prevents growing of rice in some regions where summer preciiptation is too low and/or winters are too harsh wheat, barley, millet, oats, corn, and some cash crops (cotton, flax, hemp) grown small land worked fulley commonly use crop rotation shifting cultivation based on growing crops in different fields on a rotating basis, e.g. Maya in the Yucatan grow maize by rotating fields (on a seven-year cycle) crops include rice, maize, manioc, millet, sorghum, yams, surgercane, veggies fields are cut and burned each year to enrich the soil with nutrients process called swidden or slash-and-burn seeds are planted in time for rainy season cultivated fields are used for two or three years until all nutrients are used critics it should be replaced by a more efficient means defenders say it is the most environmentally sound approach occupies 25% of world\u0026rsquo;s land, but practiced by just 5% of people used to be tradiationally done by village, now mostly private companies being replaced by logging, ranching, and cashcrops (monofarming) pastoral nomadism animals are herded in a seasonal migratory pattern 200+ million pastoralists in the world often cattle, goats, sheet, camels, and reindeer often in arid, marginal alnds — N Africa, Central Asia, Middle east when herds are moved from land to land, it\u0026rsquo;s called transhumance declining in popularity because modern tech can make better use of pastures mining, irrigation, petroleum Societal effects of agricultural practices include changing diets, role of women in agricultural production, and economic purpose. changing diets food security plays a large role in LDCs you can\u0026rsquo;t flourish if you\u0026rsquo;re physical and mental power is spent on getting food maps additional notes role of women in agricultural production economic purpose 5.1 Challenges of Contemporary Agriculture # IMP Agricultural production and consumption patterns vary in different locations, presenting different environmental, social, economic, and cultural opportunities and challenges.\nLearning Objective: Explain challenges and debates related to the changing nature of contemporary agriculture and food-production practices. Essential Knowledge: Agricultural innovations such as biotechnology, genetically modified organisms, and aquaculture have been accompanied by debates over sustainability, soil and water usage, reductions in biodiversity, and extensive fertilizer and pesticide use. biotechnology, genetically modified organisms, and aquaculture technological innovations have led to much higher yield debates over sustainability, soil and water usage, reductions in biodiversity, and extensive fertilizer and pesticide use pesticides kill off good bugs, possibly whipe out entire vital species by accident the majority of the latest tech is avaliable only the core countries, not periphery agricultural diversity has been on the decline, increased chance of blight New, or very old, disease comes back and, because of lack of genetic diversity, most crops highly susciptible Patterns of food production and consumption are influenced by movements relating to individual food choice, such as urban farming, community-supported agriculture (CSA), organic farming, value-added specialty crops, fair trade, local-food movements, and dietary shifts. urban farming community-supported agriculture (CSA) organic farming avoid using synthetic chemical fertilizers and GMOs aim to protect earth and produce safe, healthy food with \u0026ldquo;zero impact\u0026rdquo; on environment value-added specialty crops fair trade local-food movements dietary shifts Most typical citizen is an asian farmer who produces enough to get by MDCs people eat a lot more Cliamte affects what people eat MDCs this is less of an impact due to better tech making shipping faster LDCs can only really eat what is avaliable locally Cultural prefences still dictate diet \u0026lsquo;Fast-food\u0026rsquo; diet Meat consumption: MDCs get 1/3 of protein from meat LDCs get 1/10 of protein from meat, rely more on grains Challenges of feeding a global population include lack of food access, as in cases of food insecurity and food deserts; problems with distribution systems; adverse weather; and land use lost to suburbanization. food access (food insecurity and food deserts problems with distribution systems adverse weather land use lost to suburbanization The location of food-processing facilities and markets, economies of scale, distribution systems, and government policies all have economic effects on food-production practices. 5.1 Women in Agriculture # IMP Agricultural production and consumption patterns vary in different locations, presenting different environmental, social, economic, and cultural opportunities and challenges.\nLearning Objective: Explain geographic variations in female roles in food production and consumption. Essential Knowledge: The role of females in food production, distribution, and consumption varies in many places depending on the type of production involved. Historically, Men gathered the materials and women used these materials to manufacture household objects and maintained there house Obstacles to equality + empowerment Impact of empowerment effects of this women empowerment / equality on population growth effects of this women empowerment / equality on economic development effects of this women empowerment / equality on gender roles in the developing world. "},{"id":64,"href":"/ap/cmech/","title":"AP Physics C: Mechanics","section":"AP Notes","content":" This are very disjoint notes I took long ago. I would recommend using this for practice qs and perhaps equation review after you have a solid understanding of the chapters. My other notes are much more comprehensive, I swear! :) 1. Kinematics # Four Primary Equations # $$\\Delta x=\\frac{1}{2}(v_f-v_i)\\Delta t \\text{ \u0026ndash; no } a$$ $$v_f=v_i+a\\Delta t \\text{ \u0026ndash; no } x$$ $$\\Delta x=v_i \\Delta t+\\frac{1}{2}a \\Delta t^2 \\text{ \u0026ndash; no } v_f$$ $$\\Delta x=v_f \\Delta t-\\frac{1}{2}a \\Delta t^2 \\text{ \u0026ndash; no } v_i$$ $$v_f^2=v_i^2+2a \\Delta x \\text{ \u0026ndash; no } t$$ Used when .$a$cceration is constant Slope and Area # ![/docs/ap/mech/Untitled.png](/docs/ap/mech/Untitled.png) Top is .$x$, middle is .$v$, bottom is .$a$ ![/docs/ap/mech/Untitled-2.png](/docs/ap/mech/Untitled-2.png) Projectile Motion # Half of parabolic flight time: $$t_\\text{top}=\\frac{v_i*\\sin\\theta}{g}$$ Peak in .$y$ direction: $$y_\\text{max}=\\frac{v_i*\\sin^2\\theta}{2g}$$ Distance traveled in .$x$ direction: $$x_\\text{max}=\\frac{v_i*\\sin2\\theta}{g}$$ Desmos tools Projectile motion Displacement, Velocity, and Acceleration Practice # FRQs to study - Graphs ![/docs/ap/mech/Untitled-3.png](/docs/ap/mech/Untitled-3.png) - Changing Acceleration / Velocity ![/docs/ap/mech/Untitled-4.png](/docs/ap/mech/Untitled-4.png) Example Qs 1.![/docs/ap/mech/Untitled-5.png](/docs/ap/mech/Untitled-5.png) ![/docs/ap/mech/Untitled-6.png](/docs/ap/mech/Untitled-6.png) 2.![/docs/ap/mech/Untitled-7.png](/docs/ap/mech/Untitled-7.png) ![/docs/ap/mech/Untitled-8.png](/docs/ap/mech/Untitled-8.png) 3.![/docs/ap/mech/Untitled-9.png](/docs/ap/mech/Untitled-9.png) ![/docs/ap/mech/Untitled-10.png](/docs/ap/mech/Untitled-10.png) 4.![/docs/ap/mech/Untitled-11.png](/docs/ap/mech/Untitled-11.png) ![/docs/ap/mech/Untitled-12.png](/docs/ap/mech/Untitled-12.png) 5.![/docs/ap/mech/Untitled-13.png](/docs/ap/mech/Untitled-13.png) ![/docs/ap/mech/Untitled-14.png](/docs/ap/mech/Untitled-14.png) 6.![/docs/ap/mech/Untitled-15.png](/docs/ap/mech/Untitled-15.png) ![/docs/ap/mech/Untitled-16.png](/docs/ap/mech/Untitled-16.png) 7.![/docs/ap/mech/Untitled-17.png](/docs/ap/mech/Untitled-17.png) ![/docs/ap/mech/Untitled-18.png](/docs/ap/mech/Untitled-18.png) 8.![/docs/ap/mech/Untitled-19.png](/docs/ap/mech/Untitled-19.png) ![/docs/ap/mech/Untitled-20.png](/docs/ap/mech/Untitled-20.png) 1. ![/docs/ap/mech/Untitled-21.png](/docs/ap/mech/Untitled-21.png) ![/docs/ap/mech/Untitled-22.png](/docs/ap/mech/Untitled-22.png) 2. Forces # .$N = \\text{kg m/s}^2$ \u0026ndash; a force of 1N causes a 1kg mass to accelerate at 1ms.$^{-2}$ Normal doesn\u0026rsquo;t always equal mg! Friction # Kinetic friction only acts when the force breaks past the static friction threshold The friction force is always the lesser of .$\\mu \\cdot N$ or the force it\u0026rsquo;s resisting $$F_s \\le \\mu_s \\cdot F_N$$ Spring # $$F_\\text{spring} = -kx$$ $$k=\\frac{\\Delta F}{\\Delta x}$$ Thus, the slope .$\\Delta y / \\Delta x$ of a force vs. distance is .$k$ Centripital # $$F_\\text{centripetal} = \\frac{mv^2}{r}$$\nGravity # $$mg\\sin(θ) = F_\\text{gx} \\text{ \u0026ndash; Acceleration down ramp w/no friction}$$ $$mg\\cos(θ) = F_\\text{gy} \\text{ \u0026ndash; Normal force when no other forces act in the y direction}$$\nPulleys + Atwoods # $$\\text{Acceleration of a Pulley} = \\frac{Mg}{m+M} = \\frac{Mg-\\mu mg}{m+M}$$\nDrag Force # Drag on x-axis: Drag on y-axis: Practice # FRQs to study Drag ![/docs/ap/mech/Untitled-26.png](/docs/ap/mech/Untitled-26.png) Multiple Bodies (pulleys, carts) ![/docs/ap/mech/Untitled-27.png](/docs/ap/mech/Untitled-27.png) Practice Qs 1. ![/docs/ap/mech/Untitled-28.png](/docs/ap/mech/Untitled-28.png) ![/docs/ap/mech/Untitled-29.png](/docs/ap/mech/Untitled-29.png) 2. ![/docs/ap/mech/Untitled-30.png](/docs/ap/mech/Untitled-30.png) ![/docs/ap/mech/Untitled-31.png](/docs/ap/mech/Untitled-31.png) 3. ![/docs/ap/mech/Untitled-32.png](/docs/ap/mech/Untitled-32.png) ![/docs/ap/mech/Untitled-33.png](/docs/ap/mech/Untitled-33.png) 4. ![/docs/ap/mech/Untitled-34.png](/docs/ap/mech/Untitled-34.png) ![/docs/ap/mech/Untitled-35.png](/docs/ap/mech/Untitled-35.png) 1. ![/docs/ap/mech/Untitled-36.png](/docs/ap/mech/Untitled-36.png) ![/docs/ap/mech/Untitled-37.png](/docs/ap/mech/Untitled-37.png) 1. ![/docs/ap/mech/Untitled-38.png](/docs/ap/mech/Untitled-38.png) ![/docs/ap/mech/Untitled-39.png](/docs/ap/mech/Untitled-39.png) 7. ![/docs/ap/mech/Untitled-40.png](/docs/ap/mech/Untitled-40.png) ![/docs/ap/mech/Untitled-41.png](/docs/ap/mech/Untitled-41.png) 8. ![/docs/ap/mech/Untitled-42.png](/docs/ap/mech/Untitled-42.png) ![/docs/ap/mech/Untitled-43.png](/docs/ap/mech/Untitled-43.png) 9. ![/docs/ap/mech/Untitled-44.png](/docs/ap/mech/Untitled-44.png) ![/docs/ap/mech/Untitled-45.png](/docs/ap/mech/Untitled-45.png) 10. ![/docs/ap/mech/Untitled-46.png](/docs/ap/mech/Untitled-46.png) ![/docs/ap/mech/Untitled-47.png](/docs/ap/mech/Untitled-47.png) 11. ![/docs/ap/mech/Untitled-48.png](/docs/ap/mech/Untitled-48.png) ![/docs/ap/mech/Untitled-49.png](/docs/ap/mech/Untitled-49.png) 12. ![/docs/ap/mech/Untitled-50.png](/docs/ap/mech/Untitled-50.png) ![/docs/ap/mech/Untitled-51.png](/docs/ap/mech/Untitled-51.png) 13. ![/docs/ap/mech/Untitled-52.png](/docs/ap/mech/Untitled-52.png) ![/docs/ap/mech/Untitled-53.png](/docs/ap/mech/Untitled-53.png) 14. ![/docs/ap/mech/Untitled-54.png](/docs/ap/mech/Untitled-54.png) ![/docs/ap/mech/Untitled-55.png](/docs/ap/mech/Untitled-55.png) 3. Energy # Work # $$W = \\int F\\ dx = \\vec F_\\parallel \\cdot x = +\\Delta KE = -\\Delta PE = \\int P dt$$\nForce parallel to distance traveled If force is opposing motion and acceleration changes, work stays the same Potential # $$F = -\\frac{dU}{dx}$$\nPotential Energy can only depend on position Negative relation with force indicates that the direction of the force is always towards lower PE Derivation Conservation # Consider the total work done by a force that acts on a particle as the particle moves around a closed path and returns to its starting point. If this total work is zero, we call the force a conservative force. If the total work for the round trip is not zero, we call the force a non-conservative force. Consider the work done by a force that acts on an object as the object moves from an initial position to a final position along any arbitrarily chosen path. If this work is the same for all such paths, we call the force a conservative force. If the work is not the same for all paths, we call the force a non-conservative force. $$\\Delta K + \\Delta U + \\Delta E_\\text{int}= W_\\text{ext}$$\nConservative — NO external forces Mechanical Energy conserved; ME = ME' Gravity, Spring Force Always have a potential energy associated with it Conservative force\u0026rsquo;s magnitude and direction only depend on the object\u0026rsquo;s location, not on how the object is moving Non-conservative — external force present Mechanical Energy lost; ME \u0026gt; ME' Friction, Air resistance (drag) Internal Energy Power # Rate at which work is done $$P=\\frac{dW}{dt}=\\frac{dKE}{dt}=\\frac{W}{t}=\\vec F \\cdot \\vec v$$\nSprings # $$W_\\text{spring}=\\int F_\\text{spring} dx= \\int (-kx)dx = -\\frac{1}{2}kx^2 $$ $$U_\\text{spring} = -W_\\text{spring}=\\frac{1}{2}kx^2$$\nSprings are most compressed in collisions when velocity of both objects are equal Therefore, we can treat the system as inelastic at that moment Steps Equilibrium # Neutral Equilibrium is where the Potential Energy of the object remains constant regardless of position. For example, a ball rolling on a level surface. Stable Equilibrium is where the Potential Energy of the object increases as the position of the object moves away from the equilibrium position and therefore the object naturally returns to the equilibrium position. For example, a water bottle being tipped to the side. Unstable Equilibrium is where the Potential Energy of the object decreases as the position of the object moves away from the equilibrium position and therefore the object naturally moves away from the equilibrium position. For example, a marker being tipped to the side. Practice # Practice Qs 1. ![/docs/ap/mech/Untitled-60.png](/docs/ap/mech/Untitled-60.png) ![/docs/ap/mech/Untitled-61.png](/docs/ap/mech/Untitled-61.png) 2. ![/docs/ap/mech/Untitled-62.png](/docs/ap/mech/Untitled-62.png) ![/docs/ap/mech/Untitled-63.png](/docs/ap/mech/Untitled-63.png) ![/docs/ap/mech/Untitled-64.png](/docs/ap/mech/Untitled-64.png) 3. ![/docs/ap/mech/Untitled-65.png](/docs/ap/mech/Untitled-65.png) ![/docs/ap/mech/Untitled-66.png](/docs/ap/mech/Untitled-66.png) 3. ![/docs/ap/mech/Untitled-67.png](/docs/ap/mech/Untitled-67.png) ![/docs/ap/mech/Untitled-68.png](/docs/ap/mech/Untitled-68.png) 4. ![/docs/ap/mech/Untitled-69.png](/docs/ap/mech/Untitled-69.png) ![/docs/ap/mech/Untitled-70.png](/docs/ap/mech/Untitled-70.png) 4. ![/docs/ap/mech/Untitled-71.png](/docs/ap/mech/Untitled-71.png) ![/docs/ap/mech/Untitled-72.png](/docs/ap/mech/Untitled-72.png) 5. ![/docs/ap/mech/Untitled-73.png](/docs/ap/mech/Untitled-73.png) ![/docs/ap/mech/Untitled-74.png](/docs/ap/mech/Untitled-74.png) 1. ![/docs/ap/mech/Untitled-75.png](/docs/ap/mech/Untitled-75.png) ![/docs/ap/mech/Untitled-76.png](/docs/ap/mech/Untitled-76.png) 7. ![/docs/ap/mech/Untitled-77.png](/docs/ap/mech/Untitled-77.png) ![/docs/ap/mech/Untitled-78.png](/docs/ap/mech/Untitled-78.png) 8. ![/docs/ap/mech/Untitled-79.png](/docs/ap/mech/Untitled-79.png) ![/docs/ap/mech/Untitled-80.png](/docs/ap/mech/Untitled-80.png) 1. ![/docs/ap/mech/Untitled-81.png](/docs/ap/mech/Untitled-81.png) ![/docs/ap/mech/Untitled-82.png](/docs/ap/mech/Untitled-82.png) 10. ![/docs/ap/mech/Untitled-83.png](/docs/ap/mech/Untitled-83.png) ![/docs/ap/mech/Untitled-84.png](/docs/ap/mech/Untitled-84.png) 11. ![/docs/ap/mech/Untitled-85.png](/docs/ap/mech/Untitled-85.png) ![/docs/ap/mech/Untitled-86.png](/docs/ap/mech/Untitled-86.png) 12. ![/docs/ap/mech/Untitled-87.png](/docs/ap/mech/Untitled-87.png) ![/docs/ap/mech/Untitled-88.png](/docs/ap/mech/Untitled-88.png) 1. ![/docs/ap/mech/Untitled-89.png](/docs/ap/mech/Untitled-89.png) ![/docs/ap/mech/Untitled-90.png](/docs/ap/mech/Untitled-90.png) 1. ![/docs/ap/mech/Untitled-91.png](/docs/ap/mech/Untitled-91.png) ![/docs/ap/mech/Untitled-92.png](/docs/ap/mech/Untitled-92.png) 15. ![/docs/ap/mech/Untitled-93.png](/docs/ap/mech/Untitled-93.png) ![/docs/ap/mech/Untitled-94.png](/docs/ap/mech/Untitled-94.png) 16. ![/docs/ap/mech/Untitled-95.png](/docs/ap/mech/Untitled-95.png) ![/docs/ap/mech/Untitled-96.png](/docs/ap/mech/Untitled-96.png) 4. Momentum # Collisions # Elastic — bounce off # KE conserved Momentum conserved (while no unbalanced ext forces) If the final velocity of an object is less than half of the initial velocity of the object (v_i/2), then the object it\u0026rsquo;s colliding with has more mass $$v_1+v_1\u0026rsquo;=v_2+v_2\u0026rsquo;$$ $$v_1\u0026rsquo;=\\frac{m_1-m_2}{m_1+m_2}v_1$$ $$v_2\u0026rsquo;=\\frac{2m_1}{m_1+m_2}v_2$$ Inelastic — Stick # KE lost Momentum conserved (while no unbalanced ext forces) Maximum speed when m \u0026laquo; M Impulse — Force and Time # $$\\vec J = \\int \\vec F dt = \\vec F_\\text{avg} \\Delta t= \\Delta \\vec p = m \\Delta \\vec v$$\nCenter of Mass # When only gravity is acting on a object that is thrown, it will spin (pivot) around the center of mass If you split an object along the center of mass line, both sides aren\u0026rsquo;t equal in mass unless density / form is the same for both. $$x_\\text{cm}=\\frac{\\Sigma(m_ix_i)}{\\Sigma(m)}=\\frac{\\int x \\lambda \\cdot dx}{\\Sigma M}$$ $$v_\\text{cm}=\\frac{\\Sigma(m_iv_i)}{\\Sigma(m)}$$ $$\\Sigma p=mv_\\text{cm}$$ $$\\Sigma F=ma_\\text{cm}$$ Practice # Practice Qs 1. ![/docs/ap/mech/Untitled-98.png](/docs/ap/mech/Untitled-98.png) ![/docs/ap/mech/Untitled-99.png](/docs/ap/mech/Untitled-99.png) 1. ![/docs/ap/mech/Untitled-100.png](/docs/ap/mech/Untitled-100.png) ![/docs/ap/mech/Untitled-101.png](/docs/ap/mech/Untitled-101.png) 1. ![/docs/ap/mech/Untitled-102.png](/docs/ap/mech/Untitled-102.png) ![/docs/ap/mech/Untitled-103.png](/docs/ap/mech/Untitled-103.png) 1. ![/docs/ap/mech/Untitled-104.png](/docs/ap/mech/Untitled-104.png) ![/docs/ap/mech/Untitled-105.png](/docs/ap/mech/Untitled-105.png) ![/docs/ap/mech/Untitled-106.png](/docs/ap/mech/Untitled-106.png) 1. ![/docs/ap/mech/Untitled-107.png](/docs/ap/mech/Untitled-107.png) a. Integrate 0m to 4m ![/docs/ap/mech/Untitled-108.png](/docs/ap/mech/Untitled-108.png) 1. ![/docs/ap/mech/Untitled-109.png](/docs/ap/mech/Untitled-109.png) ![/docs/ap/mech/Untitled-110.png](/docs/ap/mech/Untitled-110.png) 1. ![/docs/ap/mech/Untitled-111.png](/docs/ap/mech/Untitled-111.png) ![/docs/ap/mech/Untitled-112.png](/docs/ap/mech/Untitled-112.png) ![/docs/ap/mech/Untitled-113.png](/docs/ap/mech/Untitled-113.png) ![/docs/ap/mech/Untitled-114.png](/docs/ap/mech/Untitled-114.png) 1. ![/docs/ap/mech/Untitled-115.png](/docs/ap/mech/Untitled-115.png) ![/docs/ap/mech/Untitled-116.png](/docs/ap/mech/Untitled-116.png) 1. ![/docs/ap/mech/Untitled-117.png](/docs/ap/mech/Untitled-117.png) ![/docs/ap/mech/Untitled-118.png](/docs/ap/mech/Untitled-118.png) 1. ![/docs/ap/mech/Untitled-119.png](/docs/ap/mech/Untitled-119.png) ![/docs/ap/mech/Untitled-120.png](/docs/ap/mech/Untitled-120.png) 1. ![/docs/ap/mech/Untitled-121.png](/docs/ap/mech/Untitled-121.png) ![/docs/ap/mech/Untitled-122.png](/docs/ap/mech/Untitled-122.png) 1. ![/docs/ap/mech/Untitled-123.png](/docs/ap/mech/Untitled-123.png) ![/docs/ap/mech/Untitled-124.png](/docs/ap/mech/Untitled-124.png) 1. ![/docs/ap/mech/Untitled-125.png](/docs/ap/mech/Untitled-125.png) ![/docs/ap/mech/Untitled-126.png](/docs/ap/mech/Untitled-126.png) 5. Rotation # Rotational Kinematics # Used when α is constant\n$$ \\Delta \\theta=\\frac{1}{2}(\\omega_f-\\omega_i)\\Delta t \\text{ \u0026ndash; no } \\alpha$$ $$ \\omega_f=\\omega_i+\\alpha\\Delta t \\text{ \u0026ndash; no } \\theta$$ $$\\ \\Delta \\theta=\\omega_i \\Delta t+\\frac{1}{2}\\alpha \\Delta t^2 \\text{ \u0026ndash; no } \\omega_f$$ $$\\ \\Delta \\theta=\\omega_f \\Delta t-\\frac{1}{2}\\alpha \\Delta t^2 \\text{ \u0026ndash; no } \\omega_i$$ $$\\omega_f^2=\\omega_i^2+2\\alpha \\Delta \\theta \\text{ \u0026ndash; no } t$$ Rotational Inertia # Pulleys ![/docs/ap/mech/Untitled-128.png](/docs/ap/mech/Untitled-128.png) with finishing with none+blue same time, then green, then red ![/docs/ap/mech/Untitled-129.png](/docs/ap/mech/Untitled-129.png) ![/docs/ap/mech/Untitled-130.png](/docs/ap/mech/Untitled-130.png) Rolling Down an Incline ![/docs/ap/mech/Untitled-131.png](/docs/ap/mech/Untitled-131.png) ![/docs/ap/mech/Untitled-132.png](/docs/ap/mech/Untitled-132.png) ![/docs/ap/mech/Untitled-133.png](/docs/ap/mech/Untitled-133.png) ![/docs/ap/mech/Untitled-134.png](/docs/ap/mech/Untitled-134.png) Rolling Down an Incline \u0026#43; Slipping ![/docs/ap/mech/Untitled-135.png](/docs/ap/mech/Untitled-135.png) ![/docs/ap/mech/Untitled-136.png](/docs/ap/mech/Untitled-136.png) ![/docs/ap/mech/Untitled-137.png](/docs/ap/mech/Untitled-137.png) Rolling Up an Incline ![/docs/ap/mech/Untitled-138.png](/docs/ap/mech/Untitled-138.png) ![/docs/ap/mech/Untitled-139.png](/docs/ap/mech/Untitled-139.png) ![/docs/ap/mech/Untitled-140.png](/docs/ap/mech/Untitled-140.png) ![/docs/ap/mech/Untitled-141.png](/docs/ap/mech/Untitled-141.png) ![/docs/ap/mech/Untitled-142.png](/docs/ap/mech/Untitled-142.png) Rolling Up an Incline ![/docs/ap/mech/Untitled-138.png](/docs/ap/mech/Untitled-138.png) ![/docs/ap/mech/Untitled-139.png](/docs/ap/mech/Untitled-139.png) ![/docs/ap/mech/Untitled-140.png](/docs/ap/mech/Untitled-140.png) ![/docs/ap/mech/Untitled-141.png](/docs/ap/mech/Untitled-141.png) ![/docs/ap/mech/Untitled-142.png](/docs/ap/mech/Untitled-142.png) Rolling Up an Incline \u0026#43; Slipping ![/docs/ap/mech/Untitled-143.png](/docs/ap/mech/Untitled-143.png) ![/docs/ap/mech/Untitled-144.png](/docs/ap/mech/Untitled-144.png) ![/docs/ap/mech/Untitled-145.png](/docs/ap/mech/Untitled-145.png) Should be Blue \u003e Green \u003e Red (0) Practice Qs # Practice Qs 1. ![/docs/ap/mech/Untitled-146.png](/docs/ap/mech/Untitled-146.png) ![/docs/ap/mech/Untitled-147.png](/docs/ap/mech/Untitled-147.png) 1. ![/docs/ap/mech/Untitled-148.png](/docs/ap/mech/Untitled-148.png) ![/docs/ap/mech/Untitled-149.png](/docs/ap/mech/Untitled-149.png) 1. ![/docs/ap/mech/Untitled-150.png](/docs/ap/mech/Untitled-150.png) ![/docs/ap/mech/Untitled-151.png](/docs/ap/mech/Untitled-151.png) 1. ![/docs/ap/mech/Untitled-152.png](/docs/ap/mech/Untitled-152.png) where green has lower moment of inertia, and red has larger moment of inertia ![/docs/ap/mech/Untitled-153.png](/docs/ap/mech/Untitled-153.png) ![/docs/ap/mech/Untitled-154.png](/docs/ap/mech/Untitled-154.png) 1. ![/docs/ap/mech/Untitled-155.png](/docs/ap/mech/Untitled-155.png) ![/docs/ap/mech/Untitled-156.png](/docs/ap/mech/Untitled-156.png) ![/docs/ap/mech/Untitled-157.png](/docs/ap/mech/Untitled-157.png) 1. ![/docs/ap/mech/Untitled-158.png](/docs/ap/mech/Untitled-158.png) - Answer ![/docs/ap/mech/Untitled-159.png](/docs/ap/mech/Untitled-159.png) ![/docs/ap/mech/Untitled-160.png](/docs/ap/mech/Untitled-160.png) ![/docs/ap/mech/Untitled-161.png](/docs/ap/mech/Untitled-161.png) ![/docs/ap/mech/Untitled-162.png](/docs/ap/mech/Untitled-162.png) ![/docs/ap/mech/Untitled-163.png](/docs/ap/mech/Untitled-163.png) 1. ![/docs/ap/mech/Untitled-164.png](/docs/ap/mech/Untitled-164.png) ![/docs/ap/mech/Untitled-165.png](/docs/ap/mech/Untitled-165.png) 1. ![/docs/ap/mech/Untitled-166.png](/docs/ap/mech/Untitled-166.png) ![/docs/ap/mech/Untitled-167.png](/docs/ap/mech/Untitled-167.png) 9 ![/docs/ap/mech/Untitled-168.png](/docs/ap/mech/Untitled-168.png) ![/docs/ap/mech/Untitled-169.png](/docs/ap/mech/Untitled-169.png) 10 ![/docs/ap/mech/Untitled-170.png](/docs/ap/mech/Untitled-170.png) ![/docs/ap/mech/Untitled-171.png](/docs/ap/mech/Untitled-171.png) 11 ![/docs/ap/mech/Untitled-172.png](/docs/ap/mech/Untitled-172.png) ![/docs/ap/mech/Untitled-173.png](/docs/ap/mech/Untitled-173.png) 12 ![/docs/ap/mech/Untitled-174.png](/docs/ap/mech/Untitled-174.png) ![/docs/ap/mech/Untitled-175.png](/docs/ap/mech/Untitled-175.png) 13 ![/docs/ap/mech/Untitled-176.png](/docs/ap/mech/Untitled-176.png) ![/docs/ap/mech/Untitled-177.png](/docs/ap/mech/Untitled-177.png) "},{"id":65,"href":"/ap/stats/","title":"AP Statistics","section":"AP Notes","content":" The content of these notes are solid, but formatting is not since they're exported from Notion. Unit 1: Exploring One-Variable Data # Types of Variables # Categorical variables assigns labels that place each individual into a particular group, called a category. Zip code. hair color Quantitative variables takes number values that are quantities—counts or measurements. Height, GPA Explanatory x on graph independent variable — what we\u0026rsquo;re changing measures an outcome of a study. Response y on graph (potentially) dependent variable — what we\u0026rsquo;re measuring may help predict or explain changes in a response variable Confounding Any factor that messes skews data Confounding occurs when two variables are associated in such a way that their effects on a response variable cannot be distinguished from each other. If you are asked to identify a possible confounding variable in a given setting, you are expected to explain how the variable you choose (1) is associated with the explanatory variable and (2) is associated with the response variable. Frequencies # A frequency table shows the number of individuals having each value. A relative frequency table shows the proportion or percent of individuals having each value. A marginal relative frequency gives the percent or proportion of individuals that have a specific value for one Categorical variable. What percent of people in the sample are environmental club members? What proportion of people in the sample never used a snowmobile? A joint relative frequency gives the percent or proportion of individuals that have a specific value for one Categorical variable and a specific value for another Categorical variable. We can compute marginal relative frequencies for the row totals to give the distribution of snowmobile use for all the individuals in the sample: We can compute marginal relative frequencies for the column totals to give the distribution of environmental club membership in the entire sample of 1526 park visitors A conditional relative frequency gives the percent or proportion of individuals that have a specific value for one Categorical variable among individuals who share the same value of another Categorical variable (the condition). What proportion of snowmobile renters in the sample are not environmental club members? What percent of environmental club members in the sample are snowmobile owners? Types of Graphs # Pie Chart — Categorical Need frequency value and corresponding label Doesn\u0026rsquo;t show sample size Bar Graph — Categorical Needs bar labels, axis names, units, vertical axis scale should start at 0 A side-by-side bar graph displays the distribution of a Categorical variable for each value of another Categorical variable. The bars are grouped together based on the values of one of the Categorical variables and placed side by side. A segmented bar graph displays the distribution of a Categorical variable as segments of a rectangle, with the area of each segment proportional to the percent of individuals in the corresponding category. Doesn\u0026rsquo;t show sample size, only proportions This can be fixed by using a mosaic plot which scales the width corresponding to size Dotplot — Quantitative A dot plot shows each data value as a dot above its location on a number line. Needs title, axis label, unit of measurement How to find percentile Percentile is the percent of people you\u0026rsquo;re better than, or percent of people that are worse than you Find how many points the decided point is ahead of, then divide by sample size The blue point is greater than 17 points, making it 17/20 —\u0026gt; in the 85% percentile Stemplot — Quantitative A stemplot shows each data value separated into two parts: a stem, which consists of all but the final digit, and a leaf, the final digit. The stems are ordered from lowest to highest and arranged in a vertical column. The leaves are arranged in increasing order out from the appropriate stems. Needs key and title Key should give context Key: 8|2 is a [context — student whose resting pulse rate] is 82 [beats per minute]\nHistogram — Quantitative A histogram shows each interval of values as a bar. The heights of the bars show the frequencies or relative frequencies of values in each interval. Needs title, axis label, unit of measurement Boxplot — Quantitative Describing Distributions (SOCS) + Context # Always be sure to include context when you are asked to describe a distribution. This means using the variable name, not just the units the variable is measured in. When comparing distributions of Quantitative data, it’s not enough just to list values for the center and variability of each distribution. You have to explicitly compare these values, using words like “greater than,” “less than,” or “about the same as.”\nShape (Skew) # A distribution is skewed to the right if the right side of the graph is much longer than the left side. A distribution is skewed to the left if the left side of the graph is much longer than the right side. The distribution of [context] is [skewed left/right/sym]\nOutlier # Gaps too Low outliers \u0026lt; Q1 − 1.5 × IQR High outliers \u0026gt; Q3 + 1.5 × IQR Doesn\u0026rsquo;t follow trend, large residual The [context — games played with 5 points / person with a height of 3\u0026rsquo;] appears to be an outlier\nCenter # Mean / average The mean is sensitive to extreme values in a distribution. These may be outliers, but a skewed distribution that has no outliers will also pull the mean toward its long tail. We say that the mean is not a resistant measure of center — Shouldn\u0026rsquo;t be used with skew or outliers Median Resistant — should be used with outliers and skew Spread / Variability # Range Not resistant — Shouldn\u0026rsquo;t be used with skew or outliers The data vary from [min] to [max] [context — points scored / heights] meaning it had a range of [max - min]\nStandard Deviation Measure of the typical distance of the values in a distribution from the mean. It should be used only when the mean is chosen as the measure of center. sx is not a resistant measure of variability — Shouldn\u0026rsquo;t be used with skew or outliers Larger values of sx indicate greater variation sx is always greater than or equal to The Interquartile Range (IQR) What The quartiles of a distribution divide the ordered data set into four groups having roughly the same number of values. To find the quartiles, arrange the data values from smallest to largest and find the median. The first quartile Q1 is the median of the data values that are to the left of the median in the ordered list. The third quartile Q3 is the median of the data values that are to the right of the median in the ordered list. IQR = Q3 - Q1 Resistant because they are not affected by a few extreme value — should be used with outliers Why is it important? # They might be inaccurate data values. Maybe someone recorded a value as 10.1 instead of 101. Perhaps a measuring device broke down. Or maybe someone gave a silly response, like the student in a class survey who claimed to study 30,000 minutes per night! Try to correct errors like these if possible. If you can’t, give summary statistics with and without the outlier. They can indicate a remarkable occurrence. For example, in a graph of net worth, Bill Gates is likely to be an outlier. They can heavily influence the values of some summary statistics, like the mean, range, and standard deviation. It can make it easier to see associations between variables An association exists when there is a difference in outcome for different inputs We can only find definitive associations for the sample, and we have to use test to find out if we can extrapolate this data to a larger sample For example, there may be an association between AP Stats students and not having post-HS plans and overall being less likely to go to University when compared to AP Calc students Five number summary (+ boxplot) # Min Q1 Median Q3 Max Standardized score (z-score) — the \u0026rsquo;test statistic' # Tells us how many standard deviations from the mean the value falls, and in what direction.\nValues larger than the mean have positive z-scores. Values smaller than the mean have negative z-scores.\nShape must be close to normal for z-scores to work\nNever say that a distribution of Quantitative data is Normal. Real-world data always show at least slight departures from a Normal distribution. The most you can say is that the distribution is “approximately Normal.” 68–95–99.7 Approximately 68% of the observations fall within σ of the mean μ Approximately 95% of the observations fall within σ 2 of the mean μ Approximately 99.7% of the observations fall within σ 3 of the mean μ Transforming Data # Multiplying / dividing by a constant (Units converted) Multiplies (divides) center and location (mean, five-number summary, percentiles) by b Multiplies (divides) measures of variability (range, IQR, standard deviation) by b Does not change the shape of the distribution Adding/subtracting constant Adds a to (subtracts a from) measures of center and location (mean, five-number summary, percentiles) Does not change measures of variability (range, IQR, standard deviation) Does not change the shape of the distribution Percentile # invNorm(.9, 0, 1) would find the z-score of 90% Good video Unit 2: Exploring Two-Variable Data # How to Describe a Scatterplot # Use CONTEXT Direction (association) Two variables have a positive association when above-average values of one variable tend to accompany above-average values of the other variable and when below-average values also tend to occur together. More [x-unit], more [y-unit] Two variables have a negative association when above-average values of one variable tend to accompany below-average values of the other variable. More [x-unit], less [y-unit] There is no association between two variables if knowing the value of one variable does not help us predict the value of the other variable. Form: # A scatterplot can show a linear form or a nonlinear form. The form is linear if the overall pattern follows a straight line. Otherwise, the form is nonlinear. Strength (correlation): # A scatterplot can show a weak, moderate, or strong association. An association is strong if the points don’t deviate much from the form identified. An association is weak if the points deviate quite a bit from the form identified. Correlation doesn’t imply causation. In many cases, two variables might have a strong correlation, but changes in one variable are very unlikely to cause changes in the other variable \u0026lsquo;r\u0026rsquo; — Correlation Coefficie It is only appropriate to use the correlation to describe strength and direction for a linear relationship Has same sign (positive or negative) as the slope r measures the direction and strength of the association, and does not measure form The correlation r is always a number between −1 and 1 (−1 ≤ r ≤ 1) The correlation r indicates the direction of a linear relationship by its sign: r \u0026gt; 0 for a positive association and r \u0026lt; 0 for a negative association. The extreme values r = −1 and r = 1 occur only in the case of a perfect linear relationship, when the points lie exactly along a straight line. If the linear relationship is strong, the correlation r will be close to 1 or −1. If the linear relationship is weak, the correlation r will be close to 0. Unusual features: # outliers that fall outside the overall pattern and distinct clusters of points — doesn\u0026rsquo;t follow trend large residual definition link influential point if you remove the point, then there would be substantial changes on slope, y-int, or r Interpreting # There is a [strength — fairly strong/weak], [direction — positive / negative] [form — (non)linear] relationship between [x var] and [y-var] with [any outliers + outlier point].\nResiduals # a = y-int, b = slope, s = s, R-sq = .$r^2$\nLeast-squares Regression Line (LSRL) # A regression line is a line that describes how a response variable y changes as an explanatory variable x changes. Made to reduce the residual Regression lines are expressed in the form where ŷ(pronounced “y-hat”) is the predicted value of y for a given value of x. Extrapolation is the use of a regression line for prediction far outside the interval of x values used to obtain the line. Such predictions are often not accurate. Don’t make predictions using values of x that are much larger or much smaller than those that actually appear in your data. Interpretation — NEEDS CONTEXT y-int y=b0+b1*x b0 For a [context of x-var] with a [x-unit] of 0, the predicted [y-var] is [b0]\nSlope b1 For every increase of 1 in [x-unit], the predicted [y-unit] increases by [b1] [y-units]\nResidual Difference between actual and predicted value Interpretation: The actual [y-var] for a [context] of [x-input \u0026amp; x-units] is [actual value (point we know) - predicted value] [lower/higher] than predicted by the LSRL.\nPlug in respective values to LSRL to get the predicted value Residual Plot a scatterplot that displays the residuals on the vertical axis and the explanatory variable on the horizontal axis. To determine whether the regression model is appropriate, look at the residual plot. If there is no leftover curved pattern in the residual plot, the regression model is appropriate. LSRL is good Interpretation: Because the residual plot does not show a clear pattern, the linear model is appropriate for the data\nIf there is a leftover curved pattern in the residual plot, consider using a regression model with a different form. LSRL is bad Interpretation: Because the residual plot shows a clear patter, the linear model is not appropriate for the data\nStandard deviation of residuals: .$s$ # The standard deviation of the residuals s measures the size of a typical residual. That is, s measures the typical distance between the actual y values and the predicted y values. Interpretation: The actual [y-var] [units] is typically around [s] away from the predicted by the least-squares regression line with x = [x-units]\nThe coefficient of determination: .$r^2$ # The coefficient of determination .$r^2$ measures the percent reduction in the sum of squared residuals when using the least-squares regression line to make predictions, rather than the mean value of y. In other words, .$r^2$ measures the percent of the variability in the response variable that is accounted for by the least-squares regression line. Interpretation: About [.$r^2$ in percent form]% of the variability for [y-var] is accounted for by the least-squares regression line with x = [x-var]\nUnit 3: Collecting Data # Chapter 4\nSampling # The population in a statistical study is the entire group of individuals we want information about. A census collects data from every individual in the population. A sample is a subset of individuals in the population from which we collect data. A sample survey is a study that collects data from a sample that is chosen to represent a specific population. Poor Sampling # Convenience sampling selects individuals from the population who are easy to reach. Voluntary response sampling allows people to choose to be in the sample by responding to a general invitation Bias: any difference between the sample result and the truth about the population that tends to occur in the same direction whenever you use the same sampling method The design of a statistical study shows bias if it is very likely to underestimate or very likely to overestimate the value you want to know. Bias is not just bad luck in one sample, it’s the result of a bad study design that will consistently miss the truth about the population in the same way If you’re asked to describe how the design of a sample survey leads to bias, you’re expected to do two things: Describe how the members of the sample might respond differently from the rest of the population Explain how this difference would lead to an underestimate or overestimate. Suppose you were asked to explain how using your statistics class as a sample to estimate the proportion of all high school students who own a graphing calculator could result in bias. You might respond, “This is a convenience sample . It would probably include a much higher proportion of students with a graphing calculator than in the population at large because a graphing calculator is required for the statistics class. So this method would probably lead to an overestimate of the actual population proportion.” Undercoverage occurs when some members of the population are less likely to be chosen or cannot be chosen in a sample. Most samples suffer from some degree of undercoverage. A sample survey of households, for example, will miss not only homeless people but also prison inmates and students in dormitories. Nonresponse Nonresponse occurs when an individual chosen for the sample can’t be contacted or refuses to participate Nonresponse leads to bias when the individuals who can’t be contacted or refuse to participate would respond differently from those who do participate. Consider a telephone survey that asks people how many hours of television they watch per day. People who are selected but are out of the house won’t be able to respond. Response Bias Response bias occurs when there is a systematic pattern of inaccurate answers to a survey question. The way questions are worded or the order in which they\u0026rsquo;re asked can lead to response bias Good Sampling # Simple random sample (SRS) Involves using a chance process to determine which members of a population are included in the sample . Gives each possible sample an equal chance of being selected A simple random sample (SRS) of size n is chosen in such a way that every group of n individuals in the population has an equal chance to be selected as the sample. For example, to choose a random sample of 6 students from a class of 30, start by writing each of the 30 names on a separate slip of paper, making sure the slips are all the same size. Then put the slips in a hat, mix them well, and pull out slips one at a time until you have identified 6 different students. Strata, Stratified random sample Strata are groups of individuals in a population who share characteristics thought to be associated with the variables being measured in a study. good for when sample sizes between population groups (stratas) are different Stratified random sampling selects a sample by choosing an SRS from each stratum and combining the SRSs into one overall sample. For example, in a study of sleep habits on school nights, the population of students in a large high school might be divided into freshman, sophomore, junior, and senior strata. After all, it is reasonable to think that freshmen have different sleep habits than seniors. The following activity illustrates the benefit of choosing appropriate strata. Clusters, Cluster sampling A cluster is a group of individuals in the population that are physically located near each other. Cluster sampling selects a sample by randomly choosing clusters and including each member of the selected clusters in the sample . Cluster sampling is often used for practical reasons, like saving time and money. Imagine a large high school that assigns students to homerooms alphabetically by last name, in groups of 25. Administrators want to survey 200 randomly selected students about a proposed schedule change. It would be difficult to track down an SRS of 200 students, so the administration opts for a cluster sample of homerooms. The principal (who knows some statistics) selects an SRS of 8 homerooms and gives the survey to all 25 students in each homeroom. Systematic Random Sampling In systematic random sampling, the researcher first randomly picks the first item or subject from the population . Then, the researcher will select each n\u0026rsquo;th subject from the list. The procedure involved in systematic random sampling is very easy and can be done manually. The results are representative of the population unless certain characteristics of the population are repeated for every n\u0026rsquo;th individual, which is highly unlikely. Experiments # Goal is to reduce bias and allow replication with the hopes that we find statistically significant results that we can infer/extrapolate to the population Four conditions of Experimental Design Comparison. Use a design that compares two or more treatments. Random assignment. Use chance to assign experimental units to treatments. Doing so helps create roughly equivalent groups of experimental units by balancing the effects of other variables among the treatment groups. Control. Keep other variables the same for all groups, especially variables that are likely to affect the response variable. Control helps avoid confounding and reduces variability in the response variable. Replication. (more than one experimental unit in each treatment group) — Use enough experimental units in each group so that any differences in the effects of the treatments can be distinguished from chance differences between the groups. Study: Observational Study: observes individuals and measures variables of interest but does not attempt to influence the responses. Observational Study vs experiment experiment (randomly) assigns treatments in studies the researcher has no interaction/input whatsoever data is observed and recorded naturally, scientists had no say can reduce bias from scientists no random assignment of subjects, but random sample can be taken therefore, we can make inferences about the population from which the individuals were chose, but not about cause and effect ( link) Vocab Experiment: deliberately imposes some treatment on individuals to measure their responses Response / Explanatory / Confounding Variables Placebo: A placebo is a treatment that has no active ingredient, but is otherwise like other treatments. The placebo effect describes the fact that some subjects in an experiment will respond favorably to any treatment, even an inactive treatment. Control: In an experiment, control means keeping other variables constant for all experimental units. Treatment: A specific condition applied to the individuals in an experiment Control group In an experiment, a control group is used to provide a baseline for comparing the effects of other treatments. Depending on the purpose of the experiment, a control group may be given an inactive treatment (placebo), an active treatment, or no treatment at all. Experimental unit: the object to which a treatment is randomly assigned Subjects: When the experimental units are human beings, they are often called subjects. Factor: In an experiment, a factor is a variable that is manipulated and may cause a change in the response variable. Levels: In an experiment, a factor is a variable that is manipulated and may cause a change in the response variable. The different values of a factor are called levels. Blinds In a double-blind experiment, neither the subjects nor those who interact with them and measure the response variable know which treatment a subject received. In a single-blind experiment, either the subjects don’t know which treatment they are receiving or the people who interact with them and measure the response variable don’t know which subjects are receiving which treatment Replication In an experiment, replication means using enough experimental units to distinguish a difference in the effects of the treatments from chance variation due to the random assignment. Sampling Variability Refers to the fact that different random samples of the same size from the same population produce different estimates. Larger random samples tend to produce estimates that are closer to the true population value than smaller random samples. In other words, estimates from larger samples are more precise. Statistically significant When the observed results of a study are too unusual to be explained by chance alone, the results are called statistically significant. Types of Experiments Block, Randomized block design A block is a group of experimental units that are known before the experiment to be similar in some way that is expected to affect the response to the treatments. In a randomized block design, the random assignment of experimental units to treatments is carried out separately within each block. Matched Pairs A matched pairs design is a common experimental design for comparing two treatments that uses blocks of size 2. In some matched pairs designs, two very similar experimental units are paired and the two treatments are randomly assigned within each pair. In others, each experimental unit receives both treatments in a random order. Random Assignment: In an experiment, random assignment means that the treatment / placebo is randomly given out Scope of Inference Inference: The process of drawing conclusions about a population based on samples, since we infer information about the population from what we know about the samples. Random Selection — sample units are selected randomly allows inference about the population from which the individuals were chosen groups may not be representative of population includes studies Random Assignment — experimental units are assigned to treatments using a chance process. allows inference about cause and effect. groups may differ between studies if not randomly assigned tend to average out all other uncontrollable factors so that they aren\u0026rsquo;t confounding with the treatment effects not studies Additional Requirements: The association is strong. The association is consistent. Larger values of the explanatory variable are associated w/ stronger responses. The alleged cause precedes the effect in time. Criteria for Establishing Causation When an Experiment CANNOT Be Done ● The association is strong. ● The association is consistent. ● Larger values of the explanatory variable are associated w/ stronger responses. ● The alleged cause precedes the effect in time. ● The alleged cause is plausible. Ethics All planned studies must be reviewed in advance by an institutional review board charged with protecting the safety and well-being of the subjects. All individuals who are subjects in a study must give their informed consent before data are collected. All individual data must be kept confidential. Only statistical summaries for groups of subjects may be made public. Unit 4: Probability, Random Variables, and Probability Distributions # Chapters 5 \u0026amp; 6\nProbability # LAW OF LARGE NUMBERS A law that states if we observe more and more repetitions of any chance process, the proportion of times a specific outcome occurs approaches its actual probability. We cannot accurately predict outcomes in the SHORT RUN; Order only emerges in the LONG RUN. No such thing as Law of Averages – Only Law of Large Numbers!!!!! Probibility The probability of any outcome of a chance process is a number between 0 and 1 that describes the proportion of times the outcome would occur in A VERY LONG SERIES OF REPETITIONS. Outcomes that will never ever occur Probability = 0 Outcomes that will always occur Probability = 1 Simulation The imitation of chance behavior, based on a model that accurately reflects the situation. The Simulation Process Describe how to use a chance device to imitate one trial (repetition) of the simulation. Tell what you will record at the end of each trial. Remember that every label needs to be the same length. In the golden ticket lottery example, the labels should be 01 to 95 (all two digits), not 1 to 95. When sampling without replacement, be sure to mention that repeated numbers should be ignored. Perform many trials of the simulation. Use the results of your simulation to answer the question of interest. Example Probability Model: A description of some chance process that consists of 2 parts: a list of all possible outcomes SAMPLE SPACE: The list of all possible outcomes. the probability for each outcome EVENT Any collection of outcomes from some chance process — A subset of the entire sample space. MUTUALLY EXCLUSIVE Two events A \u0026amp; B are mutually exclusive if they have no outcomes in common and so can never occur together – that is, if P(A and B) = 0. General Rules $$0 ≤ P(A) ≤ 1 \\text{ for any event }A$$ $$P(S) = 1 \\text{ if }S\\text{ is the sample space in a probability model}$$ $$P(A)=\\frac{\\text{Number of outcomes in event } A}{\\text{Total number of outcomes in sample space}}\\text{ in the case of EQUALLY LIKELY outcomes,}$$ $$\\text{Complement Rule: } P(A^c)=1-P(A); \\text{where }A^c=\\text{the event that A does not occur}$$ $$\\text{Addition rule for mutually exclusive events: }P(A \\text{ or } B)=P(A \\cup B) = P(A) + P(B)$$ $$\\text{General addition rule: } P(A \\text{ or } B) =P(A \\cup B)= P(A) + P(B) − P(A \\text{ and } B) $$ $$\\text{Dependent events: } P(A \\text{ and } B) = P(A ∩ B) = P(A) ⋅ P(B | A)$$ $$\\text{Independent events: } P(A \\text{ and } B) = P(A ∩ B) = P(A) ⋅ P(B)$$ $$\\text{Probability of A given B: } P(A|B)=\\frac{P(A \\text{ and } B)}{P(B)} $$ Conditional CONDITIONAL PROBABILITY Example The probability that one event happens given that another event is known to have happened. The conditional probability that event B happens GIVEN that event A has happened is denoted by P(B | A). INDEPENDENT EVENTS A and B are independent events if knowing whether or not one event has occurred does not change the probability that the other event will happen. In other words, events A and B are independent if $$P(A ∣ B) = P(A ∣ B ^c ) = P(A)$$ Alternatively, events A and B are independent if $$P(B ∣ A) = P(B ∣ A^c) = P(B)$$ Random Variables # DISCRETE RANDOM VARIABLE A random variable that has a countable number of outcomes with gaps. Examples: ACT Scores; # of Free-Throws Made, etc. CONTINUOUS RANDOM VARIABLE A random variable that has an infinite number of outcomes with no gaps. Examples: Temperature; Race Times; Heart Rate, etc. Mean Variance Standard Deviation Transforming — only works for independent! When MULTIPLYING (or DIVIDING) each value in a probability distribution by some number b, the ● mean is MULTIPLIED (or DIVIDED) by b ● variance is MULTIPLIED (or DIVIDED) by b^2 ● standard deviation is MULTIPLIED (or DIVIDED) by b When ADDING (or SUBTRACTING) the number a to each value in a probability distribution, the ● mean INCREASES (or DECREASES) by a ● variance STAYS THE SAME ● standard deviation STAYS THE SAME Combining — only works for independent! Suppose we add two normal distributions (X + Y) or we subtract two normal distributions (X – Y). The shape of the resulting distribution will be NORMAL and the mean and standard deviation can be calculated using the RULES. where \\row (no ^2) is standard deviation Difference between the binomial setting and the geometric setting Binomial Binomial Setting: Binary? Each observation falls into 1 of 2 categories: SUCCESS or FAILURE Independent? The n observations are all INDEPENDENT. (knowing one outcome of a trial has no effect on the other trials) Note: if sampling w/o replacement, you need to check the 10% condition Number? There is a fixed number n of TRIALS/OBSERVATIONS. Success? The probability of success, p, is SAME for each trial. BINOMIAL DISTRIBUTION If large counts is verified, then the binomial distribution\u0026rsquo;s shape is approximately normal The distribution of the count X of successes in the binomial setting with parameters n and p. n = # of Trials/Observations p = Probability of Success (per Trial) Possible Values for X = whole #s 0 to n Abbreviation = B (n, p) BINOMIAL COEFFICIENT The number of ways to arrange k successes among n trials; “Combinations” Binomial Probability Formula binomialPdf / Cdf also works Geometric: The Geometric Setting Binary? Each observation falls into 1 of 2 categories: SUCCESS or FAILURE Independent? The n observations are all INDEPENDENT. (knowing one outcome of a trial has no effect on the other trials). Trials? The goal is to count the number of trials until the FIRST SUCCESS Success? The probability of success, p, is SAME for each trial. Shape skewed right GEOMETRIC PROBABILITY FORMULA geometCdf / Pdf also works Unit 5: Sampling Distributions # Chapter 7 + 10\nSampling Distribution: # The sampling distribution of a statistic is the distribution of values taken by the statistic in all possible samples of the same size from the same population. Always say “the distribution of [blank],” being careful to distinguish the distribution of the population, the distribution of sample data, and the sampling distribution of a statistic. Sampling distribution of the sample proportion The sampling distribution of the sample proportion p hat describes the distribution of values taken by the sample proportion p hat in all possible samples of the same size from the same population. Conditions Random: The data must come from a well-designed RANDOM sample or a RANDOMIZED experiment. Normal: The sampling distribution is approximately NORMAL, meaning we can use a z-test statistic. Large Counts: (np ≥ 10) \u0026amp; (n (1 − p) ≥ 10 ) Independent: If 2 samples, both samples must be independent 10% Condition: When sampling w/o replacement to verify the use of our standard deviation ( 10n \u0026lt; N ) Sampling distribution of the sample mean The sampling distribution of the sample mean x describes the distribution of values taken by the sample mean x in all possible samples of the same size from the same population. Conditions Random: The data must come from a well-designed RANDOM sample or a RANDOMIZED experiment. Normal: The sampling distribution is approximately NORMAL, meaning we can use a z-test/t-test statistic. Either (or both) condition(s) must be met: CLT n ≥ 30 — n_diff ≥ 30 for paired data The central limit theorem (CLT) says that when n is larger than 30, the sampling distribution of the sample mean x is approximately Normal. Distribution shouldn\u0026rsquo;t be skewed values above the median are much more variable than the values below the median Independent: If 2 samples, both samples must be independent 10% Condition: When sampling w/o replacement to verify the use of our standard deviation ( 10n \u0026lt; N ) — 10*n_diff \u0026lt; N_diff for paired data Sampling Variability: Sampling variability refers to the fact that different random samples of the same size from the same population produce different values for a statistic. Parameter: A number computed from a population Statistic A number computed from a SAMPLE What makes a statistic a good estimator of a parameter? LOW BIAS (Randomization) High bias is usually because of a poor sampling design (lack of randomness). LOW VARIABILITY (Sample Size) Reduce the variability of a statistic is to INCREASING SAMPLE SIZE. Difference between proportions Difference between means Many students use “accurate” when they really mean “precise.” For example, a response that says “increasing the sample size will make an estimate more accurate” is incorrect Paired Data # Paired data result from recording two values of the same Quantitative variable for each individual or for each pair of similar individuals. 2 sets of data that are not independent from each other, then they\u0026rsquo;re paired Analyzing Paired Data: To analyze paired data, start by computing the difference for each pair. Then make a graph of the differences. Use the mean difference x and the standard deviation of the differences as summary statistic. Confidence Intervals # Point estimator: a statistic that provides an estimate of a population parameter. The value of that statistic from a sample is called a point estimate. Ideally our “best guess” at the value of an unknown parameter. Because the sample mean ¯x is an unbiased estimator of the population mean μ, we use the statistic ¯x as a point estimator ****of the parameter μ. The best guess for the value of μ is ¯x Unbiased Estimator: A statistic used to estimate a parameter is an unbiased estimator if the mean of its sampling distribution is equal to the value of the parameter being estimated. Confidence Level α The confidence level C% gives the overall success rate of the method used to calculate the confidence interval. Interpretation If we were to select many random samples from a population and construct a C% confidence interval using each sample, about C% of the intervals would capture the [parameter in context].\nConfidence interval When interpreting a confidence interval, make sure that you are describing the parameter and not the statistic. Interpretation “We are C% confident that the interval from [min] to [max] captures the true value of the [parameter in context].”\nMargin of error describes how far, at most, we expect the estimate to vary from the true population value. In a C% confidence interval, the distance between the point estimate and the true parameter value will be less than the margin of error in C% of all samples. How to decrease MOE The confidence level decreases. To obtain a smaller margin of error from the same data, you must be willing to accept less confidence. The sample size n increases. In general, increasing the sample size n reduces the margin of error for any fixed confidence level. Margin of error accounts for only the variability we expect from random sampling. It does not account for practical difficulties, such as undercoverage and nonresponse in a sample survey Critical Value The critical value is a multiplier that makes the interval wide enough to have the stated capture rate. Z-score when we know stdiv t-score when we don\u0026rsquo;t know stdiv Standard Error (SE) Proportions # Four-step process: State What parameter do you want to estimate and at what confidence level? 1 proportion \u0026ldquo;We wish to estimate the true proportion of all [parameter], with [C%] confidence.\u0026rdquo;\n2 proportions \u0026ldquo;We wish to estimate the true difference of the proportion of all [parameter 1] and all [parameter 2] for [context], with [C%] confidence.\u0026rdquo;\nPlan Identify the appropriate inference method \u0026ldquo;We\u0026rsquo;ll carry out a [ONE/TWO]-SAMPLE Z INTERVAL FOR A POPULATION PROPORTION (because we\u0026rsquo;re estimating a proportion and we know the standard deviation.)\u0026rdquo;\nCheck conditions Do Perform the calculations. \u0026ldquo;Because the conditions are true, we can do our calculations:\u0026rdquo; 1 proportion 2 proportions where z* is the critical value for the standard Normal curve with C% of its area between −z* and z*. Conclude Interpret your interval in the context of the problem. We are [C%] confident that the interval of [min] to [max] [units] captures the true proportion of all [context]\n2 sample difference If 0 is within confidence interval range: Because 0 is contained in the [C%] confidence interval it is plausible there is no difference between [parameter 1] and [parameter 2]. We do not have convincing evidence of a difference of proportions of [context]\nIf 0 is NOT within confidence interval range: Because 0 is not contained in the [C%] confidence interval it is plausible there is a difference between [parameter 1] and [parameter 2]. We have convincing evidence of a difference of proportions of [context]\nMeans # Four-step process State What parameter do you want to estimate and at what confidence level? 1 proportion We wish to estimate the true mean of all [parameter], with [C%] confidence.\n2 proportions We wish to estimate the true difference of the mean of all [parameter 1] and all [parameter 2] for [context], with [C%] confidence.\nPlan Identify the appropriate inference method If we know stdiv We\u0026rsquo;ll carry out a [ONE/TWO]-SAMPLE Z INTERVAL FOR A POPULATION MEAN(because we know the standard deviation.)\nIf we don\u0026rsquo;t know stdiv We\u0026rsquo;ll carry out a [ONE/TWO]-SAMPLE Z INTERVAL FOR A POPULATION MEAN(because and we don\u0026rsquo;t know the standard deviation.)\nCheck conditions Do Perform the calculations. z-score Because we know conditions are true, can do our calculations 1 mean 2 means with z* score and \\row t-score Because we know conditions are true, we can say that the t-distribution\u0026rsquo;s degree of freedom (df) is df = n - 1 and we\u0026rsquo;ll carry out a [one/two]-sample t interval for a population mean 1 mean 2 means Difference Conclude Interpret your interval in the context of the problem. We are [C%] confident that the interval of [min] to [max] [units] captures the true mean of all [context]\n2 sample difference If 0 is within confidence interval range: Because 0 is contained in the [C%] confidence interval it is plausible there is no difference between [parameter 1] and [parameter 2]. We do not have convincing evidence of a difference between means of [context]\nIf 0 is NOT within confidence interval range: Because 0 is not contained in the [C%] confidence interval it is plausible there is a difference between [parameter 1] and [parameter 2]. We have convincing evidence of a difference between means of [context]\nt-scores A t-distribution is specified by its degrees of freedom (df) calculated df = n - 1 The spread of the t-distribution is MORE than that of a standard Normal distribution. The t-distribution has MORE probability in the tails than the standard Normal distribution, since substituting the estimate sx for the parameter σ introduces MORE variation into the statistic. As degrees of freedom increases, the t-distribution becomes CLOSER to the standard Normal distribution, since sx estimates MORE accurately when the sample size is large. Choosing sample size # Sometimes, we want to choose our sample size (n) so that we may estimate a proportion within a particular margin of error. We must choose our sample size before we start sampling. Conservative Approach: Use p .5 , because it maximizes the margin of error. Better Approach if Possible: Make a guess about the value of p based on prior knowledge, common knowledge, previous studies, etc. $$Z^*\\sqrt{\\frac{p(1-p)}{n}} \\leq ME, \\text{and solve for n}$$ Sample Size for a Desired Margin of Error when Estimating μ To determine the sample size n that will yield a C% confidence interval for a population mean with a specified margin of error ME: Get a reasonable value for the population standard deviation σ from an earlier or pilot study. Find the critical value z* from a standard Normal curve for confidence level C%. Set the expression for the margin of error to be less than or equal to ME and solve for n: Tests # Shared Vocab # Significance Test A formal procedure for comparing OBSERVED DATA with a CLAIM whose truth we want to assess. Null hypothesis — H0 A test is designed to assess the strength of the evidence AGAINST this. This hypothesis is often the statement of “no difference.” Alternative hypothesis — Ha The claim about the population we are trying to find evidence FOR. This hypothesis should always be created BEFORE seeing the data. One sided less than or greater than Two sided not equal Both Null \u0026amp; Alternative Hypotheses refer to a POPULATION and use PARAMETERS (μ \u0026amp; p) p-value Assuming H0 is true, the probability the statistic (such as p^hat or x^bar) would take a value as extreme or more extreme than the one actually observed. The smaller the p-value, the STRONGER the evidence is AGAINST the H0 Interpretation \u0026ldquo;Assuming H0 is true, there is a [P-val] probability of getting the [sample val] [or even smaller/larger] by random chance with a sample size of [n]\u0026rdquo;\nsignificance level The level at which that, when our p-value falls below it, we consider it to be SIGNIFICANT We consider that our sample is so unlikely to happen IF H0 is true, that it likely did NOT happen by chance error + power Type 1: When H0 is true, but we REJECT H0 P(Type I) = confidence level α Type 2: When Ha is true, but we FAIL TO REJECT H0 P(Type II) = 1 - Power Power The ability of a test to correctly detect the alternative when it\u0026rsquo;s true. When Ha is true, and we CORRECTLY REJECT H0 Interpretation \u0026ldquo;Given Ha is true (in context), there is a (power) probability we correctly rejecting H0 (finding convincing evidence for Ha)\nPower = 1 – P(Type II Error) How to increase INCREASE the sample size (n), INCREASE the Confidence Level (α), or Make Ha further away from H0 STANDARDIZED TEST STATISTIC A standardized test statistic measures how far a sample statistic is from what we would expect if the null hypothesis H0 were true, in standard deviation units. Proportions # Four-step process State State your Hypotheses: H[relation] = [p/µ] interpret values — 1 proportion where p is the true proportion of [context] and Significance Level (alpha)\ninterpret values — 2 proportion where p is the true difference between the proportions of [parameter 1] and [parameter 2] of [context] and Significance Level (alpha)\nPlan Identify the appropriate testing method We\u0026rsquo;ll carry out a [ONE/TWO]-SAMPLE Z TEST FOR A POPULATION PROPORTION (because we\u0026rsquo;re estimating a proportion and we know the standard deviation)\nCheck conditions Do Perform the calculations. Because we know conditions are true, can do our calculations 1 sample 2 sample Proportion Difference find p-value Conclude Interpret your p-value in the context of the problem. P-value less than Assuming the [H0] is true, there is a [p-value] probability of getting [statistic found] or [more [and/neither] less — more for H0 \u0026lt; Ha; less for Ha \u0026lt; H0; both for H0 ≠ Ha] in a sample of [sample size] purely by chance. Because [p-value] is less than [alpha] of [confidence level], we have evidence to reject the null hypothesis, and have some evidence that the null hypothesis may be true, meaning [context]\nP-value greater than Assuming the [H0] is true, there is a [p-value] probability of getting [statistic found] or [more [and/neither] less — more for H0 \u0026lt; Ha; less for Ha \u0026lt; H0; both for H0 ≠ Ha] in a sample of [sample size] purely by chance. Because [p-value] is greater than [alpha] of [confidence level], we do not have enough evidence to reject the null hypothesis, meaning [context] Means # Four-step process State State your Hypotheses: H[relation] = [p/µ] interpret values — 1 proportion where p is the true mean of [context] and Significance Level (α)\ninterpret values — 2 proportion where p is the true difference between the means of [parameter 1] and [parameter 2] of [context] and Significance Level (α)\nPlan Identify the appropriate testing method We\u0026rsquo;ll carry out a [[ONE/TWO]-SAMPLE]/MATCHED PAIRS] T TEST FOR A POPULATION MEAN\nCheck conditions Do Perform the calculations. Because we know conditions are true, can do our calculations with (n-1) degrees of freedom 1 sample 2 sample Mean Difference Paired Paired find P-value Conclude Interpret your p-value in the context of the problem. P-value less than Assuming the parameter is true, there is a [p-value] probability of getting [statistic found] or more/less in a sample of [sample size] purely by chance. Because [p-value] is less than [alpha] of [confidence level], we have evidence to reject the null hypothesis, and have some evidence that the null hypothesis may be true, meaning [context]\nP-value greater than Assuming the parameter is true, there is a [p-value] probability of getting [statistic found] or more/less in a sample of [sample size] purely by chance. Because [p-value] is greater than [alpha] of [confidence level], we do not have enough evidence to reject the null hypothesis, meaning [context]\n"}]