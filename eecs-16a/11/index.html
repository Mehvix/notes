<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="\(\) Positioning Systems # Just read Note 21.1-2
Vectors # Inner Products # The Euclidean inner product between two vectors $\vec u, \vec v$ is defined as&mldr; $$\langle \vec u, \vec v \rangle \equiv \vec u \cdot \vec v \equiv \vec u^T \vec v$$ $$\dots = \begin{bmatrix} v_1 v_2 \dots v_n \end{bmatrix}\begin{bmatrix} u_1\\ u_2\\ \vdots \\ u_n \end{bmatrix}$$ $$\dots = v_1 u_1 + v_2 u_2 + \dots v_n u_n$$ $$\dots = \sum_{i=1}^n v_i u_i$$ Naming In physics, the inner product is called dot product; $\vec u \cdot \vec v$ Scalar product is also occasionally used because it produces a scalar output Properties # In general, if $\mathbb{V}$ is a real vector space$^{[1]}$, we say that the mapping $\vec u, \vec v \in \mathbb{V} \to \langle \vec u, \vec v \rangle \in \mathbb{R}$ is an inner product iff it satisfies the following properties:"><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="11: Locationing & Trilateration"><meta property="og:description" content="\(\) Positioning Systems # Just read Note 21.1-2
Vectors # Inner Products # The Euclidean inner product between two vectors $\vec u, \vec v$ is defined as&mldr; $$\langle \vec u, \vec v \rangle \equiv \vec u \cdot \vec v \equiv \vec u^T \vec v$$ $$\dots = \begin{bmatrix} v_1 v_2 \dots v_n \end{bmatrix}\begin{bmatrix} u_1\\ u_2\\ \vdots \\ u_n \end{bmatrix}$$ $$\dots = v_1 u_1 + v_2 u_2 + \dots v_n u_n$$ $$\dots = \sum_{i=1}^n v_i u_i$$ Naming In physics, the inner product is called dot product; $\vec u \cdot \vec v$ Scalar product is also occasionally used because it produces a scalar output Properties # In general, if $\mathbb{V}$ is a real vector space$^{[1]}$, we say that the mapping $\vec u, \vec v \in \mathbb{V} \to \langle \vec u, \vec v \rangle \in \mathbb{R}$ is an inner product iff it satisfies the following properties:"><meta property="og:type" content="article"><meta property="og:url" content="http://notes.mehvix.com/eecs-16a/11/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2022-05-08T18:48:10-07:00"><title>11: Locationing & Trilateration | notes.mehvix.com</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.89a77f7e702a8626749b948bbfb01109823daf6c1246ca407d1378833494c402.css integrity="sha256-iad/fnAqhiZ0m5SLv7ARCYI9r2wSRspAfRN4gzSUxAI=" crossorigin=anonymous><script defer src=/flexsearch.min.js></script>
<script defer src=/en.search.min.6248f0d4778be3a7f06cb3a79412a91077b31b0fd8bc3ea06e6436002692323d.js integrity="sha256-Ykjw1HeL46fwbLOnlBKpEHezGw/YvD6gbmQ2ACaSMj0=" crossorigin=anonymous></script>
<script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script>
<link rel=icon href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ““</text></svg>"><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>MathJax={tex:{inlineMath:[["$","$"],[".$","$"]],processEscapes:!0,processEnvironments:!0,macros:{bigsup:["#1{^{\\vbox{\\hbox{$\\scriptstyle#1$}\\nointerlineskip\\hbox{}}}}",1],norm:[`\\left\\lVert#1\\right\\rVert`,1]}},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script id=MathJax-script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.min.js?config=TeX-AMS_CHTML" integrity="sha512-9DkJEmXbL/Tdj8b1SxJ4H2p3RCAXKsu8RqbznEjhFYw0cFIWlII+PnGDU2FX3keyE9Ev6eFaDPyEAyAL2cEX0Q==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:".$",right:"$",display:!1},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><link rel=stylesheet href=http://notes.mehvix.com/css/custom_styling.css><div class=print style=text-align:center><h1 id=print-location>Notes can be found as interactive webpage at</h1></div><script>let a=document.createElement("a");a.appendChild(document.createTextNode(`notes.mehvix.com${window.location.pathname}`)),a.href="http://notes.mehvix.com"+window.location.pathname,document.getElementById("print-location").appendChild(a)</script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>notes.mehvix.com</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-ad45289da5715225c5154e9ed2d01bfd class=toggle>
<label for=section-ad45289da5715225c5154e9ed2d01bfd class="flex justify-between"><a role=button>CS 194</a></label><ul><li><a href=http://notes.mehvix.com/cs-194/cs-194/>Main</a></li></ul></li><li><input type=checkbox id=section-381d9181c0cc4fe35fea10df5bf8d07d class=toggle>
<label for=section-381d9181c0cc4fe35fea10df5bf8d07d class="flex justify-between"><a role=button>MCB C61</a></label><ul><li><a href=http://notes.mehvix.com/mcb-c61/1/>1: Evolution of the Mind, the Brain, and Brain Chemistry</a></li><li><a href=http://notes.mehvix.com/mcb-c61/2/>2: DNA, Synapses, and Neuroanatomy</a></li><li><a href=http://notes.mehvix.com/mcb-c61/3/>3: Pharmacology; Neurodevelopment</a></li><li><a href=http://notes.mehvix.com/mcb-c61/4/>4: Sensory Perception</a></li><li><a href=http://notes.mehvix.com/mcb-c61/5/>5: Connectivity</a></li></ul></li><li><a href=http://notes.mehvix.com/cogsci-c100/>CogSci C100</a></li><li><input type=checkbox id=section-20c391324c82ffdef893b60d754b7005 class=toggle checked>
<label for=section-20c391324c82ffdef893b60d754b7005 class="flex justify-between"><a role=button>EECS 16A</a></label><ul><li><a href=http://notes.mehvix.com/eecs-16a/0/>0: System Design & Linear Equations</a></li><li><a href=http://notes.mehvix.com/eecs-16a/1/>1: Gaussian Elim. & Matrices + Vectors</a></li><li><a href=http://notes.mehvix.com/eecs-16a/2/>2: (In)dependence & Circuit Analysis</a></li><li><a href=http://notes.mehvix.com/eecs-16a/3/>3: Transformations & Inverse</a></li><li><a href=http://notes.mehvix.com/eecs-16a/4/>4: Vector Spaces & Eigenstuff</a></li><li><a href=http://notes.mehvix.com/eecs-16a/5/>5: Basis & Circuit Analysis</a></li><li><a href=http://notes.mehvix.com/eecs-16a/6/>6: Voltage Dividers & Measurement</a></li><li><a href=http://notes.mehvix.com/eecs-16a/7/>7: 2D Touchscreens & Superp. + Equivalence</a></li><li><a href=http://notes.mehvix.com/eecs-16a/8/>8: Capacitors & Capacitive Touchscreen</a></li><li><a href=http://notes.mehvix.com/eecs-16a/9/>9: Op-Amps, Comparators & Charge Sharing</a></li><li><a href=http://notes.mehvix.com/eecs-16a/10/>10: NFB, GRs & Buffer + Loading</a></li><li><a href=http://notes.mehvix.com/eecs-16a/11/ class=active>11: Locationing & Trilateration</a></li><li><a href=http://notes.mehvix.com/eecs-16a/12/>12-13: Least Squares & ML</a></li></ul></li><li><input type=checkbox id=section-7571d6f544c6ffc847948b0f74d82ef1 class=toggle>
<label for=section-7571d6f544c6ffc847948b0f74d82ef1 class="flex justify-between"><a role=button>Engineering 29</a></label><ul><li><a href=http://notes.mehvix.com/e-29/0/>0: Intro & Tolerancing</a></li><li><a href=http://notes.mehvix.com/e-29/1/>1: Fundamentals of Graphical Communication & Subtractive Processes</a></li><li><a href=http://notes.mehvix.com/e-29/2/>2: Cutting-based Processes & Other Subtractive Processes</a></li><li><a href=http://notes.mehvix.com/e-29/3/>3: Additive Processes: Intro & Extrusion</a></li><li><a href=http://notes.mehvix.com/e-29/4/>4: Additive Processes: Light-based, etc.</a></li><li><a href=http://notes.mehvix.com/e-29/5/>5-6: Forming Processes</a></li><li><a href=http://notes.mehvix.com/e-29/6/>6-7: Joining processes</a></li><li><a href=http://notes.mehvix.com/e-29/7/>7-9: Visualization</a></li><li><a href=http://notes.mehvix.com/e-29/10/>10: Metrology</a></li><li><a href=http://notes.mehvix.com/e-29/11/>11-12: GD&amp;T</a></li></ul></li><li><a href=http://notes.mehvix.com/anthro-c12ac/>Anthro C12AC</a></li><li><a href=http://notes.mehvix.com/asamst-20a/>ASAMST 20A</a></li><li><input type=checkbox id=section-32aba3efd274a559b3dccd4e800c9d4b class=toggle>
<label for=section-32aba3efd274a559b3dccd4e800c9d4b class="flex justify-between"><a role=button>Math 53</a></label><ul><li><a href=http://notes.mehvix.com/math-53/10/>10: Parametric Equations and Polar Coordinates</a></li><li><a href=http://notes.mehvix.com/math-53/12/>12: Vectors & Geometry of Space</a></li><li><a href=http://notes.mehvix.com/math-53/13/>13: Vector Functions</a></li><li><a href=http://notes.mehvix.com/math-53/14/>14: Partial Derivatives</a></li><li><a href=http://notes.mehvix.com/math-53/15/>15: Multiple Integrals</a></li><li><a href=http://notes.mehvix.com/math-53/16/>16: Vector Calculus</a></li><li><a href=http://notes.mehvix.com/math-53/trig/>Trig Identities</a></li><li><a href=http://notes.mehvix.com/math-53/trig-calc/>Trig Calculus</a></li></ul></li><li><input type=checkbox id=section-98c46cabf82aecebcca8f97f2965f738 class=toggle>
<label for=section-98c46cabf82aecebcca8f97f2965f738 class="flex justify-between"><a role=button>Physics 7B</a></label><ul><li><a href=http://notes.mehvix.com/physics-7b/17/>17: Temperature, Thermal Expansion, & Ideal Gas Law</a></li><li><a href=http://notes.mehvix.com/physics-7b/18/>18: Kinetic Theory of Gases</a></li><li><a href=http://notes.mehvix.com/physics-7b/19/>19: Heat & First Law of Thermo</a></li><li><a href=http://notes.mehvix.com/physics-7b/20/>20: Second Law of Thermo</a></li><li><a href=http://notes.mehvix.com/physics-7b/21/>21: Electric Charges & Fields</a></li><li><a href=http://notes.mehvix.com/physics-7b/22/>22: Flux & Gauss's Law</a></li><li><a href=http://notes.mehvix.com/physics-7b/23/>23: Electric Potential</a></li><li><a href=http://notes.mehvix.com/physics-7b/24/>24: Capacitance, Dielectrics, Electric Energy Storage</a></li><li><a href=http://notes.mehvix.com/physics-7b/25/>25: Electric Current and Resistance</a></li><li><a href=http://notes.mehvix.com/physics-7b/26/>26: DC Circuits</a></li><li><a href=http://notes.mehvix.com/physics-7b/27/>27: Magnetism</a></li><li><a href=http://notes.mehvix.com/physics-7b/28/>28: Sources of Magnetic Field</a></li><li><a href=http://notes.mehvix.com/physics-7b/29/>29: Electromagnetic Induction & Faraday's Law</a></li><li><a href=http://notes.mehvix.com/physics-7b/30/>30: Inductance, Electromagnetic Oscillations, & AC Circuits</a></li></ul></li><li><input type=checkbox id=section-a18e6d23bfa638ffa382e954bd79207f class=toggle>
<label for=section-a18e6d23bfa638ffa382e954bd79207f class="flex justify-between"><a role=button>AP Notes</a></label><ul><li><a href=http://notes.mehvix.com/ap/huge/>AP Human Geography</a></li><li><a href=http://notes.mehvix.com/ap/cmech/>AP Physics C: Mechanics</a></li><li><a href=http://notes.mehvix.com/ap/stats/>AP Statistics</a></li></ul></li></ul><ul><li><a href=https://cs61a.rouxl.es/ target=_blank rel=noopener>CS61A (Anto's)</a></li><li><a href=# target=_blank rel=noopener>â€”</a></li><li><a href=https://www.mehvix.com target=_blank rel=noopener>wÂ³.mehvix.com</a></li><li><a href=https://pass.mehvix.com target=_blank rel=noopener>pass.mehvix.com</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>11: Locationing & Trilateration</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#positioning-systems>Positioning Systems</a></li><li><a href=#vectors>Vectors</a><ul><li><a href=#inner-products>Inner Products</a><ul><li><a href=#properties>Properties</a></li><li><a href=#geometric-interpretation>Geometric Interpretation</a></li><li><a href=#special-operations>Special Operations</a></li></ul></li><li><a href=#orthogonal-vectors>Orthogonal Vectors</a></li><li><a href=#norms>Norms</a><ul><li><a href=#properties-1>Properties</a></li></ul></li><li><a href=#cauchy-schwarz-inequality>Cauchy-Schwarz Inequality</a></li><li><a href=#projections>Projections</a></li></ul></li><li><a href=#trilateration>Trilateration</a></li><li><a href=#signals>Signals</a><ul><li><a href=#cross-correlation>Cross-Correlation</a></li></ul></li></ul></nav></aside></header><article class=markdown><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script>
<script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>
\(\)</span><h1 id=positioning-systems>Positioning Systems
<a class=anchor href=#positioning-systems>#</a></h1><p>Just read
<a href=https://eecs16a.org/lecture/Note21.pdf>Note 21.1-2</a></p><h1 id=vectors>Vectors
<a class=anchor href=#vectors>#</a></h1><h2 id=inner-products>Inner Products
<a class=anchor href=#inner-products>#</a></h2><blockquote><p>The
<a href=https://en.wikipedia.org/wiki/Euclidean_space#Euclidean_vector_space>Euclidean</a>
<a href=https://en.wikipedia.org/wiki/Inner_product_space>inner product</a> between two vectors $\vec u, \vec v$ is defined as&mldr;<div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><p>$$\langle \vec u, \vec v \rangle \equiv \vec u \cdot \vec v \equiv \vec u^T \vec v$$</div><div class="flex-even markdown-inner"><p>$$\dots = \begin{bmatrix}
v_1 v_2 \dots v_n
\end{bmatrix}\begin{bmatrix}
u_1\\
u_2\\
\vdots \\
u_n
\end{bmatrix}$$
$$\dots = v_1 u_1 + v_2 u_2 + \dots v_n u_n$$
$$\dots = \sum_{i=1}^n v_i u_i$$</div></div></p></blockquote><ul><li>Naming<ul><li>In physics, the inner product is called <strong><a href=https://en.wikipedia.org/wiki/Dot_product>dot product</a></strong>; $\vec u \cdot \vec v$</li><li><strong>Scalar product</strong> is also occasionally used because it produces a scalar output</li></ul></li></ul><h3 id=properties>Properties
<a class=anchor href=#properties>#</a></h3><p>In general, if $\mathbb{V}$ is a real vector space$^{[1]}$, we say that the
<a href=https://en.wikipedia.org/wiki/Map_%28mathematics%29>mapping</a> $\vec u, \vec v \in \mathbb{V} \to \langle \vec u, \vec v \rangle \in \mathbb{R}$ is an inner product iff it satisfies the following properties:</p><h4 id=1-symmetry-langle-vec-u-vec-v-rangle--langle-vec-v-vec-u-rangle-for-all-vec-u-vec-v-in-mathbbv>1. Symmetry: $\langle \vec u, \vec v \rangle = \langle \vec v, \vec u \rangle$ for all $\vec u, \vec v \in \mathbb{V}$
<a class=anchor href=#1-symmetry-langle-vec-u-vec-v-rangle--langle-vec-v-vec-u-rangle-for-all-vec-u-vec-v-in-mathbbv>#</a></h4><h4 id=2-linearity>2. Linearity:
<a class=anchor href=#2-linearity>#</a></h4><ul><li>Homogeneity: $\langle \gamma \vec u, \vec v \rangle = \gamma \langle \vec u, \vec v \rangle$</li><li>Super position: $\langle \vec u + \vec w, \vec v \rangle = \langle \vec u, \vec v \rangle + \langle \vec w, \vec v \rangle$ for $\vec w \in \mathbb{V}, \gamma \in \mathbb{R}$</li></ul><h4 id=3-positive-definiteness-langle-vec-v-vec-v-rangle-geq-0-with-equality-iff-vec-v--vec-0>3. Positive-definiteness: $\langle \vec v, \vec v \rangle \geq 0$ with equality iff $\vec v = \vec 0$
<a class=anchor href=#3-positive-definiteness-langle-vec-v-vec-v-rangle-geq-0-with-equality-iff-vec-v--vec-0>#</a></h4><hr><p>$^{[1]}$In 16A we do not want to think about complex numbers so we tend to have $\vec u, \vec v \in \mathbb{R}^n$</p><h3 id=geometric-interpretation>Geometric Interpretation
<a class=anchor href=#geometric-interpretation>#</a></h3><blockquote><p>The inner product of vectors two vectors is their magnitudes multiplied by the angle between them
$$\langle \vec u, \vec v \rangle = \Vert \vec u \Vert \Vert \vec v \Vert \cdot \cos \theta$$</p></blockquote><ul><li>Proof on
<a href="https://eecs16a.org/lecture/Note21.pdf#page=6">page 6</a></li><li>The inner product <em>does not depend on the coordinate system</em> the vectors are in&ndash; it only depends on the relative angle between these vectors and their length.</li><li>Note that we cannot just look at the value of the inner product $\vec u, \vec v$ in making the judgement about the vectorsâ€™ similarity, due to the scaling property<ul><li>Making the vectors 10 times longer/shorter doesnâ€™t make them any more or less aligned with each other!</li><li>What we can do is normalize the vectors &ndash; maintain direction and set magnitude to 1<ul><li>E.x. $\hat v = \frac{\vec v}{\Vert \vec v \Vert}$ &ndash; the $\hat{ }$ symbol indicates a unit vector (magnitude = 1)</li><li>Nice derivation on
<a href="https://eecs16a.org/EECS16ACompendiumOfNotesAndPracticeProblems.pdf#page=108">page 108</a></li></ul></li></ul></li></ul><h3 id=special-operations>Special Operations
<a class=anchor href=#special-operations>#</a></h3><blockquote><p><strong>Motivation:</strong> The act of computing an inner product is very simple computationally; itâ€™s just a few additions and multiplications, so computers are highly optimized for computing inner products. Therefore, it is useful to represent other common operations in terms of inner products.</p></blockquote><p>For $\vec v \in \mathbb{R}^n$</p><ol><li>Sum of Components: $\langle \vec 1, \vec v \rangle = v_0 + v_1 + \dots + v_n$</li><li>Average: $\langle \hat n^{-1}, \vec v \rangle = \frac{v_0}{\hat n} + \frac{v_1}{\hat n} + \dots + \frac{v_n}{\hat n} = \frac{v_0 + \dots + v_n}{n}$</li><li>Sum of Squares: $\langle \vec v, \vec v \rangle = v_0^2 + v_1^2 + \dots + v_n^2$</li><li>Selective Sum: $\langle \vec e_2 + \vec e_5 + \dots + e_n, \vec v \rangle = v_2 + v_5 + \dots v_n$</li></ol><h2 id=orthogonal-vectors>Orthogonal Vectors
<a class=anchor href=#orthogonal-vectors>#</a></h2><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><blockquote><p>Two vectors $\vec v, \vec u \in \mathbb{R}^n$ are <strong>orthogonal</strong> if their inner product is zero, i.e. $\langle \vec v, \vec u \rangle = 0$</p></blockquote><ul><li><a href=https://en.wikipedia.org/wiki/Orthogonality>Orthogonality</a> can be thought of
<a href=https://en.wikipedia.org/wiki/Perpendicular>perpendicularity</a> to higher dimensions than two/three</li><li>Note that the
<a href=https://en.wikipedia.org/wiki/Standard_basis>standard unit vectors</a> are <em>always</em> orthogonal to each other.</li><li>E.x. orthogonal vectors in $\mathbb{R}^2$ to the right:</li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/eecs-16a/11/ortho.png alt></div></div><h2 id=norms>Norms
<a class=anchor href=#norms>#</a></h2><blockquote><p>The
<a href=https://en.wikipedia.org/wiki/Norm_%28mathematics%29#Euclidean_norm>Euclidean Norm</a> (or 2-norm) of a vector represents the vectorâ€™s length, or magnitude. Defined as $\Vert \vec v \Vert = \sqrt{v_1^2 + \dots v_n^2} = \sqrt{\langle \vec v, \vec v \rangle}$ where the inner product on the right is the Euclidean inner product</p></blockquote><ul><li>The norm of a vector is the magnitude</li><li>This corresponds to the usual notion of distance in $\mathbb{R}^2, \mathbb{R}^3$<ul><li>The set of points with equal Euclidean norm is a circle in $\mathbb{R}^2$ or a sphere in $\mathbb{R}^3$</li></ul></li><li><em>Aside:</em> More generally, any choice of inner product will give rise to a corresponding norm via defining $\Vert \vec v \Vert := \sqrt{ \langle \vec v, \vec v \rangle}$</li></ul><h3 id=properties-1>Properties
<a class=anchor href=#properties-1>#</a></h3><p>For $\vec v, u \in \mathbb{R}^2$&mldr;</p><h4 id=1-non-negativity-vert-vec-v-vert-geq-0>1. Non-negativity: $\Vert \vec v \Vert \geq 0$
<a class=anchor href=#1-non-negativity-vert-vec-v-vert-geq-0>#</a></h4><h4 id=2-zero-vector-vert-vec-v-vert--0-iff-vec-v--vec-0>2. Zero Vector: $\Vert \vec v \Vert = 0 \iff \vec v = \vec 0$
<a class=anchor href=#2-zero-vector-vert-vec-v-vert--0-iff-vec-v--vec-0>#</a></h4><h4 id=3-scalar-multiplication-vert-gamma-vec-v-vert--vert-gamma-vert-vert-vec-v-vert>3. Scalar Multiplication: $\Vert \gamma \vec v \Vert = \vert \gamma \vert \Vert \vec v \Vert$
<a class=anchor href=#3-scalar-multiplication-vert-gamma-vec-v-vert--vert-gamma-vert-vert-vec-v-vert>#</a></h4><h4 id=4-triangle-inequality-vert-vec-v--vec-u-vert-leq-vert-vec-v-vert--vert-vec-u-vert>4. Triangle Inequality: $\Vert \vec v + \vec u \Vert \leq \Vert \vec v \Vert + \Vert \vec u \Vert$
<a class=anchor href=#4-triangle-inequality-vert-vec-v--vec-u-vert-leq-vert-vec-v-vert--vert-vec-u-vert>#</a></h4><h2 id=cauchy-schwarz-inequality>Cauchy-Schwarz Inequality
<a class=anchor href=#cauchy-schwarz-inequality>#</a></h2><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><blockquote><p>$$\vert \langle \vec v, \vec u \rangle \vert \leq \Vert \vec v \Vert \Vert \vec u \Vert$$</p></blockquote><p>We can prove this knowing $\vert \cos \theta \vert \leq 1$:</p></div><div class="flex-even markdown-inner"><p>$$\vert \langle \vec v, \vec u \rangle \vert = \big\vert \Vert \vec u \Vert \Vert \vec u \Vert \cdot \cos \theta \big\vert $$
$$\vert \langle \vec v, \vec u \rangle \vert = \Vert \vec u \Vert \Vert \vec u \Vert \cdot \big\vert\cos \theta \big\vert $$
$$\therefore \vert \langle \vec v, \vec u \rangle \vert \leq \Vert \vec u \Vert \Vert \vec u \Vert $$</div></div><h2 id=projections>Projections
<a class=anchor href=#projections>#</a></h2><ul><li>The
<a href=https://en.wikipedia.org/wiki/Vector_projection>vector projection</a> of $\vec x$ onto $\vec y$ &mdash; $\text{proj}_{\vec y}\vec x$ &mdash; refers to the component of $\vec x$ that is aligned in the same direction as $\vec y$&ndash; or exactly opposite; it helps to imagine a line going through $\vec y$</li><li>By definition, we see that $\text{proj}_{\vec y}\vec x \in \text{Span} \{\vec y \}$<ul><li>If the projection is zero, then the vectors are orthogonal &ndash; there is no component of $\vec y$ that is aligned with $\vec x$</li></ul></li></ul><p><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>We can break up $\vec x$ into it&rsquo;s parallel and perpendicular components to $\vec y$, $\vec x_\parallel, \vec x_\perp$<ul><li>The length of the parallel component $\Vert \vec x_\parallel \Vert$ gives the <em>scalar</em> projection of $\vec x$ onto $\vec y$
$$\cos \theta = \frac{\langle \vec x, \vec y \rangle}{\Vert \vec x \Vert \Vert \vec y \Vert}$$
$$\therefore \text{comp}_{\vec{y}} \vec x = \Vert \vec x_\parallel \Vert = \cos\theta \Vert \vec x \Vert$$
$$\dots = \frac{\langle \vec x, \vec y\rangle}{\Vert \vec y \Vert} $$</li></ul></li><li>This is the scalar projection, which we can give direction by multiplying it by $\hat y$</li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/eecs-16a/11/proj.png alt="Dot Product"></div></div>$$\text{proj}_{\vec y}\vec x = ( \text{comp}_{\vec{y}} \vec x)\hat y = \left( \frac{\langle \vec x, \vec y\rangle}{\Vert \vec y \Vert}\right) \frac{\vec y}{\Vert \vec y \Vert} = \frac{\langle \vec x, \vec y\rangle}{\Vert \vec y \Vert ^2} \vec y = \frac{\langle \vec x, \vec y\rangle}{\langle \vec y, \vec y\rangle} \vec y$$</p><ul><li>This new, unique vector is closest to $\vec x$ as measured by the norm &ndash;
<a href="https://eecs16a.org/lecture/Note21.pdf#page=9">page 9</a></li><li>The above only uses generic properties of the inner product, and does not need to the specific choice of the Euclidean inner product to work out.</li><li>See also:
<a href=/math-53/12/#projections>Math 53 12.3: Projections</a></li></ul><h1 id=trilateration>Trilateration
<a class=anchor href=#trilateration>#</a></h1><blockquote class="book-hint info"><p><a href="https://youtu.be/ILxKidrD3K8?t=57"><em>I&rsquo;m on a journey to the center of three</em></a></blockquote><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>We know the locations of the beacons $\vec a_1,\vec a_2,\vec a_3$</li><li>We know the distances $d_1,d_2,d_3$</li><li>We want to find the position of $\vec x$</li></ul><p><img src=/docs/eecs-16a/11/tri.png alt></p><hr><ul><li>These two equations are linear in $\vec x$, so we can then stick them into a matrix<ul><li>This system can be solved for a location</li><li>Notice that three circles uniquely define a point in 2D; this argument extends in 3D to four spheres, 4D to five hyper-spheres, etc.</li></ul></li></ul></div><div class="flex-even markdown-inner"><p>$$\Vert \vec x - \vec a_1 \Vert^2 = d_1^2$$
$$\Vert \vec x - \vec a_2 \Vert^2 = d_2^2$$
$$\Vert \vec x - \vec a_3 \Vert^2 = d_3^2$$
$$\equiv$$
$$(\vec x - \vec a_i)^T (\vec x - \vec a_i) = d_i^2$$
$$\equiv$$
$$\vec x^T \vec x - \vec x^T\vec a_i -\vec a_i^T\vec x + \vec a_i^T \vec a_i - = d_i^2$$
$$\equiv$$
$$\Vert \vec x \Vert^2 - 2 \langle \vec x, \vec a_i \rangle + \Vert \vec a_i \Vert^2 = d_i^2$$</p><blockquote><p>We have <strong>squared terms</strong> (not linear!) involving unknown variable $\vec x$</p></blockquote><hr><blockquote><p>We&rsquo;ll subtract equation 1 from equation 2, and separately again from equation 3.
$$2 (\vec a_1 - \vec a_2)^T \vec x = \Vert \vec a_1 \Vert^2 - \Vert \vec a_2 \Vert^2 - d_1^2 + d_2^2$$
$$2 (\vec a_1 - \vec a_3)^T \vec x = \Vert \vec a_1 \Vert^2 - \Vert \vec a_3 \Vert^2 - d_1^2 + d_3^2$$
$$\equiv$$
$$\begin{bmatrix}
2 (\vec a_1 - \vec a_2)^T \\
2 (\vec a_1 - \vec a_3)^T \\
\end{bmatrix}\vec x = \begin{bmatrix}
\Vert \vec a_1 \Vert^2 - \Vert \vec a_2 \Vert^2 - d_1^2 + d_2^2 \\
\Vert \vec a_1 \Vert^2 - \Vert \vec a_3 \Vert^2 - d_1^2 + d_3^2 \\
\end{bmatrix}$$</p></blockquote></div></div><h1 id=signals>Signals
<a class=anchor href=#signals>#</a></h1><blockquote><p><strong>Signal:</strong> a message that contains information as a function of, in this class, time &ndash; can also be a function of space (i.e. an image)</p><ul><li><strong>Discrete-time Signal:</strong> defined at specific points in time (for example, every minute) &ndash; can represent as a list of numbers</li><li><strong>Continuous-Time Signal:</strong> defined over all time &ndash; not focused on in 16A</li></ul></blockquote><ul><li>We can represent a discrete-time signal as a list of numbers, and thus as a vector where each element is the value at a single time point</li></ul><blockquote><p><img src=/docs/eecs-16a/11/sig.png alt>
Every element of the vector represents the signal value at one timestep. Weâ€™ll use the notation $s[k]$ to represent the $k$-th element of the vector where initial element is at $k = 0$. E.x. in the signal $\vec s$ above, $s[0] = 0$, $s[1] = 1$, etc.</p></blockquote><h2 id=cross-correlation>Cross-Correlation
<a class=anchor href=#cross-correlation>#</a></h2><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><blockquote><p><strong>Cross-correlation:</strong> Measure of the similarity between two signals $\vec x$ and $\vec y$ based on the inner product.</p></blockquote><p>$$\text{corr}_{\vec x} ( \vec y) [k] = \sum^{\infty}_{i=-\infty} x[i] y[iâˆ’k]$$
$$\dots = \left\langle \vec x, \vec y^{(k)} \right\rangle$$</p><ul><li>$\vec x, \vec y$: input signals</li><li>$\text{corr} _{\vec x} ( \vec y) [k]$: $k$-th element of their cross-correlation</li><li>We typically iterate over $[-l, L+l]$<ul><li>$L, l$ The larger and smaller signal lengths, respectively</li><li>$x[n], y[n] = 0$ for any $n$ that they are not defined for</li></ul></li></ul></div><div class="flex-even markdown-inner"><ul><li>When the inner product is large, $\vec x, \vec y$ are more similar, and when itâ€™s small, they are more different.</li><li>The cross-correlation checks the inner product at all relative shifts between the signals, so it tells us how similar two signals are at every shift.</li><li><strong>Autocorrelation</strong>: a correlation between a signal and itself<ul><li>Tells us how similar a signal is to all shifts of itself.</li></ul></li><li>Not commutative: $\text{corr}_{\vec x} ( \vec y) \neq \text{corr}_{\vec y} ( \vec x)$<ul><li>Aside:
<a href=https://en.wikipedia.org/wiki/Convolution>convolution</a> is an operation similar to correlation but commutative<ul><li><a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>Convolutional Neural Network</a></li></ul></li></ul></li><li>Aside:
<a href="https://eecs16a.org/EECS16ACompendiumOfNotesAndPracticeProblems.pdf#page=111">Circular Correlation</a></li></ul></div></div><ul><li>E.x. for $\vec s_1 = \begin{bmatrix}1 \ 3 \ 2\end{bmatrix}^T$, $\vec s_2 = \begin{bmatrix}2 \ 1\end{bmatrix}^T$:<ul><li>$\text{corr}_{\vec s_1} ( \vec s_2) [0] = (1)(2) + (3)(1) + (2)(0) = 5$</li><li>Using numpy: <code>numpy.correlate([1, 3, 2], [2, 1], â€˜fullâ€™)</code><figure><img src=/docs/eecs-16a/11/comp.png></figure></li></ul></li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/Mehvix/notes/commit/7a744d7bb84b2ec6c28a5ee6929213a266d1cffe title='Last modified by Max Vogel | May 9, 2022' target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>May 9, 2022</span></a></div><div><a class="flex align-center" href=https://github.com/Mehvix/notes/edit/master/hugo/content/docs/eecs-16a/11.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#positioning-systems>Positioning Systems</a></li><li><a href=#vectors>Vectors</a><ul><li><a href=#inner-products>Inner Products</a><ul><li><a href=#properties>Properties</a></li><li><a href=#geometric-interpretation>Geometric Interpretation</a></li><li><a href=#special-operations>Special Operations</a></li></ul></li><li><a href=#orthogonal-vectors>Orthogonal Vectors</a></li><li><a href=#norms>Norms</a><ul><li><a href=#properties-1>Properties</a></li></ul></li><li><a href=#cauchy-schwarz-inequality>Cauchy-Schwarz Inequality</a></li><li><a href=#projections>Projections</a></li></ul></li><li><a href=#trilateration>Trilateration</a></li><li><a href=#signals>Signals</a><ul><li><a href=#cross-correlation>Cross-Correlation</a></li></ul></li></ul></nav></div></aside></main></body></html>