<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="\(\)  Least Squares #  Motivation #   We want to find an approximate solution &ndash; one that satisfies all the given equations/information as closely as possible to\dots  Minimize the impact of noise/errors Solve overdetermined systems &ndash; we&rsquo;ll often be collecting abundant information, thus we have more equations than unknowns   Applications: Least squares is the fundamental idea behind data fitting and machine learning  In data (curve) fitting, we find lines or curves that best match the data In machine learning, we use a best-fit curve to make predictions about new, unseen data."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="12-13: Least Squares & ML"><meta property="og:description" content="\(\)  Least Squares #  Motivation #   We want to find an approximate solution &ndash; one that satisfies all the given equations/information as closely as possible to\dots  Minimize the impact of noise/errors Solve overdetermined systems &ndash; we&rsquo;ll often be collecting abundant information, thus we have more equations than unknowns   Applications: Least squares is the fundamental idea behind data fitting and machine learning  In data (curve) fitting, we find lines or curves that best match the data In machine learning, we use a best-fit curve to make predictions about new, unseen data."><meta property="og:type" content="article"><meta property="og:url" content="http://notes.mehvix.com/eecs-16a/12/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2022-05-08T01:16:12-07:00"><title>12-13: Least Squares & ML | notes.mehvix.com</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.89a77f7e702a8626749b948bbfb01109823daf6c1246ca407d1378833494c402.css integrity="sha256-iad/fnAqhiZ0m5SLv7ARCYI9r2wSRspAfRN4gzSUxAI=" crossorigin=anonymous><script defer src=/flexsearch.min.js></script>
<script defer src=/en.search.min.7e45faafb795982eb0842ba42bc86af354f056adb834994a4a424aceb8c27d5c.js integrity="sha256-fkX6r7eVmC6whCukK8hq81TwVq24NJlKSkJKzrjCfVw=" crossorigin=anonymous></script>
<script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script>
<link rel=icon href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ““</text></svg>"><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>MathJax={tex:{inlineMath:[["$","$"],[".$","$"]],processEscapes:!0,processEnvironments:!0,macros:{bigsup:["#1{^{\\vbox{\\hbox{$\\scriptstyle#1$}\\nointerlineskip\\hbox{}}}}",1],norm:["\\left\\lVert#1\\right\\rVert",1]}},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script id=MathJax-script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.min.js?config=TeX-AMS_CHTML" integrity="sha512-9DkJEmXbL/Tdj8b1SxJ4H2p3RCAXKsu8RqbznEjhFYw0cFIWlII+PnGDU2FX3keyE9Ev6eFaDPyEAyAL2cEX0Q==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:".$",right:"$",display:!1},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><link rel=stylesheet href=http://notes.mehvix.com/css/custom_styling.css></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>notes.mehvix.com</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-254493c648c1f0be4cf9348c45ddbe37 class=toggle>
<label for=section-254493c648c1f0be4cf9348c45ddbe37 class="flex justify-between"><a role=button>CogSci C100</a></label><ul><li><a href=http://notes.mehvix.com/cogsci-c100/intro/>1: Introduction</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/perception/>2: Perception</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/non-visual/>3: Non-Visual Perception</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/attention/>4: Attention</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/sleep/>5: Sleep & Dreams</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/consciousness/>6: Consciousness</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/mindfulness/>7: Mindfulness</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/mem-process/>8: Memory Process</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/mem-strategies/>9: Memory Strategies</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/forgetting/>10: Forgetting & Reconstruction</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/mem-topics/>11: Memory Topics</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/imagery/>12: Imagery</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/language/>13: Language</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/problem/>14: Problem Solving, Creativity, & Decision Making</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/developement/>15: Cognitive Development</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/therapy/>16: Cognition & Therapy</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/ai-ml/>17: Artificial Intelligence & Machine Learning</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/vr/>18: Virtual Reality</a></li></ul></li><li><input type=checkbox id=section-20c391324c82ffdef893b60d754b7005 class=toggle checked>
<label for=section-20c391324c82ffdef893b60d754b7005 class="flex justify-between"><a role=button>EECS 16A</a></label><ul><li><a href=http://notes.mehvix.com/eecs-16a/0/>0: System Design & Linear Equations</a></li><li><a href=http://notes.mehvix.com/eecs-16a/1/>1: Gaussian Elim. & Matrices + Vectors</a></li><li><a href=http://notes.mehvix.com/eecs-16a/2/>2: (In)dependence & Circuit Analysis</a></li><li><a href=http://notes.mehvix.com/eecs-16a/3/>3: Transformations & Inverse</a></li><li><a href=http://notes.mehvix.com/eecs-16a/4/>4: Vector Spaces & Eigenstuff</a></li><li><a href=http://notes.mehvix.com/eecs-16a/5/>5: Basis & Circuit Analysis</a></li><li><a href=http://notes.mehvix.com/eecs-16a/6/>6: Voltage Dividers & Measurement</a></li><li><a href=http://notes.mehvix.com/eecs-16a/7/>7: 2D Touchscreens & Superp. + Equivalence</a></li><li><a href=http://notes.mehvix.com/eecs-16a/8/>8: Capacitors & Capacitive Touchscreen</a></li><li><a href=http://notes.mehvix.com/eecs-16a/9/>9: Op-Amps, Comparators & Charge Sharing</a></li><li><a href=http://notes.mehvix.com/eecs-16a/10/>10: NFB, GRs & Buffer + Loading</a></li><li><a href=http://notes.mehvix.com/eecs-16a/11/>11: Locationing & Trilateration</a></li><li><a href=http://notes.mehvix.com/eecs-16a/12/ class=active>12-13: Least Squares & ML</a></li></ul></li><li><input type=checkbox id=section-7571d6f544c6ffc847948b0f74d82ef1 class=toggle>
<label for=section-7571d6f544c6ffc847948b0f74d82ef1 class="flex justify-between"><a role=button>Engineering 29</a></label><ul><li><a href=http://notes.mehvix.com/e-29/0/>0: Intro & Tolerancing</a></li><li><a href=http://notes.mehvix.com/e-29/1/>1: Fundamentals of Graphical Communication & Subtractive Processes</a></li><li><a href=http://notes.mehvix.com/e-29/2/>2: Cutting-based Processes & Other Subtractive Processes</a></li><li><a href=http://notes.mehvix.com/e-29/3/>3: Additive Processes: Intro & Extrusion</a></li><li><a href=http://notes.mehvix.com/e-29/4/>4: Additive Processes: Light-based, etc.</a></li><li><a href=http://notes.mehvix.com/e-29/5/>5-6: Forming Processes</a></li><li><a href=http://notes.mehvix.com/e-29/6/>6-7: Joining processes</a></li><li><a href=http://notes.mehvix.com/e-29/7/>7-9: Visualization</a></li><li><a href=http://notes.mehvix.com/e-29/10/>10: Metrology</a></li><li><a href=http://notes.mehvix.com/e-29/11/>11-12: GD&T</a></li></ul></li><li><input type=checkbox id=section-32aba3efd274a559b3dccd4e800c9d4b class=toggle>
<label for=section-32aba3efd274a559b3dccd4e800c9d4b class="flex justify-between"><a role=button>Math 53</a></label><ul><li><a href=http://notes.mehvix.com/math-53/10/>10: Parametric Equations and Polar Coordinates</a></li><li><a href=http://notes.mehvix.com/math-53/12/>12: Vectors & Geometry of Space</a></li><li><a href=http://notes.mehvix.com/math-53/13/>13: Vector Functions</a></li><li><a href=http://notes.mehvix.com/math-53/14/>14: Partial Derivatives</a></li><li><a href=http://notes.mehvix.com/math-53/15/>15: Multiple Integrals</a></li><li><a href=http://notes.mehvix.com/math-53/16/>16: Vector Calculus</a></li><li><a href=http://notes.mehvix.com/math-53/trig/>Trig Identities</a></li><li><a href=http://notes.mehvix.com/math-53/trig-calc/>Trig Calculus</a></li></ul></li><li><input type=checkbox id=section-98c46cabf82aecebcca8f97f2965f738 class=toggle>
<label for=section-98c46cabf82aecebcca8f97f2965f738 class="flex justify-between"><a role=button>Physics 7B</a></label><ul><li><a href=http://notes.mehvix.com/physics-7b/17/>17: Temperature, Thermal Expansion, & Ideal Gas Law</a></li><li><a href=http://notes.mehvix.com/physics-7b/18/>18: Kinetic Theory of Gases</a></li><li><a href=http://notes.mehvix.com/physics-7b/19/>19: Heat & First Law of Thermo</a></li><li><a href=http://notes.mehvix.com/physics-7b/20/>20: Second Law of Thermo</a></li><li><a href=http://notes.mehvix.com/physics-7b/21/>21: Electric Charges & Fields</a></li><li><a href=http://notes.mehvix.com/physics-7b/22/>22: Flux & Gauss's Law</a></li><li><a href=http://notes.mehvix.com/physics-7b/23/>23: Electric Potential</a></li><li><a href=http://notes.mehvix.com/physics-7b/24/>24: Capacitance, Dielectrics, Electric Energy Storage</a></li><li><a href=http://notes.mehvix.com/physics-7b/25/>25: Electric Current and Resistance</a></li><li><a href=http://notes.mehvix.com/physics-7b/26/>26: DC Circuits</a></li><li><a href=http://notes.mehvix.com/physics-7b/27/>27: Magnetism</a></li><li><a href=http://notes.mehvix.com/physics-7b/28/>28: Sources of Magnetic Field</a></li><li><a href=http://notes.mehvix.com/physics-7b/29/>29: Electromagnetic Induction & Faraday's Law</a></li><li><a href=http://notes.mehvix.com/physics-7b/30/>30: Inductance, Electromagnetic Oscillations, & AC Circuits</a></li></ul></li><li><a href=http://notes.mehvix.com/anthro-c12ac/>Anthro C12AC</a></li><li><a href=http://notes.mehvix.com/asamst-20a/>ASAMST 20A</a></li><li><input type=checkbox id=section-a18e6d23bfa638ffa382e954bd79207f class=toggle>
<label for=section-a18e6d23bfa638ffa382e954bd79207f class="flex justify-between"><a role=button>AP Notes</a></label><ul><li><a href=http://notes.mehvix.com/ap/huge/>AP Human Geography</a></li><li><a href=http://notes.mehvix.com/ap/cmech/>AP Physics C: Mechanics</a></li><li><a href=http://notes.mehvix.com/ap/stats/>AP Statistics</a></li></ul></li></ul><ul><li><a href=https://cs61a.rouxl.es/ target=_blank rel=noopener>CS61A (Anto's)</a></li><li><a href=# target=_blank rel=noopener>â€”</a></li><li><a href=https://www.mehvix.com target=_blank rel=noopener>wÂ³.mehvix.com</a></li><li><a href=https://pass.mehvix.com target=_blank rel=noopener>pass.mehvix.com</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>12-13: Least Squares & ML</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#least-squares>Least Squares</a><ul><li><a href=#motivation>Motivation</a></li><li><a href=#what>What</a></li><li><a href=#proof>Proof</a></li></ul></li><li><a href=#theorems>Theorems</a><ul><li><a href=#theorem-231>Theorem 23.1</a></li><li><a href=#theorem-232>Theorem 23.2</a></li></ul></li></ul></nav></aside></header><article class=markdown><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script>
<script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>
\(\)</span><h1 id=least-squares>Least Squares
<a class=anchor href=#least-squares>#</a></h1><h2 id=motivation>Motivation
<a class=anchor href=#motivation>#</a></h2><ul><li>We want to find an approximate solution &ndash; one that satisfies all the given equations/information <em>as closely</em> as possible to\dots<ul><li>Minimize the impact of noise/errors</li><li>Solve
<a href=https://en.wikipedia.org/wiki/Overdetermined_system>overdetermined systems</a> &ndash; we&rsquo;ll often be collecting abundant information, thus we have more equations than unknowns</li></ul></li><li><strong>Applications:</strong> Least squares is the fundamental idea behind data fitting and machine learning<ul><li>In
<a href=https://en.wikipedia.org/wiki/Curve_fitting>data (curve) fitting</a>, we find lines or curves that best match the data</li><li>In
<a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a>, we use a best-fit curve to make predictions about new, unseen data.</li></ul></li></ul><h2 id=what>What
<a class=anchor href=#what>#</a></h2><blockquote><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><p>The goal of least squares is to minimize the error vector&rsquo;s magnitude (norm) &ndash; the square of each of it&rsquo;s components:</div><div class="flex-even markdown-inner"><p>$$\Vert \vec e \Vert = \sqrt{\sum_{i=1}^n e_i^2 }$$</div></div></blockquote><ul><li>With $m$ measurements (equations) and $n$ unknowns; $m > n$<ul><li>$\text{col}(A)$ is an $n$-dimensional subspace within the larger $m$-dimensional space that $\vec b$ lies in</li><li>That is, $\vec b$ cannot be exactly reached by $A\vec x$</li></ul></li></ul><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>$\vec x$: Best-guess that minimizes $\Vert \vec e \Vert$<ul><li>$\vec x \in \mathbb{R}^{n}$</li></ul></li><li>$\vec e = \vec b - A\vec x = \vec b - \hat x$: Error vector<ul><li>$\vec e \in \mathbb{R}^{n}$</li><li>We want to find $\vec x$ where $\vec e \perp \text{col}(A)$</li></ul></li></ul></div><div class="flex-even markdown-inner"><ul><li>$\vec b$: Actual, observed values<ul><li>$\vec b \in \mathbb{R}^{m}$</li></ul></li><li>$\hat x = A \vec x = A (A^T A)^{-1} A^T \vec b$: Predicted values<ul><li>$A \in \mathbb{R}^{m \times n}; A\vec x, \hat x \in \mathbb{R}^{m}$</li><li>Can be thought of a linear combination of the columns of $A$, with $\vec x$ acting as weights</li></ul></li></ul></div></div><h2 id=proof>Proof
<a class=anchor href=#proof>#</a></h2><ul><li>We know from the last section that the projection of $\vec a$ onto $\vec b$ results in a vector within the span of $\vec b$ that is <strong>closest</strong> <em>and</em> <strong>orthogonal</strong> to $\vec a$<div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>So we&rsquo;ll project $\vec b$ onto $\text{col}(A)$ to find the smallest possible $\vec e$</li><li>That is, we know that $\vec e \perp \text{col}(A)$ $\Longrightarrow \vec e \perp \vec a_i $ for each column of $A$ so we can write:
$$\langle \vec a_i, \vec e \rangle = 0$$
$$\langle \vec a_i, \vec b - A\vec x \rangle = 0$$
$$\vec a_i^T (\vec b - A\vec x) = 0$$
$$\therefore A^T (\vec b - A \vec x) = \vec 0$$</li></ul></div><div class="flex-even markdown-inner"><ul><li>Then solving for $\vec x$ in terms of the known $A$ and $\vec b$:
$$A^T (\vec b - A \vec x) = \vec 0$$
$$A^T \vec b - A^T A \vec x = \vec 0$$
$$A^T \vec b = A^T A \vec x$$
$$ \therefore \vec x = (A^T A )^{-1} A^T \vec b$$</li></ul></div></div></li></ul><h1 id=theorems>Theorems
<a class=anchor href=#theorems>#</a></h1><h2 id=theorem-231>Theorem 23.1
<a class=anchor href=#theorem-231>#</a></h2><blockquote><p>Vector $\vec e$ is orthogonal to every vector in the column space of $A$ iff it is orthogonal to each of the columns $\vec a_i$ that form the basis of its column space</p></blockquote><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>If $\vec e$ is orthogonal to every vector in the column space of $A$, then it is orthogonal to each of the $\vec a_i$, as each of the $\vec a_i$ are in the column space of $A$ too</li><li>Now, we will try to prove the converse: consider an arbitrary vector $\vec v \in \text{span}(A)$&ndash; by definition, we know that there exist coefficients $\alpha_i$ such that we can express $\vec v = \sum_{i=1}^m \alpha_i \vec a_i$</li><li>We also know that $\vec e$ is orthogonal to each $\vec a_i$; that is $\langle \vec e, \vec a_i \rangle = 0$</li></ul></div><div class="flex-even markdown-inner"><ul><li>We wish to show that $\vec{e}$ is orthogonal to $\vec{v}$ too:
$$\langle\vec{e},\vec{v}_i \rangle = \left\langle \vec{e}, \sum_{i=1}^m \alpha_i \vec a_i \right\rangle$$
$$\dots = \sum \left\langle \vec{e}, \alpha_i \vec a_i \right\rangle$$
$$\dots = \sum \alpha_i \left\langle \vec{e}, \vec a_i \right\rangle$$
$$\dots = 0$$</li></ul></div></div><ul><li>That is, if $\vec e$ is orthogonal to all the basis vectors of a subspace, it is orthogonal to every vector in that subspace as well!</li></ul><h2 id=theorem-232>Theorem 23.2
<a class=anchor href=#theorem-232>#</a></h2><blockquote><p>$\text{Null}(A^TA) = \text{Null}(A)$ even when $A$ has a nontrivial nullspace</p></blockquote><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>Consider an arbitrary $\vec v \in \text{Null}(A^T A)$&ndash; by definition, we have
$$A^T A \vec v = \vec 0$$
$$\vec v^T (A^T A \vec v) = \vec v^T (\vec 0)$$
$$(A \vec v)^T (A \vec v) = 0$$
$$\langle A \vec v, A \vec v \rangle = \Vert A\vec v \Vert ^2 = 0$$</li><li>Thus, it is clear that $A \vec v = 0$, so $\vec v \in \text{Null}(A)$<ul><li>That is, $\text{Null}(A^T A) \subseteq \text{Null}(A)$</li></ul></li></ul></div><div class="flex-even markdown-inner"><ul><li>Consider an arbitrary vector $\vec v&rsquo; \in \text{Null}(A)$&ndash; pre-multiplying by $A^T$ we have that&mldr;
$$A \vec v&rsquo; = \vec 0$$
$$A^T A \vec v&rsquo; = \vec 0$$</li><li>Therefore $\vec v&rsquo; \in \text{Null}(A^T A)$<ul><li>That is, $\text{Null}(A) \subseteq \text{Null}(A^T A)$</li><li>Combining this with the prior statement, we find our desired $\text{Null}(A) = \text{Null}(A^T A)$</li></ul></li></ul></div></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/Mehvix/notes/commit/f8613ce3a8c78d566ce09990e2105053b74d6fab title="Last modified by Max Vogel | May 8, 2022" target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>May 8, 2022</span></a></div><div><a class="flex align-center" href=https://github.com/Mehvix/notes/edit/master/hugo/content/docs/eecs-16a/12.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><script>(function(){function e(n){const e=window.getSelection(),t=document.createRange();t.selectNodeContents(n),e.removeAllRanges(),e.addRange(t)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#least-squares>Least Squares</a><ul><li><a href=#motivation>Motivation</a></li><li><a href=#what>What</a></li><li><a href=#proof>Proof</a></li></ul></li><li><a href=#theorems>Theorems</a><ul><li><a href=#theorem-231>Theorem 23.1</a></li><li><a href=#theorem-232>Theorem 23.2</a></li></ul></li></ul></nav></div></aside></main></body></html>