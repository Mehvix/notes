[{"id":0,"href":"/cogsci-c100/intro/","title":"Introduction","section":"CogSci C100","content":"Overview and Fields #   Cognitive Science: Study of the mind and cognition that integrates a number of different academic disciplines:  Neuroscientists study the mind’s biological machinery Psychologists directly study mental processes, such as perception, learning/memory, judgement and decision-making Computer scientists explore how those processes can be simulated and modeled in computers Philosophers ask critical questions about the nature of the mind \u0026ndash; what is mind? how does it interface with body? is is purely the brain? Evolutionary biologists and anthropologists speculate about how the mind evolved       The job of cognitive science is to provide a framework for bringing all those perspectives on the mind together Each of the various academic disciplines that comprise cognitive science use different methods, examples:  Philosophers look at where the unity of their discipline comes from  A commitment to rigorous argument and analysis Particularly in the so-called analytic tradition\u0026ndash; the tradition most relevant to cognitive science Certain problems that are standardly accepted as philosophical   In contrast, the unity of psychology comes from a shared set of experimental techniques and paradigms (Different branches of) Neuroscience employ different tools appropriate to the level of organization at which they are studying the brain; These tools and techniques generally vary in\u0026hellip;  Spatial resolution (y-axis): the scale on which they give precise measurement (varying scale: single neurons, e.x. light microscopy; to looking at parts of the brain in general \u0026ndash; which lobe/area is there activity?) Temporal resolution (x-axis): time intervals to which they are sensitive (the frequency at which you make observations: EEG is very high, to where fMRI/PETS where the effects are measured over a longer scale)     Cognitive Science includes the study of anthropology and cultural differences  Conclusions derived from Western psychology experiments may not be very representative of humanity as a whole Typical research participants tend to be WEIRD: Western, Educated, Industrialized, Rich, and Democratic       Summary #   Ideally, Cognitive Science would involve integration of these disparate methods:\n  Philosophers \u0026ndash; Deductive reasoning Psychologists \u0026ndash; Scientific method Cognitive psychologists \u0026ndash; Modeling AI researchers \u0026ndash; Computer models Neuroscientists \u0026ndash; Case studies, lesion methods, brain imaging Roboticists \u0026ndash; Build and test machines  History of Cognitive Psychology/Cognitive Science #   Cognition is mental activity – the acquisition, storage, transformation, and use of knowledge\n Early History #   Attempts to understand mind go back at least to the ancient Greeks  Discovered laws of learning and memory, e.g., method of loci \u0026ndash; using imagery to enhance your memory capacity Described human thinking in terms of mechanical \u0026lsquo;manipulation of symbols\u0026rsquo;   Study of mind remained province of philosophy until 19th century In 1879, Wundt established first psychology laboratory  One of few important dates (this is the birth date of psychology!) Studied mental processes systematically using technique of introspection  Not what we would consider rigorous now adays e.x. scientist would play a note on an instrument, then ask \u0026ldquo;how does this make you feel?\u0026rdquo;     Within decades, however, experimental psychology became dominated by behaviorism\u0026ndash; a view that virtually denied the existence of the mind  Believe that psychology should study relation between observable stimuli and observable behavioral responses Mind was banished from respectable scientific discussion \u0026ndash; you can\u0026rsquo;t tell what\u0026rsquo;s in that black box, so ignore it!   However, in 1950’s, people started to become disenchanted with behaviorism (e.x. Little Albert) + more experimental research was being done, so cognitive psychology began to emerge  Result of growth of interest in memory and developmental psychology, linguistics and computer science   The Magical Number Seven, Plus or Minus Two \u0026ndash; proved you could study the mind experimentally. Discovered that people universally learned things at similar ages   View that mental processes can best be understood by comparison with a computer  A particular cognitive process can be represented by information flowing through a series of stages      Development of Computational Model of Mind #   Alan Turing  In article published in 1936-37, conceived of information processing as an algorithmic or rule-based calculation process (Turing machine)  A Turing machine has a set of instructions (machine table) that determines what the machine will do when it encounters a particular symbol in a particular cell, depending upon which internal state it is in\n  Together with advances that were made in designing and building digital computers during and after World War II, this led to development of view that cognition involves an algorithmic process of information processing   Parallel distributed processing (PDP) and connectionist models/neural networks became popular in 1990’s  That is, processing can happen parallel, simultaneously \u0026ndash; contrast with serial processing approach Hold that cognitive processes operate in a parallel fashion  e.x: face recognition \u0026ndash; cognitive processes can be completed even when supplied information is incomplete or faulty; your friend dyes their hair, but you still recognize them next time you see them.     Research in AI and Machine Learning boomed in early 21st century due to growth in computing power and availability of large data sets  We knew how to do this way before, but didn\u0026rsquo;t have the data sets nor computational power til now   Classifications:  Artificial Intelligence (AI): tries to design computer models that accomplish the same cognitive tasks that humans do Machine Learning: a subset of AI that allows computers to \u0026ldquo;learn\u0026rdquo; (i.e. progressively improve performance on a specific task) by creating new algorithms to produce a desired output based on structured (or unstructured) data that is provided  Relies on labeled data set and human input to differentiate classifications (e.x telling the computer cats have pink noses while dogs have black, etc.)       Deep Learning: a subset of Machine Learning involving numerous layers of algorithms  Machine does not need to be provided with structured data \u0026ndash; doesn\u0026rsquo;t required labeled data set, harder to do       Neural Networks: Networks of algorithms that are similar to the neural networks present in the human brain    The Turn to the Brain in Cognitive Science #   Early models of cognitive functions, such as visual perception, focused on top-down analysis and included relatively little discussion of neural implementation \u0026ndash; not based on scientific method  Neuroimaging techniques that emerged in the 1980s and 1990s, such as PET and fMRI, allowed neuroscientists to begin establishing large-scale correlations between types of cognitive functioning and specific brain areas  Other techniques, such as single-cell recordings, have made it possible to study brain activity in nonhuman animals at the level of the single neuron      The Cerebral Cortex #  This will be on the exam!     Frontal lobes: involved in speaking \u0026amp; muscle movements and in making plans \u0026amp; judgments \u0026ndash; directly proportional to social network Parietal lobes: include the sensory cortex, important in spatial navigation Occipital lobes: include the visual areas, which receive visual information from the opposite visual field     Temporal lobes: include the auditory areas and mystical (out of body) experiences Motor cortex: area at the rear of the frontal lobes that controls voluntary movements Sensory cortex: area at the front of the parietal lobes that registers \u0026amp; processes body sensations  Limbic System #   Limbic cortex: phylogenetically older part of cortex Amygdala: Two almond-shaped neural clusters that are components of the limbic system and are linked to emotion, particularly fear and aggression Hippocampus: Donut-shaped structure that is important in memory      Are our behaviors determined by brain function? #   Or, is brain function determined by our behaviors? (Which came first\u0026ndash; the chicken or the egg?)\n  Physiological correlates can almost always be found for psychological states  If we haven\u0026rsquo;t figured it out yet, we probably will very soon   Penfield found that stimulating various parts of the brain with electrodes give rise to specific thoughts, emotions, images, or motor movements  Done on epilepsy patients in preparation for surgery (so they didn\u0026rsquo;t remove any parts that were crucial) Abnormal EEG patterns seen in those with schizophrenia, depression, obsessive-compulsive disorder (OCD), and attention deficit-hyperactivity disorder (ADHD) However, this does not necessarily mean that brain states cause mental states!  e.x. psychotherapy and drug therapy produce similar types of brain changes (e.g., in studies of treatment of depression, OCD, and ADHD) Recalling sad memories makes your brain temporarily look like the brain of someone with depression Psychotherapy (talk therapy) produces the same brain state that meditation does      Controversies in CogSci #   Do the benefits of cognitive neuroscience justify the costs?\n  Neuroimaging studies can be quite outrageously expensive, and many of these studies do not provide direct practical benefits  To run an hour PET on someone, it costs $20-30k per subject and you need many subjects for research   Some researchers claim that cognitive neuroscience has not really helped to develop psychological theories \u0026ndash; people are just wowed by pictures of brains  Limitations of the experimental method #   Artificiality of experiments (lack of ecological validity \u0026ndash; doesn\u0026rsquo;t apply to real-world scenarios): the more you control the environment, the less like real life it becomes Argument that the best things in life (e.g., love, beauty, truth, joy) cannot be quantified    There was an awful rainbow once in heaven:\nWe know her woof, her texture; she is given\nIn the dull catalogue of common things.\nPhilosophy will clip an Angel’s wings.\n \u0026ndash; John Keats\n   Belief as a confounding variable: Magellan’s diary  When Magellan interacted with native people, they could not see (perceive) his large ships The idea is that the ships were so alien to their experience that \u0026ldquo;\u0026hellip; their highly filtered perceptions couldn\u0026rsquo;t register what was happening, and they literally failed to \u0026lsquo;see\u0026rsquo; the ships.\u0026rdquo; (JZ Knight, What the Bleep Do We Know?) Certain things have to be believed until they can be seen    SQ3R technique #   Steps:  Survey: Scan material; Read headings, figures, summaries Question: Pose questions to yourself Read: Look for answers to questions as you read; Read actively, not word-by-word (key to speed-reading!) Recite: Practice rehearsal (tell someone about the material) Review: Go over answers to questions; Review material again a day or several days later   Fallacies:  You have to read every word. The slower you read, the higher your comprehension. It’s a \u0026lsquo;sin\u0026rsquo; to skip around when you are reading.    "},{"id":1,"href":"/cogsci-c100/perception/","title":"Perception","section":"CogSci C100","content":"Definition of sensation and perception #   As humans, we are cognitive beings who\u0026hellip;  Acquire information about the world around us (perception) Integrate that information with prior knowledge from our stored memory Store that knowledge in our memory so we can use it later to help us achieve our goals   First step in this process of acquiring knowledge about the world involves sensation and perception  Sensation: process by which our sensory receptors and nervous system receive stimulus energies from the environment and transduce them into neural impulses (transduction). The inherent stimuli. Objective Perception: process of interpreting and organizing sensory information through use of previous knowledge. What gives stimuli meaning. Subjective.    Early models of object perception #   Lots of machines are built on these old theories The models aren\u0026rsquo;t respected nowadays, but had useful tid-bits of information (for cogsci, ML, etc)  Template matching model #   Template matching model: object perception involves a comparison of the stimulus with set of templates or specific patterns stored in memory Static, unchanging Problem: cannot account for complexity and flexibility of object recognition  e.g. individual differences in handwriting        Feature analysis model #   Feature-analysis model: discrimination of objects is based on small number of distinct characteristics of stimuli  Are these two the same letter?: G M P R  People are faster at deciding whether G and M are different than P and R because there are fewer similarities   Supported by neurological evidence: some neurons respond only to horizontal lines, others to diagonals, etc.   Problem: Cannot explain recognition of complex objects with features that move and distort (e.g., horse or kangaroo)   Recognition-by-components model #    Recognition-by-components model: view that an object is represented as an arrangement of simple 3-D shapes called geons Six main geons above    Cup/pail composed of cylinder and curved tube geons in a particular arrangement\n    Easier to tell the object from the rightmost column versus the center, despite the latter containing more lines\n   David Marr’s Model of Visual Processing #   Not on Exam\n  The image is then transformed into a 3-D sketch in which the the axes of symmetry and elongation link the object parts  Symmetry axis: line that divides an object into mirror image halves Elongation axis: line defining direction along which main bulk or mass of a shape is distributed         The 3-D sketch is object-centered – the object’s parts are described relative to one another and are linked on the basis of shared properties and axes  This solves the object constancy problem, allowing recognition of an object presented in different orientations and under different conditions, e.g., lighting changes    Prototype model #   Prototype model: object perception involves a comparison of the stimulus with ideal, abstract example  People are faster at identifying sparrow as a bird than penguin   One of the most famous models in all of cognitive psychology (and developed at Berkeley!) It has been hypothesized that our sensory systems act primarily as a selective filtering mechanism  Prototypes more easily pass this filter This filter sorts things according to a limited number of variables (e.g., warm, unpleasant, green) out of which we construct our world But prototype theory suggests that our minds can also perceive objects in a very different way\u0026hellip;   That which is essential is invisible to the eye. – de Saint-Exupery\n   Alternative modes of perception #   Alternative modes of perception: Mindfulness is largely about seeing the “suchness” of things, that is, seeing things directly without conceptual filters What assumptions might you make about this woman if you were told she is from New England? from California?  Our preconceived notions prevent us from seeing the real person in front of us Stereotyping         If the doors of perception were cleansed, everything would appear to man as it is, infinite.\nTo see a World in a Grain of Sand, And a Heaven in a Wildflower, Hold Infinity in the palm of your hand, And Eternity in an hour. \u0026ndash; Blake\n Neural Networks #   On Quiz 2!\n  Artificial Neural Networks in Pattern Recognition Human neurons    Many different neurons connect to the dendrites of each neuron  Some produce excitatory effect; others produce inhibitory effect There are also different levels of intensity of these effects   Around a thousand connections are connected to each neurons  If the activation of the neuron reaches a certain minimum threshold, the neuron will fire        16A Notes  Because circuit analysis translates to a wide range of fields, we can model many physical systems as electrical circuits, often gaining insight about the system. You may have heard of neural networks, an important machine learning tool that can be used to “learn” tasks such as image and voice recognition from examples instead of explicit programming. Neural networks are modeled after biological neural networks, which are fundamentally circuits operating on electrical signals within a brain:\n   In a general sense, studying circuits provides you with the conceptual and mathematical tools needed to analyze such networks. More broadly, circuit concepts are relevant to understanding network analysis and signal flows in systems, which can be applied to areas ranging from transportation analysis to social network analysis. ( from EECS16A Note0)\n    Artificial neural networks (ANN)  The nodes or neurons are organized into layers in much the same way that human neural networks are The weights attached to the connections between pairs of units in adjacent layers determine the overall behavior of the network  This is similar to the way in which excitatory and inhibitory neurons of various strengths connect to a particular neuron in human neural networks   The bias term indicates what the weighted sum needs to be before the node/neuron will activate  This is similar to the threshold necessary for activation of a neuron in human neural networks         An artificial neural network is an interconnected group of nodes, inspired by a simplification of neurons in a brain. Here, each circular node represents an artificial neuron and an arrow represents a connection from the output of one artificial neuron to the input of another.\n   Ex: How might a computer recognize a “9” using neural networks? #     There is huge variety of ways in which people write 9’s To simplify things, we can represent the “9” by decomposing it to a grid of 28 x 28 pixels of varying shades of gray (between 0 and 1)   First (input) layer of network  Starts with bunch of neurons or nodes corresponding to an array of 28 x 28 pixels in the image Each node holds a number that represents the grayscale value of the corresponding pixel, ranging from 0 for black to 1 for white This is the neuron’s activation level Activations in one layer bring about activations in the next layer, which in turn bring about activations in the next layer\u0026hellip;       This is loosely analogous to how, in biological networks of neuron, some groups of neurons cause other neurons to fire   Second layer (or first “hidden layer”)  Each neuron in the second layer might pick up on whether there is an edge in one particular region You assign a weight to each one of the connections between a particular neuron in the second layer and the neurons in the first layer Then you take all the activations from the first layer and compute their weighted sum according to the weights  Could make the weights associated with almost all of the pixels 0 except for some positive weights in target region To really pick up on whether there is an edge here, could also have some negative weights associated with the surrounding pixels  Sum is largest when those middle pixels are bright but surrounding pixels are darker         But maybe you don’t want the neuron to light up anytime the sum is bigger than zero \u0026ndash; maybe you only want it to be active when the sum is bigger than say 10 So you add in some other number (the bias), like -10, to the weighted sum  The bias tells you how high the weighted sum needs to be before the neuron starts getting meaningfully active         The connections between the other layers also have weights and biases associated with them   Third layer (or second “hidden layer”)  When we recognize digits, we piece together various components  e.x: A “9” has a loop near the top and a line on the right whereas an “8” has a loop on the top and one below  Each neuron in the third layer corresponds to one of these subcomponents  e.x: A particular neuron in the third layer might be activated by any generally loopy pattern toward the top   These subcomponents are made up of the various edges from the second layer           Last (output) layer  Has 10 neurons, each representing one of the digits The activation in these neurons – some number between 0 and 1 – represents how much the system thinks a given image corresponds with a given digit Learning is about getting the computer to find a setting for all of the different weights and biases so that it will actually solve the problem at hand  This is done through backpropagation          Learning in Neural Nets: Backpropagation #   ANNs can compute any function that can be computed by a digital computer  However, it was not until the emergence of backpropagation learning algorithm that it became possible to train multilayer neural networks   The strength or weight of the connections between neurons in adjacent layers varies: neural networks learn by modifying these weights  Learning algorithms that are programmed into the ANN change the weights of the connections between pairs of neurons in adjacent layers in order to reduce the “mistakes” that the network makes The basic idea is that each hidden unit connected to an output unit bears a degree of “responsibility” for the error of that output unit If the activation level of an output unit is too low, then the weight between the output unit and each hidden unit connected to it is increased to decrease the error The network then assigns error levels to the next layer of hidden units, so the error is propagated back down through the network until the input layer is reached   tl;dr: neural networks have to \u0026rsquo;learn\u0026rsquo; by adjusting stimuli weights. When a network gets an answer wrong, it has to recursively pop back each layer and adjust the corresponding weights (increasing correct value weights, decreasing activated incorrect value weights)  Other Neural Networks Q\u0026amp;A #  Q: How many neurons should there be in each hidden layer?\nA: There are a number of empirically-derived rules-of-thumb. Of these, the most commonly relied on is “the optimal size of the hidden layer is usually between the size of the input and size of the output layers”  Q: How many hidden layers are needed? Are more layers better?\nA: No. Situations in which performance improves with additional hidden layers are very few. One hidden layer is sufficient most of the time.  Q: Why are more hidden layers not necessarily better?\nA: Increasing the number of hidden layers much more than the sufficient number will cause the network to overfit the training set. It will learn the training data, but it won’t be able to generalize to new unseen data.    Overfit Dataset:   Top-down processing in object recognition #   Limitations of models of object perception discussed above: assumes, in theory, perception is objective and accurate; in real life, that is often not the case\u0026hellip;  What we perceive, the way we perceive, is not always what would be predicted by these models Our concepts, expectations, and beliefs play a much bigger role in perception than we usually realize   Perception engages both top-down and bottom-up processing  Bottom-up processing: analysis of information coming from stimuli through sensory receptors  Object perception as combination of stimulus information from sensory receptors Emphasizes the importance of information coming from the outside world   Top-down processing: information processing guided by higher-level processes, such as our beliefs, expectations, and memories  Our knowledge, beliefs about the world inform our perceptions Emphasizes the importance of information coming from our minds   Note: we use both throughout everyday situations, rarely exclusively either or  Models can almost be sort of categorized/grouped by which of the two processing model they put emphasis on   E.x. you see a water bottle on your desk  You know it\u0026rsquo;s a water bottle since it\u0026rsquo;s physically there. You can see, and perhaps touch it You know it\u0026rsquo;s a water bottle because of it\u0026rsquo;s features which have meaning to you through living in the modern world (perhaps owning a water bottle yourself!)  If you were an alien, or a homosapien from a very long time ago, you wouldn\u0026rsquo;t know that the object was a water bottle (among other things\u0026hellip;)        Optional: Deductive versus Inductive Reasoning  Deductive reasoning works from the more general to the more specific, i.e., “top-down” approach.  In deductive reasoning there is usually a first premise, then a second premise (both of which are proven through observations), and finally an inference. Ex: All men are mortal. Smerdley is a man. Therefore, Smerdley is mortal.   Inductive reasoning works the other way, moving from specific observations to broader generalizations and theories, i.e., “bottom-up” approach  Inductive reasoning extracts a likely (but not certain) premise from specific and limited observations. Ex: I have a bag of many coins, and I’ve pulled 10 at random and they’ve all been pennies, therefore this is probably a bag full of pennies.      “Objective reality” is often not as objective as we think\u0026hellip; #   A fool sees not the same tree that a wise man sees. \u0026mdash; William Blake\n   Reversible figures (e.g., Necker cube; vase/profiles)\n  Ambiguous figures (e.g., old woman/young woman \u0026ndash; also old people tend to see the old figure first, and vis-versa)\n         Effect of expectations on perception  Perceptual set brain teasers: SOAK FOLK CROAK Context effects (e.g. bea(r|n), Presidential illusion)    #         Effects of expectations, experience, emotional patterns, and beliefs on perception #   Effects of Prior Experience on Perception  Children who have been physically abused are significantly more likely to misperceive a fearful face as angry (Pollak)       Cultural effects on perception  What is above the woman’s head? Is this an indoor or outdoor scene? (Gregory and Gombrich, 1973)       Rorscharch and Thematic Apperception Test (TAT)         When angry, people more often perceive neutral objects as guns (Baumann \u0026amp; DeSteno, 2010) Effect of beliefs/preconceived notions on perception  Rosenhan study on effects of psychological labeling      Self-fulfilling prophecies #   Self-fulfilling prophecies: People generally think that it is our experiences and perceptions that create our beliefs, but often, it is actually our beliefs that create our experiences and perceptions   Our beliefs and expectations influence others’ behavior  The Pygmalion effect: study found that students who were (randomly) labeled intellectual “spurters” showed significantly greater gains in IQ and academic performance after 8 months than controls  Follow-up: If teacher believed that girls learn to read faster than boys, they did   Children who were told they were neat and tidy became more neat and tidy than those who were told they should be neat and tidy  Follow-up: children who are told that they are good at math showed greater improvements in math scores than those who were told that they should try to become good at math   Those who over-idealize romantic partners as having many virtues and few faults tend to have happier and longer-lasting relationships (Miller, Niehuis, \u0026amp; Huston, 2006)  Moreover, the partners who are over-idealized tended to develop those traits over time! (Sandra Murray) People live up to their expectations \u0026ndash; we tend to bring out what we focus on     Our beliefs and expectations influence our own behavior  Study by Mark Snyder found that when a man was led to believe that a woman found him attractive, she was more likely to act as if she did \u0026ldquo; Gus Hansen refused to acknowledge the odds and the odds disappear\u0026rdquo;  Assume a virtue if you have it not. – Shakespeare\n     Perceptual Constancies #   Perceptual constancy: perceiving objects as unchanging (having consistent lightness, color, shape, and size) even as illumination and retinal images change  Many visual illusions result from the overuse of strategies employed to achieve perceptual constancy   Is Tile A or Tile B darker or are they the same color?\n Illusion results from visual system’s attempt to maintain lightness constancy: we perceive an object as having a constant color, even if changing illumination alters the wavelengths reflected by the object        Shape constancy: we perceive the form of familiar objects as constant even while our retinal images of them change  A door casts an increasingly trapezoidal image on our retinas as it opens, yet we still perceive it as rectangular         Müller-Lyer illusion:  Is line AB or line BC longer? Size-distance constancy: Our brains are used to perceiving angles as corners that are near or far away and sees the inward-facing corners as more distant and therefore smaller      Are the two parallelograms the same size and shape?     Ponzo illusion:  Which line is longer?        Moon illusion: Does the moon appear larger near the horizon or when it is high in the sky?    When the moon is near the horizon we perceive it to be farther away from us than when it is high in the sky, but since the moon is actually the same size, our minds make it look bigger when it is near the horizon to compensate for the increased distance    The Magical Kingdom of Salt     In the Salar de Uyuni of Bolivia, the world’s largest salt flat, with no other objects in sights, the human eye loses its ability to establish a proper field of depth. The result is some bizarre pictures.       Effects of color in marketing #   Assume that you are considering buying condoms  You enter a store and notice that the store doesn’t carry all the brands you may be familiar with, so you’re going to have to make your choice based on the product package alone You are really interested in finding a brand that is considered  Durable, strong, and well built (“rugged” condition) OR Classy, attractive, and refined (“sophisticated” condition)     Which would you choose?  Match the colors with the following  Sincerity: white, yellow.$^1$ Excitement: red, orange.$^1$ Competence: blue    Sophistication: black, pink, purple Ruggedness: brown .$^1$Marginally significant      Neurological disorders of visual perception #  Face perception and prosopagnosia #   Face recognition is “special”  Single-cell recordings of monkeys show activation of particular cells in lower temporal only when full-face photos of other monkeys are presented   Recognition accuracy for faces and houses: parts vs. whole  Study (Tanaka and Farah, 1993) in which participants were shown series of faces with person’s name and series of houses with owner’s name Later on recognition test, they showed greater recall of  Parts of houses but Whole faces         Do people tend to perceive men or women more in “parts”? Women (Gervais, Vescio , Forster et al., 2012)   Prosopagnosia: failure to recognize particular people by the sight of their faces  After stroke, sheep rancher could not recognize people but could recognize sheep  Someone would walk in the room and he wouldn\u0026rsquo;t be able to tell if it was the wife/neighbor/robber/etc   Note: the eyes also play a special role in perception   70-90% of famous portrait paintings sampled from the last five centuries have an eye at or within 5% of the painting’s exact centerline (Christopher W. Tyler)\nEvery man indicates in his eye the exact indication of his rank. – Emerson\n     Modular Processing #   Visual illusions suggest that the mind is at least in part modular (Jerry Fodor)  That is, it is not solely organized in terms of faculties, such as memory and attention, that can process any type of information Rather, there are specialized information-processing modules that  Respond automatically Cannot be “switched off”            Modular processes are usually characterized by\u0026hellip;\n Fixed neural architecture  It is sometimes possible to identify determinate regions of the brain that are associated with particular types of modular processing  e.x: fusiform face area for face recognition     Specific breakdown patterns  Modules can fail in highly determinate ways, which provide clues on the form and structure of processing  e.x: prosopagnosia        Other Neurological Disorders Related to Visual Perception #   Visual agnosia: inability to recognize/identify visual objects despite relatively good visual perception  Usually due to damage in occipital or temporal lobes  “Mr. P” in Oliver Sacks’ Man Who Mistook His Wife for a Hat Man with agnosia puzzling over a picture of a cow suddenly found himself making alternating up-and-down movements with fists. He looked down at his hands and said, “Oh, a cow!” Due to some error between vision and verbal communication     Visual neglect syndrome or unilateral spatial neglect:  Tendency to ignore – or to be unaware of – information on one half of visual field, usually the left side Typically occurs after damage (e.g., stroke) to right hemisphere, particularly damage to the parietal and frontal lobes Relatively common, easy to test for   Patients are asked to bisect each line. Their markings are typically skewed to the right, as if they do not see the leftmost segment\n    Patients are asked to draw from memory or to copy an illustration (Driver \u0026amp; Vuilleumier, 2001)\n   House       Experimenter: Are the two houses the same or different?\nPatient: The same.\nExperimenter: Which house would you prefer to live in?\nPatient: The left house.\n         Capgras syndrome: characterized by belief that family and/or friends are imposters  Damage to pathway between visual cortex and amygdala, which regulates emotions Emotional “glow” that we normally feel around people we are close to is missing Ramachandran argues that this emotional “glow” is, to a large extent, what gives us a sense of continuity in our relationships Classified as some kind of schizophrenia   Functional blindness (conversion disorder): unexplained vision loss with no organic basis  Cambodian women who had witnessed horrible war atrocities became either partially or wholly blind Impairs primarily body functions / processes  Psychological defense mechanism     Blindsight: vision without awareness  Blindness resulting from damage to visual cortex When presented with various shapes like circles and square, or photos of faces of men and women, patient could not tell (or guess) what his eyes were gazing at However, when shown pictures of people with angry or happy faces, he was able to guess the emotions expressed, at a rate far better than chance Patients are also able to correctly “guess” the identity or location of particular objects Patients report that they get a “gut” feeling that allows them to perform these tasks     Blindsight patient was able to meander around all the clutter in a hallway that he was told was empty (Weiskrantz)\n    A second pathway of visual perception may account for this phenomenon    Two pathways of visual perception #     Study looked at speed with which people were able to find a specific hidden object among a group of similar objects Participants were instructed to  Passively allow the target to just “pop” into their minds OR Actively direct their attention to the target   Participants in Passive Group 1 outperformed those in Group 2 (Smilek, Enns, Eastwood et al., 2006)    Targets   Look for the circle with just one gap, and say whether the gap is on the left or the right Use “relax” strategy, then try active search strategy     Proposed explanation:  Participants who were basically told to relax and go with their gut instinct used a secondary pathway of visual perception that Does not go through the visual cortex Instead simply makes a very short loop through the limbic system: the emotional, instinctual center of the brain        Research evidence for existence of two pathways:  Auditory cortex of rats was destroyed, then rats were exposed to tone paired with an electric shock Rats quickly learned to fear tone, though they could not “hear” it! Explanation: the sound took the direct route from ear to thalamus to amygdala, bypassing all higher avenues (Joseph Ledoux)      Development of perception #    Adults who were born blind and later gained vision through newly-developed surgical interventions (e.g., cataract surgery) usually have some difficulty recognizing objects  At age 3, Mike May lost his vision in an explosion. Decades later, a new cornea restored vision to his right eye. Unfortunately, although signals were now reaching his visual cortex, it lacked the experience to interpret them  May could not recognize expression, or faces, apart from features such as hair Yet he can see an object in motion   Ended up committing suicide because he found himself in a world he didn\u0026rsquo;t (couldn\u0026rsquo;t) understand or comprehend      There is a critical period for normal sensory and perceptual development Kittens reared in a cylinder with only vertical black and white stripes later had difficulty perceiving horizontal bars  Kitten would play with rod only when it was held upright As if they couldn\u0026rsquo;t see the horizontal rod        "},{"id":2,"href":"/e-29/0/","title":"Week 0: Intro \u0026 Tolerancing","section":"Engineering 29","content":"01-18: Course introduction #  Overview #  This class focuses on three main components \u0026ndash; manufacturing processes, dimensional tolerances, and design communication \u0026ndash; and how they interact with one another.\n The class is made up of 9 modules:\n Fundamentals Subtractive manufacturing processes Additive manufacturing processes Forming processes Joining processes Graphical visualization techniques Metrology: measuring manufactured objects Geometric dimensioning and tolerancing The future of manufacturing  Why manufacturing? #   In 2018, U.S. manufacturing accounted for 11.6% of the U.S. economy, 18.2% of global manufacturing output, and 8.2% of the U.S. workforce \u0026ndash; source Manufacturing output is growing, and is returning to the U.S.; output increased \u0026gt;30% between end of 2008 and 2014 67% of U.S. R\u0026amp;D is funded by industry Even when production is offshore, design is often done here anyway Automation is increasing, yet there is a shortage of skilled (human) talent Even if you don\u0026rsquo;t want to go into manufacturing industry, research and academia still require manufacturing knowledge Even if the process if outsourced, design is still done in the US. To design well, you have to have a base-level understanding of manufacturing    Manufacturing output and employment are rising\n    Many companies have regionalized their supply chains since the pandemic\n   Processes #  In this class we will consider multiple families of processes:  This is a rapidly moving field that is always adapting This class should give you a top level overview so you can evaluate novel methods  Materials #  In this class we will consider multiple families of materials:  Materials choices influence performance  For example, consider the progress of the plane: In 1903 the right brothers low-density wood with steel wire and silk In 1935 the Douglas DC3 used aluminum alloy (since it became feasible to produce and manipulate) Now the 2010 Boeing 787 Dreamliner is made up of 50 wt% composites 20 wt% aluminum 15 wt% titanium 20% lower fuel consumption per passenger mile  Composite materials are two(+) materials combined together to get best of both worlds, in aviation typically stiff/strong carbon fibers embed in tough/fatigue-resistant polymers.     Materials choices influence market size  There isn\u0026rsquo;t always a best material; different materials fit different markets/needs Opposite side of the coin: There may be multiple valid material choices for a particular function    Tolerance #   Tolerancing is a formal way of specifying limits on the amount of dimensional variability allowable in manufactured parts  We need a range because measurements will never be 100% precise; we need to define an acceptable range Some sources of variation  Human operator changes and/or errors Tool wear Environmental changes (temperature, humidity leads to tiny expansions / contractions) Input material variability Measurement error     Affordable mass-production relies on interchangeability of parts  When mating parts of given designs, it should not matter which specific parts   Therefore part dimensions must be consistent  But no manufacturing process is perfectly consistent   If you don\u0026rsquo;t understand the process of manufacturing and the capabilities of tools, then you will won\u0026rsquo;t know how to create manufacturable designs    Tighter tolerances (closer tolerance limits) are generally more expensive to achieve The solid green line shows an ideal process The dotted green line shows the impact of an error shifting the distribution, shifting the tails to approach the tolerance upper / lower bound The red line shows a unsuitable process (even if it\u0026rsquo;s calibrated accurately, the poor precision causes high variance that it\u0026rsquo;s not really feasible; however, if outside of the limits an additive (or less common subtractive) could be used to )   How E29 integrates manufacturing and tolerancing #   Tighter tolerances are more expensive The physics of a process determine how tight a tolerance is achievable and how much it costs Therefore we need to understand how manufacturing processes work in order to:  Select a suitable process for the application Specify reasonable tolerances Geometric Dimensioning and Tolerancing: a graphical language for specifying tolerances robustly    Design Communication #   Important to effectively describe your ideas and designs graphically  Persuade \u0026ndash; we need to be able to show are perspective Instruct \u0026ndash; we need an agreed an unambiguous way to communicate Document \u0026ndash; we need to convey how to construct our final design Seek feedback \u0026ndash; we need to ensure everyone is on the same page   Drawings can be 2D or 3D representations  Interpreting 2D drawings made by others Creating 2D “working drawings” with unambiguous instructions   Design communication is not only graphical  Oral, written Manufacturing relies on teams Teaming activities    01-20: Fundamentals of Tolerancing #   See why we study tolerancing from yesterday\u0026rsquo;s notes  Basic tolerance formats #   Unilateral  e.g. Inches: .$.500^{+0.005}_{-0.000}$, Metric: .$35^{+0.05}_0$ (notice sigfig notation)   Bilateral  Most common; start with nominal then you have some tolerance bounds above and below Equal or unequal deviations from nominal dimension Same number of decimal places for upper and lower limits e.g. Inches: .$.500 \\pm .005$ or .$.500^{+0.005}_{-.010}$, Metric: .$35 \\pm 0.05$ or .$35^{+0.05} _{-0.10}$   Limit  Given only bounds, not the nominal value e.g. Inches: .$.250, .248$, Metric: .$35.05, 35.00$    Tolerance buildup #   In the real world we have error, so the way we define dimensions have an impact Best dimensions to label depend on function  That is, dimensioning should be done intentionally such that critical distances result in minimal error, e.g.suppose distance between .$X$ and .$Y$ is critical      Chain is bad since the potential (and often times real world) maximum error is large  The errors compound since dimensions are in reference to other dimensions that may will contain error. The more dimensions chained, the greater the possible error   Baseline is better \u0026ndash; every feature references a single base.  However the worst case is still significant .$X$ may be off by .$\\pm .05$ and .$Y$ may be off .$\\mp 05$, compounding to .$\\pm 0.10$!   Direct is ideal  Depends on which dimensions are critical (that is, .$X, Y$)     Normal cumulative distribution function #   Tighter tolerances (closer tolerance limits) are generally more expensive to achieve The physics of the process used determines the curve\u0026rsquo;s characteristics  .$\\sigma$ is the stdiv (width) of this density   .$\\mu = x_0$ is the target (average) value we give This probability density characterizes how this function is distributed and the chance a given range of values occur  The area under the curve in a given range is the probability the value falls within that range Single values, i.e .$x_0$, have a 0% probability. We can only calculate ranges because this is a density function.       Probability density, e.g. given by Gaussian/Normal probability density function: $$p(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-\\frac{(x-x_0)^2}{2\\sigma^2}}$$\n    Why do we care about statistics?  We want to look at a process, look at tolerances, and figure out whether it\u0026rsquo;s worth to manufacture using this process If you know the distribution of a process, you can work out the probability a given part satisfies spec limits.   There is no easy, exact analytical way to integrate the normal probability density function.  The probability that a randomly chosen member of a normally distributed population has a value .$\\leq x$ is $$\\int_{-\\infty}^x p(x)\\ dx = P(x) = Z\\bigg(\\frac{x-\\mu}{\\sigma}\\bigg) = \\frac{1}{2}\\bigg[1 + \\text{erf}\\bigg(\\frac{x-\\mu}{\\sigma\\sqrt{2}}\\bigg)\\bigg]$$  .$\\text{erf()}$ is the error function .$Z$ is the normal cumulative distribution function; values of .$Z$ are tabulated in a Z table      Example probability of part lying between within spec limits   Process capability and tolerancing #   Sigma, .$\\sigma$, is the standard deviation of dimensions actually produced by a process  Six sigma processes  Six Sigma (6σ) is a set of techniques and tools for process improvement. [\u0026hellip;] A six sigma process is one in which 99.99966% of all opportunities to produce some feature of a part are statistically expected to be free of defects.\n  Specification limits are .$12\\sigma$ apart. Here, 2 parts per billion lie outside specification limits if process is \u0026lsquo;in control\u0026rsquo; (i.e. if mean output of process is centered between specification limits) Arose because the cost of manufacturing, specifically the process that creates an error, has a cost. This cost can grow very large, very quickly, when mass-manufacturing.  You\u0026rsquo;re best off spending money improving the process so the distribution gets tighter The alternative is either (1) accepting errors (resulting in faulty products) or (2) testing all components to ensure they are \u0026lsquo;good\u0026rsquo; and tossing out the bad ones   Process capability: .$C_p = \\frac{\\text{USL - LSL}}{6\\sigma}$    Classes of Fit #   Tolerances should be\u0026hellip;  Not too tight: tight tolerances are expensive Not too loose: otherwise function is compromised      Clearance fit: designed with space left between two components  e.g. a shaft with a bearing need to have some give / free space   Interference (push) fit: designed to be touching  You may want interference because you want the friction between the components; you want the two pieces to not move/rotate/etc How? Elastic or even plastic deformation e.g. two pieces may need to fit tightly with friction as to prevent vibrations Expansion fit:  If there are large forces/torques acting on these two components so you want them very tight e.g. you may temporarily expand one component (e.x. with heat) to fit on/around the other, then it will shrink down   Shrink fit:  Same as expansion, but using some cooling process (e.x. liquid nitrogen) Why do this over heat?  It\u0026rsquo;s typically more expensive to cool down The material may deform / weaken \u0026ndash; e.g. steel will be degraded if heated up       Transition fit: complete interchangeability is compromised to allow looser tolerance on individual components.  If fit type is not critical. But even then, why not choose one or the other? Because you don\u0026rsquo;t want a large gap and the materials/parts cannot withstand the force needed to assemble them with an interference fit. The pieces are just for alignment \u0026ndash; think Ikea assembly pegs; they\u0026rsquo;re just to align components. It\u0026rsquo;s easier to manufacture these parts     Snap fits #    Involves temporary elastic deflection which enables parts to interlock, e.g. involving bending of one component Done often with molded parts Tends to involve Cantilever (e.g. casings), Annular (e.g. pen lids, take-out soup container lids) Designed to be assembled once, and typically not disassembled (multiple times) \u0026ndash; irreversible. Relatively simple: you don\u0026rsquo;t need screws/glues/etc. \u0026ndash; useful for rapid prototyping since you don\u0026rsquo;t have to consider fasteners Takes advantage of the fact that the material has some elasticity  You need to stay within the elasticity limits of the material Most 3D plastics have \u0026rsquo;enough\u0026rsquo; give You (generally) want to design such that the stress is from bending, not stretching    More, additional, extra, readings   Terminology Definitions #   Don\u0026rsquo;t stress about memorizing these !\n   Maximum material condition (MMC): The greatest allowable amount of material left on the part (max size for a shaft; min size for a hole) Minimum/least material condition (LMC): The least allowable amount of material left on the part (min size for a shaft; max size for a hole)  Important with MMC since they tell us how much they\u0026rsquo;re able to \u0026lsquo;slosh around\u0026rsquo;   Basic size: Exact theoretical size from which limits are derived  Different form nominal since basic refers to the standard table which gives respective upper and lower bounds (MMC and LMCs) Hole basis: Basic size is minimum size of hole Shaft basis: Basic size is maximum size of shaft \u0026ndash; used when many components need to fit on to one shaft. Basic size could be chosen to be in-between hole and shaft basis   Tolerance: Allowable variation of one particular dimension Fundamental deviation: Difference between basic size and the closer of the MMC and LMC Allowance: Difference between maximum material conditions of the two components   Types of fit #   These types are created by ANSI: American National Standards Institute Exact values are tabulated in many source    RC: Running and sliding clearance fits  Nine categories:  RC1: Close sliding: assemble without perceptible “play” (e.g. watches)  Less than a 1/1000\u0026quot;. Basically impossible for air, let alone liquids, through.   RC2: Sliding fits: seize with small temperature changes (e.g. ) RC3: Precision running: not suitable for appreciable temperature differences RC4: Close running: moderate surface speeds and pressures RC5/6: Medium running: higher speed/pressure RC7: Free running: where accuracy not essential and/or temperature variations large RC8/9: Loose running   Go for lower if you want minimal vibration/gaps \u0026ndash; no perceivable play. Has drawbacks:  The less clearance, the easier it is to seize up \u0026ndash; especially if two components are touching and made up of different materials (different expansion/contraction rates). Susceptible to dust, you would have to seal the machine or use it in clean conditions.   If you go less precise, you don\u0026rsquo;t need to go slow, cheaper operator costs, cheaper tooling RC Chart    RC Table      LC: Locational clearance fits  Normally stationary, but freely assembled/disassembled Used when you need clearance to dis able and clean LC Chart        LT: Location transition fits  Accuracy of location important Small amount of clearance or interference OK e.g. ikea furniture pegs   LN: Locational interference  When you need friction Accuracy of location is critical         FN: Force fits  When you need to hold a load (typically uses temporary heating) Designed to transmit frictional loads from one part to another    Example: Which type of fit?   Processes, tolerances, and surface quality #   How do we relate physical processes and tools to these values?    From MF Ashby, Materials Selection in Mechanical Design\n Roughness #   How do we define roughness? You may use tool that uses a tiny needle to \u0026lsquo;scan\u0026rsquo; the surface, measuring deflections as you go    From MF Ashby, Materials Selection in Mechanical Design\n  RMS roughness: root mean square of deviations over the measured surface length  i.e.: .$R^2 = L^{-1} \\int_0^L y^2\\ dx$ Usually, tolerance, .$T$, lies between 5R and 1000R   Generally, if you go high rotation speed and slow translational speed you get less rough surfaces RMS Roughness Example      "},{"id":3,"href":"/eecs-16a/0/","title":"Week 0: System Design \u0026 Linear Equations","section":"EECS 16A","content":"01-18: Course Introduction #    Slides Notes 0, 1A   All logistics, no notes!\n01-20: Introduction to Imaging, Tomography, and Linear Equations #    Slides Notes 1A, 1B   System Design #   We use devices, such as imagers, that provide information, such as a visual representation of a system  Often, these devices don’t work alone \u0026ndash; they are part of a larger system that uses a combination of both physical sensors and signal processing techniques.   When we take projections of images, we tend to need to take multiple measuring (pictures) from differing angles  Otherwise we have issues with overlap and ambiguity To generate 3D models, we need these multiple perspectives   We ideally want to design a system that gives us a set of linear equations  Some times we can only approximate these linear equations Lots of physical processes (i.e xrays!) are exponential so we just slap a log on it  .$\\hat y = p \\cdot (e^{x_1} + \\dots + e^{x_n})$ .$y = -\\log_e (\\hat y \\cdot p^{-1}) = x_1 + \\dots + x_n$ .$\\hat y$ is our measured energy value .$x_n$ is the .$n$th \u0026lsquo;pixel\u0026rsquo; .$p$ is the power of the energy source Tomography Example      To solve, we need enough independent equations that do not contain redundant information, otherwise there will be multiple ambiguous solutions Different models are made up of different configurations (of the energy source and measuring sensor) and result in different system of equations  We can obtain equations by moving both the energy source and measuring sensor (think document scanner) to get each individual pixel We can also move the energy source alone instead \u0026ndash; think camera pointed at image with a projector used to light up certain (group of) pixel(s)  Different patterns have pros/cons \u0026ndash; speed, resolution, accuracy, number of measurements, energy use        Linear Algebra #   The study of linear functions and linear equations, typically using vectors and matrices Linearity is not always applicable, but can be a good first-order approximation There exist good fast algorithms to solve these problems (and lots of fun properties!) Consider .$f(x_1, \\dots, x_n) : \\mathbb{R}^n \\to \\mathbb{R}$; .$f$ is linear if the following hold\u0026hellip;  Homogeneity: .$f (\\alpha x_1, \\dots, \\alpha x_n) = \\alpha f(x_1, \\dots, x_n)$  If I scale the input by a scalar (i.e. by a factor of 2) then the output should also scale by the same factor   Super position (distributivity): if .$x_i = y_i + z_i$ then .$f(y_1 + z_1, \\dots, y_n + z_n) = f(y_1, \\dots y_n) + f(z_1, \\dots z_n)$  2 possible inputs:  Pass the first input through the system to get a value. Pass another input through the system, and get another value. Add those two values to get a result.   1 possible input:  Pass the summation of value 1 and value 2 through the system to get a result.   If the result of both approaches are equal, then distributivity holds. Otherwise, distributivity does not hold. We can account for both Homogeneity and Super position by proving the function holds under the following equation: $$\\alpha_1 f(x_1, \\dots x_n) + \\dots + \\alpha_n f(y_1, \\dots, y_n) = f(\\alpha_1 x_1 +\\alpha_n y_1, \\dots, \\alpha_1 x_n + \\alpha_n y_n)$$ where .$y_n$ is a some scalar       Linear functions can always be expressed as .$f(x_1, \\dots, x_n) = c_1 x_1 + \\dots + c_n x_n$  For .$\\mathbb{R}^2$, that is, .$f(x_1, x_2) = c_1 x_1 + c_2 x_2$ We know this system is linear so it follows these two rules above. So we should set up an equation where we can apply these properties.  $$ x_1 = 1 \\cdot x_1 + 0 \\cdot x_2;\\ x_2 = 0 \\cdot x_1 + 1 \\cdot x_2$$ $$\\text{Let } y_1 = 1, z_1 = 0; y_2 = 0, z_2 = 1$$ $$ \\Longrightarrow x_1 = x_1 y_1 + x_1 z_1;\\ x_2 = x_2 y_2 + x_2 z_2$$ $$ \\Longrightarrow x_1 = x_1 (y_1 + z_1);\\ x_2 = x_2 (y_2 + z_2)$$ $$\\text{Therefore, } f(x_1, x_2) = f(x_1 y_1 + x_2 z_1, x_1 y_2 + x_2 z_2)$$ $$= x_1f(y_1, y_2) + x_2f(z_1, z_2)$$ $$= x_1f(1, 0) + x_2f(0, 1)$$ $$= c_1 x_1 + c_2 x_2\\ \\blacksquare$$\n    Linear Set of Equations Consider the set of .$M$ linear equations with .$N$ variables: $$\\begin{matrix}a_{11} x_1 + a_{12} x_2 + \\dots + a_{1N} x_{N} = b_1\\\\ a_{21} x_1 + a_{22} x_2 + \\dots + a_{2N} x_{N} = b_2\\\\ \\text{} \\vdots\\\\ a_{M1} x_1 + a_{M2} x_2 + \\dots + a_{MN} x_{N} = b_M\\end{matrix}$$  \u0026hellip;it can be written compactly using augmented matrix: $$\\begin{bmatrix}a_{11} \u0026amp; a_{12} \u0026amp; \u0026hellip; \u0026amp; a_{1N} \u0026amp; \\text{|} \u0026amp; b_1\\\\ a_{21} \u0026amp; a_{22} \u0026amp; \u0026hellip; \u0026amp; a_{2N} \u0026amp; \\text{|} \u0026amp; b_2\\\\ \\vdots \u0026amp; \\text{} \u0026amp; \\vdots \u0026amp; \\text{ } \u0026amp; \\text{|} \u0026amp; \\vdots\\\\ a_{M1} \u0026amp; a_{M2} \u0026amp; \u0026hellip; \u0026amp; a_{MN} \u0026amp; \\text{|} \u0026amp; b_M\\end{bmatrix}$$    An interesting thing to notice about this representation is that the symbols corresponding to our unknowns have vanished entirely!   Algorithm for solving linear equations  Three basic operations that don\u0026rsquo;t change a solution:  Multiply an equation with nonzero scalar  .$2x+3y=4$ is same as .$4x+6y=8$ In other words, no solution exists that satisfies the second equation, but not the first. Consequently, the second equation is not only implied by, but also implies the first equation. When each of two equations imply the other, we say that they are equivalent.   Adding a scalar constant multiple of one equation to another Example If we have the equations.. $$(1)\\ 5a+6b=7$$ $$(2)\\ 8a+9b=10$$  \u0026hellip;we can multiply .$(2)$ by the scalar 3 and add it to .$(1)$, to obtain the new system $$(3)\\ 29a+33b=37$$ $$(2)\\ 8a+9b=10$$   Clearly, observe that any solution to the first system will also be a solution to the second, since the first system of equations implies the second. But is the reverse true? Well, observe that equation .$(1)$ can be recovered by taking equation .$(3)$ and subtracting our scalar (in this case, 3) multiplied by equation .$(2)$. In other words, our second system is, not only implied by, but also implies the first system, so it does not introduce any new solutions. Thus, replacing the first system with the second does not change the solution set of our linear system, so this operation is valid.\n   Swapping equations (changing arbitrary labels, trivial)      Note 1AB Extra #   Affine function: a function that can be written as a sum of a linear function and a scalar constant, so though .$\\beta (x)=2x+1$ is not linear, it is still affine  Notice that the definition of affine functions includes all linear functions (by setting the scalar constant to 0), so every linear function is affine, but not all linear functions are affine. These definitions mean that while all functions describing a line can be shown to be affine, not all of them are linear. This has the unfortunate consequence that, in informal conversation, affine functions may be called linear, since both describe a line. This usage, though common, is wrong!, as seen with .$\\beta (x)$ above     Linear Equation: Formally, a linear equation with the unknown scalars .$x_1, x_2, \\dots x_n$ is an equation where each side is a sum of scalar-valued linear functions of each of the unknowns plus a scalar constant.  Expressed algebraically, we obtain the most general form of a linear equation, where the .$f_i$ and .$g_i$ are each linear functions with a single scalar input and output, and .$b_f$ and .$b_g$ are two scalar constants: $$f_1(x_1) + f_2(x_2) + \\dots + f_n(x_n) + b_f = g_1(x_1) + g_2(x_2) + \\dots + g_n (x_n) + b_g$$ Now, recall that linear functions with a single scalar input and output can be expressed in a very particular form \u0026ndash; we know that we can write .$f_i(x) = a_i \\cdot x$ and .$g_i(x) = a_i \u0026rsquo; \\cdot x$, where all the .$a_i$ and .$a_i \u0026lsquo;$ are scalar constants. Substituting, we find that the general form of a linear equation can be rewritten as $$a_1x_1 + a_2 x_2 + \\dots = a_n x_n + b_f = a_1\u0026rsquo; x_1 + a_2 \u0026rsquo; x_2 + \\dots + a_n \u0026rsquo; x_n + b_g$$ Notice that this expression can be thought of as a “weighted sum” of the .$x_i$, where the weights are the scalar constants .$a_i$. When the weights do not depend on any of the terms (such as when the weights are constants), we call the weighted sum a linear combination of said terms. So the above expression is typically referred to as a linear combination of the .$x_i$. That is,  A linear equation is one that equates two linear combinations of the unknowns plus a constant term.\n    Our system will have infinitely many solutions if any two variables are ambiguous Our system will have no solutions if we have a row of zeroes followed by a non-zero  That is, .$\\begin{bmatrix}0 \u0026amp; 0 \u0026amp; \u0026hellip; \u0026amp; 0 \u0026amp; \\text{|} \u0026amp; \\alpha\\end{bmatrix} \\Longrightarrow 0x_1 + 0x_2 + \\dots 0x_n = \\alpha y$ is clearly impossible (no solutions) for any non-zero .$\\alpha$    Practice questions  "},{"id":4,"href":"/e-29/1/","title":"Week 1: Fundamentals of Graphical Communication \u0026 Subtractive Processes","section":"Engineering 29","content":"01-25: Fundamentals of graphical communication #  Evolution of graphical visualization #   Hand drawing Instrument drawing (using mechanical things to measure distances) 2D CAD (initially only able to draw side views) 3D CAD (solid modeling)  Automatic generation of 2D working drawings Enable easy communication of measurements between designer and manufacturer Created with the assumption that manufactured objects are made up of elementary objects, geons? Now we have the ability to run algos to analyze models, removing unnecessary bits We\u0026rsquo;re moving towards computer-generated geometry that\u0026rsquo;s contained by human input     #     Increasingly complex geometries   Topological optimization Internal lattices The way we interface with drawings has to keep up with this   New interfaces  Virtual and augmented reality for visualizing designs    Why bother sketching by hand? #     Why not go straight to CAD? Some possible reasons:  There is a connection between drawing and your own creativity; a feedback loop of sorts CAD bottlenecks you to designing a certain way Find one’s own distinctive style Avoid making detailed decisions too early Keep geometries more freeform Ideas may come to mind anywhere, anytime Potentially quicker      Sketch Examples  Leonardo da Vinci: “helicopter” (c. 1489)  Charles and Ray Eames: chair  Renzo Piano + Richard Rogers: Pompidou Center    Philippe Starck: lemon squeezer  Aside: how is it made? \n    #     Jonathan Ive/Apple design team: iPhone  Burj Khalifa: Adrian Smith  Tesla Model 3: Franz Holzhausen  Concept drawing for Berkeley Engineering     Essentials of 2D sketching #   Line types matters  Solid: edges Dashed: hidden detail Chain: centerline.  - . - .  \u0026hellip;   Faint: construction  Align, but don\u0026rsquo;t touch, features   Dimension lines:  Fainter than edges, and not connected. Long, thin arrows. Lots of differing standards, just be consistent          3D pictorial approaches #  Isometric drawing #   \u0026lsquo;iso\u0026rsquo; = same, \u0026lsquo;metric\u0026rsquo; = measure  Any lines parallel .$x,y,z$ on the lines are equal length   Orthogonal edges of a 3D object map to:  Vertical lines Lines at .$\\pm 30^\\circ$ to horizontal   Enables creating reasonably realistic drawings fairly easily Dimensions in these orthogonal directions are preserved on page Dimensions in other directions are not preserved on page       Circles in isometric  Use construction lines for bounding box Mark midpoints Draw longer quadrants first Through holes: use construction lines for obscured circle; darken later What if circle is not on an orthogonal face?        Coded plans for practicing isometric sketching #   Principle: number in cell gives height of column to be drawn Codes could be given on isometric or square grid ( plan view) Square grid: viewpoint explicitly specified       Different views / perspectives may obscure different features. Chose the one that minimizes information loss / ambiguity You can shade certain surface to convey shadow (and thus depth, 3D information) Plan View Draw Example     Axonometric drawing #   Orthogonal edges are represented by:  Vertical lines Lines at .$\\pm 45^\\circ$ to horizontal   Advantage:  Floorplans are not skewed/distorted   Disadvantage:  Areas of equal orthogonal faces are not equal on drawing Can look more \u0026ldquo;distorted\u0026rdquo;    #     Example of axonometric drawing\n Sometimes called “planometric” Popular in architecture to preserve floorplans     Oblique drawings #   Front view is undistorted Conveys lots of information of a single face Angles are arbitrary (here they\u0026rsquo;re ~45) Receding lines drawn at a constant angle Judgement needed to select scale for receding direction      Perspective drawing #   Simulates how the eye sees 3D objects: further away objects/details are smaller Much more challenging than other methods  Receding lines not parallel But CAD software can generate   Horizon line Vanishing point(s)  One point: dimensions referenced from closest surface Two points: dimensions referenced from closest edge     #    Introduction to sketching tools #  Digital sketching tools #   Autodesk Sketchbook  Now discontinued! :(  OneNote is an alright alternative   Import isometric grid on Layer 2 Draw on Layer 1   Google Jamboard Adobe Photoshop, Illustrator Software resource page in bCourses   Analog sketching tools #   Set square/drawing triangle Pencils:  Various hardness/softness Mechanical vs traditional   Pens  Ballpoint Felt tip Technical      Possible ways of enhancing 3D sketches #   Shading \u0026ndash; simulate the effect of light falling on object  e.x shadows, glare,   Visual clarity \u0026ndash; edges bolder: example of how it clears confusion Suggesting motion, sound, texture, etc.   #      01-27: Subtractive processes: types of subtractive process; mechanics of cutting #  Subtractive manufacturing processes #   Subtractive processes are those that begin with standard stock material (in rod, bar, sheet, plate form etc) and remove material to impart shape  Types of subtractive process #   Material comes in range of mediums: billet (below, left), sheet, foil, wire, pellets, etc. A subtractive process removes material from a larger piece of material to define the geometry needed  Subtractive processes therefore generate waste material How we deal with this is important   Take 5 minutes to brainstorm all the ways you can think of to remove material in a controlled way from a solid piece of stock to create a geometry  Also think about what could happen to the waste material What are some ways of removing material? Can we re-use the extra material?     How can we cut away material? Some possibilities: #   Cutting \u0026ndash; taking a sharp edge to material  Drilling, boring, reaming Milling Lathe operations: turning, facing, tapping Shearing/punching/puncturing Sawing Chiseling Collectively: “machining”   Electric field  Electrical discharge machining (EDM): electrode, wire      Localized melting or vaporization  Laser cutting, laser ablation Flame, plasma cutting Hot wire (typically used for plastics) Aside: is melting really subtractive?   Misc  Chemical methods ( Etching) Explosives (think mining) Forcing apart (using physical force)       Abrasion \u0026ndash; rough, abrasive wheels rotate at high speed across the surface of the component, removing particles of the workpiece. This approach is well suited even to the hardest of materials, although control of geometry is not as great as in cutting operations, for example.  Grinding, sanding, lapping, polishing, filing Abrasive jet (water jet) - Sand blasting    Why would we choose a subtractive process #   Instead of an additive process? Instead of a forming process, e.g. casting?  Some possible reasons to: #   Stock materials tend to be readily available (and inexpensive compared with the specialist powders that are used in some additive processes such as selective laser melting Precision and finish are exceptionally good – probably better than any other family of processes Need strength / structure Material cannot be molded (it\u0026rsquo;s the only feasible process) Doesn\u0026rsquo;t alter heat treatment (if feed and speed isn\u0026rsquo;t too high) Short runs \u0026ndash; no specialized tooling costs Easy customization \u0026amp; More control for iterative product development – every component produced can be different if needed  All you need is to generate new .gcode; versus a whole mold     Why not choose subtractive? #   Slow for large run sizes compared to forming processes  Most processes are “serial”, meaning that each feature on the component needs to be produced sequentially, making the processes slow. This is in contrast, for example, to molding/casting operations where the entire component is produced in approximately one step.   Fairly costly in comparison  Large amount of waste generated (low efficiency) High operator skill is often demanded, raising processing costs   Cuts across metal grains \u0026ndash; not as strong as forged or possibly cast components focus on material cutting Cutting operations rely on wedge-shaped teeth    Mechanics of lathe turning of metals #   To understand the key concepts of metal cutting, we focus specifically on lathe turning  i.e. a reduction in the diameter of a cylindrical component using a cutting tool.   We focus on the turning of metals and their alloys, although turning is also widely used to process polymeric materials and even composite materials (wood being one “composite” that is regularly turned). Cutting operations rely on wedge-shaped teeth   Lectures 4 and 5 will focus on cutting-based operations; Lecture 6 will look at some of the others A close look at a metal cutting operation\n   Terminology #   The workpiece (or simply work — the solid material that is to be reduced in diameter) is held firmly at one end in a chuck, whose jaws are tightened against the workpiece enough that the friction between the work and the chuck is always enough to resist the torques experienced by the work during cutting. The work is rotated, using an electric motor, at angular velocity .$\\omega$, which is typically hundreds or even thousands of revolutions per minute. Let us call the axis of rotation z. If the radius of the workpiece is a at the location of cutting, then the linear, tangential velocity of the work relative to the tool is .$V_\\text{cut} = \\omega a$, provided that .$\\omega$ is expressed in radians/second (to convert from rev/min to rad/sec multiply by .$2\\pi/50$). The cutting tool is mounted on a cross-slide/carriage assembly, which enables precise control of the cutting edge along the z axis and also radially outwards from the z axis (let us call this radial direction the x axis). The carriage and cross-slide could be moved by manual screws or by computer-controlled motors with positional feedback. Once the work is rotating at its target speed, the tool is positioned slightly to the right of the end of the work and the tool is moved inwards in the x direction (towards the rotational z axis) by a distance .$d$, called the depth of cut. The tool is then moved from right to left along the workpiece at a velocity called the feed rate given by .$V_\\text{feed} = f\\omega$, where .$f$ is the feed, or the distance moved by the tool along the z axis in one revolution of the work.  Feed rate is a velocity, while feed is a distance per revolution — this subtlety of terminology is important to note. Note that in almost any turning process, .$V_\\text{cut} \u0026raquo; V_\\text{feed}$    A close look at a metal cutting operation #     High-speed video: cutting tool moves across surface\n  Teeth are at a specific, optimal wedge angle wrt the material to shave away stock Material is sheared off the workpiece (like butter and knife) Quality of cut depends on rake angle (front angle), .$\\alpha$, of tool  Rake angle vertical (.$\\alpha = 0$): material piles up and lot of heat is generated Rake angle too large: tool is fragile, can dig into material Rake angle just right: cutting happens close to tool What is “just right” for the rake angle .$\\alpha$?  .$30^\\circ$ is a good magic starting value   Clearance angle should be non-zero  Allows you to run the tool in reverse over the material without cutting          Material Removed #   The metal that is cut, or shaved, away from the workpiece is called the chip, and depending on (1) how brittle or ductile the work material is, (2) the shape of the cutting tool, and (3) the speed of cutting, the chip may be either a fairly continuous spiral or a series of small chips that regularly fracture. Many small chips are desirable from a practical perspective because, unlike very long continuous chips, they do not tend to become tangled around the work and potentially scratch it. Cutting tools will often have protrusions on their front surface that are designed to break up a chip as it comes off the workpiece. So in turning, a spiral of material is being removed from the work that has initial cross-section .$d \\times f$ and with the tool sweeping through the material with velocity .$V$. Thus, the volumetric removal rate of material is .$R_\\text{MR} = Vdf$.  Cutting depends on material properties #   More ductile materials (aluminum, mild steel, copper etc): long, spiral-shaped chips of material More brittle materials (e.g. cast iron): comes off in short chips   Basic types of chips produced in metal cutting and their micrographs:\n(a) continuous chip with narrow, straight primary shear zone;\n(b) secondary shear zone at the tool-chip interface; (c) continuous chip with built-up edge;\n(d) segmented or nonhomogeneous chip; and\n(e) discontinuous chip.\n      "},{"id":5,"href":"/eecs-16a/1/","title":"Week 1: Gaussian Elim. \u0026 Matrices + Vectors","section":"EECS 16A","content":"01-25: Gaussian Elimination, Vectors #    Slides Notes 2A, 2B   Upper Triangular Systems #   Consider the following equation $$x-y+2z=1$$ $$y-z=2$$ $$z=1$$   \u0026hellip;which can be represent as an augmented matrix: $$\\begin{bmatrix} 1 \u0026amp; -1 \u0026amp; 2 \u0026amp; \\text{|} \u0026amp; 1\\\\ 0 \u0026amp; 1 \u0026amp; -1 \u0026amp; \\text{|} \u0026amp; 2\\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; \\text{|} \u0026amp; 1 \\end{bmatrix}$$    These are called upper triangle matrices \u0026ndash; they are nice in that they\u0026rsquo;re easy to solve!  The solution is reached when the diagonal is all one, the remaining is zero (excluding the rightmost \u0026lsquo;answer\u0026rsquo; colum)    Row Echelon Form #   More precisely, a matrix is in row echelon form when the following criteria are met:  All nonzero rows are above all zero rows. The leading coefficient of a non-zero row is always to the right of the leading coefficient of the row above it.   $$\\begin{bmatrix} 1 \u0026amp; * \u0026amp; * \u0026amp; * \u0026amp; \\text{|} \u0026amp; *\\\\ 0 \u0026amp; 1 \u0026amp; * \u0026amp; * \u0026amp; \\text{|} \u0026amp; *\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; \\text{|} \u0026amp; *\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\text{|} \u0026amp; 0\\\\ \\end{bmatrix}$$    The leading coefficient of every non-zero row (which we call the  pivot, and say is in the pivot position) is 1.  Some textbooks will require this third property, others don\u0026rsquo;t      Reduced Row Echelon Form #    Reduced Row Echelon Form: requires that, in addition to the upwards propagation of variables in step (3), we will obtain a matrix with the following properties, in addition to the two mentioned above:  The matrix is in row echelon form. The leading coefficient of every non-zero row (which we call the pivot, and say is in the pivot position) is 1. Each column with an element that is in the pivot position of some row has 0s everywhere else.   $$\\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; * \u0026amp; 0 \u0026amp; \\text{|} \u0026amp; *\\\\ 0 \u0026amp; 1 \u0026amp; * \u0026amp; 0 \u0026amp; \\text{|} \u0026amp; *\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; \\text{|} \u0026amp; *\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\text{|} \u0026amp; 0\\\\ \\end{bmatrix}$$    Sometimes abbreviated (especially in programming) as rref. By construction, the Gaussian elimination algorithm always results in a matrix that is in reduced row echelon form.  Once an augmented matrix is reduced to reduced row echelon form, variables corresponding to columns containing leading entries are called basic variables, and the remaining variables are called  free variables  If there just isn\u0026rsquo;t enough information and the equations do not contradict each other, then there exist an infinite number of solutions. When this happens, choose some variable (ideally, which is in most of the equations) and then solve each equation in terms of that variable (e.x. .$z$ is in all equations, so now write .$x,y,\\dots$ in terms of .$z$).      Example We start with the following system: $$x-y+2z=1$$ $$2x+y+z=8$$ $$-4x+5y = 7$$  \u0026hellip;which we can write as a matrix $$\\begin{bmatrix} 1 \u0026amp; -1 \u0026amp; 2 \u0026amp; \\text{|} \u0026amp; 1\\\\ 2 \u0026amp; 1 \u0026amp; 1 \u0026amp; \\text{|} \u0026amp; 8\\\\ -4 \u0026amp; 5 \u0026amp; 0 \u0026amp; \\text{|} \u0026amp; 7 \\end{bmatrix}$$   \u0026hellip;and we can row-reduce to upper triangle (Row echelon)\n \u0026hellip;which we can use back substitution to solve\n   Tomograph Example      Error #   In real systems, we will always have noise (error) that makes our systems slightly skewed  So what if we repeat the example above, but have a measurement of .$+0.1$\u0026hellip; are there any solutions?      Graphing #   We can represent our solution as a set of linear equations, meaning we can represent them graphically   01-27: Vectors, Matrices, Multiplications, And Span #    Slides Notes 2A, 2B   Last lecture, we showed how vectors and matrices could be used as a way of writing systems of linear equations more compactly, demonstrating through our tomography example that modeling a set of measurements as a system of equations can be a powerful tool.\n  In these following notes, we are going to more thoroughly discuss how to perform computations with vectors and matrices. In future notes, we will consider additional properties of vectors and matrices and see how these can help us understand real-world systems.\n  Vectors #   Given a collection of .$n$ real numbers such as .$x_1, x_2, \\dots x_n$, we can represent this collection as a single point in an .$n$-dimensional real space .$\\mathbb{R}^n$, denoted as a .$\\vec x$ Each .$x_i$ (for .$i$ between .$1$ and .$n$) is called a component, or element, of the vector.   $$\\vec x = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix}$$    The size of a vector is the number of components it contains Two vectors .$\\vec x$ and .$\\vec y$ are said to be equal, .$\\vec x = \\vec y$, if they have the same size and .$x_i = y_i$ for all .$i$ Vectors are interesting because they can represent any set of numbers  Representing as vectors lets us apply a lot of nice operations to them + represent them graphically In Tomography, we can write a vector to represent the amount of light absorbed by each bottle in a row or column. E.x. color (RGB values), pictures (set of pixels), solar cycles, Electrical circuit quantities    Vectors Representing State #   Vectors can be used to represent the state of a system, defined as follows:  State: The minimum information you need to completely characterize a system at a given point in time, without any need for more information about the past of the system.\n  State is a powerful concept because it lets us separate the past from the future.  The state completely captures the present\u0026ndash; and the past can only affect the future through the present E.x: Consider modeling the dynamics of a quadrotor. The state of a quadrotor at a particular time can be summarized by its 3D position, angular position, velocity, and angular velocity, which can be represented as a vector .$\\vec q \\in \\mathbb{R^{12}}$, as illustrated:     Special vectors #  Zero \u0026amp; One Vector: #   You can usually tell the size of the zero from the context: if .$\\vec x \\in \\mathbb{R}^{n}$ is added to .$\\vec 0$, then .$\\vec 0$ must also be in .$\\mathbb{R}^{n}$   $$\\vec 0 = \\begin{bmatrix} 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix}$$  $$\\vec 1 = \\begin{bmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix}$$     Standard Unit Vector: #   A standard unit vector is a vector with all components equal to .$0$ except for one element, which is equal to .$1$. A standard unit vector where the .$i$th position is equal to .$1$ is written as .$\\vec e_i$ The system .$e_1, \\dots, e_n \\in \\mathbb{R}^{n}$ is called the standard basis in .$\\mathbb{R}^{n}$   $$\\vec e_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix},\\ \\vec e_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ \\vdots \\\\ 0 \\end{bmatrix},\\ \\vec e_n = \\begin{bmatrix} 0 \\\\ 0 \\\\ \\vdots \\\\ 1 \\end{bmatrix}$$    When talking about standard unit vectors in the context of states, we might also use the word “pure” to refer to such states. This is because they only have one kind of component in them. Other states are mixtures of pure states.  Vector Operations #  Addition #   Must be same size and space (e.g. complex numbers, real numbers, etc.) Properties:  Many of the properties of addition you are already familiar with when adding individual numbers hold for vector addition as well. For three vectors .$\\vec x, \\vec y, \\vec z \\in \\mathbb{R}^n$ (and .$\\vec 0 \\in \\mathbb{R}^n$), the following properties hold:  Commutativity: $$\\vec x + \\vec y = \\vec y + \\vec x$$ Additive identity: $$\\vec x + 0 = \\vec x$$    Associativity: $$(\\vec x + \\vec y) + \\vec z = \\vec x + (\\vec y + \\vec z)$$ Additive inverse: $$\\vec x + (- \\vec x) = 0$$       Vector addition can be performed graphically as well:   Scalar Multiplication #   We can multiply a vector by a number, called a scalar:  Scalar: a number. In mathematics and physics, scalars can be used to describe magnitude or used to scale things (e.g. cut every element of a vector in half by multiplying by 0.5, or flip the signs of each element in a vector by multiplying by −1).\n    In general, for a scalar .$\\alpha$ and vector .$\\vec x$, this looks like this: $$\\alpha \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\begin{bmatrix} \\alpha x_1 \\\\ \\alpha x_2 \\\\ \\vdots \\\\ \\alpha x_n \\end{bmatrix} $$ We can obtain the zero vector by multiplying any vector by 0: $$0\\vec x = \\vec 0$$ Properties:  Associative, distributive, and multiplicative identity hold \u0026ndash; trivial      As an example, we can scale a vector .$\\vec x \\in \\mathbb{R}^{2}$ by 2 or -2:     Vector Transpose #   .$\\vec x$ is always a column vector, so to convert (represent) a row vector, we apply the transpose: .$\\vec x^T$ If the elements of the matrix .$A \\in \\mathbb{R}^{N \\times M}$ are .$a_{ij}$ The elements of .$A^T \\in \\mathbb{R}^{M \\times N}$ are .$a_{ji}$ Matrix transpose is not (generally) an inverse!   $$\\vec x = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_N \\end{bmatrix}; \\vec x \\in \\mathbb{R}^{N \\times 1}$$ $$\\vec x^T = \\begin{bmatrix} x_1 \u0026amp; x_2 \u0026amp; \\dots \u0026amp; x_N \\end{bmatrix}; \\vec x^T \\in \\mathbb{R}^{1 \\times N} $$    The transpose of a row vector is a column vector  Thus, the transpose of the transpose of a vector recovers the original vector.   It is important to recognize that, though the transpose of a vector contains the same elements as the original vector, it is still a different vector!  That is to say, for any vector .$\\vec x$ (with at least two components), .$\\vec x ^T \\neq \\vec x$   The transpose of a matrix has a very nice interpretation in terms of linear transformations, namely it gives the so-called adjoint transformation.  Vector-Vector Multiplication #   By convention, a row vector can only be multiplied by a column vector (and vice versa). Multiplication is valid only for specific matching dimensions!  Width of the first, matches length of the second\u0026rsquo;s transpose e.x. given .$\\vec x, \\vec y \\in \\mathbb{R}^{N\\times 1}$  We can take the transpose of .$y$ and multiply by .$\\vec x$:  This is also known as inner product or dot product Commutative for real numbers (this ceases to be true when we start working with complex numbers in 16B) $$\\vec y^T \\vec x = y_1 x_1 + y_2 x_2 + \\dots + y_N x_N = \\text{some scalar} \\in \\mathbb{R}^{1\\times1}$$    Alternatively, we can take .$\\vec x$ and multiply by the transpose of .$y$  Also known as outer product Do not commute! $$\\vec x \\vec y^T = \\text{some matrix} \\in \\mathbb{R}^{N \\times N}$$         Matrices #   A collection of numbers in a rectangular form  Or, given .$\\mathbb{R}^{M \\times N}$, a collection of .$M$ rows and .$N$ column vectors   Remark: Matrices are often represented by capital letters (e.g. .$A$),   $$A = \\begin{bmatrix} a_{11} \u0026amp; \\dots \u0026amp; a_{1N} \\\\ \\vdots \u0026amp; \\ddots \u0026amp; \\vdots\\\\ a_{M1} \u0026amp; \\dots \u0026amp; a_{MN} \\end{bmatrix}$$    A matrix is said to be square if .$M=N$ (that is, if the number of rows and number of columns are equal). Relation between scalars, vectors, and matrices  A vector is a degenerate matrix, that is, .$\\vec x \\in \\mathbb{R}^{n \\times 1}$ A scalar is a degenerate vector or matrix, that is, .$a \\in \\mathbb{R}^{1 \\times 1} $   Transpose:  Just as we could compute the transpose of a vector by transforming rows into columns, we can compute the transpose of a matrix, .$A^T$ , where the rows of .$A^T$ are the (transposed) columns of .$A$   $$A^T = \\begin{bmatrix} a_{11} \u0026amp; \\dots \u0026amp; a_{M1} \\\\ \\vdots \u0026amp; \\ddots \u0026amp; \\vdots\\\\ a_{1N} \u0026amp; \\dots \u0026amp; a_{NM} \\end{bmatrix}$$    Mathematically, .$A^T$ is the .$N\\times M$ matrix given by .$A^T_{ij}$ A square matrix is said to be symmetric if .$A = A^T$ , which means that .$A_{ij} = A_{ji}$ for all .$i, j$.    Special Matrices #   Zero Matrix: Trivial Identity Matrix: Square matrix whose diagonal elements are .$1$ and whose off-diagonal elements are all .$0$   $$I_3 = \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0\\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix}$$    Note that the column vectors (and the transpose of the row vectors) of an .$N \\times N$ identity matrix are the unit vectors in .$ \\mathbb{R}^{N}$. The identity matrix is useful because multiplying it with a vector .$\\vec x$ will leave the vector unchanged: .$I \\vec x = \\vec x$.  In fact, we will see that multiplying a square matrix by an identity matrix of the same size will yield the same initial matrix: .$AI = IA = A$    Column vs Row #   The interpretation of rows and columns that come from the system-of-linear-equations perspective of doing experiments. There, each row of the matrix represents a particular experiment that took one particular measurement. For a given row, the coefficient entries represent how much the corresponding state variable affects the outcome of this particular experiment. In contrast, the columns represent the influence of a particular state variable on the collection of experiments taken together. These perspectives come in handy in interpreting matrix multiplication.\n Matrix Operations #  Matrix Addition #   Two matrices of the same size can be added together by adding their corresponding components. For instance, we can add two matrices A and B (both in .$ \\mathbb{R}^{m \\times n}$) as follows:   Matrix-Vector Multiplication #   Given .$A \\in \\mathbb{R}^{M \\times N}, \\vec x = \\mathbb{R}^{N\\times 1}$, we end with some vector .$\\in \\mathbb{R}^{M\\times 1}$ Visual View      Matrix-Matrix Multiplication #     Matrix-Matrix multiplication involves multiplying each row vector in .$A$ with each column vector in .$B$, starting from the top row of matrix .$A$ and leftmost column of matrix .$B$.  Effectively, the left matrix is multiplied by each column vector in the second matrix to produce a new column of .$AB$   Given .$A \\in \\mathbb{R}^{M \\times N},\\ B = \\mathbb{R}^{N\\times L}$, we end with some matrix .$\\in \\mathbb{R}^{M \\times L}$  We can also interpret the .$A \\vec x$ product in the context of .$A$’s columns:  Matrix multiplication does not commute!  That is .$A \\times B \\neq B \\times A$ In fact, both quantities can only be calculated if the number of rows in .$A$ equals the number of columns in .$B$ and the number of rows in .$B$ equals the number of columns in .$A$.   Matrix Multiplication is Associative Fun fact: Computers have to do so many multiply and add operations that it\u0026rsquo;s optimized at a processor level (leaned about this is 61C)  "},{"id":6,"href":"/cogsci-c100/non-visual/","title":"Non-Visual Perception","section":"CogSci C100","content":"Auditory Perception: Psychological Effects Of Music #  Effects Of Music On Cognition #   Music has been found to influence memory, decision making, and other cognitive processes  Study conducted in supermarkets found that use of slow background music increased sales by 38% over use of fast music - shoppers stayed in store longer and bought more, a lot more (Milliman, R.E., 1986)  Particularly effective for purchasing decisions with high affective/low cognitive involvement, e.g., jewelry, sportswear, and beer   Follow-up study found this is only the case for music in minor mode (Knoeferle, Spangenberg, Herrmann et al., 2011)   Study on effects of music on decision making (Hansen \u0026amp; Melzner, 2014)  Group 1: Listened to tritone or dissonant, unfamiliar chords  Beginning of Simpson’s theme song      Group 2: Listened to perfect fifth or consonant, familiar chord  Twinkle, twinkle little star       Are people in Group 1 or Group 2 more likely to be swayed by aggregate, as opposed to individualized, information?  Aggregate info: overall star rating on Amazon review Individualized info: actual customer reviews that appear at the bottom of the page  Group 2        The Mozart Effect #   Initial research  Participants who spent 10 minutes listening to Mozart afterwards showed mean spatial IQ scores that were 8-9 points higher (significant, not giant) than that of controls in relaxation conditions  Effect did not extend beyond 10-15 minutes Effect was specific to spatial temporal performance     Follow-up studies with rats suggest that effect cannot be explained merely by “enjoyment arousal”  Rats exposed to Mozart in utero and for 60-day postpartum period completed maze test significantly more quickly and with fewer errors than control rats exposed to minimalist music, white noise, or silence (Jenkins, J.S., 2001)   Longer-term effects  Children from low SES backgrounds who were given classical music in wind and string instruments for 18 months performed significantly better on IQ tests administered after program ended (Barbaroux, Dittinger \u0026amp; Besson, 2019)    Specificity of music #   No enhancement in performance on spatial temporal tests was shown after listening to minimalist or oldtime pop music - In fact, one experiment found that heavy metal increased amount of time it took for mice to run a maze by 20 minutes \u0026ndash; and the mice also started killing each other! Other types of music that resemble Mozart’s in high degree of long-term periodicity, especially within the 10-60s range (e.g., Bach), also found to be effective  The Mozart effect on epilepsy #   Listening to Mozart has been found to decrease abnormal brain wave activity and number of seizures in patients with epilepsy (Grylls, Kinsky, Baggott et al., 2018)  One study found that 23 of 29 patients showed decrease in seizure activity after listening to Mozart piano sonata Abnormal spikes fell from 62% to 21% in one patient Beneficial effects of music on neonates (early-born babies)   Preterm babies who listened to music (not necessarily Mozart) in the neonatal intensive care unit had brain activity that more closely resembled that of full-term babies (Lordier, Meskaldji, Grouiller et al., 2019)    Match the following: (Rentfrow \u0026amp; Gosling, 2003, 2006)   classical, jazz, blues, and folk music lovers\n country, pop, and religious music lovers    cheerful verbally intelligent outgoing conscientious open to experience   Answers (2, 1, 2, 2, 1)         Music is the only sensory experience that can activate all areas of the brain simultaneously!  Meditation can do this too, but it\u0026rsquo;s not sensory        Music Therapy #   Typically used for people with Alzheimer’s, learning disabilities, autism, ADHD, Down Syndrome, intellectual disability, brain injuries, physical disabilities, chronic pain  Alzheimer\u0026rsquo;s patients have shown improvements in memory when listening to their favorite songs In children, helps with emotional self expression, improves social and communication skills, as well as motor functioning Various studies with cancer patients there have found significant reductions in anxiety, pain, and tiredness after music therapy was introduced   Music being played alone shows an improvement in mental and physical well being. However, it is more effective when paired with the playing of an instrument or singing along.  Individual Differences In Perception #   Introverts vs. Extroverts 🍋  Introverts salivate more to lemon juice \u0026ndash; both by self-report and experimentally Introverts tend to retain elevated heart rate for a longer time period after exposure to noxious odors Introverts are more sensitive to pain \u0026ndash; and are able to learn more quickly from punishment         At the same time, extroverts are more likely to drink/smoke to much and end up in jail  Synesthesia #   Synesthesia: stimulation of one modality leads to perceptual experience in another Color grapheme (seeing specific letters or numbers in specific colors) synesthesia is most common type of synesthesia  We all have some sense of underlying synesthesia:  Which is a dog barking \u0026lsquo;woof woof\u0026rsquo;, doorbell ringing \u0026lsquo;ding ding\u0026rsquo;, and a furnace billowing \u0026lsquo;woosh wooosh\u0026rsquo;?     Which is booba and which is keekee?  Some people visualize months like this:      These examples were created by synesthetes, and most people agree on them  However, only synesthetes seem to be able to create these pieces     Study conducted at Science Museum in London  Visitors viewed two musical animations, one designed by synesthetes, the other by nonsynesthetes Then asked which animation better matched the music  Participants overwhelmingly chose the synesthete-designed animation   Suggests that we all unconsciously link together music and vision but only synesthetes are consciously aware of these links  This sensory crossover probably occurs in the limbic system      Two theories of synesthesia #   Brain architecture of synesthetes is equipped with more connections between neurons, causing the usual modularity to break down  Says the brain is made of many modules, and synesthetes have more connections between these modules   “Feed-backward” connections that carry information from high-level multisensory areas of the brain back to single sense areas are not properly inhibited  Normally, information processed in such multisensory areas is allowed to return only to its appropriate singlesense area In synesthetes’ brains, that inhibition is disrupted, allowing the different senses to become jumbled        Subliminal Perception And Priming #   Subliminal perception: Messages that are presented below one’s absolute threshold for conscious awareness may influence behavior  Experiment in which emotionally positive scenes (e.g., kittens) or negative scenes (e.g., werewolf) were subliminally flashed before participants viewed slides of faces  More positive ratings were given to faces that had been associated with positive scenes (Krosnizk, Betz, Jussim et al., 1992; Anderson, Siegel, White et al., 2012)   Graduate students evaluated their research ideas more negatively shortly after viewing the unperceived scowling face of their adviser  In the experimental group, students were more likely to be critical (less confident) in their ideas     Advertisers have made all sorts of exaggerated claims of being able to sell products when the product is flashed very briefly, along with an image of a very attractive person. In general, not well-supported by evidence.  The word \u0026lsquo;beef\u0026rsquo; was flashed at below-threshold durations while participants watched a film. They were later more hungry, but did not specifically prefer beef to other foods.  Suggests that meaning not easily extracted from subliminal presentations; rather, stimuli act at an emotional level of priming task (Dijksterhuis, Aarts, \u0026amp; Smith, 2006)        No real evidence that listening to subliminal message tapes during sleep effective but some research suggests some types of sensory stimuli during sleep may affect learning and memory  “Cramming” during sleeping study (Antony, Gobel, O’Hare et al., 2012)  Participants learned to play 2 simple piano melodies, then took a 90-minute nap While they slept, one of the melodies was quietly played on repeat  Able to play cued melody more accurately than other melody when they awoke     Smoking cessation study (Arzi, Holtzman, Samnon et al., 2014)  When asleep, study participants were exposed to two odors, cigarette smoke and rotten fish During the following week, those who had smelled the mix of both odors lit up 30% less than those in control groups  Conditioning was more effective during Stage 2 than during REM sleep Explicit olfactory aversive conditioning during wakefulness did not alter smoking behavior          Priming: unconscious activation of particular associations in memory   People showed either of these images and instructed to draw a nature scene; those shown the left image tended to draw scenes with water (find the duck!)\n  Scrambled-sentence test: Make a grammatical four-word sentence as quickly as possible out of the following five-word sets:  Him was worried she always From are Florida oranges temperature Ball the throw toss silently Shoes give replace old the He observes occasionally people watches Be will sweat lonely they Sky the seamless gray is Should now withdraw forgetful we Us bingo sing play let Sunlight makes temperature wrinkle raisins   After completing this test, participants walked significantly more slowly – almost as if they felt old – than control participants (Bargh, Chen, \u0026amp; Burrows, 1996)    "},{"id":7,"href":"/eecs-16a/2/","title":"Week 2: (In)dependence \u0026 Circuit Analysis","section":"EECS 16A","content":"02-01: Linear (in)dependance, Matrix Transformations #    Slides  Note 3   Recall the simple tomography example from Note 1, in which we tried to determine the composition of a box of bottles by shining light at different angles and measuring light absorption. The Gaussian elimination algorithm implied that we needed to take at least 9 measurements to properly identify the 9 bottles in a box so that we had at least one equation per variable. However, will taking any 9 measurements guarantee that we can find a solution? Answering this question requires an understanding of linear dependence. In this note, we will define linear dependence (and independence), and take a look at what it implies for systems of linear equations.\n  Linear Dependence #   Linear dependence is a very useful concept that is often used to characterize the “redundancy” of information in real world applications.  Closely tied to the idea of free and basic variables as we’ve already seen   We will give three (equivalent) definitions of linear dependence:  A set of vectors .$\\{\\vec v_1, \\dots \\vec v_n \\}$ is linearly dependent if there exists scalars .$\\alpha_1, \\dots, \\alpha_n$ such that .$\\alpha_1 \\vec v_1 + \\dots + \\alpha_n \\vec v_n = \\vec 0$ and not all .$\\alpha_i$ are equal to zero. This combination of all-zero scalars has a special name: the \u0026ldquo;trivial solution.\u0026rdquo; A set of vectors .$\\{\\vec v_1, \\dots \\vec v_n \\}$ is linearly dependent if there exists scalars .$\\alpha_1, \\dots, \\alpha_n$ and an index .$i$ such that .$\\vec v_i = \\sum_{j\\neq i} \\alpha_j \\vec v_j$. In other words, a set of vectors is linearly dependent if one of the vectors could be written as a linear combination of the rest of the vectors A set of vectors is either linearly dependent or linearly independent. More specifically, consider the sum in the first definition. If there is a solution to satisfy this equation other than to make all the scalars .$\\alpha_1 = \\dots = \\alpha_n = 0$, (that is, a nontrivial solution) then the vectors are linearly dependent.   Why three (equivalent) definitions? Because each is useful in different settings.  It is often easier mathematically to show linear dependence with definition (1) since we don’t need to try to “single out” a vector to get started with the proof. (2) gives us a more intuitive way to talk about redundancy. If a vector can be constructed from the rest of the vectors, then this vector does not contribute any information that is not already captured by the other vectors.    Proof of equivalency  Linear Independence #   From the first definition of linear dependence we can deduce that a set of vectors .$\\{\\vec v_1, \\dots, \\vec v_n \\}$ is linearly independent if .$\\alpha_1 \\vec v_1 + \\dots + \\alpha_n \\vec v_n = \\vec 0$ implies .$\\alpha_1 = \\dots = \\alpha_n = 0 $  A set of vectors is linearly independent if it is not linearly dependent. E.x. any two vectors that are multiples of one another are dependent    Systems of Linear Equations #   Recall that a system of linear equations can be written in matrix-vector form as .$A\\vec x = \\vec b$, where .$A$ is a matrix of variable coefficients, .$\\vec x$ is a vector of variables, and .$\\vec b$ is a vector of values that these weighted sums must equal. We will show that just looking at the columns or rows of the matrix .$A$ can help tell us about the solutions to .$A\\vec x = \\vec b$.  Theorem 3.1 #   If the system of linear equations .$A\\vec x = \\vec b$. has an infinite number of solutions, then the columns of .$A$ are linearly dependent  If the system has infinite number of solutions, it must have at least two distinct solutions .$\\vec x_1, \\vec x_2$ which must satisfy   $$A\\vec x_1 = \\vec b$$ $$A\\vec x_2 = \\vec b$$    Subtracting the first equation from the second equation, we have   $$A (\\vec x_2 - \\vec x_1) = \\vec 0$$    Define alpha as \u0026hellip;\n   $$\\vec \\alpha = \\begin{bmatrix} \\alpha_1 \\\\ \\vdots \\\\ \\alpha_n \\\\ \\end{bmatrix} = \\vec x_2 - \\vec x_1$$    Because .$\\vec x_1, \\vec x_n$ are distinct, not all .$\\alpha_i$\u0026rsquo;s are zero. Let the columns of .$A$ be .$\\vec a_1, \\dots \\vec a_n$. Then, .$A \\vec \\alpha = \\sum^n_{i=1} \\alpha_i \\vec a_i = \\vec 0$. By definition, the columns of .$A$ are linearly dependent.  The sum term says that, in other words, matrix-vector multiplication is a linear combination of columns:       Theorem 3.2 #    If the columns of .$A$ in the system of linear equations .$A\\vec x = \\vec b$ are linearly dependent, then the system does not have a unique solution.  Start by assuming we have a matrix A with linearly dependent columns   $$A = \\begin{bmatrix} | \u0026amp; | \u0026amp; \u0026amp; | \\\\ \\vec a_1 \u0026amp; \\vec a_2 \u0026amp; \\dots \u0026amp; \\vec a_n \\\\ | \u0026amp; | \u0026amp; \u0026amp; | \\\\ \\end{bmatrix}$$    By the definition of linear dependence, there exist scalars .$\\alpha_1, \\dots, \\alpha_n$ such that .$\\alpha_1\\vec a_1 + \\dots + \\alpha_n \\vec a_n = \\vec 0$ where not all of the .$\\alpha_i$’s are zero. We can put these αi’s in a vector:   $$\\vec \\alpha = \\begin{bmatrix} \\alpha_1 \\\\ \\vdots \\\\ \\alpha_n \\\\ \\end{bmatrix}$$    By the definition of matrix-vector multiplication, we can compactly write the expression above:   $$A\\vec \\alpha = \\vec 0$$ $$\\text{where } \\vec \\alpha \\neq \\vec 0$$    Recall that we are trying to show that the system of equations .$A\\vec x = \\vec b$ does not have a unique solution. We know that systems of equations can have either zero, one, or infinite solutions.  If our system of equations has zero solutions, then it cannot have a unique solution, so we don’t need to consider this case.     Now let’s consider the case where we have at least one solution, .$\\vec x$:  Therefore, .$\\vec x + \\vec \\alpha$ is also a solution to the system of equations! Since both .$\\vec x$ and .$\\vec x + \\vec \\alpha$ are solutions, and .$\\vec \\alpha \\neq \\vec 0$, the system has more than one solution. We’ve now proven the theorem.     $$A \\vec x = \\vec b$$ $$A \\vec x + \\vec 0= \\vec b$$ $$A \\vec x + A \\vec \\alpha = \\vec b$$ $$A (\\vec x + \\alpha) = \\vec b$$     Note that we can add any multiple of .$\\alpha$ to .$\\vec x$ and it will still be a solution – therefore, if there is at least one solution to the system and the columns of .$A$ are linearly dependent, then there are infinite solutions.\n Intuitively, in an experiment, each column in matrix .$A$ represents the influence of each variable .$x_i$ on the measurements. If the columns are linearly dependent, this means that some of the variables influence the measurement in the same way, and therefore cannot be disambiguated. See page five for good example.     Implications: #   This result has important implications to the design of engineering experiments. Often times, we can’t directly measure the values of the variables we’re interested in. However, we can measure the total weighted contribution of each variable. The hope is that we can fully recover each variable by taking several of such measurements. Now we can ask: “What is the minimum number of measurements we need to fully recover the solution?” and “How do we design our experiment so that we can fully recover our solution with the minimum number of measurements?”\n  Consider the tomography example. We are confident that we can figure out the configuration of the stack when the columns of the lighting pattern matrix .$A$ in .$A\\vec x = \\vec b$ are linearly independent. On the other hand, if the columns of the lighting pattern matrix are linearly dependent, we know that we don’t yet have enough information to figure out the configuration. Checking whether the columns are linearly independent gives us a way to validate whether we’ve effectively designed our experiment.\n Row Perspective #  Optional!   Intuitively, each row represents some measurement  If the number of measurements taken is at least the number of variables and we cannot completely determine the variables, then at least one of our measurements must be redundant (it doesn’t give us any new information).   This intuition suggests that the number of variables we can recover is equal to the number of unique measurements, or the number of linearly independent rows \u0026ndash; this formal proof will come in a later note when we talk about rank. Now have two perspectives: in the matrix, each row represents a measurement, while each column corresponds to a variable.  Therefore, if the columns are linearly dependent, then we have at least one redundant variable. From the perspective of rows, linear dependency tells us that we have one or more redundant measurements.    Span #   Span of the columns of .$A$ is the set of all linear combinations of vectors .$\\vec b$ such that .$A\\vec x = \\vec b$ has a solution  .$\\exists \\vec x$ s.t. .$A \\vec x = \\vec b \\Longrightarrow \\vec b \\in \\text{span(cols}(A))$   That is, the set of all vectors that can be reached by all possible linear combinations of the columns of .$A$  Formally, .$\\text{span}(\\vec v_1, \\dots, \\vec v_N) = \\bigg\\{\\sum_{i=1}^N \\alpha_i \\vec v_i\\ |\\ \\alpha_i \\in \\mathbb{R},\\ \\vec a_i \\in \\mathbb{R}^{M}\\bigg\\}$   A set of vectors is linearly dependent if any one of the vectors is in the span of the remaining vectors.  That is, if any one of the vectors could be represent as the combination of the remaining vectors (that is, it\u0026rsquo;s in the span of the others) On the other hand, if each vector adds another dimension to the span (contains novel information) then they\u0026rsquo;re said to be linearly independent   span, range, and column space of .$A$ all refer to the span of the columns of .$A$   Two Examples  e.x. what is the span of the cols of .$A = \\begin{bmatrix} 1 \u0026amp; 1 \\\\ 1 \u0026amp; -1\\\\ \\end{bmatrix}$? $$\\text{span(cols of A)} = \\bigg\\{ \\vec v\\ |\\ \\vec v = \\alpha \\begin{bmatrix} 1\\\\ 1\\\\ \\end{bmatrix} + \\beta \\begin{bmatrix} 1\\\\ -1\\\\ \\end{bmatrix}; \\alpha, \\beta \\in \\mathbb{R}\\bigg\\} = \\mathbb{R}^{2}$$ e.x. what is the span of the cols of .$A = \\begin{bmatrix} 1 \u0026amp; -1 \\\\ 1 \u0026amp; -1\\\\ \\end{bmatrix}$? $$\\text{span(cols of A)} = \\bigg\\{ \\vec v\\ |\\ \\vec v = \\alpha \\begin{bmatrix} 1\\\\ 1\\\\ \\end{bmatrix}; \\alpha \\in \\mathbb{R}\\bigg\\} = \\text{line } (x_1 = x_2)$$      02-03: Intro to Circuit Analysis #    Slides Note 11 A, B    Our ultimate goal is to design systems that solve people’s problems. To do so, it’s critical to understand how we go from real-world events all the way to useful information that the system might then act upon. The most common way an engineered system interfaces with the real world is by using sensors and/or actuators that are often composed of electronic circuits; these communicate via electrical signals to processing units, which are also composed entirely of electronic circuits. In order to fully understand and design a useful system, we will need to first understand Electrical Circuit Analysis.\n   There are four main steps involved when designing information devices and systems  Analog World Sensor Input Data Processing Actuation (16B)    Tiny Bit of Solid-State Physics #    Conductors have lots of electrons  Move around very easily E.x. copper, gold, silver, water   Conductors have lots of electrons  But they are at an energy level where they need to be given some energy level (e.x 1 eV) to move E.x. solar cell, diodes   Insulators do not let electrons pass through them  E.x. capacitors have a big insulator in the middle, that is, current only goes through a capacitor when the magic smoke is released    Electrical Quantities #     Quantity Symbol Units What     Current .$I$ Amps, .$A$ Flow of charges (e.g. electrons) in the circuit due to a potential difference   Voltage .$V$ Volts, .$V$ Potential energy (per charge) between two points in the circuit   Resistance .$R$ Ohms, .$\\Omega$ Material’s tendency to resist the flow of current.     Voltage .$\\pm$ depends on reference point  Voltage, or electric potential, is only defined relative to another point (mountain/height analogy). Similarly, in circuits, we will frequently define a reference point, called ground, against which other voltages can be measured.   Current .$\\pm$ depends on direction  Circuit Diagram #   Collection of elements, where each element has some voltage across it and some current through it Two main elements:  Notes: Points where elements meet Junctions: Points where different material meet   Voltage = difference of two potential      Basic Circuit Elements #  Wire #   The most common element in a schematic is the wire, drawn as a solid line The .$IV$ relationship for a wire is:  .$V_\\text{elem} = 0$: A wire is an ideal connection with a constant, zero voltage across it. .$I_\\text{elem} = ?$: The current through a wire can take any value, and is determined by the rest of the circuit.        Resistor #   The .$IV$ relationship of a resistor is called Ohm’s Law:  .$V_\\text{elem} = I_\\text{elem} R $: The voltage across a resistor is determined by Ohm’s Law. .$I_\\text{elem} = V_\\text{elem} / R$: The current through a resistor is determined by Ohm’s Law.        Limit check\n The slope is proportional to .$R^{-1}$, that is, the larger the resistance the lower the slope .$\\lim_{R \\to 0}$ results in an wire (above) .$\\lim_{R \\to \\infty}$ results in an open circuit (below)   Open Circuit: #   This element is the dual of the wire.  .$V_\\text{elem} = ?$: The voltage across an open circuit can take any value, and is determined by the rest of the circuit. .$I_\\text{elem} = 0$: No current is allowed to flow through an open circuit; always zero.        Voltage Source: #   A voltage source is a component that forces a specific voltage across its terminals. The + and − sign indicates which direction the voltage is pointing. The voltage difference between the “+” terminal and the “−” terminal is always equal to Vs, no matter what else is happening in the circuit.  .$V_\\text{elem} = V_S$ \u0026ndash; The voltage across the voltage source is always equal to the source value. .$I_\\text{elem} = ?$ \u0026ndash; The current through a voltage source is determined by the rest of the circuit.        Current Source: #   A current source forces current in the direction specified by the arrow indicated on the schematic symbol. The current flowing through a current source is always equal to Is, no matter what else is happening in the circuit. Note the duality between this element and the voltage source.  .$V_\\text{elem} = ?$ \u0026ndash; The voltage across a current source is determined by the rest of the circuit. .$I_\\text{elem} = I_S$ \u0026ndash; The current through a current source is always equal to the source value.        Rules for Circuit Analysis #   See also: 26.3 Kirchhoff’s Rules  Kirchhoff’s Current Law (KCL) #   Node: A place in a circuit where two or more of the above circuit elements meet   The net current flowing into/out-of any node is zero: $$(-i_1)+(-i_2)+i_3 = 0$$ That is, the current flowing into a node must equal the current flowing out of that node $$ i_1+i_2=i_3$$      Kirchhoff’s Voltage Law (KVL) #   The sum of voltages across the elements connected in a loop must be zero Mathematically, KVL states that: $$\\sum_\\text{loop} V_k = 0$$ $$\\Longrightarrow V_A - V_B - V_C = 0$$      Height Analogy #   If you walk in a circle (a loop) so that you end up back where you started, than your total change in elevation must be zero, no matter how much you go up or down. If you walk in a line, ending up somewhere different, than your total change in elevation is equal to the sum of all of the elevation changes along the way.    Real World Analogy     The sum of voltages across the elements connected in a loop must be equal to zero “what goes up must come down”   If the arrow corresponding to the loop goes into the “+” of an element, we subtract the voltage across that element. We went “downhill” from higher voltage to lower voltage so we lost “elevation.”   If the arrow goes into the “-” of an element, we add the voltage across that element This is like going “uphill”     Ohm’s Law and Resistors #  $$V_\\text{element} = I_\\text{element}R$$\n The unit of .$R$ is Volts/Amperes, called Ohms .$\\Omega$. See also: 25.3 Ohm’s Law: Resistance and Resistors  "},{"id":8,"href":"/e-29/2/","title":"Week 2: Cutting-based Processes \u0026 Other Subtractive Processes","section":"Engineering 29","content":"02-01 Cutting-based Processes #  Modeling of material cutting #    Chips are created and separated from the work by plastic deformation, i.e. shearing, of the work.  Sheer plane is created by the tool (teal segment) Throughout the shear plane, the shear stress must equal or exceed the shear strength of the work material for cutting to proceed. The value of the shear angle is not something that we directly control, but depends on several factors.     Lathe operations #      To analyze chip formation, we consider the 2D y–z plane, with the x axis out of the page  We assume that all plastic deformation occurs in a single plane, the shear plane, which is oriented at an shear angle .$\\phi$, to the direction of relative motion .$V_\\text{cut}$ of the tool and work. The shear plane meets the sharp edge of the cutting tool at the bottom of the cut. The area of the shear plane is .$fd / \\sin \\phi$ where .$f$ is the feed (also denoted by .$t_0$ in some texts), and .$d$ is the cut depth (out of the page; also denoted by .$w$ in some texts).    Turning on a lathe #   Nomenclature of cutting process #    The tool itself has a carefully designed shape. Its front face is positioned at an angle .$\\alpha$, the rake angle, from a plane normal to the direction of relative tool–workpiece motion.  As we will see, the rake angle will always be chosen to be greater than zero, to ensure a clean cut and to reduce the amount of mechanical work needed to produce a cut.   The flank angle, meanwhile, is that between the bottom of the tool and the post-cutting workpiece surface.  The flank angle needs to be greater than zero to reduce friction and any resulting scratching or fusion between the tool and the freshly machined surface. We can control the rake and flank angles by manufacturing a cutting tool to our specifications.    Merchant’s circle: cutting forces #    Force diagram that resolves the reaction force exerted by the tool on the work\n It is important to consider the magnitudes and directions of the forces that are exerted by the tool on the workpiece during cutting. These forces determine the torque required to rotate the work, the amount of elastic distortion of the work or the lathe that might occur during cutting (potentially leading to inaccuracies in the manufactured component), and also whether the tool will experience a load large enough to fracture it.\n  One way to analyze these forces is with Merchant’s Circle. This Circle is a graphical device developed in the 1940s by Eugene Merchant to visualize cutting loads. The circle itself does not represent the shape of the work being cut. This is a force diagram – i.e. the lengths of lines represent magnitudes of forces, not physical distances. The directions of the lines do correspond to actual orientations in space. The horizontal axis corresponds to the cutting direction. We can use Merchant’s Circle to understand how to design and optimize the cutting process. For example, suppose that we have obtained an estimate of .$\\phi$ from experimental measurements of the chip thickness. We could then use the trigonometrical relationships illustrated in Merchant’s Circle, substituting our estimated .$\\phi$ and our known .$\\alpha$ for the tool, to estimate the friction angle .$\\beta$, which would be difficult to measure directly. This approach might be used to compare the effect on friction angle of various candidate tool materials, coatings, or lubricants.\n   Relating cutting geometry to cutting forces\n Material properties link the geometry of the tool and cutting path to the forces involved. The material being cut needs to exceed its shear yield stress to start deforming (cutting) and creating a chip. If the material exceeds its ultimate shear strength, the chip becomes more likely to fragment into pieces as it forms (which may help clear waste material away). However, the more strain involved in chip formation for a given material, the more work has to be invested in the cutting operation. Therefore designing the cutting operation to limit shear strain can help to limit cutting energy required.     Predicting shear strain .$\\gamma$ #   Since we wish to limit the amount of shear strain, .$\\gamma$, occurring during cutting, we need to understand how it depends on parameters that we can control.  Parameters we control: .$f, V_\\text{cut}, d, \\omega, \\alpha$. Parameters we don’t directly control, but can measure: .$c, F_c , F_t$ Parameters we don’t directly control and are hard to measure directly: .$\\phi, \\beta$, and forces other than .$F_c$ and .$F_t$   Next, we show (via geometry) how shear strain .$\\gamma$ depends on shear angle .$\\phi$ (which is hard to measure directly) and on rake angle .$\\alpha$ (which is known in advance).  To predict shear angle .$\\phi$, we then have two options:  Measure chip thickness, .$c$, and use geometry to work out .$\\phi$ in terms of .$f, c$ and .$\\alpha$, or Use Merchant’s shear angle relationship to express .$\\phi$ in terms of .$\\alpha$ and .$\\beta$, and find .$\\beta$ by measuring cutting and thrust forces .$F_c$ and .$F_t$ (e.g. by force sensors on the cutting tool holder)     Then, we can take action to control shear strain and cutting force.  Relationship between .$\\phi$ and .$\\gamma$ #   Using chip thickness to .$\\approx \\phi$ #   If we did not have any experimental estimate of .$\\phi$ (since it\u0026rsquo;s a function of the material\u0026rsquo;s properties) but we did have an estimate of .$\\beta$ and knowledge of rake angle .$\\alpha$ (since we can control the tool we use(\u0026rsquo;s rake angle)) and the shear strength of the work material, .$\\tau_y$, we could use Merchant’s shear angle relationship to predict both .$\\phi$ and the cutting force.\n   We can measure a chip to get .$c$ Can then use the relationship between .$\\phi$ and .$\\gamma$ to estimate .$\\gamma$ Merchant’s shear angle relationship  Study Advice: #   Don\u0026rsquo;t memorize this derivation!  This is to show how we can do process diagnosis if we understand each step of the process and how they relate to one another   Understand merchant forces, shear/friction angle, the physical relationship between these angles, and terms (cutting depth, feed (cut amount per rotation), feed rate (speed moving tool along machine))   Merchant’s shear angle relationship #   The total reaction force exerted by the tool on the work, .$R$, can be resolved in any of three useful coordinate frames:  The first frame is defined by the cutting direction. .$F_c$ is the cutting force, the force in the direction of relative motion of the tool and work. This force is important because the mechanical work done by the lathe is equal to the cutting force times the distance moved in the direction of cutting. The force perpendicular to the cutting force, the thrust force, .$F_t$, can contribute to bending of the work during turning and can become problematic and lead to vibration, particularly with long slender workpieces if they are not supported at both ends. The second frame is defined by the rake (front) face of the tool, and decomposes the reaction force into a frictional force .$F$ parallel to the rake face, and a normal reaction component .$N$. These loads are related by the friction angle: .$\\beta = \\arctan (F/N)$ where .$F/N$ is the coefficient of friction between the chip and the tool. This coefficient can be considerably larger than 1, particularly if chip material bonds to the front of the tool (leading to a built-up edge) and chip–tool sliding involves plastic deformation of the chip. Ideally .$\\beta$ will be as small as possible, which can be achieved with liquid lubrication of the cutting location and/or by special tool coatings which make it smooth and reduce the coefficient of friction. The third frame is defined by the shear plane, and is composed of the shear force .$F_s$ which acts within the shear plane, and the normal component .$F_n$   We assume that shear stress equals the shear strength of the workpiece material in the shear plane, and that shear stresses are lower elsewhere in the material. Also assume that the value of the shear angle .$\\phi$ is naturally such that the shear strength, .$\\tau_y$, of the workpiece material is reached in the shear plane at the lowest possible cutting force .$F_c$. If we know the material’s shear strength, the friction angle .$\\beta$, and the shear angle .$\\phi$, we can (roughly) estimate the required cutting force .$F_c$. Need to solve for .$\\phi$ in terms of parameters we can control: .$\\alpha$ (directly through tool geometry) and .$\\beta$ (indirectly through lubrication). To find value of .$\\phi$ for maximum shear stress at a given .$F_c$, set derivative .$\\frac{d\\tau}{d\\phi}$ to zero and solve:  Aside: This equation assumes that all deformation occurs in the sheer plane The lower the friction angle, the higher the sheer angle, requiring larger cutting forces  To estimate .$\\beta$, we can measure .$F_c$ and .$F_t$ and use the force-resolving circle, and then substitute into the expression for .$\\phi$:   $$\\tan(\\beta - \\alpha) = \\frac{F_t}{F_c}$$ $$\\beta = \\arctan\\bigg(\\frac{F_t}{F_c}\\bigg) + \\alpha$$      Insights:  Increasing the rake angle .$\\alpha$ (via tool design) and lowering friction angle .$\\beta$ (by application of an appropriate lubricant/coolant – e.g. water/oil mixture) both help to increase shear angle, reducing the area of the shear plane. However there are limits: for instance, if .$\\alpha$ becomes too large, .$F_t$ may become negative in which case the tool would dig into the workpiece and result in a very poor finish.  There\u0026rsquo;s a limit to how high .$\\alpha$ can reasonably be, though. If it becomes so large that the angle enclosed at the tool tip is extremely sharp, the tool will become highly susceptible to cracking. Moreover, at very large .$\\alpha$ the thrust force may change direction and tend to pull the tool into the work, leading to vibration and a very poor finish. Examples of process changes   This model is an approximation; alternative models exist Merchant’s circle: examples of process changes\n    The larger .$\\phi$, the shorter the shear plane and the smaller the cutting force is expected to be for a given feed, cut depth and material (reducing the cutting force is desirable). If .$\\phi \\approx 0$, the shear plane would be large and the cut would be rough.  As a rule of thumb, if the angle between the shear plane and the rake face of the tool is about 90°, cutting will be of reasonably high quality as long as adequate lubrication and a reasonable cutting speed are used.   Meanwhile, knowledge of .$\\gamma$ can help give a picture of how much plastic deformation is occurring in the chip between the moment of first yield and the chip leaving the cutting tool.    Cutting power #   The above analysis relies on having knowledge of multiple geometrical parameters, the friction coefficient, and material properties such as shear strength. These values will often not be available; another approach is to characterize metal cutting operations with a specific energy value, which is the energy required to remove a unit volume of material from the work.  Specific energies are usually reported with quite a wide range (e.g. 0.4–1.1 J/mm.$^3$ for aluminum alloys) to take into account the variability of tool–material friction and tool geometries that might be used. Different workpiece materials are associated with different specific energies, .$U$ (J/mm.$^3$): the work that must be done per unit volume material removed. However, these energies, which are widely tabulated in handbooks, provide a simple way to relate cutting speed, force and power. The cutting power is simply the product of material removal rate and specific energy. The material removal rate can be computed as the product of cutting speed, feed and cut depth.  Broadly speaking, the harder the tool and the softer the workpiece, the larger the feeds and speeds that can be successfully used. The ductility of the workpiece (strain at fracture) also plays a role in determining suitable feed and speed.     Not all of the cutting power will go straight into plastic deformation of the work material. In a typical process about 30% of the work done would be dissipated as tool–chip friction. Additionally, the electrical power input to the lathe will exceed the cutting power required, because the motor will not be perfectly efficient and there will also be some mechanical losses in the lathe. .$U$ approximately folds in work done in the shear plane, work done against friction, and mechanical losses in the lathe – hence each material has a quite wide range for .$U$  Example values of .$U$ (J/mm.$^3$): Aluminum alloys: 0.4 – 1.1 Titanium alloys: 3.0 – 4.1 Steels: 2.7 – 9.3   Expression linking .$U$, cutting power .$P_C$, and geometry:  Since .$F_C$ depends on the tool, we can find the span of possible .$f, d$ values with the equation above (which need to be sufficiently great to remove material from the work)   We have discussed the concepts of shear plane, rake angle and cutting power, etc, in the context of lathe turning  But these concepts apply across a whole range of metal-cutting processes, including facing processes on a lathe, as well as drilling, milling, planing, and even processes that use tools with many small cutting edges, such as sawing and rasping. In all of these processes the cutting edge shape is optimized to reduce the amount of mechanical work done to remove material, and give a clean, smooth cut.    Tool temperatures and lifetimes #   The basic requirement of any cutting tool is that it must be made of a material that is harder than the material it is cutting.  For cutting many metals and alloys, we can use high speed steel (HSS), which is a hardened steel containing tungsten, chromium and vanadium as alloying elements. The cutting speeds that are possible with HSS, however, are lower than can be achieved with harder, higher-melting-point, tool materials. An example of such a material would be tungsten carbide.   Cutting tool materials, being very hard, are very challenging to machine, and so are made either by grinding or by powder metallurgy, where powder mixtures are pressed in a mold into the shape of the required tool insert and are then baked to fuse the powder.  We say tool insert because the objects made by powder metallurgy are small square items that are mounted into a larger holder.   The inserts usually have multiple usable edges, so as soon as one of them is blunt or fractured, the insert can simply be rotated in the holder without re-aligning the tool in the machine.  An example of a tool material produced by powder methods is “cemented carbide” which is hard tungsten carbide powder bound together with cobalt. Cemented carbides are harder wearing than conventional high-speed steel and easier to produce than pure tungsten carbide tools. Coatings are also important in tool fabrication. Titanium nitride and diamond-like carbon are examples of coatings that reduce chip–tool friction, in part by reducing the surface roughness of the tool   The useful lifetime of a cutting tool is a function both of the material and of the cutting velocity at which it operates.  This is because as the cutting speed increases, the rate of frictional heat dissipation rises, heating and softening the tool material, and enabling it to erode more quickly:    Taylor tool life equation: $$VT^n = C$$\n .$V$ = cutting speed = .$V_\\text{cut}$ .$T$ = tool lifetime .$n, C$ are empirical constants     .$n \u0026lt; 1$ and predominated by the melting temperature of the tool material Smaller .$n$ values indicate that cutting tool lifetime falls more rapidly as cutting velocity increases than materials with .$n$ approaching 1. Example .$n$ values:      One advantage of using a tool material that can withstand a higher cutting speed is that one can reduce processing time. Another potential advantage is to be able to reduce the feed while not lengthening the total processing time. Smaller feeds can enable smoother finishes to be achieved, so finishing cuts will tend to have smaller feeds than roughing cuts (which remove large amounts of material quickly at the start of a turning process)  Examples of tool wear #   Some general effects of tool wear include:  increased cutting forces increased cutting temperatures poor surface finish    decreased accuracy of finished part May lead to tool breakage Causes change in tool geometry     Certain tool materials do not work well with other work materials   Typical recommended cutting speeds and feeds #    Cermets: Composite between ceramic and metal. Used if you need an especially tough tool  Carbides are hard but brittle, so they take tiny particles (typically cobalt) and mix it with a metal (tungsten often used) Talk to the Jacobs staff about this and they can teach you a lot    Cutting tool design #    (a) Schematic illustration of a right-hand cutting tool for turning. Although these tools have traditionally been produced from solid tool-steel bars, they are now replaced by inserts of carbide or other tool materials of various shapes and sizes, as shown in (b). The insert is the actual cutting feature.\n Surface roughness in machining #    Takeaway: Roughness varies with radius .$R_n$ and feed .$V_\\text{feed} = f$  If you want a mirror finish, you have to decrease feed rate   .$R_P$: Peak-to-valley roughness  Example: .$R_n = 0.5 \\text{ mm; } f = 0.1 \\text{ mm}$   Actual roughness will be up to 2-3 times worse than this ideal value: built-up edge, cracking, scratching from chips, etc Turning example   Autodesk computer-aided manufacturing (toolpath planning) demo  Etcheverry Machine Shop manual lathe demo    02-03: Other cutting processes based on plastic deformation #   Cutting-based operations other than turning:  Milling Drilling    Reaming Boring    Broaching Tapping    Punching      Milling #    Milling in action  Etcheverry demo video (manual)     Etcheverry demo video (CNC) Cut depth tends to be much greater than feed     Types of milling  Peripheral (plain, down) milling  Tool axis is parallel to surface being machined Slab, slotting, side milling, straddle, form   Face (up milling) milling  Tool axis is perpendicular to surface being machined Conventional, partial, end, profile, pocket, surface contouring         Both have pros/cons  Teeth orientation is different (down milling puts lots of force on the teeth)    Drilling #    Drilling  Flutes carry away material However, you end up with scratches on the side wall when drilling   Reaming  Reaming involves enlarge existing holes Provide better tolerance and smoother finish than drilling Reaming tools: vertical flutes        Boring #   Boring = “inside turning” Single point tool moving along the inside of a rotating workpiece   Broaching #   Tool used to get square (or non-circle) holes  How keyways are put into gears Cut per tooth is analogous to the feed       Example Geometry #   (a) Typical parts finished by internal broaching.\n(b) Parts finished by surface broaching. The heavy lines indicate broached surfaces;\n(c) a vertical broaching machine.\n Tapping #   Creates an internal (though external of possible, just uncommon) threads with no pitch nor diameter You start by creating a hole a bit smaller than the minor diameter, then drive the tap in  Tend to be treated to ensure they\u0026rsquo;re strong enough   Notice that the diameter tapers off, so you\u0026rsquo;re progressively enlarging the hole    Punching #   Comes in a set including both the punch and die Creates an edge using shear forces \u0026ndash; think industrial hole puncher  There has to be a gap between the punch and die; around 6-10% of the desired hole size (varies with type of material) Otherwise tool or medium can be damaged    Video demo   Other subtractive processes not based on plastic deformation #  Laser cutting #   In laser cutting, an intense beam of light imparts heat locally to the material and converts the solid either to liquid or directly to vapor to form an edge  Where this melted material goes (may) matter depending on the job Extremely quick With the right type of laser you can cut many materials   In ablation, a laser beam vaporizes material from the surface of a component to shape it without cutting all the way through it. A thin band of material is removed: the kerf  Has some thickness, maybe a thousandth, which may matter The cut isn\u0026rsquo;t completely vertical \u0026ndash; intensity isn\u0026rsquo;t uniform, and beam may not be completely orthogonal (and even then there is some geometry of the focal-spot)      http://alumni.media.mit.edu/~yarin/laser/physics.html\n Electrode discharge machining (EDM) #   An electrical field is applied between a high-melting-point electrode (which creates sparks, plasma) and the material that that is to be shaped is usually submerged in water.  The gap breaks down electrically and a high current flows, heating and vaporizing the work material. The electrode might be made of a wire (for profiling operations) or might be a custom-shaped electrode (e.g. made of graphite) to enable parallel transfer of a complex geometries to a workpiece.   Used when you require extreme precision  Wire has a constant width, there\u0026rsquo;s no focusing issues like with laser cutting      Wire EDM #   Not obvious in this example, but the wire can be adjusted about the .$z$-axis too Rate limitation is a function of how quickly you can cut + remove the material      https://www.mdpi.com/2076-3417/10/6/2082/htm   Abrasive jet #    Intro video A high-pressure (≫ 100 MPa) jet of water containing fine, hard particles (usually garnet) impact a sheet of material and cut through it. It\u0026rsquo;s not the water itself, rather, there are tiny particles in the water itself which concentrate the forces enough Material must be emersed under water Surface finish will be more rough (matt texture) than EDM or laser cutting      https://www.omax.com/news/blog/controlling-taper   "},{"id":9,"href":"/cogsci-c100/attention/","title":"Attention","section":"CogSci C100","content":"Physiological/neurological measures of attention #   Attention: ability to focus on one thing and ignore others  Attention is required for information to be encoded Novel stimuli capture attention \u0026ndash; something that\u0026rsquo;s different  Can be something loud, bright, salient or even sudden sound of silence     Physiological/neurological measures of attention  Neurological correlates (ERP and PET studies)  Activation of anterior and posterior attentional networks (frontal lobe)   Orienting response  Increase in heart rate and galvanic skin response        Pupil dilation  Pupil dilation reflects attentional effort \u0026ndash; pupils expand when people deep in thought If you are shown picture of someone you are romantically attracted to, your pupils dilate We are also more attracted to pictures of people with expanded pupils  In marketing/advertising, pupils are enlarged in models In 19C, ladies used to put belladonna in their eyes     Eye movement changes  Eyes tend to move toward objects of attention (even auditory attention) A number of newly developed therapies focus specifically on maintaining eye contact as a way of enhancing attunement and detecting when a person is dissociating (e.g., in treatment of PTSD and dissociative disorders) EMDR (Eye Movement Desensitization and Reprocessing) for treatment of trauma  Activation of opposite hemispheres of the brain      Selective attention #   Selective attention: focus of conscious awareness on a particular stimulus  Dichotic listening task: filter model of attention #   Donald Broadbent formulated one of the first information-processing models in psychology (1958); based on dichotic listening experiments (shadowing task):  Participants are instructed to repeat message played in one ear while ignoring message played in other ear Participants are very good at filtering out irrelevant information: they fail to notice even changes in language in the unattended ear or words that have been repeated dozens of times       However, they are usually able to pick out the gender of the speaker, words like “Fire,” and their own name (“cocktail party effect”) In general, people tend to consciously attend to one source of information and ignore other sources, but people vary in degree to which they focus attention and ignore distractions   Results of dichotic listening experiments supports filter model of attention: everything is picked up on some level, but at any given moment, we focus our awareness on only a limited aspect of all that we are experiencing  Broadbent proposed a flowchart model of selective attention to explain these results   This type of flowchart model has become a standard way for cognitive scientists to describe and explain different aspects of cognition\n  Implications: We can understand how a cognitive system as a whole works by understanding how information flows through the system   Stimuli that we do not notice can affect us  Participants were unable to recognize simple, novel tunes that had been played in unattended ear, but when asked to rate how much they liked different tunes, they preferred the ones previously played   On the other hand, research suggests that we consciously take in far less information than we think, even about objects that fall within the beam of our attentional spotlight  Change blindness experiment (Simons \u0026amp; Levin, 1998) #   Experimenter stopped people on a college campus and asked them for directions During the conversation, two confederates walked between them carrying a large door In the few seconds in which the first experimenter was obscured, another experimenter took his place and continued the conversation Only half the participants noticed the change \u0026ndash; even when specifically asked about it       Relatively dramatic changes can go undetected Due to attempt to achieve object constancy in spite of changes in sensory input (e.g., shadows, occlusion)  Divided Attention #   Divided Attention: Performance suffers when people have to attend to different stimuli at the same time; however, performance can improve with practice on some tasks, especially if one or both of the tasks are easy or well-learned.  Experienced drivers can converse with passengers while driving With practice, people can learn to read while taking dictation or categorizing words (after several months of practice) These feats of divided attention are possible because with practice, actions become automatic \u0026ndash; they no longer require much attention   However, it is virtually impossible to perform two tasks that require deep cognitive processing at the same time  Talking on cell phone (even hands-free) increases risk of accident 4 times Texting increases risk 23 times (!) (McEvoy, Stevenson, McCartt et al., 2005; Olson, Hanowski, Hickman et al., 2009)   Also, interestingly, research has also indicated that those who think they are best at multi-tasking are actually the ones who show the most severe impairments when multitasking! (Sambonmatsu, Strayer, Medeiros-Ward et al, 2013) Internet use in class  Study conducted at Michigan State University (Ravizza, Uitvlugt, \u0026amp; Fenn, 2017) found that, for every 100 minutes in class, students spent 40 minutes on non-academic website, mostly social media 5 minutes on websites that related to course material Increased non-academic internet usage in class had a negative correlation with final exam scores    Automaticity: advantages and disadvantages #  Stroop task #   Identification of color is slower in (c) because reading of word is automatic People with phobic disorders have difficulty identifying ink color of words related to feared objects Those with eating disorders take longer to report words related to body shape Those who show an attentional bias toward suicide-related words are more likely to make a suicide attempt within the following 6 months (Cha, Najmi, Park et al., 2010)      Evan Longoria’s catch #      What are some advantages to automatic processing?  Efficiency, multitasking, allows us to pay attention to higher levels of processing (you don\u0026rsquo;t think about the letters you type, rather, the content of what you\u0026rsquo;re trying to convey)   What are some potential drawbacks?  Lack of focus (car crashes), miss the rich and vividness of life  “Raisin” meditation    Theories of attention #  Bottleneck theory #   Quantity of information to which we can pay attention is limited Not widely supported by research  You can multitask in many ways    Automatic vs. controlled processing #   Automatic processing  Easy or well-practiced tasks Processing is parallel and involuntary i.e scanning list of student names for your own name      Controlled processing  Difficult or unfamiliar task Processing is serial i.e scanning list of student names for three unfamiliar names       Visual search study: automatic processing occurs only when target and irrelevant items belong to different sets  Find the two:      3 7     6 2        D 2     M R         Feature-integration theory #   Distributed attention (a)  Can be used to register single features automatically (searching for blue X among red X’s and O’s or searching for feature present) Automatic, parallel processing   Focused attention (b)  Used to search for combinations of features and for a feature that is missing (searching for blue X among red X’s, red O’s and blue O’s or searching for feature missing) Controlled, serial processing   E.x. is it easier to find the slanted green line in (a) or (b)?   Attention-Deficit/Hyperactivity Disorder #   Attention-deficit/hyperactivity disorder: difficulty sustaining attention, often fails to pay close attention to details on tasks, easily distracted by extraneous stimuli, fidgets and squirms constantly, always “on the go,” often interrupts others in conversations and games  Timing issue; subjects feel like they need to get their idea out or it will disappear   Treatment:  Medications: Ritalin and other stimulants  Supposed to attempt psychotherapy but that isn\u0026rsquo;t the case nowadays (you get much better results) Idea is that people with ADHD are constantly under-aroused, that\u0026rsquo;s why they fidget, so stimmys artificially bring them to a normal baseline   Parenting skills training classes \u0026ndash; parents taught to support/ignore certain behaviors Behavioral therapy: focusing on organization, scheduling, etc. Alternative therapies (e.g., biofeedback training) Research has indicated that the more kids with ADHD wiggle and fidget, the better they do on cognitive tests (Sarver, Rapport, Kofler et al., 2015)    Biofeedback #    Biofeedback: form of operant conditioning in which person is trained to bring autonomic processes under conscious control\n A signal, such as a tone or light, is made to come on whenever a certain desirable physiological change occurs   Person is instructed to try to keep the signal on for increasing periods of time Technique has been successfully used to teach people to reduce blood pressure, produce more regular heartbeats, decrease incidence of headaches and increase attention       Neurofeedback is now also being used to treat ADHD and chronic pain  fMRI neurofeedback for ADHD increases activation in the right inferior frontal cortex and is associated with clinical symptom improvement (Rubia, Criaud, Wulff, et al., 2019)   Reinforcement can be used to teach people to regulate many physiological responses that they are normally not aware of Training of attentional ability in normal college students    TV #   Connection between ADHD and TV viewing/video games  Many parents say, “My son can’t possibly have ADHD because he can sit for hours concentrating on a video game, so there is clearly nothing wrong with his attention span.” In fact, a child’s ability to stay focused on a screen, though not anywhere else, is actually characteristic of ADHD Not clear though whether fascination with the screen may be a cause or an effect of attention problems - or both   Evidence that TV watching may increase attention problems:  Study found that television shows impaired children’s executive functioning, particularly fantastical shows (Lillard, Drell, Richey et al., 2015)  Probably due in large to habitual reliance on bottom-up processing, that is, attention-grabbing external stimuli   Herbert Krugman found that  In less than one minute of television viewing, person\u0026rsquo;s brainwaves switches from beta waves to primarily alpha waves (lower arousal state associated with ADHD) When person stops watching television and begins reading a magazine, the brainwaves revert to beta waves When watching TV, all the information is spoon-fed to you. When you read, you are forced to use your imagination to interpret the media     Recent study published in JAMA Pediatrics found that after controlling for age, gender and income, 3-5 year old children with higher use of screen-based media  Had lower measures of structural integrity and myelination in neurons Scored lower on cognitive tests (Hutton, Dudley, Horowitz-Kraus et al., 2020)    Extra: American Academy of Pediatrics recommendations:\n Children under 18 months should avert their eyes from TV and screen media at all times For children 2 to 5, screen time should be limited to no more than 1 hour per day with the parent present   "},{"id":10,"href":"/e-29/3/","title":"Week 3: Additive Processes: Intro \u0026 Extrusion","section":"Engineering 29","content":"The rise of additive manufacturing #   Additive manufacturing or “3D printing” has been receiving enormous attention both in industry and as a tool for education and design. Something that sets additive manufacturing apart from other families of processes is the enormous rate of innovation in process technology and machine design, together with the fact that much of this innovation is done by small start-up companies and even by individuals, with the development in some cases being crowd-funded. There are huge differences between the versatility and achievable tolerances of “maker-grade” (or consumer-grade) and industry-grade tools, and in this part of the course we will describe and analyze some of the processes that are available, and provide a framework for analyzing new additive manufacturing tools as they become available.\n  The richness of innovation in machine design has been helped by the fact that the established players in 2D printing (HP, Epson, etc.) have until very recently been largely absent from 3D printing. This situation has begun to change, especially with the introduction of HP’s “Multi Jet Fusion” systems, but there is no doubt that the market is highly fragmented, and to understand it, one needs knowledge of the underlying material processing principles.\n Reasons to use additive manufacturing #   Additive manufacturing has conventionally been seen as a means of prototyping components that would then be mass-produced with some other, faster, process. Prototyping remains an important application, but there are many reasons why one would produce final, functional components additively. Reasons for selecting an additive process over another kind of process include:\n  Geometry needs customization, \u0026ldquo;mass customization\u0026rdquo;  Medical implants and prostheses; dental aligners, crowns, bridges, surgical guides, clothing, footwear   Run size too small for custom tooling  There are some components where machining would require too much time and/or labor to be economical, and mass-production techniques such as casting or injection molding would incur considerable tooling costs (complex injection molds can cost tens of thousands of dollars) e.x. Aircraft cabin components (e.g. ducting, seats); titanium alloy turbine blades; mounting brackets; engine fuel nozzles   The desired geometry cannot be made in any other way  Multi-material, graded stiffness or color Internal porosity for reduced mass The idea of “complexity as practical” or that “complexity is free” is often talked about as a distinctive advantage of additive manufacturing. Reasons for geometrically complex designs: particular aesthetic goals, to improve the aerodynamic performance of a vehicle, or to optimize mechanical properties (e.g. stiffness-to-weight ratio, or compressibility) of a component by introducing fine porous structures that mimic geometries found in nature (e.g. bone, cork, and branched tree-like structures).   Supply chain is challenging in some way (geographically or temporally)  Enables more decentralized/distributed production  Space Station: producing spare parts on the International Space Station — see the start-up company Made in Space that is developing fused deposition modeling tools to work in vacuum and zero-gravity, as well as recycling machines for the printable material, the idea being to produce components on demand without having to wait for a new spacecraft to be launched from Earth to deliver them; Producing spare parts for military use in theaters of war, where components are frequently needed more quickly than they could be shipped, installing a full machine shop in the field may not be practical, and carrying a comprehensive array of spare parts would be cumbersome Printing of food, where freshness is important and people decide what they would like to eat just minutes before they eat it.   Assembly costs can be significantly reduced.  Items that would necessitate the use of many components if made with traditional manufacturing approaches could be produced in a single piece by exploiting the extra geometrical flexibility allowed by additive manufacturing, thus saving assembly costs. Less workers (human controllers) required \u0026ndash; cheaper, less (human) error   Why Not:  Potentially waste more material Supports are annoying to remove    Working principles for additive manufacturing #   New additive processes and tools enter the market every month, so any detailed description of process technology will rapidly become outdated. Perhaps the most useful way to think about additive manufacturing technology is to isolate the different functions that are involved in any additive process, and consider the multiple independent ways in which each function might be fulfilled. Printing tools could be conceived that combine those solution principles in many different ways:\n    Material supply:  Gas (semiconductor manufacturing) Solution (Electroplating) Laminae (sheets of material), i.e Fabrisonic   Energy:  Heat Cooling (cryo-printing, biological tissue) Plasma      Spatial:  moving tool versus moving work belt/string drive screen projector  scanning mirrors (galvanometer scanner)        This is a very rapidly developing field. Some of these seem unrealistic, and they may be, but only for now.Technology is rapidly increasing and what is unfeasible today may be feasible very soon. Think neural networks\u0026ndash; we\u0026rsquo;ve known the underlying concepts since 1873 but only now has technology become fast enough for it to become feasible  Simple model for extrusion #    Material must able to heat up and cool down while maintaining it\u0026rsquo;s key properties Higher the temperature, more energy required, lower the viscosity Radius matters  Narrow is significantly harder Typical nozzle diameters are in the range 100–250 μm So more resolution is harder to achieve   Distance to drive wheel and extruder block needs to be short enough so the material doesn\u0026rsquo;t buckle  Considerations #   Turning corners  Need to synchronize extrusion rate If .$Q$ is too high, then you\u0026rsquo;ll end up with corner bulges       Volume conservation  Voids/porosity If material isn\u0026rsquo;t hot enough to remain molten, then it won\u0026rsquo;t fill the voids      Thermal gradients (difference in temperatures)  Can cause warping Heat the component during printing Heated beds (or \u0026lsquo;ovens\u0026rsquo; \u0026ndash; used in industrial machines) can help prevent this       Types of additive process #  Fused deposition modeling (FDM) #   Need models for heat transfer at printing location Also called Fused Filament Fabrication (FFF) Print time depends strongly on:  Machine, Component size/geometry, In-fill strategy        After CAD is complete, model is ran through software (i.e. cura) which turns the model into a series of triangles, which is then used to generate some tool path that forms the model  There\u0026rsquo;s some information loss throughout this process       Variations at Jacobs  Type A \u0026ndash; most basic \u0026amp; common  Single extrusion nozzle (one material) PLA: Poly Lactic Acid \u0026ndash; plant-based, recyclable, but not industrial-grade due to it\u0026rsquo;s brittleness   Ultimaker 3  PLA, PETG (tougher, bit more flexible than PLA) Dual nozzle \u0026ndash; capable of support material (or just various colors)      LulzbotTaz 6  1.2 mm nozzle   Stratasys Fortus 380 MC  ABS (reasonably tough: lego-brick material); others possible (i.e nylon) Soluble support   Markforged X7  One of the first printers that enables you to include carbon fiber-reinforced nylon  Printed composite   Stiffer than many aluminum alloys       Industrial usage  Examples: Curtain headers, internal brackets for Airbus A350; air duct components. Material: “Ultem” (polyetherimide), PEEK, nylon Used due to the ability to rapidly manufacture in bulk + light weight compared to alternatives    Support structures and extrusion diameter #    Stair-step effect  You can fix this with post-processing processes i.e. acetone vapor, sanding   Some FDM machines have two or more extrusion dies which can deposit different materials independently.  One of these extrusion heads might be set up to deposit dedicated support material, which is often soluble in water or a weak NaOH solution and can thus be readily removed from the printed part A widely used rule of thumb is that an overhang with an angle of up to 45° can be printed without any support material.    Stress Line Additive Manufacturing (SLAM) #   Fused deposition modeling (FDM) [sometimes known as fused filament fabrication (FFF)] is usually carried out layer-by-layer but inter-layer voids or defects can reduce strength or make strength highly directional. If the filament orientation can be optimized based on knowledge of the way the part will be loaded (i.e. aligning filaments with the principal stress lines), strength could be improved. This is what SLAM aims to achieve. Extrusion nozzle path planning is more challenging than in layer-by-layer FDM.      FDM of metal powder/polymer mixtures #   The filament material itself is crucial in determining the performance of the printed object. Filaments with new properties enter the market all the time. Materials with widely varying elasticity are available. It is possible to buy filaments with embedded metal particles, wood particles, carbon powder or even graphene (sheets of few-atom-thick carbon with exceptional in-plane thermal and electrical conductivity). These additives control the optical properties (e.g. reflectivity), and, with a post-printing sintering step, electrical conductivity (enabling printing of e.g. circuit boards) and possibly even thermal conductivity.\n  Nevertheless, the working principle of FDM is that a thermoplastic material is temporarily softened inside the print head and then extruded layer by layer on to the emerging component. So it is likely that the largest constituent by volume of any FDM filament will continue to need to be a thermoplastic material. At the moment, organic thermoplastic polymers are the primary ingredient of most filament materials. However, we have already seen the working principle of FDM translated from organic thermoplastic polymers to metals and to glass, which can be extruded in a sufficiently viscous form that it holds its shape long enough to be deposited on to a component.\n  A heated nozzle brings the feedstock filament close to its melting point, then an electrical current passed through the filament and into the substrate further heats the material causing it to fuse on to the substrate.  It has also been demonstrated with bulk metallic glasses, which are special alloys that remain amorphous at readily attainable cooling rates – i.e. they do not crystallize and can therefore achieve a desirable combination of hardness and toughness. Meanwhile, use of arc welding in conjunction with robotics to deposit metal has been demonstrated as a lower-resolution, but much faster, way of depositing material   Filament ~85 wt% metal powder; polylactic acid (PLA) binder   Sinter at 980 °C (copper) or 830 °C (bronze) to fuse particles If you get high enough pressure, then the metal atoms themselves will fuse  You\u0026rsquo;re not melting the object; shape is retained Same side of the coin: pores still exist  \u0026ldquo;Pores are just cracks waiting to grow\u0026rdquo; due to their sharp edges     Quench; pickle or polish     Left: After printing; Right: After Polishing\n     -- Direct ink writing #   This is a hybrid between FDM and sintering, and involves extruding a paste containing particles of the structural material in a solvent.  The material can be extruded successfully through syringe needles as small as a micrometer in diameter.  Lead zirconium titanate ceramic particles in a solvent dispensed via nozzle Piezoelectric material   The material paste is thixotropic, or shear-thinning, which means that when it is loaded and starts to flow, its apparent viscosity falls enabling it to be squeezed through the needle.  Versus than thermally softening polymer (like squeezing toothpaste from a tube)   When its shear strain rate falls again, its viscosity rises, so the extruded structure retains its shape and does not deform significantly under the action of gravity or surface tension. Once the structure has been printed, heat is applied to drive of the solvent and sinter the particles. Applications include making micro-scale sensors and actuators, and tissue scaffolds.      Material flow is achieved by using a (shear- thinning) ink Features down to ~ 1 micrometer possible by extrusion through fine needles Advantages: heat not required; more material possibilities (notably ceramics)      Shear stress in material, .$\\tau$, is defined by: $$\\tau = \\tau_y + K \\dot \\gamma ^n$$ .$\\tau_y$ is zero-shear-rate yield stress (Pa) .$K$ is a material constant .$\\hat \\gamma$ is shear (deformation) rate (1/s) .$n$ is shear-thinning exponent (\u0026lt;1 for this process to work)     "},{"id":11,"href":"/eecs-16a/3/","title":"Week 3: Transformations \u0026 Inverse","section":"EECS 16A","content":"02-08: Matrix Transformations #    Slides  Note 4   Linear Transformations #   Linear Transformation: In the previous practice set, we discussed the idea of a matrix .$A^{M \\times N}$ as a linear transformation.  Effectively, in the equation .$A \\vec x = \\vec b$, the matrix itself can be considered a transformation .$f : \\mathbb{R}^{N} \\to \\mathbb{R}^{M}$ which takes a vector .$\\vec x^{N \\times 1}$ of inputs and returns a vector .$\\vec b^{M \\times 1}$ of outputs  That is, matrices are operators that transform vectors       Just as .$f$ is a linear transformation iff homogeneity and super position hold, matrix-vector multiplications satisfy linear transformation:   $$A \\cdot (\\alpha \\vec x) = \\alpha A \\vec x$$ $$A \\cdot (\\vec x + \\vec y) = A \\vec x + A \\vec y $$     State Transformation #   As such, we can think about matrices as state transformations;  If we have a list of inputs representing some current state at some timestep .$n$ (given by .$\\vec x(n)$), then when a matrix .$A$ operates on that state, it transforms it into a new state at the next time step (.$\\vec x(n + 1)$). Consider a timestep to be a very small unit of time. Our systems here will be discrete, meaning that the transition of water happens exactly at each timestep, and not between timesteps  Aside: But in reality, water is flowing continuously! To model this rigorously, we need linear differential equations, but for now, if the timestep we take is very small, the discrete model is quite good as an approximation.     Example: Water Pulps ( Note5 )  At each time step, some portion of the water in each pump goes to itself, and some portion goes to each of the other pumps. The general state transition matrix formula for an .$n$-state system (assuming the initial and final state vectors have the same length .$n$) is as follows:  $$ \\begin{bmatrix} \\vec P_{1 \\to \\dots} \u0026amp; \\vec P_{2 \\to \\dots} \u0026amp; \\dots \u0026amp; \\vec P_{N \\to \\dots} \\\\ \\end{bmatrix}$$ $$\\equiv$$ $$\\begin{bmatrix} P_{1 \\to 1} \u0026amp; P_{2 \\to 1} \u0026amp; \u0026hellip; \u0026amp; P_{N \\to 1}\\\\ P_{1 \\to 2} \u0026amp; P_{2 \\to 2} \u0026amp; \u0026hellip; \u0026amp; P_{N \\to 2}\\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots\\\\ P_{1 \\to N} \u0026amp; P_{2 \\to N} \u0026amp; \u0026hellip; \u0026amp; P_{N \\to N} \\end{bmatrix} $$    $$\\begin{bmatrix} 0.4 \u0026amp; 0.1 \u0026amp; 0.4 \u0026amp; 0.1\\\\ 0.1 \u0026amp; 0.2 \u0026amp; 0.1 \u0026amp; 0.4\\\\ 0.2 \u0026amp; 0.3 \u0026amp; 0.2 \u0026amp; 0.2\\\\ 0.3 \u0026amp; 0.4 \u0026amp; 0.3 \u0026amp; 0.3 \\end{bmatrix}$$\n    Notice that all of the water goes somewhere and none comes up out of thin air; that is, the water is a conserved quantity. We don’t have any leakage or generation of water in the system.  This isn’t always true, but the idea of conservation will largely hold true, especially for systems based in physical reality. We can tell if the transformation is conservative by looking at each column’s values describe the movement of water from a specific node to other nodes. If any column’s values do not sum to exactly 1, then something is being lost or created in the system as a whole.  In addition, if a specific column’s sum is greater than 1, matter is entering the system through that node; conversely, if a specific column sum is less than 1, matter is leaving the system through that node. Recognize that, given information about only a single node’s column sum, we can never definitely say if the overall system is conservative or not; we only know if it might be conservative, based on other nodes.       Diagram .$\\to$ Matrix:  Given a state transition diagram, we can create the corresponding state transition matrix by reading the values at each arrow, noting the directionality (these are directed edges) and populating the rows one by one. Similarly, given a matrix, we can draw the appropriate number of nodes and label arrows going to/from each node with the values as indicated by the matrix.   How do we go back in time?  That is, we want some transition matrix .$B$ such that .$\\vec x (t-1) = B \\vec x(t)$ Flipping the direction of the edges won\u0026rsquo;t work\u0026hellip; Transpose won\u0026rsquo;t either\u0026hellip; Which leads us to\u0026hellip;    02-10: Inverse #    Slides Notes 5, 6   Matrix Inverse #   Purpose  We know that .$\\vec x(t+1) = Q \\vec x (t)$ and want some reverse-matrix .$P$ such that .$\\vec x (t) = P \\vec x (t+1)$ $$P \\vec x(t+1) = PQ\\vec x(t)$$ $$P \\vec x(t+1) = I \\vec x(t)$$  $$\\vec x(t+1) = Q \\vec x(t)$$ $$\\vec x(t+1) = Q(P \\vec x(t+1))$$ $$\\vec x(t+1) = I \\vec x(t+1)$$      Consider .$A$ as an operator on any vector .$\\vec x \\in \\mathbb{R}^{n}$:  What does it mean for .$A$ to have an inverse? It suggests that we can find a matrix that \u0026ldquo;undoes\u0026rdquo; the effect of matrix .$A$ operating on any vector .$\\vec x \\in \\mathbb{R}^{n}$. What property should .$A$ have in order for this to be possible? A should map any two distinct vectors to distinct vectors in .$ \\mathbb{R}^{n}$, i.e., .$A \\vec x_1 \\neq A \\vec x_2$ for vectors .$\\vec x_1, \\vec x_2$ such that .$\\vec x_1 \\neq \\vec x_2$.   Definition: Let .$P, Q \\in \\mathbb{R}^{N \\times N}$ be square matrices (we tackle non-square in 16B)  .$P$ is the inverse of .$Q$ if .$PQ = QP = I$ We say .$P = Q^{-1}$ and .$Q = P^{-1}$ Steps to solve with Gaussian Elimination are shown on slide 50 or \u0026lsquo;more\u0026rsquo; formally in Notes 6, page 3  For any .$n \\times n$ matrix .$M$, we can perform Gaussian elimination on the augmented matrix: If at termination of Gaussian elimination, we end up with an identity matrix on the left, then the matrix on the right is the inverse of the matrix .$M$  If we don’t end up with an identity matrix on the left, we will have a row of zeros, (which indicates that the rows of .$M$ are linearly dependent) and that the matrix is not invertible     $$\\begin{bmatrix} \u0026amp; \u0026amp; | \u0026amp; \u0026amp; \\\\ \u0026amp; M \u0026amp; | \u0026amp; I_n \u0026amp; \\\\ \u0026amp; \u0026amp; | \u0026amp; \u0026amp; \\\\ \\end{bmatrix} $$ $$ \\begin{bmatrix} \u0026amp; \u0026amp; | \u0026amp; \u0026amp; \\\\ \u0026amp; I_n \u0026amp; | \u0026amp; M^{-1} \u0026amp; \\\\ \u0026amp; \u0026amp; | \u0026amp; \u0026amp; \\\\ \\end{bmatrix}$$\n      Inverse of a 2x2 matrix #   You can derive this via Gaussian elimination (flip .$a$ with .$d$, negate .$b$ and .$c$, then divide by .$ad-bc$) $$A = \\begin{bmatrix} a \u0026amp; b\\\\ c \u0026amp; d\\\\ \\end{bmatrix}$$  $$A^{-1} = \\frac{1}{ad-bc} \\begin{bmatrix} d \u0026amp; -b\\\\ -c \u0026amp; a\\\\ \\end{bmatrix}$$    .$ad-bc$ is the determinant, so we can check quickly if an inverse exists for a square matrix by checking if they determinant exists   See slide 8 Determinant is the area the vectors form. So if they vectors form some zero-area (or volume in 3D) then it\u0026rsquo;s not one-to-one and thus not invertible      Theorems #  Theorem Note 6.1 #   If .$A$ is an invertible matrix, then its inverse must be unique\n  Suppose .$B_1, B_2$ are both inverses of the matrix .$A$. Then we have    Notice that by associativity of matrix multiplication, the left hand side of the equation above becomes We see that .$B_1 = B_2$, so the inverse of any invertible matrix is unique.   $$AB_1 = B_1 A = I$$ $$AB_2 = B_2 A = I$$\n $$AB_1 = I \\Longrightarrow B_2(AB_1) = B_2 I = B_2$$ $$B_2 (AB_1) = (B_2 A)B_1 = IB_1 = B_1$$ $$\\therefore B_1 = B_2$$\n   Another important property of inverses is that the “left” inverse and the “right” inverse are equal to each other. In particular\u0026hellip;  Theorem Note 6.2 #   If .$QP = I$ and .$RQ = I$, then .$P = R$. The matrix .$P$ can be thought of as the “right” inverse of .$Q$ and the matrix .$R$ can be thought of as the “left” inverse of .$Q$.\n  We start the proof by noticing that we know two things .$QP = I$ and .$RQ = I$. To move ahead, we can try setting .$QP = RQ$, but we cannot proceed from here, since the multiplication by .$Q$ is on different sides. So instead we take the equation .$QP = I$ and multiply both sides on the left by .$R$. This gives $$R(QP) = R(I) = R$$ Now, using the associative property of matrix multiplication we have that $$R(QP) + (RQ)P = IP = P$$ Here we used .$RQ = I$. Combining these two equations, we have that .$R = P$, and we are done  Theorem Note 6.3 #   If a matrix A is invertible, there exists a unique solution to the equation .$A \\vec x = \\vec b$ for all possible vectors .$\\vec b$.\n  Let’s try to prove this. To do so, we need to prove two statements:  That there exists at least one solution to the equation .$A \\vec x = \\vec b$, and that There exists no more than one solution to the equation .$A \\vec x = \\vec b$.   For both of the above statements, .$\\vec b$ can be any vector in .$\\mathbb{R}^{n}$ Let’s prove the first statement first. Imagine we are given a vector .$\\vec b$. Consider the candidate solution .$\\vec x = A^{−1} \\vec b$. Observe that $$A \\vec x = A(A^{-1} \\vec b) = (AA^{-1}) \\vec b = \\vec b$$ Thus, our candidate solution satisfies the equation .$A \\vec x = \\vec b$, so there exists at least one solution to that equation! Now, let’s show the second statement \u0026ndash; that no more than one solution to the equation .$A \\vec x = \\vec b$ can exist. Consider a particular solution .$\\vec x$, so .$A \\vec x = \\vec b$. Pre-multiplying both sides of this equation by .$A^{−1}$, we obtain $$A^{-1}(A \\vec x) = A^{-1} \\vec b \\Longrightarrow \\vec x = A^{-1} \\vec b$$ Therefore, if .$\\vec x$ exists, it must be the particular vector .$A^{−1} \\vec b$. In other words, there exists at most one solution to the equation .$A \\vec x = \\vec b$, so we have proven the second statement  Theorem Note 6.4 #   If a matrix .$A$ is invertible, its columns are linearly independent.\n  Let’s prove this theorem. We know that the statement “the columns of .$A$ are linearly independent” is equivalent to the statement “.$A \\vec x = \\vec 0$ only when .$ \\vec x = \\vec 0$.” This fact follows from the definition of linear independence: by definition, if .$\\vec v_1, \\dots, \\vec v_n$ are linearly independent, then .$\\sum_{i=1}^n x_i \\vec v_i$ is only .$\\vec 0$ when .$x_i = 0$. Using the column perspective of matrix multiplication (covered in Note 3), .$A \\vec x = \\sum_{i=1}^n x_i \\vec v_i$ where .$\\vec v_i$ is the .$i$th column of .$A$. Therefore, .$A \\vec x = \\vec 0$ only when all .$x_i = 0$. Therefore, we can rephrase what we’re trying to prove as $$A^{-1} \\text{ exists } \\Longrightarrow A \\vec x = \\vec 0 \\text{ only when } \\vec x = \\vec 0$$ To prove this, assume that .$A$ is invertible. Let .$\\vec v$ be some vector such that .$A \\vec x = \\vec 0$: $$A \\vec x = \\vec 0 \\text{ left-multiply by } A^{-1}$$ $$A^{-1} A \\vec v = I \\vec v = \\vec 0$$ $$\\vec v = \\vec 0$$  Theorem Lecture #   .$A$ is invertible, iff the columns of are linearly independent.\n  That is,  If columns of .$A$ are liner dependent then .$A^{-1}$ does not exist If .$A^{-1}$ exists, then the cols. of .$A$ are linearly independent   Proof concept: Assume linear dependence and invertibility and show that it is a contradiction  From linear dependence: .$\\exists \\vec \\alpha \\neq 0$ such that .$A \\vec \\alpha = 0$:   But .$\\vec \\alpha \\neq 0$, hence, .$A^{-1}$ DNE   $$A \\vec \\alpha = 0$$ $$A^{-1} A \\vec \\alpha = A^{-1} 0$$ $$I \\vec \\alpha = 0$$    Thus, the following statements are equivalent:  Matrix .$A$ is invertible .$A$ has linearly independent columns  .$A$ is full rank      .$A \\vec x = \\vec b$ has a unique solution .$A$ has a trivial nullspace The determinant of is not zero      "},{"id":12,"href":"/cogsci-c100/sleep/","title":"Sleep \u0026 Dreams","section":"CogSci C100","content":"Sleep and cognition #  The National Sleep Foundation’s Sleep IQ Test  During sleep, your brain rests. Boredom makes you feel sleepy, even if you have had enough sleep. Resting in bed with your eyes closed cannot satisfy your body’s need for sleep. Snoring is not harmful as long as it doesn’t disturb others. Everyone dreams nightly. Raising the volume of your radio will help you stay awake while driving. Sleep disorders are mainly due to worry or psychological problems. The human body never adjusts to night shift work. Most sleep disorders go away even without treatment.  Answers  F F T F T F F T F       Why do we sleep?  Fact that all vertebrates sleep, including some that would seem to be better off without it, suggests that sleep is essential Indus dolphins have evolved to take mini-naps of 4-60 seconds (totalling seven hours), bottle-nose dolphins (and some migratory birds too) have evolved to sleep half their brain at the time   Sleep requirements  Most people need at least 7-8 hours of sleep a night Some notable exceptions:  Leonardo da Vinci slept a mere 90 minutes a day, in catnaps of 15 minutes every four hours Salvador Dali liked to doze off, sitting up with a spoon in his hand. As he fell asleep, spoon would fall and clatter to the ground, and he would wake rejuvenated. Thomas Edison and Winston Churchill also thrived on catnaps         There are people who are able to function quite well on one or two hours\u0026rsquo; sleep a night    Effects of sleep deprivation on cognition #   Sleep deprivation causes irritability, fatigue, impaired concentration and creativity, greater vulnerability to accidents  Surprisingly, people are oftentimes unaware that their concentration, judgment, etc. are impaired (\u0026lsquo;LSD Effect\u0026rsquo;)   Sleep deprivation  Impairs functioning of the prefrontal cortex, which has a negative impact on attention, memory, and decision making (Wu, Gillin, Buchsbuam et al., 2006) Reduces neuroplasticity and the proliferation of cells in hippocampus, which can result in memory impairments (Fernandes, Rocha, Rocha et al., 2015)  Study by Matthew Walker \u0026amp; Robert Stickgold (2006) found that without sleep, the brain is 40% less able to make new memories   Impairs process of making broad connections and gaining creative insight  Participants were presented with a task where discovery of a hidden rule greatly improved speed of performance (Wagner, Gais, Haider et al., 2004; Ellenbogen, Hu, Payne et al., 2007)  Sleep dramatically increased the likelihood of grasping the hidden rule   Sleep causes our brain to create new links, which is why we often wake up with solutions to previously unresolvable problems     Sleep also plays an important role in emotional regulation (Walker \u0026amp; van der Helm, 2009)  After a night of no sleep, brain scans show a shutdown of the medial prefrontal cortex, which normally helps keep our anxiety in check (Simon, Rossi, Harvey et al., 2019) Research following youth through time found that sleep loss predicts depression rather than vice versa (Gregory, Rijksdijk, Lau et al., 2009)   Sleep deprivation can produce hallucinations, delusions, and paranoia   Peter Tripp’s wake-a-thon   Sleep debt can also cause metabolic and hormonal changes that mimic aging and lead to diabetes, obesity, hypertension, and memory impairment  Typical 18-year-old looks like 60-year-old in ability to metabolize glucose after 2 weeks of restricted sleep   Sleep deprivation depresses the immune system and is associated with shorter lifespan  “Poor sleep will make you fat and sad, and then kill you”\n   In adolescents #   Teens now average nearly 2 hours less sleep a night than 80 years ago Insufficient sleep in adolescence increases risk of high blood pressure, heart disease, diabetes, risk-taking behavior, depression, and car accidents  Teens who sleep less than 8 hours are 3x more likely to make suicide attempts For each hour of sleep lost, odds of an adolescent’s being obese rises by 80%   Compared to A and B students, those who receive C’s, D’s, and F’s in school obtained about 25 min less sleep per night, went to bed an average of 40 minutes later, had more irregular sleep/wake schedules (greater weekend delays of sleep schedule) Sacrificing sleep time to study actually worsens academic performance, by making it harder the next day to understand class material or do well on a test Also, a regular full night’s sleep can “dramatically improve athletic ability”  Strengthens neural connections that consolidate “muscle memories”    Treatment for insomnia #   Treatment of underlying physical/psychological problem Behavioral treatment (CBT-I)  Sleep restriction: go to bed and get up at the same time everyday Stimulus control: associate your bed with sleep Relaxation response training   Many studies have indicated that CBT is just as effective as sleep meds and has more lasting overall benefit  Other helpful practices: #   Exercise daily (preferably in late afternoon), but not right before bed No caffeine after 5PM Relax and dim lights hour or two before bedtime  Using screens in a dark room was associated with worse sleep outcomes than using them with the lights on Children who used screens at bedtime consistently scored lower on quality-of-life tests   Eat foods with more fiber and less simple carbs and saturated fat  More fiber and less saturated fat led to more slow-wave (deep) sleep More sugar and simple carbs was associated with more frequently awakenings   Consume milk, banana, or sunflower seeds right before bed to raise serotonin levels Identify problematic thoughts and determine how to deal with them  In medical students #   According to the Center for Disease Control, being awake more than 24 hours impairs performance as much as having a blood alcohol level of .10% - which is legally drunk  Many interns work 80 hours per week, typically in shifts of 30 hours   Medical students trained on traditional schedule, rather than alternative schedule with fewer weekly hours, made 5.6 times more diagnostic errors (Landrigan, Rothschild, Cronin et al., 2004)  Sleep Debt \u0026amp; Napping #   Sleep debt: “The brain keeps an accurate count of sleep debt for at least two weeks” Potential benefits of napping  Federal Aviation Administration study found that pilots who took a 20-minute nap early in their 9-to-12-hour flight were significantly more alert as measured by reaction-time task Research indicates that a  45-minute nap improves alertness for 6 hours 1-hour nap improves alertness for 10 hours Napping can be an effective way to cope with sleep crisis   However, naps can potentially disrupt nighttime sleep, so it is generally recommended that those with chronic insomnia limit naps to 20-30 min at most or to refrain from napping altogether    Neurophysiological functions of sleep #   Slow wave sleep lowers the brain\u0026rsquo;s metabolism and permits it to rest  Regions that show the highest levels of activity during the day show the lowest levels of activity during slow-wave sleep  Stimulation of person\u0026rsquo;s hand with vibrator caused activation of contralateral somatosensory cortex: more delta activity was shown in that region the next night     On the other hand, regions involved in consolidation of memories show an increase in activity during sleep  The same patterns of activation of hippocampal neurons that occur during learning are repeated when animal is sleeping   The greater the hippocampal activity during sleep after a training experience, the better the next day’s memory Also, the glymphatic system pushes cerebrospinal fluid through the brain to flush out toxins during sleep  Sleep clears brain of damaging molecules associated with neurodegeneration    REM sleep and dreams #  Stages of sleep #   Waking state  Alpha activity: regular, medium-frequency waves of 8–12 Hz; associated with a state of relaxation Beta activity: irregular, low-amplitude waves of 13–30 Hz; associated with a state of arousal or alertness   Stage 1 Sleep  Theta activity: transition between sleep and wakefulness (nodding off, hynagogic stage)   Stage 2 Sleep  Characterized by sleep spindles: bursts of waves, thought to be important in cognitive processing and\u0026hellip; K-complexes: sudden sharp waveforms when you hear a loud noise\u0026ndash;you brains senses remain active         Stages 3 and 4 Sleep (slow-wave sleep)  Delta activity: regular, low-frequency, high-amplitude waves of less than 4 Hz; occurs during deepest stages of sleep Person cannot be easily awakened, and when awakened, s/he acts groggy and confused (you don\u0026rsquo;t think you\u0026rsquo;re sleeping in stage 3)   Sleep cycles  Each cycle of REM and non-REM sleep lasts approximately 90 minutes  Most slow wave sleep occurs during first half of night Later cycles contain more stage 2 and REM sleep   90-minute cycles of rest and activity ( basic rest-activity cycle) have also been found for activities such as infant feeding, eating, drinking, smoking, heart rate, oxygen consumption, etc.       It is actually impossible to totally deprive someone of sleep for prolonged period  EEG shows that people start to have “microsleeps” of two or three seconds     Dreams and REM sleep  Dreams occur during REM sleep: even those who claim they don’t dream, if awakened during REM, will usually recall a dream when awakened from REM Dreams also occur in non-REM (NREM) sleep However, REM sleep is associated more with “true dreams” that have vivid sensory and motor imagery and sense that “you are there”;  NREM dreams tends to focus more on a thought (e.g., solving a problem), image, or emotion   Amount of time spent in REM during each cycle increases as night progresses Dreams during second half of sleep become more bizarre and emotionally intense; lucid dreams tend to occur in early morning hours Dreams are quickly lost from memory unless we catch them and think about them immediately upon awakening  To improve dream recall, keep a dream diary      Functions of dreams #   Why Do We Dream? Theories through the times\u0026hellip;   Freud’s wish-fulfillment theory of dreams: dreams are a safety valve that discharges otherwise unacceptable feelings/desires Modern psychodynamic view  Dreams reflect what is going on in our lives, our hidden impulses and desires, and underlying conflicts Dreams give clues to the solution of our underlying conflicts and problems   Hobson \u0026amp; McCarley’s activation-synthesis hypothesis  Dreams serve no purpose \u0026ndash; just side effect of random firing of neurons that serve to develop and preserve neural pathways through stimulation  Not scientific, can\u0026rsquo;t disprove \u0026ndash; same with Freudian views   Pons sends randomly generated electrical signals to the frontal cortex (activation). The frontal cortex then weaves these signals into a coherent story (synthesis)      Cognitive development theory of dreams  The neural activation associated with dreaming aids cognitive development  Peak of REM sleep occurs in 30-week-old fetus, who spends almost 24 hours a day in this state     Memory consolidation view  Participants who were trained on visual search task or word learning, then deprived of REM sleep, performed significantly worse than control participants the next morning REM sleep increases following stressful experiences or periods of intense learning (e.g., graduate student studying for Qualifying Exams)       Hypnagogic dreams and learning and memory  These dreams are characterized by:  High rate of incorporation of memories of events from the day or from older related memories  When researchers had participants play Tetris for 7 hours, then repeatedly awakened them during their first hour of sleep, three-fourths reported experiencing images of the game’s falling blocks   A preference for emotionally salient material but without high dream affect   Hypnagogic dreams normally lack the bizarreness, selfrepresentation, emotions, and narrative complexities common to REM dreams   Slow-wave sleep early in the night may aid in consolidation of declarative memory tasks while REM sleep may enhance the processing of emotional memories  REM sleep involves activation of the amygdala and limbic forebrain structures \u0026ndash; structures that are associated with regulation of emotions  Participants deprived of REM sleep show  Greater amygdala and less frontal activation after viewing emotionally distressing film Less reduction in negative affect upon second viewing (Rosales-LaGarde, Armony, del Rio-Portilla et al., 2012) You can\u0026rsquo;t process new emotions when sleep deprived         “Sleep knits up the raveled sleeve of care.” - Shakespeare\n  Case Studies: Unconscious problem solving   Great discoveries and inventions have often come to people through dreams  The tune for \u0026ldquo;Yesterday\u0026rdquo; came to Paul McCartney in a dream Man who discovered the structure of the benzene molecule had dream of snake chasing its own tail        In 1845, Elias Howe had an idea for inventing a sewing machine, but he couldn’t figure out how to connect the needle to the thread. Then one night he dreamt that he was taken prisoner by a group of natives who were dancing around him with spears. The spears all had holes near their tips… Madame Walker, the first female American self-made millionaire, founded and built a highly successful African-American cosmetic company in the 1890’s that made her a millionaire many times over: the formula for her original product, which included ingredients that could only be obtained from Africa, came to her in a dream    Content of dreams #   Repetition dimension continuum: traumatic dreams =\u0026gt; recurrent dreams =\u0026gt; repetitive themes within long dream series =\u0026gt; frequent elements in dreams  All of these may be viewed as attempts by the dreamer to work through emotional preoccupations, “fixations,” “hang-ups”   Evidence that dreams can be an effective way of working through emotional preoccupations, fixations, or “hang-ups”:  Patients with depression are more likely to be in remission a year later if:  They show high eye movement density and high affect strength during their first REM period They report more negative dreams at the beginning of the night and fewer negative dreams at the end of the night  This research suggests that negative dreams occurring at the end of the night are indicative of person’s failure to work through problems and self-regulate mood     These dreams can potentially be addressed in therapy, particularly as the last dreams of the night are those that a person is most likely to recall   Traumatic dreams (PTSD)  Repetition of the traumatic event in all its emotional detail and horror Dreams change over time as person recovers, incorporating other elements and becoming less like the exact experience Decline in traumatic dreams if dreams are discussed in groups (e.g., with other vets) Those who have recovered often suffer a relapse to the old dream content when faced with new stressors Traumatic dreams are about emotional events that people cannot resolve or “assimilate”    Recurrent Dreams and Nightmares #   Recurrent dreams  About 50% to 65% of college students report that they have experienced a recurrent dream Recurrent dreams are mostly unpleasant and may take the form of nightmares  There are usually only a few themes that make up most nightmares for most people Most frequent content theme of recurrent dreams is being attacked or chased   Recurrent dreamers tend to score significantly lower on measures of wellbeing than either former recurrent dreamers or non-recurrent dreamers Dream work as a way to resolve problem of recurrent dreams Recurrent dreams may be watered-down versions of traumatic dreams   Those who are prone to nightmares…  Often do not recall any obvious traumas Instead, they tend to be relatively normal people who work mainly as artists, teachers, and therapists \u0026ndash; tend to be creative and service oriented Usually extremely sensitive from childhood: open, vulnerable, with “thin boundaries” Research has also indicated that people with thin boundaries have dreams that are more vivid, detailed, and emotional than those with thick boundaries   Theory that nightmare sufferers are highly sensitive people for whom many everyday experiences are in effect highly traumatic  Repetitive Dream Themes #   We tend to think of dreams as irregular and infinitely varied, but this is not in fact true \u0026ndash; content analysis has revealed that dreams are much more repetitive than most people think…  Dorothea:  Kept dream journal from 1912 (when she was 25 years old) to 1963 Analysis revealed that same basic themes appeared throughout 50 years:  Eating or thinking of food appeared in 1 out of every 5 dreams Loss of an object, usually her purse, occurred in 1 out of every 6 dreams She was in a small or disorderly room, or her room was being invaded by others, in 10% of her dreams Mother appeared in another 10% of her dreams She was going to the toilet in 1 out of every 12 dreams She was late, concerned about being late, or missing a bus or train in 1 out of every 16 dreams   Six themes appeared in about 70% of her dreams   Jeffrey  Moved from one coast to the other, left his wife, “came out” as gay, and retired from his teaching position However, as in case of Dorothea, dream themes/elements tended to remain constant over 25 year period   Research has indicated that themes and emotions of dreams do not tend to change much over the course of a person’s life However, if person experiences period of profound change, dreams can change dramatically    Dream analysis #   Content analysis: systematic analysis of dream elements and themes  Analysis of dream elements in tens of thousands of dreams in countries across the world has allowed for the establishment of certain “norms”  Domhoff and his colleagues at the UC Santa Cruz have meticulously cataloged and posted more than 20,000 dreams (dreambank.net)       Cross-cultural differences  Americans tend to dream more about animals and food while Brazilians have more sexual and emotional dreams Far lower levels of physical aggression in dreams of Dutch men and women than among American men and women  Mirrored by the fact that the US is one of the most violent industrialized nation in the world and the Netherlands one of the least violent, according to crime statistics   Another study found the following rates of aggression in dreamers from different regions of the US:  East Coast: 40% Midwest: 10% West Coast: 22%        Most common dreams among college students \u0026ndash; percentage of students who have had each of following types of dreams:    Theme %     Falling 83%   Being attacked or pursued 77%   Trying repeatedly to do something 71%   Schools, teachers, studying 71%   Sexual experiences 66%   Arriving too late 64%   Eating 62%         Gender differences  Men tend to dream about sex and violence Women tend to dream more about weddings   Continuity hypothesis of dreams: “the dream life reflects the waking life”  People generally dream about the same people, places, objects, activities, wishes, and fears that dominate their waking-life    Psychoanalysis #   Content analysis and psychodynamic view of dreams  Frequency with which a particular dream character or dream activity appears reflects intensity of dreamer’s preoccupation with it \u0026ndash; dreams are a way of dealing with “emotional preoccupations,” “fixations,” or “unfinished business” That is why dreams are more often unpleasant than pleasant  8 in 10 dreams are marked by negative emotions     Barb Sanders  Content analysis of series of over 3000 dreams recorded between 1960’s (when she was a teenager) to late 1990’s Sanders married, had three children, got divorced, was involved in a series of relationships with different men, earned a Masters’ in a helping profession, worked in a community college setting, and became an actress and director in a local theater company \u0026ndash; but her dream themes for the most part did not change Characters and social interactions (these are usually the most psychologically revealing aspect of a detailed content analysis):  Mother  Appears in 7.7% of dreams \u0026ndash; more than any other character Percentage of aggressive to friendly encounters with her is 72% \u0026ndash; way above the national norm and her own baseline Sanders described her mother as “an angry, isolating person… sharp and critical and negative and physically distant”   Favorite brother  Percentage of aggressive to friendly interactions with him is 25% – almost the mirror opposite of her relationship with her mother     When you tend to have a good dream about someone, then you tend to have positive interactions with them; and vice-versa   Use of Content Analysis in Clinical Diagnosis  Analysis of 1,368 dreams from a four-year period reported by a man in his mid-thirties who was undergoing psychotherapy \u0026ndash; analyst (Calvin Hall) knew nothing about subject beyond his age and fact that he was seeing a therapist Repeated themes:  Wide range of sexual practices and objects Friendly and sexual interactions with children, with a greater focus on girls than boys Urinating and defecating Women with penises or beards, or who disguised themselves as men Various kinds of holes, openings, and tunnels, which the dreamer usually entered and explored in some way with great curiosity   Based on this analysis, Hall concluded that man had poor impulse control, confusion about gender, and a particular concern with the nature of female genitals (symbolic interpretation of holes and tunnels) \u0026ndash; and that he was a child molester whose primary desire was to look at the genitals of little girls All of these inferences proved correct according to the therapist and the dreamer Also, total lack of any reference to father in dreams, in contrast to a disproportionate number of dreams about his mother and sister  Led Hall to suspect either absence of a father or a traumatic experience with father To check for the latter, Hall searched for possible symbolic substitutes for father \u0026ndash; correctly concluded from following dream that the dreamer had himself been molested as a child by the father:  “A bull that seemed to have human intelligence came behind me and held me against him. I did not like his advances and I sensed that he wanted to have sexual relations with me. So I broke away from him.”\n       Dream work #   Basic technique:  Recall dream in as much detail as possible as soon as you awaken  To enhance dream recall, try not to move: stay in same position Try to fully recall emotions of the dream \u0026ndash; not the day ahead   Keep a scribble pad by your bed and take notes Interpret dream  In general, dream dictionaries are of limited value: we all have our own unique symbols Focus on emotional interpretation \u0026ndash; not academic interpretation (What did you feel in dream? Where do you feel like that in your life?)     \u0026ldquo;Dreams are all about emotions (activation of the limbic system)  In our dreams, we may access immensely positive emotions that we may never even have experienced before in waking life  Focusing on those emotions can potentially cause situations to manifest that naturally elicit those emotions      Extra: Jungian Dream Analysis #   Jung maintained that the figures in our dreams represent aspects of ourselves that we have disowned  Through projection, we see in others what we fail to see in ourselves These projections may be positive or negative Dream work allows us to own and integrate all of these various aspects   Jungian dream analysis involves analysis of archetypes (basic personality features) and symbols Archetypes:  Self: unites all other archetypes Persona: public image (mask) Shadow: aspects of ourselves (positive as well as negative) that we wish to deny Anima: our feminine aspect Animus: our masculine aspect   Symbols:  Animals: your own traits, good and bad  Dogs: symbol of the masculine Cats: symbol of the feminine   Vehicles: the direction you are heading in life and your body Chase: time for you to set out on your destined path, but you are refusing to let go of elements in your life that are hindering your quest Children: something new, different and joyous. May also represent innocent parts of yourself sometimes, and at other times, immaturity and childishness. Death: pertains to change. May also symbolize confronting fear, usually fear of death or change. Falling: fear of losing respect or status; or of financial difficulties, fading physical vitality, or losing someone\u0026rsquo;s love. House: represents you  Rooms: different aspects of yourself Doors: opportunities   Lost: you are lost in your life, adrift. Something is gone from your life - love, career, spirituality. Naked: inadequacy: you don\u0026rsquo;t feel prepared for some event, or for life itself. This dream may have an element of comedy - lighten up! Water  Calm water: good times ahead, clear sailing Rough waters: caution, reconsider your actions To drown can be a warning       Lucid dreaming #   Lucid dreams: dreams in which one is aware that one is dreaming and is thus able to direct the course of the dream Lucid dream practice originally derived from meditative traditions  The ultimate aim of dream yoga is not just to have fun controlling reality; rather, lucid dreams are brief, spontaneous realizations of the state of mind sought in meditation practice  These dreams involve a letting go of the ordinary sense of self and a bonding with the dream experiences themselves There is a “special” feeling of immediacy and vividness: everything becomes much more “real, clear, and somehow present” There is a sense of clarity and exhilaration that is based on a transformation of the way we normally attend to things and in our self-concept     Practice dream recall  Research has shown that people who recall dreams at least once a night report having at least one lucid dream a month Learn to recognize your most frequent or characteristic dreamsigns \u0026ndash; elements of dreams that indicate that you are dreaming (e.g., miraculous flight, purple cats, malfunctioning devices, and meeting deceased people)   Get ample sleep  The relative likelihood of lucid dreaming continuously increases with each successive REM period If you sleep 8 hours, the probability of your having a lucid dream during the last 2 hours of sleep is more than twice as great as the probability of your having a lucid dream in the previous 6 hours   Napping  Trick you can use if you can’t afford to spend 8 hours in bed: get up one hour earlier than usual, stay awake for 30 to 60 minutes, then go back to sleep During the wakeful period, read about lucid dreaming, practice reality checks and then do MILD as you are falling asleep Study found 15 to 20 times increased likelihood of lucid dreaming for those practicing the nap technique Test different sleeping positions   Practice reality testing throughout the day  Ask yourself “Am I dreaming?” and test your state… Tips on reality testing:  The pinch test doesn’t really work Try flying Find some writing or a digital watch and read it once, look away, then reread it, checking to see if it stays the same  In dreams, text changes 75% of the time it is re-read once; 95% of the time that it is re-read twice   Try to turn on a light \u0026ndash; this usually cannot be done in a dream In general, things are much more changeable in dreams than in waking life: oftentimes all you have to do is look around for unusual transmutations Lastly, anytime you find yourself seriously suspecting that you just might be dreaming you probably are      Induction techniques #   Use autosuggestion/dream inoculation  Imagine as vividly as possible that your surroundings are a dream During the day, think continuously that “all things are of the substance of dreams”   Strengthen desire/intention  Firmly resolve to recognize dreaming   Tell yourself, “Tonight I will have a lucid dream,” “Tonight I will fly” – particularly in the early morning hours or during an awakening in the latter part of your sleep period  Visualize yourself recognizing dreaming Imagine yourself carrying out an intended dream action Paul Tholey claims that most participants who consistently practice the reality testing and intention techniques will experience at least one lucid dream every night    MILD #   Mnemonic (mind) Induction of Lucid Dreams technique Preliminary training: prospective memory exercise  Look for certain pre-specified targets each day for at least a week and do a reality test as soon as you notice the target   When you awaken from a dream period, recall as many details as possible from your dream See yourself becoming lucid: Imagine that you are back in the dream from which you have just awakened, but this time you recognize that it is a dream Focus your intent: tell yourself “Next time I’m dreaming, I want to remember I’m dreaming” – and really mean it! Repeat procedure till you fall back asleep  LaBerge found that with autosuggestion, he had a lucid dream on only 1 out of 6 nights in the lab; with MILD, he had one or more lucid dreams on 20 out of 21 nights in the lab    Sleep paralysis #   Experience can be terrifying  Person feels they cannot move May feel like a great weight is holding them down; hallucinations may appear   Neurological explanation:  During REM, the voluntary muscles of the body are paralyzed Independent neural systems cause muscular paralysis, blockade of sensory input, and cortical activation – sometimes these don’t turn on or off at the same time, resulting in sleep paralysis Sometimes people panic when they experience sleep paralysis and struggle to move or to fully wake up, but such reactions are actually likely to stimulate the limbic areas of the brain and cause the REM to persist   Solution:  Remember it is a dream and therefore harmless Relax and adopt an attitude of interest and curiosity about what happens  Dreams that proceed from paralysis experiences are often quite intense and wonderful   About 20% of people who experience sleep paralysis say they really enjoy it because they\u0026rsquo;re able to enjoy it    Preventing Premature Awakening #   How to prevent premature awakening  Remain calm – relax and engage with the dream rather than withdrawing into your inner joy of accomplishment Look at the ground or at your hands: this may help stabilize dream Concentrate on the senses other than vision, such as hearing and touch (listening to voices or music, touching your body or an external object) Load the perceptual system so it cannot change its focus from the dream world to the waking world   Spinning technique  Spin like a top (or fall backwards) While spinning, remind yourself that the next thing you see will probably be a dream and do a reality test wherever you seem to arrive   The expectation of possible awakening often leads to a \u0026ldquo;false awakening\u0026rdquo; in which you dream of waking  Possible reason spinning technique works: it engages the vestibular and kinesthetic senses, discouraging the brain from changing state from dreaming to waking   Odds in favor of continuing the lucid dream:  After spinning, about 22 to 1 After hand rubbing (another technique designed to prevent awakening), about 13 to 1 After \u0026ldquo;going with the flow\u0026rdquo; (a \u0026ldquo;control\u0026rdquo; task) 1 to 2 To stay in a dream, create sensation of motion   If you do awaken, play dead  Remain perfectly motionless and deeply relax your body – there is a good chance that REM sleep will reassert itself and you will have an opportunity to enter a lucid dream consciously    Awakening at Will #   Yell – this directs your attention away from the dream and may actually activate vocal muscles of sleeping body  You can activate your vocal cords even when sleeping   Fixate your gaze on a stationary point: this will generally cause fixation point to blur, followed by dissolution of the entire dream scene and an awakening within 4 to 12 seconds  Q\u0026amp;A #   Q: Won’t all these efforts and exercises for becoming lucid lead to loss of sleep? And won’t I feel more tired after being awake in my dreams? A: Yes, lucid dream practices may result in some loss of sleep.  However, how tired you feel after a dream depends on what you did in the dream – if you battled endlessly with frustrating situations in a non-lucid dream, you probably will feel very tired afterwards On the other hand, a particularly exciting flight over a glamorous landscape can leave a person emotionally vitalized for several days: “I customarily wake [from a lucid dream] with a cheerful ‘afterglow’ that carries me through the day”  In general, people who find lucid dreams exhausting or unpleasant are not able to exercise much control over their dreams     Q: Might lucid dreaming be dangerous for some people? A: In general, for people who are not “neurotic beyond the bounds of normality,” it is completely harmless. Q: How long does it take to learn lucid dreaming? A: This varies a lot with the individual. It may take a few days to a few months to induce a first lucid dream with these practices. In general though, it will take years to get to the point where one is able to have lucid dreams at will.  Transforming nightmares #   You can resolve re-occurring nightmares by lucid dreaming and choosing to face the fear Lucid dream therapy (LDT)  Client is trained in progressive muscle relaxation, then rehearses recurrent dream in as much detail as possible Client selects a part of the recurrent dream that is emotionally and/or visually salient and during which he can imagine carrying out a particular task Client imagines performing this task (which can be as simple as looking at one’s hands) in the dream while saying that he is dreaming Later, during an actual dream, this action will cue that the experience is a dream Client is instructed to practice exercise at home just before going to sleep   Lucid dream therapy for treatment of nightmares may be particularly effective with children  Children tend to have spontaneous lucid dreams much more frequently than adults  Children who discover they can control their dreams never have to be told to go to bed!  “Bedtime became exciting because of this new world I had discovered where anything was possible and I was the Boss.”\n    Introduction to lucid dreaming can be a wonderful gift to give to a child    Other uses of lucid dreams #   Dream activities produce the same physiological effects as performance of those activities in the waking state  Thus, rehearsal of tasks can be effective in the dream state Also, lucid dreaming may potentially be useful for facilitating the functioning of the immune system and physical body generally  Ex: Woman suffering from inorgasmia was able to orgasm in lucid dream – and this permanently cured her disorder!   Same circuits activate when doing something while dreaming as doing that same something in real life    Inception #   What aspects of lucid dreams presented in the movie are real and what aspects are not? Real:  It can be very difficult to tell if one is dreaming or awake It is primarily emotions that create dreams  What characterizes REM/dream sleep neurologically is principally activation of the limbic system     Unreal:  Time does not speed up in dreams It is unclear that shared dreams can occur Lucid dreams do not tend to manifest as intense nightmares since by definition one is aware that it is only a dream and can exert at least minimal control over the dream    "},{"id":13,"href":"/e-29/4/","title":"Week 4: Additive Processes: Light-based, etc.","section":"Engineering 29","content":"Processes based on light-sensitive liquids #  Stereolithography (SLA) #   Also called Digital Light Printing (DLP) Thermoforming molds are most commonly made with stereolithography, i.e orthodontic aligners  Used because the molds need complete geometric customizability   A tray, bath or vat of a photo-sensitive liquid (a resin) is locally crosslinked (solidified) with a scanning laser beam or projected light pattern (i.e Photoinitiator), usually violet (~405 nm) or ultraviolet (~365 nm) Unwanted bonding can be avoided by making the base oxygen-permeable (e.g. by making it out of an elastomeric material, as in the Carbon 3D systems) since oxygen inhibits the photocrosslinking reaction and an oxygen-rich layer will form in the resin just above the permeable window because of air diffusing through the window   Covalent bonds form between the molecules in the liquid, forming a solid material (this reaction is called photocrosslinking)  Absorption of photons as they pass through the liquid limits crosslinking to a small layer (typically tens of μm thick) at a time   Parts are more isotropic (versus FDM), have almost matte finish Two machine design approaches:  Right: Light shines up through a window; part gradually drawn up out of a tray of resin  Requires more liquid   Projection Printing (below): Light shines down onto liquid surface; platform moves down into the vat as the part builds up  Printed object drawn upwards out of tray of resin Separation from tray: peeling or O2-inhibited dead layer            In older SLA configurations, the platform is submerged in the resin, the illumination comes in from above the resin surface, and the platform moves down into the resin bath after each layer was printed. Sometimes a mechanical ‘wiper’ is used to distribute a thin, uniform layer of uncured resin on top of the component before the next exposure step In new designs, the illumination is shone through a window in the bottom of the resin tray, and the platform moves upwards, pulling the object out of the tray as it prints.  This approach has the advantage of requiring a less deep resin tray, and eliminating the need for a wiper, but means that the machine designer must ensure that the resin does not bond to the window at the base of the resin tray.    Resin solidification in stereolithography #     Beer-Lambert model: Absorption of the illuminating light means that exposure dose .$E(z)$ (measured in W/m.$^2$) of the light is at its highest at the point where the light enters the resin, and decreases exponentially with depth below resin surface .$z$: $$E(z) = E_0 e^{-z/D_p}$$  This curve (a property of the dye/resin) follows a first-order exponential decay  This is common across most materials that absorb light; for each unit traveled by the photon, there\u0026rsquo;s a finite probability of getting absorbed. E.x. 10% of photos are absorbed in the first 10 microns, 10% of the remaining photons in the next 10 microns, etc.       A newer, potentially faster, approach for processes that rely on photocrosslinking is to expose each 2D layer in one single exposure step, rather than scanning a beam of light. The digital micromirror devices that are an integral component of modern video projectors can be used to pattern the photocrosslinking wavelength of light. Even with this layer-by-layer approach, there is still a need to Whether 3D printing will always involve this slicing approach is an open question. Since slicing often imparts anisotropic mechanical properties to printed components and limits their layer-to-layer strength, there may be a strong case for developing full 3D control over the material deposition process, so that, for example, the deposition head would move in the x, y and z directions simultaneously. Path planning to avoid collision between the machine and the component would be a significant challenge slice a 3D object into multiple 2D images.       .$D_p$ is the penetration depth, a resin property  The resin at a particular location will photocrosslink when the total illumination dose exceeds a critical value called the curing dose The depth into the resin at which the curing dose is reached is termed the curing depth   .$E$ is the dose: the time integral of power intensity over the layer time  Measured in J/m.$^2$ In projector-based systems, the source is .$E_0 = I_0\\ t_\\text{layer}$  .$I_0$ is the illumination irradiance/power intensity, which is proportional to the energy of the incoming particles per area W/m.$^2$   In laser-scanning systems, .$E_0$ is a function of illumination power intensity (W/m.$^2$), beam diameter w (m), and scanning speed, v (m/s):      Gelation just occurs at the curing depth, .$D_c$ where the resin receives the curing dose, .$E_c$: $$E_c = E_0 e^{-D_c/D_p} \\Longrightarrow D_c = D_p \\ln \\bigg( \\frac{E_0}{E_c} \\bigg)$$     Cured material may not be very strong at curing depth, so layers typically overlap in .$z$ direction to ensure material is all well-gelled    Thermal and light curing are done to finish these surfaces    Hydrodynamic stresses in dead zone #   This is the central rate-limiter in stereolithography Suction pressure forms around bottom of part  Proportional to the square of the part width     Thermal management for high print speeds #   Oil cools down print, enables meters per hours printing    SLA vs FDM #     Type Pros Cons     SLA Can reduce layer thickness to much smaller levels than FDM (see especially the Carbon 3D system which claims sub-micrometer layer thicknesses) Only a single resin material can be patterned per object    Can use digital micromirror devices to print an entire layer in one flash – potentially higher throughput than FDM Mechanical properties of photocrosslinkable resins lag behind those of FDM filaments    With thinner layers, can get more isotropic mechanical strength than in layered FDM    FDM Very wide range of printable filament materials now available, with specialist mechanical, thermal, optical, and electrical properties Anisotropic mechanical strength because of layered deposition – weaker layer-to-layer than within layers    Apparatus can be very affordable (a few hundred dollars in some cases) Surface roughness comparable to extruded filament diameter – cannot directly print shiny surfaces    Computed Axial Lithography #   CAL: Developed at Cal! A layer-free tomographic approach to photopatterning involving synthesis of 3D light dose Benefits: higher speed, the ability to print into more viscous materials, and the ability to avoid the use of solid supporting structures for delicate geometries. Enables a wider range of resin materials (notably higher viscosity resins) There a discrete number of layers, but then end up being \u0026lsquo;smeared\u0026rsquo; so they are relatively smooth         Poly Jet printing #   Also called ink-jet printing Used when a high degree of material heterogeneity is needed in a single object (e.g. in color, or mechanical stiffness) These have been commercialized, for example, by the company Stratasys with the brand name “PolyJet”   Inkjet-dispensed polymer inks are built up layer by layer and photocured (crosslinked). Layers down to ~16.$\\mu$ thick. Elastic modulus and color can be varied spatially by mixing inks A wide range of mechanical properties (including elastomers) are now possible  Rigid glassy polymers to soft rubber-like performance possible Note that these are “simulated” materials: the printed inks are photocured whereas the final production material may be, e.g., thermoplastic   Typical machines can carry about five different material cartridges at a given time, and can tune material properties by depositing finely interspersed patterns of droplets of these materials. Far more expensive than FDM or basic SLA tools. Electrically conductive materials are beginning to emerge    Available in Jacobs Hall:  Objet260 Connex3 Objet350 Connex3 Interchangeable ink cartridges   Soft, rubbery, tacky:  Tango range ~ few MPa Young’s Modulus   Rigid:  Vero (white, black, yellow, magenta, cyan, clear available) Digital ABS ~ few GPaYoung’s Modulus   Soluble support:  FullCure705 Remove by hand, water or NaOH solution         Powder/binder methods #  Selective laser Sintering (SLS) #   Use a heat source (usually a scanning laser beam) to sinter powders of the structural material directly, without a binder   Can be applied to thermoplastic polymers (esp. Nylon), metals, and even ceramics A thin layer of the powder is rolled across the printing bed, and then a laser is scanned across the layer, delivering enough heat that the powder particles melt only at their surfaces. Atoms or molecules at the contacting interfaces between particles diffuse faster in the elevated temperature and cause adjacent particles to connect to each other.  Powder particles are heated enough that surfaces melt\u0026ndash; atoms/molecules at their surfaces interdiffuse, bonding the particles.   Because the powder is not fully melted, parts usually retain some porosity  Can weaken the component compared to continuous bulk material The pores can serve as stress concentrators and promote crack propagation across the component The surface finish can be rough — the roughness is comparable to the metal particle size       Selective Laser Melting (SLM) #   Also called Direct Metal Laser or Directed Energy Deposition Laser (infrared light) actually melts the powder Removes porosity by melting the particles  Thermal gradients can be a problem   Computer generators now account for thees gradients and deformations  Changes pattern order and energy distribution   There has been a move away from metal SLS towards complete melting of the metal powder that is being fused.  Greater control of grain structure and lower porosity than with selective laser sintering Fully dense structures achievable   Scanning laser beam completely melts the powder during processing  No binders being employed but rather the structure of the component being built up directly from metal.   These processes may be layer-by-layer or, increasingly commonly, via a direct spray Isn\u0026rsquo;t feasibly monetarily right now    Examples of components #   3D printed gas turbine blades  Polycrystalline nickel superalloy Layer by layer powder fusion Survived 13,000 rpm at 1250 °C       Application: pressure sensor housing in General Electric jet engine compressor  Made using SLM Co-Cr alloy 19 of them in the GE LEAP engine Replaces a casting process Development time up to a year faster than using casting      Example of remanufacturing with SLM  Used when material is very expensive and not recyclable/reusable       Electron-beam melting #   Like SLM, produces fully dense parts Operates in vacuum to avoid metal oxidation and so that the electrons can follow a straight path without colliding with air molecules.  In contrast, SLM uses an inert gas atmosphere Vacuum allows higher temperatures to be used (\u0026gt; 800 K) Reduces oxidation and porosity due to adsorbed gases   Materials more limited than SLM  Examples: Ti grade 2, Ti6Al4V, Inconel 718, CoCrMo   Features down to a few micrometers are possible although printing times are slow compared with SLS or even SLM      Hybrid subtractive/additive manufacturing #   In the last few years hybrid machines have been demonstrated that combine a subtractive machining center (lathe, mill) with an additive capability The idea is to start with the smallest possible piece of stock material, deposit additional features of a component (e.g. flanges) additively on to that stock, and then machine back to the final shape, benefiting from the higher precision and surface finish of turning and milling. A machine made by DMG-Mori is now on the market and uses a metal spray together with a laser to deposit material, rather than a powder bed approach.   Powder-binder method #   One approach to printing objects from powders (which may include metal, polymer or ceramic powders) is to selectively dispense a binder (a sprayable ‘glue’, usually a polymer) on to layers of dry powder, holding the powder together in specific locations. After printing, the part is removed from the surrounding unbound loose powder. For polymeric parts, the binder can be colored and constitutes part of the final object. For metal or ceramic printing, the binder is subsequently be driven off (vaporized) with high heat after the whole part has been printed, and the powder is also sintered together by the heat (see below for explanation of sintering).\n      Polymer powder and deposited binder (may be colored). Left: schematic illustration of the threedimensional-printing process. Source: After E. Sachs and M. Cima. Can also be applied to binders with metal powders, which are later sintered/fused (Desktop Metal, Markforged…)  Emerging methods #   Directly fuse thermoplastic powders layer-by-layer Something like a 3D photocopier     Powdered materials #   Polymer powder production  Ball milling: grind below glass transition   Metal powder production  Solid-state reduction: crush ore, pass through furnace Atomization:rapidly freeze molten spray Electrolysis: deposition in powder form (e.g. Cu) Chemical, e.g. precipitation from solution   Size distributions typically Gaussian  SLM: typical average ~ 30 microns The more spherical, the more easily it flows Some powders more porous          Design for additive manufacturing #   Stretch-dominated lattices  e.g. octet truss structure One of the stiffest structures known Produced, e.g., by projection microstereolithography     Tuning material properties with structure #   Printed cellular structures can offer new classes of material    Current challenges with 3D printing #   Speed – for a single material and non-freeform geometry, machining is still probably quicker; injection molding is certainly faster Lower mechanical strength – directionality, porosity, surface flaws Surface finish – roughness often of many microns Resolution – from ~ 0.25 mm for basic FDM down to a few microns for SLA/SLS/SLM. Sub-micrometer resolution possible for two-photon SLA. Expense of input material – fine filaments, powders, inks: some proprietary consumables  Potential future applications of 3D printing #   Food? Clothes? Human organs? Houses? What are the challenges of 3D printing?  Intellectual property; forgery Difficulty of regulating production (e.g. of weapons; organs) Carbon footprint (energy input) of 3D-printed components vs traditionally manufactured components Overall will 3D printing create or destroy jobs?    "},{"id":14,"href":"/eecs-16a/4/","title":"Week 4: Vector Spaces \u0026 Eigenstuff","section":"EECS 16A","content":"02-15: Vector Spaces: Null Spaces and Columnspaces #    Slides Notes 7 8  Important Jargon #   Rank a matrix .$A$ is the number of linearly independent columns Nullspace of a matrix is the set of solutions to .$A \\vec x = 0$ A vector space is a set of vectors connected by two operators: .$+, \\times$ \u0026mdash; page 48 A vector subspace is a subset of vectors that have “nice properties” \u0026mdash; page 50 A basis for a vector space is a minimum set of vectors needed to represent all vectors in the space Dimension of a vector space is the number of basis vectors Column space is the span (range) of the columns of a matrix Row space is the span of the rows of a matrix   Vector Spaces #   A vector space .$\\mathbb{V}$ is a set of vectors and two operators .$+, \\cdot$ that satisfy:  Vector Addition\n Associative: .$\\vec u + (\\vec v + \\vec w) = (\\vec u + \\vec v) + \\vec w$ Commutative: .$\\vec u + \\vec v = \\vec v + \\vec u$ Additive Identity: There exists an additive identity .$\\vec 0 \\in \\mathbb{V}$ such that .$\\vec v + \\vec 0 = \\vec v$ Additive Inverse: There exists .$- \\vec v \\in \\mathbb{V}$ such that .$\\vec v + (-\\vec v) = \\vec 0$. We call .$-\\vec v$ the additive inverse of .$\\vec v$. Closure under vector addition: The sum .$\\vec v + \\vec u$ must also be in .$\\mathbb{V}$   Scalar Multiplication\n Associative: .$\\vec \\alpha(\\beta \\vec v) = (\\alpha \\beta) \\vec v$ Multiplicative Identity: There exists .$1 \\in \\mathbb{R}$ where .$1 \\cdot \\vec v = \\vec v$ Distributive in vector addition: .$\\alpha (\\vec u + \\vec v) = \\alpha \\vec u + \\alpha \\vec v$ Distributive in scalar addition: .$(\\alpha + \\beta)\\vec v = \\alpha \\vec v + \\beta \\vec v$ Closure under scalar multiplication: The product .$\\alpha \\vec v$ must also be in .$\\mathbb{V}$.    ... for any .$\\vec v, \\vec u, \\vec w \\in \\mathbb{V}; \\alpha, \\beta \\in \\mathbb{R}$   These can be grouped by axioms of closure, addition, and scaling shown on slide 10 For example .$ \\mathbb{R}^{n}$ is the vector space of all .$n$-dimensional vectors.  In fact, the set of all matrices the same size is also a vector space .$ \\mathbb{R}^{n \\times o}$ since it fulfills all of the properties above as well In this class we will generally only deal with vector spaces containing vectors in .$\\mathbb{R}^{n}$.    Subspaces #   A subspace .$\\mathbb{U}$ consists of a subset of .$\\mathbb{V}$ in vector space (.$\\mathbb{V}, \\mathbb{F}, +, \\cdot$). .$\\mathbb{U} \\subset \\mathbb{V}$ and have 3 properties  Contains .$\\vec 0 $, i.e., .$\\vec 0 \\in \\mathbb{U}$ Closed under vector addition: .$\\vec v_1, \\vec v_2 \\in \\mathbb{U} \\Longrightarrow \\vec v_1 + \\vec v_2 \\in \\mathbb{U}$ Closed under scalar multiplication: .$\\vec v \\in \\mathbb{U}, \\alpha \\in \\mathbb{F} \\Longrightarrow \\alpha \\vec v \\in \\mathbb{U}$   Examples on slide 13 Intuitively, a subspace is a closed subset of all the vectors in .$ \\mathbb{V}$.  Any linear combination of vectors in the subspace must also lie in that subspace.   Just as basis and dimension are defined for vector spaces, they have equivalent definitions for subspaces.  Basis for a Subspace: set of linearly independent vectors that span the subspace (minimal set of subspace-spanning vectors) Subspace Dimension: number of vectors in subspace-basis    Basis #   Basis: Given a vector space .$\\mathbb{V}$, a set of vectors .$\\{\\vec v_1, \\dots \\vec v_n\\}$ is a basis of the vector space if it satisfies the following properties:  .$\\vec v_1, \\dots, \\vec v_n$ are linearly independent vectors .$\\text{span}(\\{\\vec v_1, \\dots, \\vec v_n\\}) = \\mathbb{V} \\Longrightarrow \\forall \\vec v \\in \\mathbb{V}, \\exists \\alpha_1, \\dots, \\alpha_{n-1} \\in \\mathbb{R}$ such that .$\\vec v_1 = \\alpha_1 \\vec v_2 + \\dots \\alpha_{n-1} \\vec v_n$   Minimum set of vectors that spans a vector space\n  A basis of a vector space is the minimum set of vectors needed to represent all vectors in the vector space.  If a set of vectors is linearly dependent and “spans” the vector space, it is still not a basis \u0026ndash; we can remove at least one vector from the set and the resulting set will still span the vector space      Basis is not unique #   Intuitively, think about multiplying one of the vectors in a given basis by a nonzero scalar will not affect the linear independence or span of the vectors. We could alternatively construct another basis by replacing one of the vectors with the sum of itself and any other vector in the set. Mathematically, suppose that .$\\{\\vec v_1, \\dots, \\vec v_n \\}$ is a basis for the vector space we are considering.  Thus .$\\{\\alpha \\vec v_1, \\dots, \\vec v_n \\}$ where .$\\alpha \\neq 0$ is also a basis because, just as we’ve seen in Gaussian elimination row operations, multiplying a row by a nonzero constant does not change the linear independence or dependence of the rows.  We can generalize this to say that multiplying a vector by a nonzero scalar also does not change the linear independence of the set of vectors.   In addition, we know that .$\\text{span}(\\{ \\vec v_1, \\dots, \\vec v_n \\}) = \\text{span}( \\{\\alpha \\vec v_1, \\dots, \\vec v_n \\} )$  Any vector in .$\\text{span}(\\{ \\vec v_1, \\dots, \\vec v_n \\})$ can be created as a linear combination of the set .$\\text{span}(\\{ \\alpha \\vec v_1, \\dots, \\vec v_n \\})$ by dividing the scale factor on .$\\vec v_1$ by .$\\alpha$. We can use a similar argument to show that .$\\{\\alpha \\vec v_1, \\dots, \\vec v_n \\}$ is also a basis for the same vector space.     To generalize, for .$\\mathbb{R}^{N}$, any .$N$ (and only .$N$) linearly independent vectors form a basis\n   Dimension #   Dimension: The dimension of a vector space is the number of basis vectors. Since each basis vector can be scaled by one coefficient, the dimension of a space as the fewest number of parameters needed to describe an element or member of that space. The dimension can also be thought of as the degrees of freedom of your space \u0026ndash; that is, the number of parameters that can be varied when describing a member of that space.  A vector space can have many bases, but each basis must have the same number of vectors:\n Suppose a basis for the vector space we’re considering has .$n$ vectors. This means that the minimum number of vectors we can use to represent all vectors in the vector space is .$n$, because the vectors in the basis would not be linearly independent if the vector space could be represented with fewer vectors. Then we can show that any set with less than .$n$ vectors cannot be a basis because it does not have enough vectors to span the vector space \u0026ndash; there would be some vectors in the vector space that cannot be expressed as a linear combination of the vectors in the set. In addition, we can show that any set with more than .$n$ vectors must be linearly dependent and therefore cannot be a basis. Combining the two arguments, we have that any other set of vectors that forms a basis for the vector space must have exactly .$n$ vectors!     Column Space #   The range/span/column space of matrix .$A \\in \\mathbb{R}^{m \\times n}$ \u0026ndash; which we can represent as a set of vectors .$\\{ \\vec a_1, \\dots \\vec a_n \\}$ \u0026ndash; is a set of all possible linear combinations: $$\\text{span}\\big(\\{\\vec a_1, \\dots, \\vec a_n\\}\\big) = \\Bigg\\{\\sum_{i=1}^N \\alpha_i \\vec a_i\\ |\\ \\alpha_1, \\dots, \\alpha_n \\in \\mathbb{R} \\Bigg\\} = \\big\\{A \\vec x =\\ \\vec x \\in \\mathbb{R}^{n}\\big\\}$$  That is, the column space of a matrix .$A \\in \\mathbb{R}^{m \\times n}$ is the span of the .$n$ columns in .$A$ It\u0026rsquo;s the space of all outputs that the operator can map to.   Thinking about .$A$ as a linear transformation from .$ \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$, the column space is effectively the set of all outputs that this matrix can transform input vectors to Note that in the general case, input vectors and output vectors can be different lengths  The column space describes all possible output vectors .$\\vec b = \\mathbb{R}^{m \\times 1}$ It can be shown that .$\\text{span}(A)$ forms a subspace of .$ \\mathbb{R}^{m}$  Note that .$\\text{span}(A)$ is not necessarily .$ \\mathbb{R}^{m}$           Row Space #   Similarly, the row space is the span of the .$n$ rows  Rank #   The rank of .$A$ is defined as the dimension of the column space of .$A \\in \\mathbb{R}^{m \\times n}$  .$\\text{rank}(A) = \\text{dim(span(A))}$  .$\\text{dim(span}(A\\text{)) ≡ dim(col(}A))$ It’s all too easy to confuse an actual space consisting of vectors, like a matrix range describing the output (column) space, with the dimension of that space, which is just a single scalar number. Keep them straight!   .$ \\text{rank}(A) = \\text{dim(span}(A)) \\leq \\text{min}(m, n)$  This is at most .$m$, but certainly can be less, since an arbitrary .$A \\in \\mathbb{R}^{m \\times n}$ is not guaranteed to have columns whose span is all of .$ \\mathbb{R}^{m}$ Consider the simple counterexample of the zero matrix .$\\vec 0 \\in \\mathbb{R}^{m \\times n}$, which maps all .$n$-dimensional input vectors to the .$m$-dimensional all-zero vector.     In general, using the column-wise representation of matrix-vector multiplication we can show that .$\\text{rank(}A)$ is the number of linearly independent columns in .$A$.  Any output vector can be represented as a linear combination of the columns of .$A$. But some of these columns might themselves be linear combinations of other columns, which means we can replace any redundant column with a weighted sum of the other columns. By removing all redundancies, we find that a matrix with .$k \\leq \\text{min}(n, m)$ linearly independent column vectors can \u0026ldquo;unlock\u0026rdquo; exactly .$k$ dimensions in the output.   Thus, we find that .$\\text{rank}(A)$ also equals the number of pivots in the RREF of .$A$.  Since each pivot must belong to a row and a column, the number of pivots in .$A \\in \\mathbb{R}^{m \\times n}$ is limited by the smaller dimension. For a tall matrix .$m \u0026gt; n$, the columns are the limiting dimension; for a wide matrix .$n \u0026gt; m$ the rows are.    Null Space #   The null-space of .$ \\mathbb{R}^{m \\times n}$ is the set of all vectors .$\\vec x \\in \\mathbb{R}^{m}$ such that .$A\\vec x = 0$ $$\\text{null}(A) = \\big\\{\\vec x\\ |\\ A \\vec x = \\vec 0, \\vec x \\in \\mathbb{R}^{m}\\big\\}$$  That is, the set of all inputs that get mapped to .$\\vec 0$ by .$A$   $\\text{dim(null}(A))$ can be interpreted as the number of input directions for which the output is \u0026ldquo;compressed\u0026rdquo; down to zero.  We know that it can be at most .$m$, since all of the input vectors have .$m$ components. It\u0026rsquo;s the set of vectors not in columns space, that is, the number of linearly dependent columns: $$m - \\text{dim(span}(A)) = \\text{dim(null}(A))$$  The loss of dimensionality from the input space to the output space shows up in the nullspace.     .$\\vec 0$ is always in the null space — trivial Null space  This wouldn\u0026rsquo;t hold if we had affine (instead of linear) functions   Null space DNE when the determinant is not zero \u0026ndash; see last week       Procedure to Compute a Null-Space #   Computing the nullspace of .$A$ requires us to solve .$A \\vec x = \\vec 0$ \u0026ndash; the procedure is as follows:  Put .$A$ in RREF. Initialize the set .$\\mathbb{S} = \\{ \\vec 0 \\}$. Check each column for leading entries and find the number of .$F$ree and .$B$asic variables. if .$F = 0$, stop and skip to the last step. if .$F \\neq 0$, repeat the following for each free variable:  Set that free variable to .$1$, and all others to zero. Solve .$A \\vec x$ under these conditions; add the solution vector to .$\\mathbb{S}$.   Conclude that .$\\text{null}(A) = \\text{span}(\\mathbb{S})$.   Example is given on page 37-38    Rank-Nullity Theorem #   How is the number of free variables related to the total number of columns in a matrix .$A \\in \\mathbb{R}^{m \\times n}$? Well, each column of a matrix either contributes a \u0026ldquo;new direction\u0026rdquo; to the output or it is redundant with other columns and their already-discovered directions. In other words, each of .$n$ columns adds a dimension to .$\\text{span}(A)$ or to .$\\text{null}(A)$. Therefore, the following holds: $$\\text{dim(span}(A)) + \\text{dim(null}(A)) = n$$ $$\\text{rank}(A) + \\text{dim(null}(A)) = n$$\n 02-17: Eigenvectors, values #  Eigenvectors and Eigenvalues #   Consider a square matrix .$ A \\in \\mathbb{R}^{n \\times n}$. An eigenvector of .$A$ is a nonzero vector .$\\vec x \\in \\mathbb{R}^{n}$ such that $$A \\vec x = \\lambda \\vec x$$ where .$\\lambda$ is a scalar value, called the eigenvalue of .$\\vec x$.\n       That is, an eigenvector represents a sort of stability point: vectors aligned with an eigenvector will not change direction under a linear transformation .$A$  Rather, they will simply be scaled by some factor. Note that eigenvectors are a property of the matrix itself and do not depend on the specific vector being transformed (input)   The eigenvalue describes this stretching or compressing factor for vectors aligned with an eigenvector  This means any vector that’s \u0026lsquo;some\u0026rsquo; multiple of the eigenvector, when it’s transformed by .$A$, will become a scaled version of itself that\u0026rsquo;s a \u0026lsquo;some\u0026rsquo; multiple of the eigenvalue Example on page 45   Geometrically, an eigenvector, corresponding to a real nonzero eigenvalue, points in a direction in which it is stretched by the transformation and the eigenvalue is the factor by which it is stretched Because these two terms are so commonly used in conjunction, we often refer to an eigen(value/vector) pair  Note that scaling a given eigenvector for an eigenvalue will still produce a valid eigenvector, since the vector’s direction will not be changed   Given non-invertible .$A \\in \\mathbb{R}^{n \\times n}$ there are at least .$1$ and at most .$n$ eigenvalues  Given non-invertibility, some .$\\lambda_i = 0$, so we have at least 1 eigenvalue.  Indeed, all eigenvalues can be .$0$ (such as for .$\\vec 0$)!   However, non-invertibility does not place any other restrictions on our set of eigenvalues, so all other .$n-1$ eigenvalues can be distinct from this .$\\lambda_i$   Properties to know  A matrix is uninvertible iff .$0$ is an eigenvalue (because there exists a vector .$\\vec v$ such that .$A \\vec v = \\vec 0$. A scalar times an eigenvector is still an eigenvector: .$(A(c \\vec v) = c A \\vec v = c \\vec v = (c \\vec v))$ Eigenvectors with distinct eigenvalues are linearly independent (eigenvectors in the same span have the same eigenvalue) .$A^{-1} \\vec v = \\lambda^{-1} \\vec v$  .$A \\vec v = \\lambda \\vec v \\Longrightarrow A^{-1} A \\vec v = A^{-1} \\lambda \\vec v \\Longrightarrow \\vec v = \\lambda A^{-1} \\vec v \\Longrightarrow \\lambda^{-1} \\vec v = A^{-1} \\vec v$      Determinants #   The determinant is a quantity we can define for any square matrix  The determinant is nonzero if and only if the matrix is invertible and the linear map represented by the matrix is an isomorphism   For a .$2 \\times 2$ matrix, the formula is:  The absolute value of .$ad − bc$ is the area of the parallelogram, and thus represents the scale factor by which areas are transformed by .$A$.   $$\\text{det}\\Bigg( \\begin{bmatrix} a \u0026amp; b \\\\ c \u0026amp; d \\\\ \\end{bmatrix}\\Bigg) = ad - bc$$    If linearly dependent, some vectors will lie on top of each other so the area will be zero Similarly in 3D, if any column vectors are multiples of each other, we \u0026ldquo;squash\u0026rdquo; a volume into a plane or a line. That is, determinant of any square matrix is zero if the columns are linearly dependent.   For a .$3 \\times 3$ matrix, the shape is a parallelipiped, and we form hyper-volumes in higher dimensions.  We can calculate determinants for higher dimension matrices as well, as described here   The determinant of the transpose of .$A$ equals the determinant of .$A$: .$\\text{det}(A) = \\text{det}(A^\\text{T})$  \u0026lsquo;Proving\u0026rsquo; this geometrically on a whiteboard is fun, try out the .$2 \\times 2$ case Therefore, if .$A^\\text{T}$ has an eigenvalue .$\\lambda$, then .$A$ also has the eigenvalue .$\\lambda$ because .$\\text{det}(A - \\lambda I) = \\text{det}(A^\\text{T} - \\lambda I)$ This implies that in all the properties mentioned above, the word \u0026ldquo;column\u0026rdquo; can be replaced by \u0026ldquo;row\u0026rdquo; throughout  For example, viewing an .$n \\times n$ matrix as being composed of .$n$ rows, the determinant is an .$n$-linear function.   See this article which relies on the idea of elementary matrices (not covered) or this more advanced, out-of-scope stackoverflow post that deals with 16B-level topics (and beyond)    Computing Eigenvalues and Eigenvectors #     Solving this equation for nonzero (nontrivial) solutions .$\\vec x$ will yield our eigenvectors: $$A \\vec x = \\lambda \\vec x \\label{a}\\tag{1}$$  $$\\Longrightarrow (A - \\lambda I_n) \\vec x = \\vec 0_n$$  $$\\Longrightarrow A\u0026rsquo; \\vec x = \\vec 0_n$$    Note that .$A$ and .$I_n$ are fixed and only 1 parameter here that can vary in this equation: .$\\lambda$     We want to find values of .$\\lambda$ such that .$A\u0026rsquo; = (A − \\lambda I_n)$ has linearly dependent columns That is, we want to find values of .$\\lambda$ that cause the determinant of .$A\u0026rsquo;$ to become zero  Linear dependence of the columns creates a nontrivial null-space for .$A'$ .$N$th order characteristic polynomial with .$N$ solutions   Work-through on page 6   $$A\u0026rsquo; = \\begin{bmatrix} a_{11} - \\lambda \u0026amp; a_{12} \u0026amp; \u0026hellip; \u0026amp; a_{1n}\\\\ a_{21} \u0026amp; a_{22} - \\lambda \u0026amp; \u0026hellip; \u0026amp; \\vdots \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots\\\\ a_{n1} \u0026amp; \\dots \u0026amp; \u0026hellip; \u0026amp; a_{nn} - \\lambda \\end{bmatrix}$$    For the .$2 \\times 2$ case determinant is $$\\lambda^2 - (a+d)\\lambda + (ad - bc) = 0$$  Solving this quadratic equation, we can find the .$\\lambda$ values. Then, for each .$\\lambda_i$ we find, we revisit .$\\eqref{a}$ and solve for the corresponding .$\\vec x_i$ The polynomial on the left hand side of the above equation is known as the characteristic polynomial for the matrix .$A$.   If a matrix has repeated eigenvalues, they may (or may not) have distinct eigenvectors.  In general, multiplicity of eigenvalues will result in the same multidimensional eigenspace (Aside) \u0026hellip;except if the matrix is defective  An .$n \\times n$ matrix is defective iff it does not have .$n$ linearly independent eigenvectors That is, a defective matrix always has fewer than .$n$ distinct eigenvalues, since distinct eigenvalues always have linearly independent eigenvectors In which case the rank is decreased      Eigenspace #   If the eigenvectors are distinct, they form an  eigenspace $$E_\\lambda = \\text{null}(A - \\lambda I_n) = \\text{null}(A\u0026rsquo;)$$\n  That is, null space of some matrix is the set of all vectors that satisfy .$\\eqref{a}$ OR all of the eigenvectors that correspond to some eigenvalue OR the eigenspace that corresponds to the eigenvalue Exactly like the concept of span; the eigenspace is a subspace, the span of all eigenvectors for that eigenvalue (including .$\\vec 0$) Any input vectors that lie in this space (for 2 distinct eigenvectors, a plane; for 1, a line) will be scaled by the shared eigenvalue under a linear transformation. Eigenspace is a subspace, which means it\u0026rsquo;s closed under scalar multiplication  Thus, if two vectors are related by a scalar, they must both lie in the same eigenspace of .$\\lambda_i$: .$E_{\\lambda_i}$  That is, the eigenvectors that make up some eigenspace aren\u0026rsquo;t unique   But, every eigenvector can only correspond to one eigenvalue  If for some .$A$, where .$A \\vec x_1 = \\lambda_1 \\vec x_1$ and .$A \\vec x_1 = \\lambda_2 \\vec x_1$ then .$\\lambda_1 = \\lambda_2$ Thinking about a physical diagram may help clarify; .$\\lambda_1 \\neq \\lambda_2$ would require some single initial state or vector aligned with .$\\vec x_1$ to be scaled by two different values upon being transformed by .$A$  This cannot happen, so the two eigenvalues cannot be distinct       Aside: Complex eigenvalues can exist as well; they are much harder to visually understand, but mathematically, we find them using the exact same process as before.  Mean-product formula #     Mean-product formula is a nicer way of solving this, versus finding the roots of the polynomial $$m \\pm \\sqrt{m^2 - p}$$  $m$ is the mean of the trace, which is the same as the mean of the eigenvalues $p$ is the product of the eigenvalues, which is the determinant    Theorems #  Theorem 9.1 #   Given two eigenvectors .$\\vec v_1$ and .$\\vec v_2$ corresponding to two different eigenvalues .$\\lambda_1$ and .$\\lambda_2$ of a matrix .$A$, it is always the case that .$\\vec v_1$ and .$\\vec v_2$ are linearly independent.\n  Proof on page 9  Theorem 9.2 #   Let .$\\vec v_1,\\vec v_2, \\dots , \\vec v_m$ be eigenvectors of an .$n \\times n$ matrix with distinct eigenvalues. It is the case that all the .$\\vec v_i$ are linearly independent from one another.\n  Proof on page 10  Proposition 1 #   If an square .$n \\times n$ matrix .$A$ isn\u0026rsquo;t invertible, then it has some eigenvalue .$\\lambda_i = 0$\n  If a matrix is not invertible, then the dimension of its null space isn\u0026rsquo;t necessarily greater than 0 because there must be a linearly dependent row or column. If this is true, then there\u0026rsquo;s a non-zero vector .$\\vec x$ such that .$A \\vec x = 0 \\vec x$    If the matrix is not invertible, it has a nontrivial null-space. Then, by definition, there is some nonzero .$\\vec x$ for which .$A \\vec x = 0 \\vec x = \\vec 0_n$. We pattern match to .$\\eqref{a}$ and notice the equation is exactly the same if we multiply the right by .$\\vec x: A \\vec x = 0 \\vec x$.  This is kind of like pulling a scalar .$0$ out of .$\\vec 0$, leaving .$0 \\vec x$.   Now, we clearly see .$\\lambda = 0$  Proposition 2 #   For an invertible .$A$ with some eigenvalue .$\\lambda$, .$A^{−1}$ has eigenvalue .$ \\frac{1}{\\lambda}$\n  We can start at .$\\eqref{a}$: left-multiply both sides by .$A^{−1}$ to get .$\\vec v = A^{-1} \\lambda \\vec v \\Longrightarrow A^{-1} \\vec v = \\frac{1}{\\lambda} \\vec v$. Pattern match to .$\\eqref{a}$ again and we’ve shown the statement is true Note: Given invertibility, all .$\\lambda_i \\neq 0$ so this is always true  States #  Steady States #   We know that a steady state .$\\vec x^*$ of a transformation matrix .$A$ is defined to be such $$A \\vec x^* = \\vec x^* $$  In other words, it is an element of the eigenspace of .$A$ corresponding to the eigenvalue .$\\lambda = 1$. The above equation tells us that if we start at a steady state, then we will remain unaffected by the transformation matrix over time. Therefore, to solve for the steady-state of a system represented by .$P$, we solve .$\\eqref{a}$, substituting .$\\lambda = 1$  Note that this amounts to solving for the null-space of .$(P − I_n)$.     Great walk-through on page 53  Predicting Behavior for General Initial States #   Given a system and an initial state, can we predict how it’ll dynamically change over time? We saw in the Page Rank example that we seem to approach a sort of steady-state after many timesteps, but under what conditions does this happen?\n Simpler Case: .$\\vec x (0) = \\alpha \\vec v$ #   Suppose our initial state is actually a perfect multiple of an eigenvector of the system. Over time, upon repeated applications of .$A,$ we accumulate factors of .$\\lambda$; ultimately, .$A^n \\vec x = \\alpha (\\lambda^n \\vec x)$ \u0026ndash; as we can see derived to the right   $$\\vec x (0) = \\alpha \\vec v$$ $$\\vec x (1) = A\\vec x (0) = \\alpha \\lambda \\vec v$$ $$\\vec x (2) = A\\vec x (1) = \\alpha \\lambda^2 \\vec v$$ $$\\vdots$$ $$\\vec x (n) = A\\vec x (n-1) = \\alpha \\lambda^n \\vec v$$    Based on this pattern, we notice the following behaviors based on the value .$\\lambda$ as .$n \\to \\infty$:  .$\\lambda \u0026gt; 1: \\vec x (n) \\to \\infty$ \u0026ndash; Diverge, exponential growth. .$\\lambda = 1: \\vec x (n) \\to k\\vec v$ \u0026ndash; Converge, steady-state. .$0 \u0026lt; \\lambda \u0026lt; 1: \\vec x (n) \\to \\vec 0$ \u0026ndash; Converge, exponential decay. .$\\lambda = 0: \\vec x (n) = 0 \\vec v = \\vec 0$ \u0026ndash; Converge(?), instantaneous disappearance. .$\\lambda \u0026lt; 0$: Take .$|\\lambda|$ and refer to the appropriate case above. But recognize the sign switches at each timestep    General Case: .$x(0) = \\alpha_1 \\vec v_1 + \\alpha_2 \\vec v_2 + . . . + \\alpha_n \\vec v_n$ #   This form says that the initial state is now not a scalar multiple of just one eigenvectors, it’s a linear combination of all of them  Note that this is still not fully general; we assume here that all initial states are in the span of the eigenvectors of .$A$, which isn’t guaranteed.   But this case devolves into the previous one; we can simply treat each element individually, apply the techniques from the Simpler Case, and put them back together. The final form is as follows: $$\\vec x (n) = \\alpha_1 (\\lambda_1^n \\vec v_1) + \\alpha_2 (\\lambda_2^n \\vec v_2) + . . . + \\alpha_n (\\lambda_n^n \\vec v_n) \\label{b}\\tag{2}$$ Given a matrix .$A$ and some initial state .$\\vec x$, how can we actually get to this equation format?   First, we solve for the .$(\\vec v_i, \\lambda_i)$ pairs of .$A$   Then, we use Gaussian elimination to find the .$\\alpha_i$’s; Putting eq. .$ \\eqref{b}$ in matrix form yields:\n  \u0026hellip;and we compute the inverse of the matrix of eigenvectors, arriving at:\n   $$\\vec x(0) = \\begin{bmatrix} | \u0026amp; | \u0026amp; \u0026amp; | \\\\ \\vec v_1 \u0026amp; \\vec v_2 \u0026amp; \\dots \u0026amp; \\vec v_n\\\\ | \u0026amp; | \u0026amp; \u0026amp; | \\\\ \\end{bmatrix}\\begin{bmatrix} \\alpha_1 \\\\ \\alpha_2 \\\\ \\vdots \\\\ \\alpha_n \\\\ \\end{bmatrix}$$\n$$\\begin{bmatrix} \\alpha_1 \\\\ \\alpha_2 \\\\ \\vdots \\\\ \\alpha_n \\\\ \\end{bmatrix} = \\begin{bmatrix} | \u0026amp; | \u0026amp; \u0026amp; | \\\\ \\vec v_1 \u0026amp; \\vec v_2 \u0026amp; \\dots \u0026amp; \\vec v_n\\\\ | \u0026amp; | \u0026amp; \u0026amp; | \\\\ \\end{bmatrix}^{-1} \\vec x (0)$$\n   Let’s assume that we drop any terms corresponding to .$\\alpha_i = 0$ since those terms are, well, zero. Then, with what remains, we can make some intuitive observations:  .$|\\lambda_i | \u0026gt; 1: \\vec x (n) \\to \\infty$ \u0026ndash; Diverge, even if other components in the linear combination decay, the state itself \u0026ldquo;blows up\u0026rdquo; to .$\\infty$ as this component overshadows all others. .$|\\lambda_i| = −1: \\vec x (n) \\to\\ ?$ \u0026ndash; Diverge because that component oscillates forever. .$−1 \u0026lt; \\lambda_i \\leq 1: \\vec x (n) \\to \\vec x^*$ \u0026ndash; Converge, that is, steady-state! Each .$i$th term either decays to zero (.$|\\lambda_i| \\leq 1$) or stays the same (.$|\\lambda_i| = 1$), such that .$\\vec x^* = \\sum_{i,\\lambda_i=1} \\alpha_i \\vec v_i$.  We can normalize this steady-state if we want proportions (column values sum to 1) rather than absolute numbers        Some Useful Information #   If a matrix has .$n$ distinct real eigenvalues, their .$n$ associated eigenvectors are all linearly independent. An eigenspace for a given eigenvalue is the span of all eigenvectors, including .$\\vec 0$, and is also a subspace by definition. Say we calculate an eigenvector for an eigenvalue; we can pick any scalar multiple of the result and this will still be an eigenvector, since scaling a vector does not change its direction. This follows from the scalar multiplication property of subspaces. A given eigenvector can only be associated with one eigenvalue, since a vector can only be scaled by some single value upon being transformed by a matrix. But, a eigenvalue can be associated with multiple eigenvectors, the span of which form an eigenspace. If a matrix has some .$\\lambda = 0$, then for some .$\\vec x, A\\vec x = \\lambda\\vec x =\\vec 0$, so .$A$ has a nontrivial null-space. Therefore, it is not invertible. If a matrix has some .$\\lambda = 1$, then any initial state that is aligned with the corresponding eigenvector is a steady-state. More generally, any initial state for which .$\\lambda = 1$ comprises part of the linear combination potentially has a nonzero steady-state, so long as all other .$|\\lambda_i| \u0026lt; 1$.   The rotation matrix (that rotates any vector by .$\\theta$ degrees counterclockwise) is:   $$A(\\theta) = A_R = \\begin{bmatrix} \\cos\\theta \u0026amp; -\\sin\\theta \\\\ \\sin\\theta \u0026amp; \\cos\\theta \\\\ \\end{bmatrix}$$   "},{"id":15,"href":"/cogsci-c100/consciousness/","title":"Consciousness","section":"CogSci C100","content":"The mind-brain problem: What is mind? #   The nature of the mind-body or mind-brain connection was a philosophical question of importance in the early days of cognitive science  What is mind? Is it something that is physical? Is a body necessary to have a mind? We don\u0026rsquo;t talk too much about philosophy since it\u0026rsquo;s inherently not empirical / verifiable  It\u0026rsquo;s all that was possible 50 years ago Now we have neuroscience!      Different viewpoints #  Monism: #   There is only one kind of substance in the universe\n  Idealism: Everything – including the material world – is actually mind Materialism: Everything that exists – including mind – is physical  In some fundamental sense, the mind just is the brain, so that everything that happens in the mind is happening in the brain Aristotle: The brain is like a lump of clay; the different thoughts the mind can take on when it undergoes different patterns of activity are like the shapes the clay can assume Most cognitive scientists hold this view    Dualism: #   Belief in the existence of both mental (e.g., “soul”) and physical substances\n  The mind and brain are two separate and distinct things  Religious viewpoint   Few cognitive scientists are dualists  Functionalism: #   What makes something a thought, desire, pain (or any other type of mental state) is solely its function, or the role it plays, in the cognitive system of which it is a part More specifically, the identity of a mental state is said to be determined by its causal relations to sensory stimulations, other mental states, and behavior Ex: pain as a state that tends to be caused by bodily injury; to produce the belief that something is wrong with the body and desire to be out of that state; to produce anxiety  Suppose that, in humans, there is some distinctive kind of neural activity (e.g., C-fiber stimulation) that meets these conditions, then humans can be in pain simply by undergoing C-fiber stimulation However, theory permits creatures with very different physical constitutions to have mental states as well, e.g., silicon-based states of hypothetical Martians It is also logically possible for non-physical substrates to give rise to mental states, e.g., some sort of energy field  Functionalism is actually officially neutral between materialism and dualism, but it tends to be associated today with materialism, and specifically, the view that each type of mental state is identical with a particular type of neural state  This type of “species-chauvinism” is a modern phenomenon due in large to an increased emphasis on neuroscience in the last 25 years        Intelligence And The Physical Symbol System (PSS) Hypothesis #   One of central ideas of philosophy of artificial intelligence Proposed in 1975 by computer scientists Herbert Simon and Allen Newell Holds that all intelligent behavior essentially involves transforming physical symbols according to rules  GEB Ch 1-3 ++         A physical symbol system is basically an abstract characterization of a digital computer   Statement of hypothesis: A physical symbol system has the necessary and sufficient means for general intelligent action\n  Implications:  Anything capable of intelligent action is a physical symbol system  Since humans are capable of intelligent action, the human mind must be a physical symbol system   Since a physical symbol system is sufficient for intelligence, machines can be constructed that are intelligent     John Searle’s Chinese Room #     Imagine a person who does not understand Chinese in a closed room Person receives pieces of paper through one window and passes out pieces of paper through another window The pieces of paper have symbols in Chinese written on them In the room is a huge instruction manual that tells the person in the room which pieces of paper to pass out depending on which pieces of paper he receives To all intents and purposes, the person in the room is responding in Chinese But he does not in fact understand Chinese   So what does it really mean to “understand” something, to be fully “conscious”?\n   Tries to show that the physical symbol system hypothesis is completely mistaken Describes a situation in which symbols are manipulated to produce exactly the right outputs, but where there seems to be no genuine understanding and no genuine intelligence Searle also thinks that the Chinese room argument reveals a fundamental problem with the so-called Turing Test\u0026hellip;  Turing test #   Proposed by Alan Turing in 1950 as a criterion for whether a machine is displaying real intelligence If an observer is communicating with a machine and cannot tell the difference between it and a human being, then that would show that the computer was genuinely intelligent   Participants: Human interrogator (judge), one human responder, and one “machine” responder Neutral communication: No visibility or other clues (e.g., all three are responding through computer terminals, so no handwriting or “voice” clues) Interrogation: The interrogator asks the other agents (human and machine) a series of questions       Resolution: After a fixed time interval the interrogator tries to decide which is the “human” participant  Rebuttal to the Chinese room argument #   Rebuttal says that\u0026hellip;  The Chinese room does not understand Chinese, but only because it is disembodied The ability to understand Chinese involves, at a minimum, being able to carry out instructions given in Chinese, to coordinate with other Chinese speakers, and to carry on a conversation In order to build a machine that could do all this, we would need to embed the Chinese room in a robot, providing it with some analog of sensory organs, vocal apparatus, and limbs Then the system could be said to understand Chinese and behave intelligently   Searle’s response to robot reply  The basic problem still remains: simply manipulating symbols cannot create meaning There must be more to genuine thinking than simply manipulating symbols according to rules Aside: Does Google Translate understand Language?  Not really. We just feed it enough data such that it can make fairly-accurate predictions. It doesn\u0026rsquo;t understand language in that it can\u0026rsquo;t distinguish the meaning. So can some system, given enough resources (power, time, information, etc)? Then again, humans wouldn\u0026rsquo;t understand an Alien language\u0026hellip; we still have un-deciphered languages written by humans!      What is consciousness? #   Consciousness is generally defined in psychology as “awareness of our environment and our perceptions, images, and feelings” However, exactly what consciousness is is perhaps the most hotly debated issue in the modern philosophy of mind  What is consciousness? Does it exist in all creatures? Is there some part of the brain or some particular pattern of neural activity that gives rise to consciousness?   Some philosophers, like John Searle, have argued that consciousness is an emergent property of a physical brain  That is, it may not be fully explained by an understanding of its component parts   More recently, neurologists have also jumped into this debate\u0026hellip;  Neural correlates of consciousness #   Neuroscientists generally hold that consciousness results from the coordinated activity of a population of neurons But which neurons? What exactly are the neural correlates of consciousness (NCC), i.e., the minimal set of neural events sufficient for a specific conscious experience? (Christof Koch) Currently, there are two main theories:  Global Neuronal Workspace Theory (Baars, Dehaene \u0026amp; Changeux) Integrated Information Theory (Guilio Tononi)    Global Neuronal Workspace Theory #    Global workspace theory: Explains how information is made accessible for high-level cognition, action, and speech\n When we are conscious of something, many different parts of our brain have access to that information  E.x. the language/motor/planning module will all have access to this information   When we act unconsciously, that information is localized to the specific sensory motor system involved  Ex: When you type fast, you do so with little conscious awareness, so that, if asked how you do it, you would not know  Information is localized in brain circuits linking your eyes to rapid finger movements The modules don\u0026rsquo;t know the meaning of the information given to them (they\u0026rsquo;re unconscious) Low level, implies that this is subconscious       Global workspace theory maintains that consciousness forms when specialized programs or modules access a shared repository of information or “blackboard”  Data written onto this blackboard becomes available to a host of subsidiary processes, such as working memory, language, the planning module, etc.         Consciousness emerges when incoming sensory information, inscribed onto the blackboard, is broadcast globally to multiple cognitive systems    Global Neuronal Workspace (GNW) Theory #   Evolved from global workspace theory The network of neurons that broadcasts messages widely (as described in previous slide) is hypothesized to be located in the frontal and parietal lobes   Theory proposes a distributed network of high-level processors, most likely in the prefrontal, parieto-temporal, and cingulate cortices Because the blackboard has limited space, we can only be aware of a little information at any given instant  Attention makes low-level modular information available for conscious control in the global workspace   filter model of attention     Once that information is broadcast on the network and is globally available, it becomes conscious      Cortical regions important in consciousness #  Frontal and parietal #   Evidence that network of neurons that broadcast messages widely is located in the frontal and parietal lobes: Various types of nonconscious processing are associated with deficits in these areas, including\u0026hellip;.  1. Hypnosis #   Hypnosis is associated with  Decreased activity in the dorsal anterior cingulate  When hypnotized, you are in a state so absorbed in listening that one is not thinking about anything else No selective attention       #    2. Reduced connections between the dorsolateral prefrontal cortex (motor actions) and the default mode network (awareness of one’s actions), which includes the medial prefrontal and the posterior cingulate cortex \u0026ndash; why you do not recall being hypnotized\n2. Repression and dissociation #   Repressed memories  Recovered memories of child abuse   Dissociative identity disorder (multiple personality)  Condition in which two or more identities or personalities alternate in control of a person’s behavior  One personality can be diabetic, near-sighted, or allergic to a substance and the other not The two personalities can have different brain waves, vital signs and hormonal levels   Some personalities are aware of the other personalities   Research indicates that in repression/dissociation, the prefrontal cortex (executive control) disengages processing in the hippocampus (memory)  Participants asked to memorize word pairs, e.g., ordeal-roach or steam-train  Respond condition: Participants were shown cue word and asked to recall the matched word Suppress condition: Participants were shown cue word and asked to actively suppress the matched word  Word suppression was associated with activation of prefrontal cortex to disengage processing in hippocampus Suppressing matched word reduced later recall of word     Takeaway: Brain is actually more active when avoiding recalling a memory than during recall itself - Perhaps why mindfulness is impactful\n     3. Lucid dreaming #   Whereas dreams are unconscious, lucid dreams are conscious Lucid dreaming: Neuroimaging data is scant but preliminary results suggest that prefrontal and parietal regions are also involved in lucid dreaming  Currently, there is only one fMRI study contrasting lucid and non-lucid REM sleep and it is a case study (Dresler, Wehrle, Spoormaker et al., 2012)  Few people who can lucid dream at will =\u0026gt; few potential subjects   Interestingly though, the results of this study converge with MRI studies that have evaluated individual differences in lucid dreaming frequency (Baird, Castelnovo, Gosseries et al., 2018)     Compared to non-lucid REM sleep, lucid REM sleep is associated with increased activity in  Prefrontal cortex (metacognition and self-reflection) Parietal cortex and the precuneus (self-referential processing, episodic memory, and experience of agency) Occipital and inferior temporal regions (visual processing)  Lucid dreams are oftentimes associated with increased visual vividness and clarity of the dream scene          4. Unilateral spatial neglect #   Visual neglect syndrome or unilateral spatial neglect:  Tendency to ignore – or to be unaware of – information on one half of visual field, usually the left side Typically occurs after damage (e.g., stroke) to right hemisphere, particularly damage to the parietal and frontal lobes    Patients are asked to draw from memory or to copy an illustration (Driver \u0026amp; Vuilleumier, 2001)\n   Posterior hot zone #   However, other research suggests that it is primarily regions in the “posterior hot zone” – not the prefrontal – that generate the sights, sounds, and other sensations of life as we experience it   Electrical stimulation of cerebral cortex #   Prior to removing a brain tumor or locus of a patient’s epileptic seizures, neurosurgeons map functions of nearby cortical tissue by directly stimulating it with electrodes  Stimulating the posterior hot zone triggers a variety of distinct sensations and feelings Stimulating the frontal cortex by and large elicits no direct conscious experience   Similar effects have been found after removal of cortical tissue  Removal of large sections of frontal cortex (e.g., prefrontal lobotomy) does not significantly affect conscious experience, though patient may develop problems with emotional control, motor deficits, or uncontrollable repetition of specific actions or words However, removal of even small regions of the posterior cortex can lead to loss of an entire class of conscious content – patients may be unable to recognize faces or to see motion, color, or space    Brain-injured patients #   One possible reason for the discrepancy in research findings is that the part of the cerebral cortex that is primarily associated with consciousness depends on the type of consciousness in question In particular, some philosophers have distinguished between two types of consciousness:  Access consciousness (or A-consciousness):  Pertains to accessibility of information, i.e., conscious vs. nonconscious information processing Prefrontal and parietal cortical areas may play important roles in this Related to the “easy problem” of consciousness: explaining in computational or neural terms how an organism accesses and deploys information   Phenomenal consciousness (or P-consciousness):  Pertains to how and why we experience the world as we do Posterior hot zone may play critical role in this This is what David Chalmers has called the “hard problem” of consciousness  Why and how is it that sentient organisms have qualia or phenomenal experiences? Why and how is it that some internal states are felt states (e.g., heat or pain, rather than unfelt states (e.g., a thermostat or a toaster)?          The Global Neuronal Workspace Theory of consciousness lends insight to access consciousness However, it does not address the problem of phenomenal consciousness Integrated Information Theory, which will be turning to shortly, does address the latter  Cerebellum #   One thing though that most researchers agree on is that the seat of consciousness is not located in the cerebellum, though this part of the brain contains  Four times as many neurons as the cortex Half the total number of neurons in the whole brain People who lack a cerebellum (either from birth or as a result of brain injury) are still capable of conscious perception, leading a “normal” life without any loss of awareness  Suggests that sheer number of neurons is not a decisive factor in the creation of conscious experience\n        But why?  One reason might be that the cerebellum’s processing mostly happens locally with minimal interactions between neurons The cerebellum is almost exclusively a feed-forward circuit with no complex feedback loops that reverberate with electrical activity passing back and forth It’s functionally divided into hundreds of independent computational modules with distinct, non-overlapping inputs and output, controlling movements of different motor or cognitive systems This idea that exchange and integration of neural signals is the basis of phenomenal consciousness is one of the main ideas of integrated information theory    Integrated Information Theory #   In the early 2000s, Guilio Tononi pioneered a technique called zap and zip to probe whether someone is conscious or not  Scalp of patient was “zapped” with an intense pulse of magnetic energy using TMS (transuranium magnetic stimulation) This induced a brief electric current in the neurons underneath, which would reverberate across the cortex, exciting and inhibiting other neurons A network of EEG sensors recorded those electrical signals, and as they unfolded over time, yielded a movie The data from the movie was compressed using an algorithm commonly used to “zip” computer files Zipping yielded an estimate of the complexity of the brain’s response    Loss and recovery of integration and information in thalamocortical networks:\nA: Wakefulness\nB: Anesthesia\nC: Vegetative state: UWS – unresponsive wakefulness syndrome, MCS – minimally conscious state, LIS – locked-in syndrome\n  Research findings from zap and zip:  Volunteers who were awake had a “perturbational complexity index” significantly highly than when deeply asleep or anesthetized Method was subsequently able to correctly determine whether patients were conscious or in a vegetative state Measures of the brain’s responses to the TMS also seem to predict the consciousness of patients in a non-communicative and vegetative state– a finding with potentially profound clinical applications  This suggests that the more information that is shared and processed between many different components of the brain in response to a single experience, the higher the level of consciousness   This is the main idea of integrated information theory (IIT): Consciousness arises from neural integration and complexity  Similar to what GNWT says \u0026ndash; different parts of brain that can access information are higher level     If information integration theory is right, it would have implications far beyond neuroscience and medicine  For instance, proof of consciousness in a creature, such as a lobster, could transform the fight for animal rights It would also answer some long-standing questions about AI  Tononi argues that the basic architecture of the computers we have today \u0026ndash; made from networks of transistors \u0026ndash; precludes the necessary level of information integration that is necessary for consciousness (given our current medium we cannot represent consciousness)  Even if they can be programmed to behave like a human, they would never have our rich internal life He emphasizes this is not just a question of computational power or the kind of software that is used  “The physical architecture is always more or less the same, and that is always not at all conducive to consciousness”\n         Xenobots #   Potential for consciousness in xenobots (“living robots”)?  Created by scientists from skin cells and heart cells in the form of stem cells harvested from frog embryos Xenobots are able to move in a coherent fashion to explore their watery environment and can survive for days or weeks, powered by embryonic energy stores Made of organic material (thus, biodegradable) so it shouldn\u0026rsquo;t cause long-term issues   Functions  Groups of xenobots can move around in circles, pushing pellets into a central location Others were built with a hole through the center and were able to use that as a pouch to successfully carry an object When xenobot was cut in half, it stitched itself back up and kept going   Potential applications  Serving as new material for technologies that is fully biodegradable Intelligent drug delivery: carrying medicine to a specific place in body Traveling in arteries to scrape out plaque Searching out and break down harmful compounds or radioactive wastes Gathering microplastics in the oceans    Criticism of IIT #   Tononi’s methods (zap n zip) so far only offer a very crude “proxy” of the brain’s information integration To really prove his theory’s worth, more sophisticated tools will be required that can precisely measure processing in any kind of brain One problem is that, using previous techniques, the time taken to measure information integration across a network increases “super exponentially” with the number of nodes under consideration  Even with the best technology, the computation could last longer than the lifespan of the universe Daniel Toker at UCB has recently proposed a shortcut for the mathematical calculations necessary to test the theory    Controversies in CogSci: #   What are some potential strengths and weaknesses of Tononi’s Integrated Information Theory?\n Evidence for unconscious processes #   Some prominent psychologists today maintain that 100 years of research has provided no clear evidence for the existence of the “unconscious,” but that claim seems to be exaggerated By one estimate, our five senses take in 11,000,000 bits of information per second, of which we consciously process about 40 Some specific evidence for the existence of the unconscious\u0026hellip;  Consciousness and thought suppression #   White bear/red Volkswagon study  Goup 1: Participants were told to try not to think about white bears Goup 2: Participants were told to try not to think about white bears but if they did, to replace the thought with the image of a red Volkswagon   Which group was more successful?  Group 2:   It’s very difficult (if not impossible!) to suppress a maladaptive thought; it’s much easier to replace the thought with a more desirable one (Wegner, Schneider, Carter et al., 1987)\n    Unconscious behaviors #   Split brain:  A condition in which the two hemispheres of the brain are isolated by severing the connecting fibers (mainly those of the corpus callosum) between them After operation, patients often notice that left hand seems to have a “mind of its own”  Suggests that consciousness involves operations of verbal mechanism located in left cerebral hemisphere\n    Freudian slips  Lood gegs Bine foddy    Unconscious perception #   Subliminal perception and priming Rope tying study  Participants are asked to tie together two strings that are hanging from the ceiling The strings are separated so that they can’t reach one of them while holding the other A table and pliers are made available At some point, the researcher walks into the room and accidentally sets one of the strings swinging Invariably, within a few minutes, the participant would figure out the solution to the problem\u0026hellip;       When interviewed afterwards though, they said that the idea “just came to them” (Maier, 1931)\n     Surgery patients in double-blind study wore earphones during their operations, listening to either  Soothing background music and Positive suggestions about the safety and success of the procedure   Results: Compared to controls, experimental group  Woke up feeling significantly less pain (25% on average) Required less pain medication post-surgery (70 required no opiates at all, compared with 39 in the control group) (Nowak, Zech, Asmussen, et al., 2020 )    Unconscious communication #   Study on 23-year-old woman who showed no outward signs of conscious awareness after being in a car accident (Owen, Coleman, Boly et al., 2006; wn, 2014)  When researchers asked her to imagine playing tennis vs. walking around her home, fMRI scans revealed activity in regions similar to healthy person’s brain     Follow-up analysis of 42 behaviorally unresponsive patients revealed 13 more who also showed meaningful though diminished brain responses to questions (Stender, Gosseries, Bruno et al., 2014)  Researchers wonder if such fMRI scans might enable a “conversation” with some unresponsive patients, by instructing them, for example, to answer yes to a question by imagining playing tennis        Repressed memories #   Recovered memories of child abuse Dissociative identity disorder (multiple personality) Anosognosia: “unawareness of illness”  Stroke patients with this disorder may deny that his arm is paralyzed    Unconscious conditioning in advertising #   Men shown picture of car with sexy woman standing in front judged car to be more appealing, better designed, more expensive, faster, and less safe than control group of men  However, 22 out of 23 participants denied their rating had been influenced by the presence of the model  “I never let myself be blinded by advertising; the car itself is what counts\u0026quot;\n     Unconscious processing and sexual attraction #   We are often influenced by factors of which we are entirely unaware Suspension bridge study:  Males were interviewed by attractive female supposedly as part of research project, either  Just after crossing a narrow, wobbly footbridge 230 feet above rapids OR 10 minutes after crossing the bridge   They were given the researcher’s telephone number in case they had questions later  Those in first condition were much more likely to call to ask for a date afterwards Participants had no idea their attraction was influenced by the situation (Meston \u0026amp; Frohlich, 2003)      Unconscious learning (Extra) #   Unconscious learning: behavioral responses can be reinforced through associations without person’s awareness Double agent experiment  Graduate student interviewer was told to nod his head whenever participant engaged in a particular behavior (e.g., chin rubbing) order to reinforce this behavior “Interviewer” was actually the real participant in the experiment; the participant was a confederate “Participant” was instructed to rub his chin whenever the interviewer said “yeah”  Frequency of interviewer’s saying “yeah” increased substantially   When interviewer was eventually told what had happened, his reaction was one of “stunned incredulity” (Rosenfeld \u0026amp; Baer, 1969)   Thumb twitch study  Participants were told that they were participating in a study on effects of stress on body tension and that effects of stress would be manipulated by randomly alternating periods of soothing music and static In fact, noise was not presented randomly: it was terminated whenever participants contracted a very small muscle in their left thumb that could only be detected by an electrode Participants in uninformed group were told nothing about how static could be turned off Participants in partly informed group were told that static could be turned off by specific response and to try to discover that response Results:  Dramatic increase in contractions of this muscle in all participants However, interview afterwards revealed that all the participants in uninformed group still believed they had no control over the noise Only one participant in the partly informed group believed that he had discovered the effective response, which involved “subtle rowing movements with both hands, infinitesimal wriggles of both ankles, a slight displacement of the jaw to the left, breathing out, and then waiting” (Hefferline, Keenan, Harford et al., 1959)       Controversies in Cognitive Science #   What are some of the implications of the computational model of mind generally? And more specifically, with regard to consciousness? What are some limitations of the computational model of mind?  Altered States of Consciousness #  Hypnosis #   Hypnosis: social interaction in which one person (the hypnotist) suggests to another (the subject) that certain perceptions, feelings, thoughts, or behaviors will spontaneously occur  Hypnotic susceptibility #   Hypnotic susceptibility: Correlated with measures of imagery vividness and absorption – people who are hypnotically susceptible tend to have rich fantasy lives and easily become absorbed in the imaginary events of a novel or movie  Uses of hypnosis #  Hypnotic recovery of memories #   Hypnosis may boost recall  Used to help witness in Chowchilla school bus kidnapping case to successfully recall kidnapper’s license plate    Use of hypnosis in treatment of physical and psychological disorders #   But can also cause people to construct false memories and to increase their confidence in these false memories  Hypnotized witnesses may end up testifying confidently to events they never experienced Latter is particularly problematic because highly hypnotizable subjects are especially vulnerable to false memory suggestions   Hypnotherapy: Clinical applications of hypnosis  Hypnosis quite successful in treating physical disorder (e.g., warts, headaches, asthma) Not so successful in treating psychological disorders (e.g., smoking, overeating, alcoholism) Recovery rate for latter increases though when combined with other therapies like systematic desensitization    Hidden observer #   Research by Hilgard suggests that a dissociated part of the hypnotized person (the hidden observer) is aware of what is happening even when person is ostensibly unaware  Ice water study: person kept smiling while hidden observer wrote, “This is agony, let me out!” Lemon study: person seemed to be enjoying “orange,” while hidden observer yelled out “You’ve just squirted acid in my mouth!”    Use of hypnosis in pain control #   Use of hypnosis in childbirth  Standard hypnotherapy Hypnobirthing: combination of self-hypnosis and childbirth education   A number of studies have indicated that hypnobirthing is associated with shorter hospital stays, shorter length of labor, reduction in self-reported pain, reduced epidural and analgesic use However, other studies have found inconclusive results, so overall more research is needed Mechanism:  There are sensory and emotional components of pain perception  Sensory component is mediated by somatosensory cortex Cognitive/emotional component is mediated by the anterior cingulate cortex and the prefrontal cortex  fMRI studies using hypnotic suggestion found that a decrease in the unpleasantness of pain reduced the activation of the anterior cingulate cortex without affecting the activity of the somatosensory cortex        Hallucinogens #   History  Used in Aztec, Mayan, Incan, West African, South Asian, and Egyptian societies since ancient times  To promote physical and mental healing To induce spiritual experiences and access “altered states of consciousness”   1960s emergence of counterculture movement led to widespread usage of hallucinogens in the US Social/cultural differences in use of hallucinogens  Largely part of underground lifestyle in the West Openly used for spiritual purposes in other parts of the world       LSD #   LSD: Lysergic Acid Diethylamide Drug action:  Stimulates serotonergic and dopaminergic receptors \u0026ndash; not fully understood   Positive effects:  Causes perceptual distortions and hallucinations: “altered states of consciousness”  Emotions can vary from euphoria to detachment or panic   Sense of self may dissolve, as does boundary between oneself and external world Research has indicated that LSD may be effective for treating anxiety due to terminal illness, alcoholism, and cluster headaches   Adverse effects:  No documented fatalities from pharmacological action of LSD, but behavioral fatalities and suicides can occur May trigger panic attacks and extreme anxiety (“bad trips”); flashbacks May trigger psychotic break, especially in those with family history of schizophrenia    Maps page  MDMA, Ecstasy #   Drug action:  Causes release of serotonin, norepinephrine (adrenaline), and dopamine, and blocks their reabsorption   Positive effects:  Emotional elevation, disinhibition, feelings of connectedness with everyone Research has indicated that MDMA may be effective for treating PTSD   Adverse effects:  Dehydration, overheating, and increase in blood pressure can cause death, especially when combined with dancing at raves “Ecstasy” pills may be cut with dangerous chemicals Potential damage to serotonin-producing neurons, leading to increased risk of depression and sleep problems  Less serotonin the next morning, can also be long-term if used too much   Memory impairments    Maps page  Psilocybin #   Drug action:  Stimulates serotonin receptors   Positive effects:  Causes euphoria, perceptual distortions, hallucinations May induce spiritual experiences   Marsh Chapel Experiment on Harvard Divinity School students in 1962 Participants reported profound religious experiences In 25-year follow-up, all of the participants described experience as having elements of “a genuine mystical nature and characterized it as one of the high points of their spiritual life” Single administration induced significant increase in personality dimension of openness to experience that persisted for over a year   May be effective in treating depression and OCD   Adverse effects:  May cause nausea, panic attacks, confusion, and psychotic episodes, leading to accidents and suicide attempts    Psychedelic therapy #   Abram Hoffer study in the 1960’s  Gave alcoholics a small dose of mescaline, then deliberately induced peak experiences by means of music, poetry, painting – whatever used to produce peak experiences before the person became alcoholic  50% were supposedly permanently cured     Moratorium on research in this area from early 1970s to early 2000s due to war on drugs However, resurgence of interest and research in this area in recent years, in particular with regard to use of hallucinogens – especially MDMA and LSD – to treat substance abuse, PTSD, obsessive-compulsive disorder, depression, cluster headaches, and emotional suffering associated with terminal illness UCB launched the campus’s first center for psychedelic science and public education in 2020  Will conduct research using psychedelics to investigate  Cognition, perception, emotion and their biological bases in the human brain  Initial studies will focus on psilocybin   Integration of psychedelics with psychotherapy to treat psychological disorders and brain mechanisms involved Ability of these compounds to improve cognitive flexibility, alter visual perception, engender feelings of awe and change patterns of brain activity   Center also plans to collaborate with the Graduate Theological Union and eventually train guides or facilitators, in the cultural, contemplative and spiritual care dimensions of psychedelics    Mysticism or psychosis (Extra!) #   \u0026ldquo;From the first, the experience seemed to me to be holy. What I saw was the Power of Love – the name came to me at once – the Power that I knew somehow to have made all the universes, past, present and to come; to be utterly infinite, an infinity of infinities, to have conquered the Power of Hate, its opposite, and thus created the sun, the moon, the planets, the earth, light, life, joy and peace, never ending\u0026hellip;.In that peace I felt utterly and completely forgiven, relieved from all burden of sin. The whole infinity seemed to open up before me, and during the weeks and months that followed I passed through experiences which are virtually indescribable. The complete transformation of “reality” transported me as it were into the Kingdom of Heaven. I feel so close to God, so inspired by His Spirit, that in a sense I am God. I see the future, plan the Universe, save mankind; I am utterly and completely immortal; I am even male and female. The whole Universe, animate and inanimate, past, present and future is within me; all things are possible.”\n Answer: Psychotic episode of John Custance\n   All at once, without warning of any kind, I found myself wrapped in a flame-colored cloud. For an instant I thought of fire, an immense conflagration somewhere close by in that great city; the next, I knew that the fire was within myself. Directly afterward there came upon me a sense of exultation, of immense joyousness accompanied or immediately followed by an intellectual illumination impossible to describe. Among other things, I did not merely come to believe, but I saw that the universe is not composed of dead matter, but is, on the contrary, a living Presence; I became conscious in myself of eternal life, but a consciousness that I possessed eternal life then; I saw that all men are immortal; that the cosmic order is such that without any peradventure all things work together for the good of each and all; that the foundation principle of the world, of all the worlds, is what we call love, and the happiness of each and all is in the long run absolutely certain.”\n Answer: Mystical experience of R.M. Bucke, Canadian psychiatrist\n   “When I walk the fields, I am oppressed, now and then, by an innate feeling that everything I see has a meaning, if only I could understand it. And this feeling of being surrounded with truth, which I cannot grasp, amounts to indescribable awe sometimes. Have you not felt that your real soul was imperceptible to your mental vision, excepting a few hollow moments?”\n Answer: Mystical experience of Charles Kingsley, a Christian mystic\n   “I am simple; I need not think. Feeling is all; feeling is love. God is love. Love is the expression of God. Feeling is only fire. Fired by God. The dancer becomes the divining motion. Dance is the divine in the world. The Dionysian religion. Love is God. I am love; I am God.”\n Answer: Psychotic experience of Nijinsky, Russian ballet dancer\n   Distinctions:  The mystic, unlike the person with psychosis, develops a strong sense of self The mystic tends to reduce self-importance; psychosis tends to involve inflated self-importance The mystic tends to have ever increasing serenity, which leads him or her to be more involved in life and more loving towards all beings; those with psychosis have difficulty relating with anybody and clearly withdraw from the world The mystical experience, though ineffable, is usually coherent and what is described is clear; those with psychosis tend to be thought-disordered so their descriptions are not very lucid The mystical experience is usually brief, though it leaves so vivid an imprint that it can be remembered clearly 25 years later; in psychosis, the person may get stuck in the experience and be unable to come out of it In mysticism, there is a gradual reduction of attachment to the world; in psychosis, there is a fusion and a continuous shifting of the world The mystic tends to take responsibility, not only for themselves, but for all aspects of life around them; those with psychosis project out of themselves those things that seem especially negative     Near-Death Experience #   Near Death Experience: an altered state of consciousness reported after a close brush with death  Reported by about 10 to 15 percent of those revived from cardiac arrest Many describe visions of tunnels, bright lights or beings of light, a replay of old memories, and out-of-body sensations   Typical report:  “I was left with an awareness that something more was going on in life than just the physical part of it\u0026hellip; There is more than just consuming life, more than just what we can buy. There comes a point when you have to give in to it\u0026hellip; The typical near-death survivor emerges from his experience with a heightened appreciation for life, determined to live life to the fullest. He has a purpose in living even though he cannot articulate just what the purpose is.”\n   Controversies in CogSci: Implications and limitations of the computational model of mind #   Ultimately, the experiences that Altered States of Consciousness involve cannot really be captured by language\u0026hellip;  Cognitive Neuroscience of Consciousness #   As discussed earlier, various types of nonconscious processing are associated with suppression of or reduced activity in parts of the frontal and parietal cortices  Hypnosis is associated with reduced activity in the dorsal anterior cingulate and reduced connections between various regions of the frontal cortex that are part of the default mode network (self-awareness) and the motor cortex Non-lucid dreaming, in comparison with lucid dreaming, is associated with reduced activity in areas of the prefrontal and temporoparietal lobes involved in self-referential processes Study by Michael C. Anderson found that in repression, the prefrontal cortex (executive control) disengages processing in the hippocampus (memory)   Other important brain structures:  Anterior cingulate cortex (ACC)  Forms “collar” around front part of corpus callosum Functions:  Integrates cognitive and affective information Awareness and processing of conflicting information Selective attention          Insular cortex  Lies deep within the lateral sulcus Functions:  Self-awareness Consciousness Emotional regulation          Extra:\n In addition, study on repression found that autonomic arousal during free association task  Predicted subsequent memory failure Was accompanied by increased activation of conflict-related brain regions (e.g., anterior cingulate cortex) and deactivation of memory-related regions (e.g., hippocampus) (Schmeing, Kehyayan, Kessler, et al., 2013)   When patients with dissociative identity disorder read stories that pertained to their trauma (Simone Reinders), the alters that were unaware of the trauma, relative to alters that were aware of the trauma, showed  Increased activity in cingulate gyrus Reduced amygdala and insula activity Reduced cardiovascular response      "},{"id":16,"href":"/eecs-16a/5/","title":"Week 5: Basis \u0026 Circuit Analysis","section":"EECS 16A","content":"02-22 Basis #   Note 10  Slides     Change of Basis #   Previously we’ve seen that a basis for a vector space is a minimal spanning set of vectors. We can also define the standard basis vectors, e,x. the standard basis for .$ \\mathbb{R}^{3}$ is the set .$\\mathbb{E}$:   $$\\mathbb{E} = \\big(\\hat i, \\hat j, \\hat k \\big)$$ $$\\dots \\equiv ( \\vec e_1, \\vec e_2, \\vec e_3)$$ $$\\dots \\equiv \\left( \\begin{bmatrix} 1\\\\ 0\\\\ 0\\\\ \\end{bmatrix}, \\begin{bmatrix} 0\\\\ 1\\\\ 0\\\\ \\end{bmatrix}, \\begin{bmatrix} 0\\\\ 0\\\\ 1\\\\ \\end{bmatrix}\\right) $$     We can represent any set of vectors that form as basis as a linear combination of the standard .$ \\mathbb{R}^{3}$ basis vectors\n When you plot a vector, the basis is normally implicit as the standard basis vectors    Change Of Basis Operation: Preserves the geometrical vector but modify its coordinates such that when plotted in the new basis, the original and final vector are physically the same  Such that we\u0026rsquo;re essentially re-expressing the coordinates of some .$\\vec v$ (formed with basis .$\\mathbb{E}$) in some new basis .$\\mathbb{E}'$    We know that the basis vectors define the linear transformation matrix: $$\\begin{bmatrix} | \u0026amp; \u0026amp; | \\\\ \\vec e_1 \u0026rsquo; \u0026amp; \\dots \u0026amp; \\vec e_n \u0026rsquo; \\\\ | \u0026amp; \u0026amp; | \\\\ \\end{bmatrix}$$     Thus, we need to solve for the scalars that multiply each of the new basis vectors, .$v_i \u0026rsquo; $, to produce the same physical vector .$\\vec v$ as before:   $$\\begin{bmatrix} | \u0026amp; | \\\\ \\vec e_1 \u0026rsquo; \u0026amp; \\vec e_2 \u0026rsquo; \\\\ | \u0026amp; | \\\\ \\end{bmatrix}\\begin{bmatrix} v_1 \u0026rsquo; \\\\ v_2 \u0026rsquo; \\\\ \\end{bmatrix} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\end{bmatrix} = \\vec v $$    Generally, we can say that if given a vector .$\\vec v$ expressed with coordinates in the standard .$n$-dimensional basis .$\\mathbb{E}$, then we can solve for the coordinates .$\\vec v \u0026rsquo; $ in a different .$n$-dimensional basis .$A$ with .$\\vec v \u0026rsquo; = A^{-1} \\vec v$  .$A$ is formed with the columns of the new basis. To do the opposite (basis .$A \\to \\mathbb{E}$), we apply .$A$: .$\\vec v = A \\vec v \u0026rsquo; $ Finally, suppose that we’re given .$\\vec v$ with coordinates in an arbitrary basis .$P$ (matrix with columns .$\\vec p_1, \\dots, \\vec p_n$), and we want to change to another arbitrary basis .$Q$ with columns .$\\vec q_1, \\dots, \\vec q_n$. We must apply the transformation .$Q^{-1} P$. This follows from first transforming .$\\vec v$ to the standard basis from .$P$, and then transforming to the new basis .$Q$       The only question is whether we preserve the coordinates (which are the mathematical representation) and change the physical vector in accordance with the new basis, or preserve the physical vector and find the new coordinates.   Page 57 has pretty figures      Matrix Change of Basis #   We can apply our knowledge to linear transformations to understand what it means to change the basis of a matrix\n  Given transformation .$T \\in \\mathbb{R}^{n \\times n}$ with input .$\\vec v_1$ and output .$\\vec v_2$, we can apply our column-wise interpretation of the matrix-vector product, but now, we must take care of the fact that our vectors may lie in a different basis than .$E$.   Suppose we have basis vectors .$\\vec a_1, \\dots, \\vec a_n$ forming .$A \\in \\mathbb{R}^{n \\times n}$, and vectors .$\\vec v_1, \\vec v_2$ represented in this basis: .$\\vec v_i = v_{i,1} \u0026rsquo; \\vec a_1 + \\dots v_{i,n} \u0026rsquo; \\vec a_n$  Each .$v_{i,k}$ is the .$k$th element of the vector .$\\vec v_i$ We can also represent .$T$ in this basis as .$T \u0026rsquo; $   We start with .$\\vec v_1 = A \\vec v_1 \u0026rsquo; $ and .$\\vec v_2 = A\\vec v_2 \u0026rsquo; $. Since .$T\\vec v_1 = \\vec v_2$ by definition of linear transformation .$T$, we can plug in: .$TA\\vec v_1 \u0026rsquo; = A\\vec v_2 \u0026rsquo; \\Longrightarrow A^{−1} T A \\vec v_1 \u0026rsquo; = \\vec v_2 \u0026rsquo; $. Clearly, just as how we had .$T\\vec v_1 = \\vec v_2$, we have an analogous transformation in the new basis: .$T \u0026rsquo; \\vec v_1 \u0026rsquo; = \\vec v_2 \u0026rsquo; $, where .$T \u0026rsquo; = A^{−1} T A $.     .$T \u0026rsquo; $ is equivalent to .$A$, then .$T$, then .$A^{−1}$\n   Diagonalization #   Why bother with change of basis? In practical applications, matrix operations form the core of some very computationally heavy algorithms \u0026ndash; we need to be able to easily invert matrices, raise them to high powers, and multiply them commutatively; all of these can be accomplished with diagonal matrices, where all entries not on the diagonal are zero  An identity matrix of any size, or any multiple of it (a scalar matrix), is a diagonal matrix. Its determinant is the product of its diagonal values   First, we must choose a diagonalizing basis .$A$ that consists of the .$n$ eigenvectors of .$T$.  This is only possible if .$T$ is diagonalizable, which requires it to have .$n$ linearly independent eigenvectors  Note this is different from the .$n$ columns being independent!   Then, to figure out how .$T$ transforms .$\\vec v_1$, we write .$\\vec v_1 = \\vec v_{11} \u0026rsquo; \\vec a_1 + \\dots + \\vec v_{1n} \u0026rsquo; \\vec a_n$ $$T \\vec v_1 = T \\vec v_{11} \u0026rsquo; \\vec a_1 + \\dots + T v_{1n} \u0026rsquo; \\vec a_n$$ $$\\dots = v_{11} (T \\vec a_1) + \\dots + v_{1n} (T\\vec a_n)$$ $$\\dots = v_{11} (\\lambda_1 \\vec a_1) + \\dots + v_{1n} (\\lambda_n \\vec a_n)$$ Using the middle matrix (diagonal!) as a sort of \u0026ldquo;sifting\u0026rdquo; matrix; each row only has one nonzero value, so we only multiply the .$v_{1i} \\vec a_i$ value by the corresponding .$\\lambda_i$: $$T \\vec v_1 = \\begin{bmatrix} | \u0026amp; \u0026amp; | \\\\ \\vec a_1 \u0026amp; \\dots \u0026amp; \\vec a_n \\\\ | \u0026amp; \u0026amp; | \\\\ \\end{bmatrix}\\begin{bmatrix} \\lambda_{1} \u0026amp; \u0026amp; \\\\ \u0026amp; \\ddots \u0026amp; \\\\ \u0026amp; \u0026amp; \\lambda_{n} \\end{bmatrix}\\begin{bmatrix} v_1 \u0026rsquo; \\\\ v_2 \u0026rsquo; \\\\ \\vdots \\\\ v_n \u0026rsquo; \\\\ \\end{bmatrix}$$ Notice now we have an equation of the form: $$T \\vec v_1 = AD \\vec v_1 \u0026rsquo; \\Longrightarrow T\\vec v_1 = ADA^{-1} \\vec v_1 \\Longrightarrow T = ADA^{-1}$$  Here, .$D$ is the diagonal matrix containing the eigenvalues of the transformation One useful result is that .$T^k = AD^k A^{-1}$ (expand and group .$A^{-1}A = I$)  Since .$D$ is easy to raise to high powers (.$D^k$ contains all diagonal entries raised to the .$k$th power), the computation of numerous transformations becomes much easier To raise a diagonal matrix to a power, one can raise each element to that power        02-24 Intro to Circuit Analysis #    Slides Note 11 A B    We will label nodes instead of junctions because all of the junctions that are connected to each other by wires can be labeled with a single voltage variable .$u$. A set of such junctions connected to each other only via wires is defined as a node. Nodes have the same voltage at every point on them.  Circuit Analysis Algorithm #    Select a reference (ground) node .$u_1 = 0$  This node will have 0 potential \u0026ndash; all voltages are measured relative to this node Arbitrary selection \u0026ndash; any node can be chosen for this purpose. In this example, we choose the node at the bottom of the circuit diagram.        Label Nodes .$[u_2, \\dots, u_{n}]$\n First lets look at the nodes with voltage set by Voltage Sources. Voltage sources set the voltage of the node they are connected to.   In the example, there is only one source, .$V_S$, and we label the corresponding source .$u_1$ (names are arbitrary, but must be unique). Now we label all remaining nodes in the circuit except the reference \u0026ndash; in this example there are two, .$u_2$ and .$u_3$.        Label currents .$[I_1, \\dots, I_k]$ through non-wire elements  The direction is arbitrary (top to bottom, bottom to top, it won’t matter, but stick with your choice in subsequent steps). Then mark the element voltages following the passive sign convention.        Label element potentials based on passive sign convention.  The element voltage for .$I_S$ is not marked in the example since it will not be needed in the calculations below. Same for the voltage source. There is no harm in marking those, too.        KCL Equations  Write KCL equations for all nodes with unknown voltage, .$u_2$ and .$u_3$ in the example. See Week 2      At .$u_2$ we get (sum of all currents entering the node equals sum of currents exiting): $$I_{R_1} = I_{R_2} + I_{R_4}$$ and similar for .$u_3$: $$I_{R_4} + I_{I_S} = I_{R_3}$$    Element IV Relationships  Find expressions for all element currents in terms of voltage and element characteristics (e.g. Ohm’s law) for all circuit elements except voltage sources.  In the example there are five unknown elements: .$R_1, R_2, R_3, R_4, I_S$   Find expressions for element currents for all elements (except the voltage source) using their characteristics.      Applying Ohm’s law to the two resistors, we find that  $$I_{R_1} = \\frac{V_{R_1}}{R_{1}}$$ $$I_{R_2} = \\frac{V_{R_2}}{R_{2}}$$ $$I_{R_3} = \\frac{V_{R_3}}{R_{3}}$$ $$I_{R_4} = \\frac{V_{R_4}}{R_{4}}$$ $$I_{I_S} = I_S$$ and we have .$u_1 = V_S$Applying Ohm’s law to the two resistors, we find that   Solve .$A\\vec x = \\vec b$ \u0026ndash; see page 12 and/or slide 14  .$\\vec x = [I_1, \\dots I_k, u_1, \\dots, u_n]^T$: The unknown element variables we\u0026rsquo;re solving for .$\\vec b \\in \\mathbb{R}^{k+n}$: The vector of elements values we\u0026rsquo;re solving for  Units are either .$V$olts or .$A$mps   .$A \\in \\mathbb{R}^{k+n \\times k+n}$ Steps:  If there are .$n$ nodes (including the ground node), use KCL on .$(n−1)$ nodes to fill in .$(n−1)$ rows of .$A$ and .$\\vec b$ If there .$k$ non-wire elements, use the IV relationships of each non-wire element to fill in the remaining .$k$ equations (rows of .$A$ and values of .$\\vec b$).      Branch Current #   Sometimes we want to solve for branch currents: These are easily obtained from the node voltages and element equations.    For example above, the current .$I_{R_4}$ through resistor .$R_4$ is $$I_{R_4} = \\frac{V_{R_4}}{R_4} = \\frac{u_2 - u_3}{R_4}$$    Voltage Divider #  Passive sign convention #   The passive sign convention dictates that positive current should enter the positive terminal and exit the negative terminal of an element.       As long as this convention is followed consistently, it does not matter which direction you arbitrarily assigned each element current to; the voltage referencing will work out to determine the correct final sign. When we discuss power later in the module, you will see why we call this convention “passive.”\n Trivial Junctions #   Trival junction: A junction connecting only two elements.  KCL dictates that the current entering the junction must be equal to the current exiting. Since there are only two elements, it follows that the two currents must be equal (as long as we label the direction of current flow to be the same – if not, the currents will simply be opposite in sign).   Therefore, another simplification to our analysis procedure is to label the currents only in the non-wire elements in our circuit (Sometimes these currents are called branch currents)  When we use KCL, we can now consider nodes (instead of junctions) i.e. the current flowing into the node is equal to the current leaving the node.    "},{"id":17,"href":"/eecs-16a/6/","title":"Week 6: Voltage Dividers \u0026 Measurement","section":"EECS 16A","content":"03-01: Voltage Dividers #  Voltage Divider #   The voltage divider circuit consists of a voltage source (.$V_S$) and two resistors (.$R_1$ and .$R_2$) Example:  We label the node connected to the voltage supply as .$u_1 (= V_S)$, since the voltage supply goes between this node and ground. Label the remaining node as .$u_\\text{mid}$ and the voltages and currents through every element in the circuit with .$V_i$ and .$I_i$ respectively Write KCL equations for all nodes with unknown voltage - in this case, this is just .$u_\\text{mid}$, since .$u_1 = V_S$.  The current entering that node is .$I_{R_1}$ and the current leaving it is .$I_{R_2}$ Since these currents must be equal, .$I_{R_1} = I_{R_2}$        4. Find expressions for element currents for all elements (except the voltage source) \u0026ndash; all steps on page 3 $$I_{R_1} = \\frac{V_S - u_\\text{mid}}{R_1}$$  $$I_{R_2} = \\frac{u_\\text{mid}}{R_2}$$   5. Substitute the element currents into our KCL equation. We have $$I_{R_1} = I_{R_2} \\Longrightarrow \\frac{V_S - u_\\text{mid}}{R_1} = \\frac{u_\\text{mid}}{R_2}$$ 7. Solve the above equation. Rearranging, we find that $$V_S R_2 −u_\\text{mid}R_2 = u_\\text{mid}R_1$$ $$ \\Longrightarrow u_\\text{mid}(R_1 +R_2) = V_SR_2$$ $$ \\Longrightarrow u_\\text{mid} = \\frac{R_2}{R_1 + R_2} V_S = \\frac{1}{1+ \\frac{R_1}{R_2}} V_S = \\alpha V_S$$ The reason this circuit is called a \u0026ldquo;voltage divider\u0026rdquo; is that we can create any output voltage of .$u_\\text{mid} = \\alpha V_S$ for any .$\\alpha \\in [0,1]$ (assuming that all of the resistance values are non-negative) by varying the ratio of the resistor values .$R_1/R_2$. As we will see shortly, varying this ratio is exactly the mechanism we will use to convert the relative position of a user’s touch to a voltage.    .$R_2$, the resistor in the numerator, is the one next to ground. .$R_1$ is connected to a non-zero voltage node (in this case .$u_1 = V_S$).  03-03: Power and Voltage/Current Measurement #  Physics of Circuits #    Read 7B 25.2 - 5 Notably,  .$P_\\text{el} = I_\\text{el} \\cdot V_\\text{el} = V^2_\\text{el} \\cdot R^{-1}_\\text{el} = I^2 _\\text{el} R _\\text{el}$  When .$P = IV$ is positive, power is being dissipated When .$P = IV$ is negative, power is being generated/delivered.   .$R = \\rho \\frac{L}{A}$     Touchscreen #    Given that the top (red) layer has a resistivity .$\\rho$ and a cross-sectional area .$A$, the resistance of the top layer from the touchpoint to the right-hand end is given by .$R_1 = \\rho \\frac{L_\\text{rest}}{A}$, the resistance of the top layer from the left-hand end to the touchpoint is given by .$R_2 = \\rho \\frac{L_\\text{touch}}{A}$ We can see that .$u_\\text{mid}$ can be found because it\u0026rsquo;s a voltage divider: $$u_\\text{mid} = \\frac{\\rho \\frac{L_\\text{touch}}{A}}{\\rho \\frac{L_\\text{rest}}{A} + \\rho \\frac{L_\\text{touch}}{A}}V_S = \\frac{L_\\text{touch}}{L_\\text{touch} + L_\\text{rest}}V_S = \\frac{L_\\text{touch}}{L}V_S$$  .$L = L_\\text{touch} + L_\\text{rest}$: The length of the touchable portion of the screen     The relationship we have found between .$u_\\text{mid}$ and .$V_S$ is very convenient because .$u_\\text{mid}$ is not dependent on any material property such as .$\\rho$ and .$A$. This means that the top layer can be built with any material and the relationship between .$u_\\text{mid}$ and .$V_S$ is still valid. There are always some non-idealities in the world \u0026ndash; by making .$u_\\text{mid}$ independent of any material property, we can make the circuit model immune to such non-idealities. We also have the freedom to choose a material for the top layer that is good for display purposes (rather than needing a specific material for the touchscreen to work).\n Measuring a Circuit #    The voltmeter measures voltage across the circuit, while the ammeter needs to be put in-line with the circuit so that the current flows through the ammeter.\n  The measurement should not change the energy of the circuit  It turns out that the most complete and concise way of guaranteeing these measurement tools do not influence the circuit is to state that they do not allow any power dissipated through the measurement device.    Voltmeter #  Because our voltmeter is made to measure voltage, we can naturally assume that the .$V \\neq 0$; this means that a voltmeter must have .$I = 0$ going into it to ensure .$P = IV = 0$.\n.$I=0$ occurs when in open-circuits, where exactly zero current is flowing.\nRecall that, for a given voltage, the higher the associated resistance, the lower the current and therefore the lower the dissipated power. That is, .$\\lim{R \\to \\infty} \\Longrightarrow I = 0$ $$V_\\text{el1} = I_\\text{meas} R$$ $$V_? - V_\\text{el1} - V_\\text{meas} = 0$$ $$\\Longrightarrow V_? = V_\\text{el1} + V_\\text{meas}$$ $$\\Longrightarrow V_? = I_\\text{meas} R + V_\\text{meas}$$ $$\\therefore V_? = V_\\text{meas} \\iff I_\\text{meas} = 0$$\n $$I_\\text{meas} = \\frac{V_\\text{meas}}{R_\\text{meas}}$$ $$\\therefore I_\\text{meas} = 0 \\iff R_\\text{meas} \\gg V_\\text{meas}$$\n  Voltmeters are added in parallel to the circuit, otherwise they would stop the current from flowing.    Ammeter #  The ammeter has the circuit’s current flowing through it. Therefore, to ensure .$P = IV = 0$, the ammeter needs .$V = 0$.\n.$V=0$ occurs in short-circuits (ideal wires), where exactly zero potential difference exists\n$$I_? = I_R + I_\\text{meas}$$ $$\\therefore I_? = I_\\text{meas} \\iff I_R = 0$$\n $$I_R = \\frac{V_\\text{meas}}{R}$$ $$\\therefore I_R = 0 \\iff V_\\text{meas} = 0$$\n  Ammeters are added in series to the circuit, otherwise they would short-circuit the measured component.    "},{"id":18,"href":"/e-29/5/","title":"Weeks 5 \u0026 6: Forming Processes","section":"Engineering 29","content":"Before #   So far in the class, we have seen a wide range of additive and subtractive processes which are capable of creating components in metals, alloys, polymeric materials, ceramics, and composites. The one thing that these processes all have in common is that they are serial — meaning that one feature is produced after another in a predefined sequence. This serial nature inherently limits productivity and may require considerable operator skill. High operator skill, which leads to high overhead costs, is especially needed when a tool such as a lathe is manually operated, but may be needed even if the tool is computer numerically controlled, because work still has to be properly mounted and the machine correctly aligned to it. Subtractive processes have been used for centuries, both in the mass-production of precision components, and in one-off custom and prototyping jobs. Additive manufacturing has until recently been seen as a purely prototyping tool, although increasingly is being adopted for short-to-medium production runs.\n  Casting, and injection molding, on the other hand, form all features in a component almost simultaneously by forcing molten material into a mold, and potentially offer a faster, more affordable route to mass production. Injection molding is suitable only for mass production because of the high expense of the molds needed, and production runs of \u0026gt;10,000 are usually needed for economic operation. Casting comes in many flavors, from high pressure die-casting — which is really the equivalent of injection molding for processing metals — to gravity-driven sand-casting, which is used both for long production runs and for one-off fabrication jobs because of its ability to create very large components (\u0026gt; 1 m in some cases) with reasonable simplicity. The higher throughput of casting comes at the expense of lower achievable tolerances than machining (considerable fractions of a millimeter, as opposed to tolerances of a few micrometers). Forming processes such as casting are thus often followed by subtractive secondary processing to bring key features within tolerance. In this module we will highlight some of the attributes of casting and injection molding.\n  Forming of Polymers (Molding Processes) #  Injection molding #   An injection molding machine consists of a mechanism to melt and extrude the polymer, and a molding unit. Injection molding is the workhorse of plastics manufacturing and can achieve cycle times of under a minute. Most plastics that are injection molded are thermoplastics, meaning that they can be reversibly changed between solid and fluid states by heating and cooling. Injection molding, however, can also be used to inject materials that covalently crosslink when heated (thermosetting plastics), making components that are more heat-resistant than thermoplastics. Injection molding has even been adapted to mold metal powders which are then sintered inside the mold (powder injection molding).\n Polymer Melting #   In conventional injection molding, the material to be molded enters the machine as solid pellets, which are drawn into a rotating, heated screw whose diameter decreases along its length to compress the material, drive out air voids, and turn it into a continuous molten flow. This flow is then extruded from a nozzle into a clamped mold, which is typically machined from tool steel but may contain inserts of other materials for specific applications.\n  Very thick material (viscosity) isn\u0026rsquo;t an issue due to large pressures used (Pressures typ. \u0026gt; 100 MPa) Pellets go into hopper where they\u0026rsquo;re carried along and melted  The inside diameter of the screw gets larger so the pellets get compressed as they\u0026rsquo;re pushed along the screw until all air is driven out and it\u0026rsquo;s a constant stream Wire mesh ensures only \u0026rsquo;liquid\u0026rsquo; passes (removes any debris/dust/funky filament)     Machinery #   The core is the part that is inserted into the mold (surrounding case)  These two components constrain geometry Must have a very tight fit due to very high pressures (hydrolics is commonly used)     Process Stages #   Heat up and screw the molten plastic to the tip of the core Plunge the core into the mold and inject the molten material Hold for a few seconds to let the material to solidify Retract the core and bring back the mold to release the new piece   Cycle times approx. 10 s to 1 minute    The mold is held at a temperature that is high enough to allow the polymer to fill the mold before solidifying, but cool enough that cycle time is not excessively long. The molded material needs to fall to below its glass transition temperature, below which the material becomes rigid, before it is ejected from the mold. Ejection is usually automated, with mechanical ejector pins emerging from the mold to push the molded component into a collection bin.\n Features #   Connectors are placed as to minimize material used and heat; fractals can be used to optimize these patterns\n  Hot Runners #   Overmolding and insert molding #   Multiple polymers  Rigid and rubbery  Can make hinges between rubber and rigid material Enables tooth brush bristles to be held in You need a precise temperature in the range of the material so it deforms enough to bind with another surface while not permanently deforming   Different colors   Encase metallic objects \u0026ndash; object is molded around for..  Rigidity Strength Abrasion resistance Way to circumvent having to 3D printed threads        Physical limitations on geometry #   As soon as coming in contact with surface, the polymer looses heat  Thus, penetration depth is limited by how quickly the polymer \u0026lsquo;freezes\u0026rsquo; You can increase pressure and temperature (thus viscosity) to circumvent this \u0026ndash; but there are of course tradeoffs (longer heat up time, \u0026lsquo;maximum heat\u0026rsquo; material can withstand)   For very tiny surface the surface geometry starts to matter too (e.x. income-angle may matter, as does mold material and how it interacts with the polymer)   Defects #   Flash \u0026ndash; extra material squeezed out around edges, typically not a big deal Flow lines \u0026ndash; may matter for certain applications Short shot \u0026ndash; not enough material injected  Typically because extruder doesn\u0026rsquo;t output enough or because mold is pulled away too soon   Misrun \u0026ndash; material doesn\u0026rsquo;t make it to end of material Warping \u0026ndash; uneven section thickness, causing non-constant heat density and thus warping  The more rigid geometry, the more differential thermal contraction can happen before warping occurs Why ribs are used commonly used \u0026ndash; small regions of strips of material is, from a structural POV, better than evenly distributing it across the surface   Trapped air \u0026ndash; solved by adding very tiny venting channels for air to escape  Can fail if clogged with tiny debris, causing flash   Silver streak \u0026ndash; polymer flowing over surface and solidifying too early Sink marks \u0026ndash; mass below surface pulls downwards, resulting in tiny dip  Caused by ribs (supports) in particular! Visible in polished surfaces \u0026ndash; thus you can avoid it by giving the surface a finish     Design of Molds #   Cost of molds drives economic batch size  ≳ 10,000 parts   Design considerations  Draft angle: typically 1 − 2° Air vents   Advanced features  Multi-core molds Active water cooling Materials with very high thermal conductivity e.g. Cu-Be alloys  For large moldings where achieving rapid enough cooling of the component is a challenge, high-thermal-conductivity materials such as copper–beryllium alloys may be used for part of the mold.\n    Material shrinkage needs to be compensated for in the sizing of the mold Examples of typical linear contractions between solidification and room temperature:     Material Approx. linear shrinkage (%)     ABS 0.6   Nylon 2.0 \u0026ndash; crystaline   PC 0.7 \u0026ndash; amorphic   PE 2.5   PS 0.4   PVC 0.5      Watercooling system around mold\n     Surface texturing methods #   Polishing Sanding Grinding Blasting \u0026ndash; for more complex geometry  Sand or glass beads   EDM Chemical etching  Ferric chloride, nitric acid         Nanoscale Features #   Nanopatterned hard mold coatings such as chromium nitride have recently been introduced to enable injection molding of nanostructures giving butterfly winglike structural color \u0026ndash; structural color\n  Other Polymer Forming Processes #  Reaction Injection Molding #   For if you aren\u0026rsquo;t making many copies (so creating a mold isn\u0026rsquo;t worth while) Materials are reactive when they come in contact \u0026ndash; think of epoxy    Enables thermosets, not just thermoplastics, to be molded  Compression Molding #   A lower-throughput but simpler and more affordable polymer molding technique is compression molding, in which a charge of the material to be formed is placed directly into the mold, and the mold halves are then brought together. The simplicity of the technique lends it to modest-sized production runs, and it is particularly suitable for thermosetting polymers, which crosslink when heated and can be removed from the mold at the molding temperature, because they do not need to be brought below a glass transition to acquire rigidity\n   Much simpler apparatus; tens of MPa (rather than hundreds) Relies on a thermosetting material to solidify part  Flash is common    Extrusion #    Wide range of length-scales possible  FDM printing (~0.1 mm) Large pipes and construction sections (\u0026gt; 1 m possible) \u0026ldquo;Keeping mass as far away from center is a good way to optimize usage\u0026rdquo;   Before leaving die, materials which are extruded outwards slightly because the high pressures cause the extrusion to shrink down Hollow sections possible with specially designed mandrels E.x aluminum alloys (80-20), PVC are common extrusion materials      Blow Molding #   Blow molding is very widely used to produce components with thin side walls, such as plastic bottles. An extruded tube of softened thermoplastic polymer is clamped between two halves of a mold and air pressure inside the tube is increased. This expands the material until it conforms to the mold, stretching the material and making it thinner as it does so.\n   Better than injection molding for very thin walls Extrusion followed by inflation  Or, can use injection molded preform (e.x. plastic bottle threading)    Forming of metals and alloys (Casting processes) #  Reasons to use casting #   You have an established component design which needs to be mass-produced: casting can create many parts in less time than machining or additive manufacturing. Geometric versatility: with appropriate mold design, sophisticated re-entrant geometries can be produced in about the same time as a simple geometry. Processing time does not increase strongly with geometric complexity, as it does in machining. The need to process high-melting-point (“refractory”) alloys: melting point is correlated with hardness, making machining increasingly difficult as melting temperature increases. A highprecision casting technique such as investment casting can be a good option for achieving demanding tolerances with refractory alloys. A desire to minimize material wastage: in casting, very little material is used beyond that required for the actual component, and any surplus (e.g. for risers and runners, as discussed below) can be re-melted and re-used. In contrast, in subtractive manufacturing much of the stock may be machined away as chips which are laborious and may be somewhat energy-intensive to recycle.   Variables in casting  Material insertion: gravity- or pressure-driven? Mold material: expendable or permanent? Pattern material: expendable or permanent?    Sand Casting #   Gravity-fed  Heat loss and shrinkage is a concern, so extra risers are included (which also serve as vents)   Manual process that creates large objects Few-hundred runs a year, takes a few hours per run If the mold halves do not mate perfectly, molten metal may travel along their interface, leading to flash, which is usually thin enough to be easily broken off or abraded/machined away     In sand casting, a single-use mold is produced by compacting a sand mixture around a pattern, which has the same shape as the final required component. The pattern might be made by machining timber or metal, or by additive manufacturing. The mold is prepared in two halves, the cope (top) and drag (bottom), with the sand being contained within a metal flask that has two interlocking parts. The pattern is removed from the compacted sand mixture before the mold is closed up. If re-entrant or hollow components are to be cast, one or more cores are introduced into the mold before the cope and drag are brought together. These cores are also single-use and may be made from sand that is bound with organic material such as gelatin. The mold needs to have several features in addition to the cavity that will contain the actual cast component. First we need a downsprue, or sprue, into which the molten metal can be poured. Second we need runners which are horizontal channels that carry the molten metal from the sprue to the mold cavity. Thirdly we need one or more risers, which allow air to escape from the mold as the metal enters, and are also designed to be the last part of the metal to solidify. Risers can thus provide a small amount of surplus material to compensate for the volume shrinkage that occurs when the metal solidifies. Risers need to be strategically positioned around the mold cavity to supply this material where it is needed. The design of sprues, runners and risers requires skill and experience, and is one of the key competitive advantages of successful foundries.   Photos       Materials #   Sand, or silica, is used as a mold material because of its high melting point (~1600 ˚C) relative to that of the material being cast (e.g. 660 ˚C for aluminum). Sand on its own, however, will not hold the shape of the mold. Green sand is a sand, clay, and water mixture which holds together via the capillary forces between particles and by particle jamming between the larger sand particles and the much smaller clay particles. Green sand has the advantage that it can simply be shaken off the cast component after solidification, and recycled many times.\n  If a mold cavity has particularly large unsupported regions, a stronger mold material may be needed. In this case the clay and water may be replaced by a stronger binder, which may thermally or chemically cure to make a solid mold material. Such molds are more robust but are not reusable.\n  An alternative approach is to use loose sand and compact it under vacuum between plastic sheets to make it solid. The plastic is vaporized as soon as the molten metal hits it.\n  Options for sand-based molds:  Green sand  Typically SiO2, particles a ≥ 10µm in diameter Mixed with 7-10% clay (e.g. kaolinite, 2SiO2.Al2O3.2H2O). Typically \u0026lt; 2 µm diameter Bound with 2-4% water Clay particles promote mechanical jamming of sand particles and with the water bind sand together Shake off and sieve to re-use   Dry or chemically bound sand  Mix sand with an organic binder May require heat to cure: 200 − 320 ℃ Or may cure via a chemical reaction Enables larger unsupported mold cavities than green sand       But sand harder to re-use: needs grinding down     Why use sand?  It is refractory: i.e. high melting point – higher than the metal/alloy being poured. e.g. silica: melts at 1600 ℃; pure aluminum: melts at 660 ℃    Gravity casting: pouring #   As molten metal is poured by hand from the crucible in which it has been heated, it accelerates under gravity and flows into the mold cavity. The height of the sprue is crucial in determining the speed with which the metal enters the cavity, and hence how long it takes to fill. If filling is insufficiently fast, there is a risk that metal will solidify before filling is complete; if, however, it is too fast, the momentum of the molten metal may dislodge sand from the walls of the mold, leading to the inclusion of sand impurities in the cast component and weakening the casting.\n  The speed can be estimated by considering the amount of gravitational potential energy that is converted to kinetic energy during the pouring process. The other important concept here is continuity, where we assume that the molten metal is incompressible (constant volume). So molten metal will flow at a higher velocity along narrower parts of a runner, for example.\n      Bernouilli’s Law (conservation of energy): #    We can usually neglect head losses and pressure changes:    Continuity (conservation of mass): #    Continuity of mass and energy together explain why the downsprue is sometimes tapered: to prevent a pressure drop and aspiration of air (or sand) from the sidewalls into the molten metal.    Mold filling time:     Solidification #   Solidification occurs when sufficient heat has been conducted out of the metal into the surrounding mold (or from the top of a sprue or riser to the air). The outside of the component will usually solidify earliest because of its proximity to the sand, leading smaller grains or crystals of metal to form near the surface of the component and larger, columnar grains to be directed radially towards the center of the component. This inhomogeneous grain structure may give undesirable mechanical properties which may need to be corrected by subsequent heat treatment or by machining back the surface.\n  A widely used model for solification time is Chvorinov’s Rule, in which the solidification time is expressed as the product of a mold constant, .$C_M$, and a geometrical term, .$(V/A)^2$. The mold constant is a purely material-dependent constant depending on the properties of the alloy being cast and the mold material. The geometrical term is the square of the .$V$olume to surface .$A$rea ratio of the component being cast. The reason the exponent is taken to equal 2 is that most of the heat leaves the cast material by conduction (rather than convection or radiation), so heat is transported by diffusion. The relevant timescale thus increases as the square of the relevant linear dimension for heat transport.\n  Total solidification time .$T_{TS}$ is composed of the sum of:  Pouring time, .$T_{MF} = V/Q$ Solidification time, .$T_S$  .$T_{TS} = T_{MF} + T_S;\\ \\ T_S \\gg T_{MF}$ (heat)     Chvorinov’s rule: $$T_{TS} \\approx C_m \\left(\\frac{V}{A}\\right)^n$$  .$V$: Mold Volume .$A$: Surface Area .$VA$ is geometry dependent only .$C_m$: Mold constant (material property) .$n \\approx 2$: heat transport from molten metal is largely by conduction; so is governed by diffusion of atomic vibrations – consider Fick’s laws of diffusion   Solidification begins from the outside of the mold cavity  Small “chill crystals” form (which can be machined away) Columnar grains grow inwards Equiaxed grains near center        Shrinkage #   Two types of shrinkage are relevant in casting. The first is solidification shrinkage, which is a volumetric reduction associated with the phase change from liquid (amorphous) to solid (ordered, crystalline). A good question to ask about solidification shrinkage is whether the material is effectively solid or liquid while this shrinkage is happening, as its state during shrinkage will determine the shape of a component after the shrinkage occurs. To answer this question, we can envision the liquid-to-solid phase change happening through the nucleation and growth of solid metal crystals within the cooling molten metal. Thus, up until the moment when solidification is complete, we can reasonably think of the material as still being fluid, so that gravity will cause it to fill the walls of whatever container it is in. Thus, solidification shrinkage will not be uniform in all directions, but rather will predominantly be in the vertical direction (see the shrinkage question in the homework on casting).\n  The second form of shrinkage is thermal contraction, a type of shrinkage that you have probably already encountered in other contexts. Here, the solid cast component reduces in dimensions linearly with temperature, as its temperature falls from the melting point down to the temperature at which it is extracted from the mold.\n  Cast components exhibit shrinkage:  Solidification shrinkage (due to liquid-to-solid phase change: disordered liquid becomes a denser, more ordered lattice structure). May lead to unwanted porosity if additional molten metal cannot enter the region vacated by the shrinking metal.       Thermal contraction (reduction in solid volume as component cools from melting point to room temperature). May lead to hot tearing/hot cracking since the material is relatively soft just below its melting point.     Possible defects and remedies #     Defect Description/cause Possible remedy/ies     Porosity Small voids in casting; caused by solidification shrinkage .$^1$ Appropriately placed risers to supply material during solidification; chills   Misrun Metal solidifies before reaching the extremities of the mold cavity Avoid high-aspect-ratio features in design; pour metal at higher temperature; use heated mold (e.g. cast iron); redesign sprue/runner/gate and/or add additional sprue locations   Hot cracking/tearing Differential thermal contraction of solidified material: material which has just solidified, but is still soft because of its high Chills to promote faster cooling of thicker sections so molten regions are not trapped inside the casting   Pin holes Air entrapped in molten metal flow More careful pouring; appropriate sprue design   Flash Metal escapes along parting line between two mold halves More careful packing of sand; post-processing of casting to remove flash   Cold shut Metal flows through multiple paths in mold and solidifies before the metal from the different paths meets Same remedies as for misrun   Cold shot Splattered, solidified metal entrained in flow Slower pouring   Sand wash Erosion of mold surface in metal flow Reduce pouring velocity/height   Sand blow Embedded sand particles in casting Careful design of sprue taper    .$^1$: Voids can appear in the more massive regions of a casting which solidify later than the surrounding material, or the surface of a casting sinks, producing aVdefect known as a pipe. Some of the effects of solidification shrinkage can be counteracted by introducing chills, which are more thermally massive and conductive regions of a mold, made, e.g., of steel and embedded in the mold in close proximity to the more massive regions of a cast component to accelerate cooling.\nOther Casting Processes #  Vacuum molding: a sand-casting variant #   Sand held in place under compressive stress No need for binders – sand is easy to recover Plastic burns away quickly when molten metal poured   Low-pressure casting #   Rather than pouring the molten metal directly into the mold, it is held in a ladle beneath the mold, and pneumatic pressure is used to drive the metal through a tube into the mold. This has the advantage that it can be automated, so that filling time can be made highly repeatable. It also helps to prevent the oxides that form at the surface of the molten metal from being injected to the mold — in gravity casting, some of these oxides risk entering the mold during pouring and weakening the cast component. The mold in low-pressure casting is typically metallic (e.g. cast iron) and reusable.\n  Advantages over sand casting:  Metal enters cavity at a more controlled velocity Mold is reusable: better surface finish Molten metal is taken from center of the bath – scum (oxides) from surface does not enter the mold     Hot Chamber #   Suitable for metals with lower melting points (e.g. Zn, Sn, Pb, in some cases Mg) Plunger system exposed to high temperatures: the metal being cast must not chemically attack this mechanism Pressures around 7-35 MPa Production rates up to 500 parts per hour      High-Pressure Die Casting (Cold Chamber) #   Die casting comes in two main types: hot chamber and cold chamber. The choice of machine design depends on the melting point of the metal to be cast, with the hot chamber approach more suited to lower-melting-point materials for which it is feasible to build a plunger assembly that can be immersed in the molten material. The pressures in die casting range from several MPa to over 100 MPa, which is comparable with plastic injection molding and enables molten metal to be driven rapidly into the fine geometries in a mold. Casting dies are made of alloys with higher melting points than the metal to be injected, and require highly precise machining.\n  Suitable for metals with higher melting points (e.g. Al and alloys, brass, Mg alloys) since plunger mechanism is not immersed in the melt Pressures around 14-140 MPa are needed because the molten metal cools more rapidly These high pressures can cause flash Not as fast as hot-chamber die casting because of the ladling process   Rubber Plaster Molding #   Rubber-plaster molds at General Foundry “Chills”   Investment casting #   Involves coating a single-use wax pattern with a slurry which is a suspension of ceramic particles in liquid. The slurry is baked to solidify it, the pattern is melted out, the metal cast and the mold then broken off after solidification. The pattern can be produced to extremely fine tolerances (e.g. by 3D printing or machining), and the slurry particles are far finer than sand particles, so the surface finish achievable in this way is far superior to that of sand casting.\n  Prepare wax pattern Several components may be connected on a “tree” Coat in fine-particle refractory material (ceramic slurry) Build up and solidify refractory coating Melt out wax Pour molten metal and solidify Break mold away from component    Other forming processes #  Drawing #   Pull solid material through a die, instead of pushing as in extrusion Strain-hardens the material as well as reducing diameter    Deep drawing #   Rapid way of forming thin-walled, 3D metal shapes  Sinks Drinks cans     Pressing #    Deformation of sheet metal between tools/dies #   Vehicle body panels Introduce stiffening features, curvature  Forging #   Deforming metallic materials at significant fraction of melting temperature Pressing nearly molten metal with a die to form a shape  60-70% melting point   Can be open- or closed-die (left and right below, respectively)   Rolling #   Reduce thickness of metallic sheet between stacked rollers Can be a continuous process Material is generally near but below melting point Cold rolling possible for small thickness reductions: smooth finish    "},{"id":19,"href":"/cogsci-c100/mindfulness/","title":"Mindfulness","section":"CogSci C100","content":"Mindfulness, awareness and acceptance #  Why Study Mindfulness? #   Western research has indicated that meditation can be effectively used to:  Treat psychological disorders, including anxiety, depression, substance abuse, eating disorders, sleep disorders, ADHD, and conduct disorder  Recent reviews indicate that overall effect sizes are modest, but mindfulness is still considered an evidence-based treatment for most psychological disorders The small effects are comparable with what would be expected from the use of psychotropic medications (e.g., antidepressant) in a primary care population but without the associated toxicities   Treat physical conditions, including chronic pain and cardiovascular disease, and enhance immune system function Lengthen life span quite dramatically \u0026ndash; 30% reduction in mortality due to heart disease and 49% reduction in mortality due to cancer, according to one 20-year study (Schneider, Alexander, Staggers, et al., 2005)  If this is replicable then you\u0026rsquo;d make lots of money \u0026ndash; part of the reason for the research interest   Slow the cognitive decline associated with “normal aging” (Lazar, Kerr, \u0026amp; Wasserman, 2005; Luders, Toga, Lepore et al., 2009) Increase activity in areas of the brain associated with optimism, empathy, attention, and emotional regulation  Highly trained “super-meditators” show activity in these regions that is off the charts      Calm-abiding practice #   All mindfulness therapies share a common aim of cultivating an attitude of awareness of the present moment with acceptance  This is an attitude that extends toward whatever is arising at the moment, including thoughts, feelings, and experiences of contact with the outer world The aim is in line with the psychoanalytic view that it is primarily experiential avoidance that causes distress    Research #   Neuropsychological evidence that awareness/labeling of negative emotions actually reduces their intensity \u0026ndash; fMRI study by Lieberman, Eisenberger, Crockett et al. (2007)  Participants were shown frightening faces/faces expressing strong emotions and asked to choose a word that described the emotion on display       Controls were asked merely to identify the gender of the people in the photos - Labeling the fear-inducing object  Reduced activity in the amygdala, the seat of fear and other negative emotions Increased activity in a parts of the prefrontal cortex (right ventrolateral and medial PFC) involved in vigilance and discrimination, relative to controls     Naming the emotion transformed the images from objects of fear to objects of scrutiny, potentially resulting in a more effective response      Study on spider phobia (Kircanski, Lieberman, \u0026amp; Craske, 2012)  Four experimental conditions that differed in their instructions for what to do with the anxiety  Label the anxiety felt about the spider Reappraisal: think differently of the spider so that it feels less threatening Distract from the anxiety elicited by the spider No specific instruction (control)   Later (on Day 2 and Day 9), participants returned to the lab and were again exposed to spiders to test the long-term effects of their emotion manipulation   Those who had been assigned to labeling their emotions had lower physiological reactivity to the spiders, as measured by skin conductance responses Within the affect labeling condition, participants who verbalized a larger number of fear and anxiety words had even fewer skin conductance responses   Researchers recruited participants who had a spider phobia and exposed them to spiders    Limitations #   Unfortunately though, being accepting and nonjudgmental is easier said than done because of our natural human tendency to avoid painful experiences  It is very difficult, if not impossible, to force ourselves to fully experience situations and emotions that we deem to be painful   Traumatic experiences are a classic example of this However, even in ordinary life, we are constantly dissociating from painful situations and emotions \u0026ndash; or ones that we think may potentially cause pain  This may range from actual pain-inducing experiences to insights that might cause us to feel bad about ourselves     There is a limit to the extent to which we can force ourselves just to “be with” our anger or sadness or fear    Meditation #   Meditation is a technique that can help resolve this problem of experiential avoidance  Step One in mindfulness practice is to engage in focused meditation because\u0026hellip;  It is very difficult to be aware of ourselves and our surroundings if we are afflicted by \u0026ldquo; monkey mind\u0026rdquo;  Focused meditation allows us to calm monkey mind   Focused meditation ultimately enables us to connect with the nonmoving mind and the “suchness” of experience, which produces a sense of general “Okness”     Focused meditation is just calmly abiding, with the object of concentration \u0026ndash; not obsessive glomming  There should be a relaxed connection with the object The aim is to “be present with the object,” not to lock onto it and grip it like a dog, or to concentrate on it the way you might concentrate on memorizing the details of an image As the meditation develops, allow your perception of the object to change as you are present with the object on more and more subtle levels…  The focus becomes just stillness itself, rather than the physical object You find that there is something in you that is imperturbable and open, fundamentally calm Developing one-pointedness of concentration enables you to find one-pointedness in yourself, the non-moving mind, which resolves all things     Stilling the eyes is a way of stilling the mind\n   Instructions #   Find a quiet place and sit in a comfortable position with your spine straight. You can sit cross-legged or in a chair. Tilt the chin very slightly down but do not allow the head to loll forward. Place your hands comfortably on your lap. Take a few deep breaths. Collect your attention, and begin to move it slowly down your body. Notice the sensations in each part of your body. Relax any tensions, particularly in the face, neck and hands. Direct your gaze softly downwards or close your eyes if you wish. Focus on an object (e.g., a bit of the wall in front of you, a statue, a sound like “Om”) or on the breath. Be fully present with the object of your attention. If you are focusing on the breath, don’t gloss over the inhalation and say, “OK, well, this is the inhalation part” \u0026ndash; that’s just labeling it. “Be with” each in-breath for its full duration and with each out-breath for its full duration, as if you were riding the waves of your own breathing. Seek nothing. No “next”! Integrate your whole body in the experience. Meditation is state of full body awareness. If your attention wanders (and it will!), simply release the thought and focus back on the object of your attention. After a while, you can try noticing the distractions and acknowledging it with a simple word, e.g., thinking, wandering, hearing.  Meditation Q \u0026amp; A #   If one has a physical condition that makes sitting uncomfortable, is it OK to meditate while lying down or standing up?  Yes, and in fact, depending on the physical condition, that might be highly advisable There are four standard meditation positions: sitting, lying down flat on one’s back, standing, and walking   Can focused meditation produce negative effects?  In general, focused meditation is considered a safe practice, but there are large individual differences in how people respond to any practice, so use good judgment and stop and seek help when necessary  In particular, for those with trauma or abuse histories (or “fear types”), even basic meditation practices can can lead to intense, and possibly uncomfortable emotions   In those cases, when doing focused meditation, it is recommended that one direct attention to an external object or the feet, rather than the breath, as the latter may trigger too many memories and emotions      Lurid example of the agitated mind and how it causes us to be unable to sit alone with our thoughts and emotions  Participants were asked to sit in a chair, without a device or a book and without falling asleep, for 6 to 15 minutes They were given the option to self-administer mild electric shocks rather than just sit alone with their thoughts   67% of men and 25% of women did just that! (Wilson, Reinhard, Westgate, et al., 2014)    Relationship between attention and happiness #   Study in which 1000 people were texted at random times throughout the day As soon as participants received text, they had to answer 3 questions  What are you doing right now? Where is your mind right now? Is it focused on what you’re doing or is it focused elsewhere? How happy or unhappy are you right at this very moment? (Killingsworth \u0026amp; Gilbert, 2010)   Results:  Average American adult spends 47% of waking life not paying attention to what they’re doing When they were not paying attention, they were significantly less happy  “A Wandering Mind Is an Unhappy Mind” (Killingsworth)\n     Meditation and the Default Mode Network #   Mode Network (DMN) when meditating, as well as when they are not meditating The DMN or “task negative network”  Includes posterior cingulate cortex (PCC), medial prefrontal cortex (mPFC), and angular gyrus Is active when we are not focused on a particular task \u0026ndash; rumination Is involved in self-referencing, recognition of emotions in others, remembering the past, and imagining the future    Meditators from various traditions show reduced activity in their Default     Is associated with ruminating about the past, worrying about the future, thinking about what other people are thinking about you    Mindfulness as a Two-Part Process #   However, use of calm-abiding practice (focused awareness) to stabilize the mind is only the first step in mindfulness practice This first step is what make the second step \u0026ndash; mindfulness or awareness of the present moment with acceptance (open monitoring) \u0026ndash; possible because\u0026hellip;  Calm-abiding practice connects you with the suchness of things, with the ground of reality, which imbues all things with a sense of “Okness” This deep state causes the sense of judgment to naturally drop away, and there is a cognition that everything is exactly as it should be  Whatever is felt is meant to be felt, and whatever is thought is meant to be thought  “There is no where you can be that you were not meant to be” ♬\n       Mindfulness practice #   When a thought arises, note  How it manifests in your body How it manifests in your energy (i.e., emotionally) Whether it is a positive, negative, or neutral thought   These are all implicit and shouldn\u0026rsquo;t require any thought       You can also try noting more specifics about the thought, e.g., whether it is about wanting, grasping, anger, fear, etc., as well as the kind of self the thought is associated with  Integration of body and mind #   A number of modern-day teachers have emphasized that inclusion of some sort of practice that integrates the physical body with the mind (such as various types of yoga, running, etc) is critical for mindfulness to be effective for modern laypeople who do not have luxury of spending 12 hours a day meditating To a large extent, becoming more mindful or aware of one’s thoughts and emotions means becoming more aware of one\u0026rsquo;s body  Meditation can help us “physicalize the mind,” so that when we have a negative thought, we can actually feel it almost as something physically pulling us off center  This can make it vastly easier to control negative thoughts and emotions in daily life   When you have a negative thought, it\u0026rsquo;s as if someone is pulling you off axis \u0026ndash; mindfulness is being aware of this connection   A meta-analysis of 78 fMRI studies of meditation found that one of the main commonalities among various different styles of meditation was changes in activity of the insula (Fox, Dixon, Nijeboer et al., 2016)  The insula specializes in body awareness     Some yogis have demonstrated quite remarkable control over body functions, such as breathing, heart rate, body temperature and other vital function  e.x. Tummo practice        Instructions #   When your attention is relatively stable on the object of attention, try shifting your awareness to the process of thinking itself. Watch thoughts come into and leave the field of your attention. Try to perceive them as “events” in your mind. Note their content and their charge while, if possible, not being drawn into thinking about them, or thinking the next thought, but just maintaining the “frame” through which you are observing the process of thought. Note that an individual thought does not last long. It is impermanent. If it comes, it will go. Be aware of this. Note how some thoughts keep coming back. Note what feelings are associated with different thought contents. If you get lost in all this, just go back to focusing on the object.  Important: this exercise requires great concentration and should only be done for short periods of time, like two to three minutes per sitting in the early stages.    Insight #  Working with Negative Emotions #   If you are in an overall relatively positive frame of mind and the emotion is not very strong:  Try to experience the emotion fully in your body-energy-mind, that is, focus on the energy and physical sensations of the emotion, but do not let yourself get caught up in the content, in the story associated with the emotion  You may not feel happy due to some event/circumstance that clouds your vision. Recognize these emotions\u0026ndash; what is this stimuli evoking that you wish to avoid? Try to focus on this emotion and realize that it is just that \u0026ndash; an emotion, sensations in your body. They are not the end-of-the-world, just sensations, and as such they are malleable and can be changed if you believe so.\n  Initially, you should only try to do this very briefly  This practice is not about analyzing thoughts or emotions If you are still thinking about the emotion or the situation that caused the emotion 30 seconds later, STOP (this is important \u0026ndash; you can harm yourself!)        Once you have substantial meditation experience, when you experience a negative emotion, you can\u0026hellip;  Look straight at the emotion and let it dissolve or “liberate” as it arises  It\u0026rsquo;s easy to recognize this, and even tell yourself this \u0026ndash; it\u0026rsquo;s another to truly embody this belief   Instantaneously see the various factors that caused the emotion to arise   That is, mindfulness gives us insight into the narrative we have about ourselves  Rather than holding beliefs (e.g., “I am worthless”) to be a true description of who we are, we see the narrative as a constellation of thoughts This can foster more breathing room and lead to increased well being It’s not so much about changing the narrative, but rather about changing our relationship to it     Your ordinary mind cannot do this: remember that meditation is not done with the ordinary thinking mind  When we think, we just stay caught in our own conceptual systems, our own habitual ways of looking at things   Meditation accesses a deeper mind with much greater awareness that is able to solve problems more effectively    Instructions (Dealing with Negative Emotions) #   Start with calm-abiding meditation. Now if there\u0026rsquo;s something difficult that\u0026rsquo;s happening for you \u0026ndash; a difficult emotion, or a physical sensation that\u0026rsquo;s hard, let your attention go to that. It may be an aching in your shoulder or back, or a headache, or it could be a sense of sadness, or anxiety, or anger.  Where do you feel that sensation in your body? Where do you feel that emotion in your body? Notice it, just notice it for one moment. Tap into it, feel it. Make sure to breathe.   And now return your attention back down to the object of concentration and the centered stillness. And just let yourself stay there for a moment. Feeling it, sensing it, relaxing, maintaining the mindfulness, yet giving yourself a break from what could be potentially overwhelming to feel. And now once again return your attention to that part of the body that feels unpleasant \u0026ndash; the body ache or pain, or the emotion, the sensations of the emotion in your body, the vibrations in your chest, or the clenching in your belly, or the tightness in your jaw. Just notice, and breathe, and let it be there. Let whatever is there, be there. And then bring your attention again back down to the feeling of centeredness. Relaxing, staying present and alert, feeling the safety, the connection in that place. Now let yourself stay connected to this place, but see if you can cast what we might call a sidelong glance at the difficult area in your body. Is it possible to still feel connected to you body in the area that feels good, and yet know there\u0026rsquo;s something going on that feels unpleasant, and just let it be there? Keeping maybe 75% of your attention on the part that feels peaceful and at ease, still breathing, casting the sidelong glance at this difficult area, noticing what happens to it. Is it growing or shrinking? Is it changing, shifting into something else? Become aware of whatever it is it\u0026rsquo;s doing, relaxing, breathing.  Using Mindfulness to Break Habits #   Develop greater awareness of how you are feeling immediately before you engage in the problematic behavior Develop greater awareness of how you feel during the activity Devise an alternative behavior  Note how you feel when you utilize the replacement activity instead (kind of self-conditioning)   Be honest if you are unable to implement the replacement activity\u0026ndash; simply note how you feel as you continue to engage in the old habit and in particular, how you feel when you finally stop  The end sucks, and your body will dwell on this emotion. Thus, that will reduce the odds or your engaging in the behavior again in the future   The promise of happiness from cravings often misleads, so one strategy for overcoming addictions is to mindfully focus attention on the actual experience when indulging a craving or temptation, so as to compare it with the expectation of reward that preceded it. – Kelly McGonigal\n     Ex: Binging on hot cheetos and YouTube videos  Become more aware of how you feel physically and emotionally as you sit there munching, watching video after video  Perhaps you are feeling tired or hopeless Once you recognize that, you can see if you can devise some other activity that will more effectively alleviate the tiredness or sense of hopelessness, e.g, going to bed or talking to a friend   Again, note that this is simply data collection  It’s not about beating yourself up for being “bad” or “lacking in discipline.” Just be fully aware of what you are experiencing   Also, become more aware of exactly how you feel when you finally do turn off the computer and consciously note those feelings  This will increase your chances of being able to prevent a repetition of the behavior in the long run   Mindfulness might also allow you to notice things that help stop the behavior, e.g., only taking small portions so that you would need to get up to obtain more hot cheetos    Guided Meditations #   There are many websites and apps now with guided meditations  Some of these have practices that are empirically validated and others don’t Here are a couple of websites with evidence-based practices:   UCLA Mindful Awareness Research Center (MARC)  Ronald Siegel, assistant clinical professor of psychology at Harvard Medical School      Acceptance and transformation #   Making peace with where we are  Feeling and accepting our negative emotions allows us to transform those emotions On the other hand, ignoring, repressing, denying, or even trying to change negative emotions ties up our energetic resources and actually makes real change much more difficult  “What you resist, persists”\n  This is the underlying premise of mindfulness practice and, as discussed earlier, it is also supported by neuropsychological research (Lieberman et al., 2007; Kircanski et al., 2012)   But if I accept myself fully, won’t that undermine my motivation to try hard and improve?  Actually, it’s just the opposite: beating up on yourself results in a less effectual response:  If an experience is painful, we tend to avoid looking at it, so we don’t learn from it The attempt to suppress the negative thoughts and emotions saps our energetic resources Feeling bad about ourselves causes us to engage in more unhealthy habits      Self-compassion study (Breines \u0026amp; Chen, 2012) #   Participants were told that the purpose of the study was to understand the relationship between test performance and personality and asked to identify their biggest weakness Then they took a difficult test (a 10-item version of the GRE antonyms test) Afterwards, they were given an opportunity to study a list of words and definitions that would be on a subsequent 10-item antonyms test for as long as they wanted  Self-compassion group: saw an additional statement embedded in the instructions that read, “If you had difficulty with the test you just took, you’re not alone. It’s common for students to have difficulty with tests like this. If you feel bad about how you did, try not to be too hard on yourself.” Self-esteem control condition saw an additional statement that read, “If you had difficulty with the test you just took, try not to feel bad about yourself—you must be intelligent if you got into Berkeley.”   Results:  No one guessed the hypothesis that viewing test failure in a certain way might affect study time or effort Self-compassion increased study time, which in turn predicted higher test scores, though it did not directly lead to improved performance    Open, Nonjudgmental Awareness #   Mindfulness practice is about developing greater awareness Taken to higher levels, this can produce states of great bliss  If we fully connect with the “suchness” of things in our body-energy-mind, we find a ground which holds everything and gives rise to a sensation of great bliss in the center of the body  This takes the truism that true happiness must come from within to a whole new level!   The experience of bliss in turn makes it possible to connect even more fully with the suchness of things, to be even more inclusive\u0026hellip;   The above is accompanied by a transformation of perception  The big secret is that enlightenment is right here right now You see that everything is perfect just as it is  You don’t need to change anything bad into anything good or to “fix” yourself in any way \u0026ndash; wabi-sabi Ironically, this actually makes it easier to effect changes because your energy is no longer all tied up in beating yourself up      Obstacles (Optional) #   Mental elaborations stand in stark contrast to the kind of open, nonjudgmental, direct awareness described above  As Rick Hanson points out, most of the negative emotions we feel do not come from actual aversive events, but from our reactions to them Suppose you’re walking through a dark room at night and stub your toe on a chair  Right after the first stab of pain comes “Who moved that darn chair?!” This then continues to elaborate, maybe moving to the person whom you think moved the chair and all the evil things they have done to you     In addition, attachment to/obsession with particular outcomes prevent us from experiencing the kind of open, nonjudgmental awareness associated with deep meditative states   Applying Mindfulness to Daily Life #   Mindfulness practice is not just about sitting on a meditation cushion; it’s about a way of being that extends to how we engage in all of our daily activities  It’s knowing that you are exactly where you should be this moment and appreciating this moment, engaging in activities with full focus of attention   Ex: Walking meditation is about really enjoying the walking \u0026ndash; walking not in order to arrive, but just to enjoy each step   We shake off all worries and anxieties, not thinking of the future, not thinking of the past, but just enjoying the present moment We are aware of the contact between our feet and the Earth  “Walking as if we are kissing the Earth with our feet” \u0026ndash; Thich Nhat Hanh\n    Similarly, if we try to rush through washing the dishes in order to get to dessert, it will become an unpleasant task. And we will be equally incapable of enjoying our dessert\u0026hellip;  Focusing on the future becomes a habit \u0026ndash; you cannot just selectively focus on pleasant tasks  “With the fork in my hand, I will be thinking about what to do next, and the texture and the flavor of the dessert, together with the pleasure of eating it, will be lost. I will always be dragged into the future, never able to live in the present moment.” \u0026ndash; Thich Nhat Hanh\n      If you ask a Zen teacher how to find enlightenment, he might answer, “Have you eaten? Then wash your bowls.”  If you cannot find the meaning of life in an act as simple as that of doing the dishes, you will not find it anywhere        Instructions: Mindful Eating #   Sit comfortably in a chair. Place a raisin in your hand. Examine the raisin as if you had never seen it before.  Imagine it as its \u0026ldquo;plump self\u0026rdquo; growing on the vine surrounded by nature. As you look at the raisin, become conscious of what you see: the shape, texture, color, size. Is it hard or soft? Notice any thoughts that arise.   Bring the raisin to your nose and smell it.  Are you anticipating eating the raisin? Is it difficult not to just pop it in your mouth? How does the raisin feel? How small it is in your hand?   Place the raisin in your mouth. Become aware of what your tongue is doing. Bite ever so lightly into the raisin. Feel its squishiness. Chew three times and then stop. Describe the flavor of the raisin. What is the texture? As you complete chewing, swallow the raisin. Sit quietly, breathing, aware of what you are sensing. Then repeat with other raisins.  Clarifications #   Mindfulness doesn’t just mean “noticing things”  It’s about being present with experience in a way that’s much more vivid, immediate, and real Even “negative emotions” are perceived as juicy experiences that are “OK” The world will seem to light up like a lightbulb    Awe #   Asked what Zen training leads to, a Western student in Japan answered  “No paranormal experiences that I can detect. But you wake up in the morning and the world seems so beautiful you can hardly stand it.”\n  Research has indicated that the emotion that confers the greatest health benefits may be awe (Stellar, John-Henderson, Anderson et al, 2015)  Participants who scored high on awe had the lowest levels of interleukin-6, which is tied to inflammation (and thus mortality)    Instructions: Mountain Meditation #   Find a time when you can sit for half an hour without interruption. Assume a comfortable erect position with back erect, chin slightly tucked in towards the chest, both feet flat on the floor (if sitting in chair), and hands quietly resting on thighs. Tense and release the muscles from your toes to your head. Observe your breath and remain in tune with feeling the air pass in and out of your nostrils with each inhalation and exhalation as you continue the meditation. (Continued on next slide)  Mindfulness-Based Stress Reduction (MBSR) programs incorporate a number of mindfulnessrelated practices, such as Mountain Meditation and Lovingkindness Meditation   Visualize a mountain and then become that mountain  Imagine yourself as being that majestic mountain with your summit in the clouds. Imagine how solid and strong and how connected to the earth you are, for you, the mountain, have stood for thousands of years.  Breathing in, I see myself as a mountain Breathing out, I feel solid and strong.\n  The weather has always been in a state of flux around you. The views change from blue sky views with gentle breezes and showers to mighty banks of storm clouds, dispensing heavy downpours, to sleet and snow. Yet, you have stood firm and immovable, and the winds of change have whirled for centuries around you without any noticeable effects.  Breathing in makes me calm. Breathing out helps me settle.\n  Just as changes in weather whirling about outside of you, the mountain, provoke no angst, the emotions, activities and situations that whirl around you in your everyday life shall not disturb you when your meditation ends. You shall remain tall and strong and connected.  Breathing in, I feel secure. Breathing out, I feel grounded.\n  You shall remain upright, firmly grounded and connected to the earth, regardless of the weather whirling around you. So now just sit and continue to follow your breath as you sink deeply into your majestic mountain base without collapsing your spine. Become one with the feelings of solidity, strength and connection.  Breathing in, I feel still and connected. Breathing out, I reflect things as they are.\n  End your meditation when you feel it is time to do so.    Lovingkindness Practice #  Instructions #  Preliminary practice #   Start by giving loving-kindness to yourself because without loving yourself, it is almost impossible to love others. If you are an empty cup, you have nothing to give.  May I be happy May I abide in well-being May I be secure May I dwell in safety   Practice this regularly for some days to establish a strong sense of loving-kindness for yourself.  Main practice #   Visualize a love that someone gave you that really moved you, perhaps in your childhood. Remember a particular instance when they really showed you love, and you felt their love vividly. Now let that feeling arise again in your heart and infuse you with gratitude.  As you do so, your love will go out naturally to that person who evoked it. You will remember then that even though you may not always feel that you have been loved enough, you were loved genuinely once. Knowing that now will make you feel again that you are, as that person made you feel then, worthy of love and really lovable.   Let your heart open now, and let love flow from it; then extend this love to all beings.  Begin with those who are closest to you, then extend your love to friends and to acquaintances, then to neighbors, to strangers, then even to those whom you don’t like or have difficulties with, even those whom you might consider as your “enemies,” and finally to the whole universe. Let this love become more and more boundless. (From The Tibetan Book of Living and Dying)    Research on Compassion Practice #   Study on compassion meditation in long-term Tibetan meditation practitioners who had had logged in 10,000-50,000 hours of practice (Lutz, Greischar, \u0026amp; Rawlings, 2004)  Meditators were asked to engage in compassion meditation during EEG study Compassion meditation does not focus on particular objects, memories, or images; rather the emphasis is on generating feelings of benevolence and compassion, causing them to “pervade the mind as a way of being” Controls were undergraduates who had been given a crash course in compassion meditation and had practiced for an hour   Results:  Long-term practitioners produced showed high levels of activity in gamma-band frequencies (25-42+ Hz) and increased neural synchrony  Larger the waves, the more in sync your brain is (this naturally decreases with age)   This involves large regions of the brain pulsing in synchrony 30-80 times a second As they went deeper into meditation (jhana states), there appeared to be both a spreading and a strengthening of gamma wave activity When controls engaged in compassion meditation, they also showed an increase in gamma activity, but the increase was slight     The color scale indicates the percentage of subjects in each group that had an increase of gamma activity during the mental training: (Left) Controls; (Right) Practitioners   Correlation between the length of the long-term practitioners\u0026rsquo; meditation training and the ratio of relative gamma activity averaged across electrodes in the initial baseline condition   Gamma waves and neural synchrony #   Gamma waves  Type of very high-frequency brain wave Size of the gamma wave is related to the number of neurons firing in sync Research has linked neural synchrony of high-frequency brain waves to enhanced attention, working memory, learning and conscious perception  Greater synchrony between various sections of the brain indicates greater integration of cognitive and affective functions and less dissociation Compartmentalization of brain functions is associated with aging and cognitive decline     What the meditation practitioners themselves reported experiencing during this state:  A change in the quality of moment-to-moment awareness, bringing with it a vast panorama of perceptual clarity  “It is as if a mental fog lifts, one that you did not realize had been impeding your perception” (Davidson)\n    Monks who had spent the most years meditating generated the highest levels of gamma waves  Increased gamma activity and neural synchrony were evident in the long-term practitioners even when they were not meditating    Gamma Wave \u0026amp; Cognitive Functioning #   MIT neuroscientists found that exposing mice to strobe lights and clicking sounds at frequencies that stimulate gamma waves reduced levels of beta-amyloid associated with Alzheimer’s and improved cognitive function (Martorell, Paulson, Suk et al., 2019)   Study 1:  Mice were engineered to exhibit Alzheimer’s-like qualities Exposed to clicking sounds at 40 Hz for an hour a day for a week   Results:  Induced synchronized gamma-wave oscillations in the brain  Gamma waves are involved in concentration, sleep, perception, and movement, and are disrupted in patients with Alzheimer’s   Reduced levels of beta-amyloid and tau-proteins in the auditory cortex and nearby hippocampus  Increased activation of microglia, which is important in clearing harmful debris, as well as improved functioning of blood vessels   Mice performed better on memory tasks, including recognizing objects and navigating a water maze to find a hidden platform      Results:  Increased gamma brain waves in the visual cortex, hippocampus, and prefrontal cortex Reduced neuronal and synaptic loss in these brain regions Reduced inflammation Improved performance on memory tasks Findings point to an overall neuroprotective effect, even in the later stages of neurodegeneration New clinical trials starting using human participants       Study 2:  Mice were exposed to a combination of light and sound stimulation (Martorell, Paulson, Suk et al., 2019)   Results:  Expanded effects to prefrontal cortex Resulted in clustering of microglia around amyloid deposits and reduced amyloid pathology Effects were short-lived, however, diminishing a week after stimulation      Longer-term follow-up study on mice with more advanced Alzheimer’s disease  Mice given 6 weeks of gamma entrainment using strobe lights (Adaikkon, Middleton, Marco et al., 2019)         Optimism and prefrontal dominance #   EEG studies by Richard Davidson found that meditation practice is associated with increased left prefrontal activity (Davidson, 2012)\n  As mentioned earlier, left prefrontal cortex brain activity is known to be associated with positive outlook and feelings of happiness and well-being (Davidson, 2012) Meditation, Prefrontal Dominance \u0026amp; Optimism  Early on, Davidson had noticed that an elderly Tibetan monk in one of his studies showed much greater predominance of activity in the left prefrontal than any of the other people previously tested Research on other long-term meditators provided further confirmatory evidence For instance, one meditation adept, Matthieu   Ricard, showed increased left pre-frontal cortical activity that was 4.5 standard deviations outside the standard bell curve        An early study found that less extensive meditation practice (40 minutes a day for 8-10 weeks) was also associated with a significant shift in hemispheric dominance In addition, degree of shift in activity from right to left prefrontal was found to correlate with enhancement in immune system (resistance to flu virus) (Davidson, Kabat-Zinn, Schiumacher et al., 2003)   Left Right Brain Dancer #      Empathy and ability to identify microexpressions #  Neurological Effects of Mindfulness #   MRI study on Western lay practitioners who incorporated meditation practice into their daily lives (Lazar, Kerr, \u0026amp; Wasserman, 2005)  Meditators averaged 6.2 hours of practice a week for 9.1 years   Compared to control participants, showed thickening in parts of prefrontal cortex and the right anterior insula  These regions of the brain are involved in attention, sensory processing, and empathy Cortical growth was not due to the growth of new neurons, but resulted from  Wider blood vessels More supporting structures such as glia and astrocytes Increased branching and connections         Between-group differences in prefrontal cortical thickness were most pronounced in older participants, suggesting that meditation might be particularly important in preserving cognitive functions as people age      VBM study on long-term meditators found similar effects  Lay practitioners who had practiced meditation for 10-90 min daily for an average of 24 years   Meditation was associated with increased gray matter volume in areas important in emotional regulation and memory, including  Orbitofrontal cortex Hippocampus   Meditation increases density of gray matter in frontal and temporal in much the same way that physical exercise increases the size of muscles (Luders, Toga, Lepore et al., 2009)    Other Cognitive \u0026amp; Affective Benefits #   Paul Ekman found enhanced ability to identify microexpressions in meditators  A series of faces displaying various expressions was shown in very quick succession The target expression remained onscreen for one thirtieth of a second Participants were asked to identify that expression         The two experienced Western meditators whom Ekman tested achieved results that were far better than those of 5000 participants previously tested  The ability to recognize such fleeting facial expressions has been associated with a capacity for empathy and insight, as well as openness to new experiences, intellectual curiosity, and general reliability and efficiency  “They do better than police men, lawyers, psychiatrists, customs officials, judges - even secret service agents” \u0026ndash; the group that had hitherto proven to be the most accurate, according to Ekman\n     Psychological effects of mindfulness #  Treatment of Psychological Disorders #   Research has indicated that mindfulness practices are useful in the treatment of a wide array of psychological disorders, including:  Anxiety and depression (Hofmann, Sawyer, Witt, \u0026amp; Oh, 2010) Substance abuse (Melemis, 2008) Eating disorders (Kristeller \u0026amp; Hallett, 1999) Stress (Grossman, Niemann, Schmidt \u0026amp; Walach, 2004)   Effects of meditation on these psychological, as well as physical, conditions are probably mediated at least in part by reduction in cortisol levels Research by Herbert Benson in the 1970s (primarily on transcendental meditation) found that meditation is associated with“a wakeful, hypometabolic state of parasympathetic activity” (fancy way of saying relaxed)  Research #   Research on use of mindfulness in treating psychological disorders in children and adolescents:  14-18 year olds who took an MBSR class reported a decrease in anxiety, depression, and somatic complaints, as well as an increase in sleep quality and self-esteem, compared with controls Meta-analysis of 15 studies on children and adolescents found that mindfulness was effective in treating anxiety disorders, ADHD, substance abuse, sleep disorders, and conduct disorder (Biegal, Brown, Shapiro, \u0026amp; Schubert, 2009) More recent reviews have found that meditation enhances ability to regulate emotions and attention in children (Burke, 2010) (Meeiklejohn, Phillips, Freedman et al., 2012; Cairncross \u0026amp; Miller, 2016)    Mindfulness and Subjective Well-being #   Research on mindfulness practice and subjective well-being (self-reported happiness)  Brown (2009) found that a large discrepancy between financial desires and financial reality was correlated with low subjective well-being but that the accumulation of wealth did not tend to close the gap Mindfulness practice however was associated with a lower financial-desire discrepancy and thus higher subjective well-being  Mindfulness may promote the perception of “having enough”      Optional #   2014 meta-analysis published in JAMA Internal Medicine called into question the effectiveness of mindfulness training programs in improving mental health and reducing stress-related behavior  The meta-analysis examined 47 randomized controlled trials of mindfulness meditation programs, which included a total of 3,515 participants Studies were primarily 8-week-long mindfulness training programs that used psychological and behavioral assessments, rather than neuroimaging Along with mindfulness, meta-analysis included meditations that emphasized use of a mantra  Mantra: repetition of a word or phrase in such a way that it helps one transcend to an effortless state where focused attention is absent (Goyal, Singh, Sibinga et al., 2014)     Results:  Meditation programs resulted in  Only moderate reductions in anxiety, depression, pain, and stress/distress   These small effects were comparable with what would be expected from the use of antidepressants but without the associated toxicities   Problems identified in review:  Use of outcome measures that can be easily biased by participants’ beliefs in the benefits of meditation Control participants that received less time and attention from the teacher or the group than those in meditation program Very few mantra meditation programs met inclusion criteria   Reviewers pointed out that effectiveness of programs may depend in part on  Type of meditation practice Amount of training Use and qualifications of instructor Degree of emphasis on religion or spirituality Whether program integrated dietary regimens and/or movement exercises (e.g., yoga)     Most forms present meditation as a skill that requires expert instruction and time dedicated to practice   Research Issues #   The modest psychological effects found in studies of short-term mindfulness contrasts with the much larger effects of neuroimaging and reaction time studies on long-term meditation practitioners  This suggests that  Results of meditation studies depend in part on amount of practice and amount of training/teaching received by practitioner Changes in brain function and structure may precede noticeable psychological and behavioral changes  Even novice meditators showed increase in gamma waves during compassion meditation but effects endured past period of meditation only in long-term practitioners (Lutz, Greischar, \u0026amp; Rawlings, 2004)       One problem though that pertains even to the well-controlled studies with long-term meditators (e.g., showing increased left prefrontal activity in meditators and enhanced ability to detect microexpressions) is that it’s not clear precisely which meditation practice(s) may be contributing to those effects  Some recent studies try to address this problem by asking participants to engage in specific types of meditation practice while in the scanner   The problem of multiple practices is compounded by the fact that many of the long-term meditators practice within traditions that require extensive preliminary training involving  Working with the mind, e.g., developing greater awareness of the feeling tone of thoughts Ethical precepts: just focusing on doing what you know at a deep level to be right is another doorway to great meditation experience  “Right is right were wisdom in the scorn of consequence” \u0026ndash; Tennyson\n     Physical Effects of Mindfulness #  Mortality Rates #   Experimental study in which patients with mild hypertension were trained in meditation and followed for 19 years  Meditation group showed a 23% decrease in overall mortality, a 30% decrease in rate of cardiovascular mortality and a 49% decrease in the rate of mortality due to cancer compared with controls   73 residents of homes for elderly were assigned either to daily meditation (transcendental meditation or mindfulness), a relaxation group, or a no-treatment group  After three years, survival rate was 100% for TM, 87% for mindfulness, 65% for relaxation, and 77% for no-treatment group  Only differences between meditation and nonmeditation groups were significant     In general, there are more similarities than differences between psychological effects of different types of meditation (Schneider, Alexander, Staggers, et al., 2005) (Alexander, Langer, Newman et al., 1989)  Gene Expression #   Just one day (8 hours) of intensive practice of mindfulness meditation resulted in significant modulation of expression of proinflammatory genes (Kaliman, Alvarez-Lopez, Cosin-Tomas et al., 2014)  Mindfulness and Physical Pain #   A large component of “physical pain” is actually mental  The mind reacts to pain with fear, rejection, despondency, or a feeling of powerlessness, dramatically compounding the pain These are the mental elaborations mentioned earlier “This pain means that my body is suffering injury and I’m going to DIE!!”     Pain is actually just sensations \u0026ndash; it’s the aversion response that causes most of the suffering  Sort of like little kid screaming about getting shots, when the punches they get roughhousing on the playground are actually many times more painful   As you focus on your bodily sensations, you begin to realize that what you thought was pain is just a cluster of sensations The mind learns to recognize those sensations simply as sensations (“Oh, that’s my feet tingling or my knees burning”) Rather than thinking about the pain, how to get it to stop, what to do about it, etc., over time, one is able to just be with the sensations and not try to fix it    Research #   Research on neurophysiological response to pain in meditators vs. non-meditators (Grant, Courtemanche, Rainville et al., 2011; Lutz, McFarlin, Perlman et al., 2013)  Used hot laser to create pain in the foot/arm     Results:  In comparison with the non-meditators, the Zen practitioners  Showed significantly greater activity in the somatosensory cortex, as well as in the insula, the part of the brain involved in proprioception (noticing body sensations)  Reported that the pain sensations were very, very vivid   Showed significantly less activity in parts of the prefrontal which are involved in evaluating the pain Rated the pain very low, as a 1, 2, or 3, as opposed to the non-meditators who rated their pain as a 8, 9, or 10   Meditators with the most experience showed the largest reductions in prefrontal and amygdala activation In addition, the lower pain sensitivity in meditators was strongly predicted by reductions in functional connectivity between executive (prefrontal) and pain-related cortices     Results suggest a functional decoupling of cognitive-evaluative and sensory-discriminative dimensions of pain, allowing practitioners to view painful stimuli more neutrally  Consciousness, Mindfulness \u0026amp; the Mind-Body Connection #   In our culture, we normally think that:  Our mind is identical with our body OR Our mind is in our body   However, the meditation traditions from which mindfulness arises hold that  Our body is actually in our mind … and that we are a lot more than we think The small sense of self with which we normally identify is an arbitrary construct based on sensory feedback mechanisms  Ramachandran demo           Elisabeth Haich’s experience: Asked to sit under a palm tree and meditate on it week after week Three stages of concentration: intellectual, emotional, spiritual  First stage: you think about what this object actually is Second stage: “with every nerve and every drop of your blood,” you feel the object of concentration and what it is like Third stage: you become identical with the object of concentration  … all of a sudden I have the odd feeling that I am no longer looking at the tree from the outside, but from the inside. To be sure I still perceive its outward form with my eyes, but I begin, to an everincreasing extent, to see and experience the inner being, the animating creative principle of the palm … to see it, to experience it, TO BE IT!\n  And finally there comes a moment when I am suddenly conscious of the fact that the palm is no longer outside myself \u0026ndash; no! \u0026ndash; it never was outside \u0026ndash; it was only a false conception on my part \u0026ndash; the palm tree is in me and I in it \u0026ndash; I myself am the palm tree!\n         "},{"id":20,"href":"/eecs-16a/7/","title":"Week 7: 2D Touchscreens \u0026 Superposition + Equivalence","section":"EECS 16A","content":"03-08: 2D Resistive Touchscreens #  Bottom Plate #   Trivially, we see that if we add a wire connected to .$u_\\text{mid}$ that will have the same voltage across it (wires have zero voltage drop) So why have the bottom plate at all? It lets us take the measurement for .$V_\\text{out}$ using connection points on the edge of the plate instead of having to put a probe or wire at the actual touch point every time!        What if this bottom plate is non-ideal? That is, .$R \\neq 0$ ? #   Both of these resistors are followed by an open circuit. From the definition of an open circuit, we know that zero current will flow through it. If .$i_\\text{mid} = i_{R4} +i_{R3}$ from KCL, and .$i_{R4} = i_{R3} = 0$ from the definition of an open circuit (Ohm’s Law says that .$0V = R \\cdot 0A$), the voltage across these new resistors will be .$0$.     This means that, even with an imperfectly conductive bottom plate, the voltage .$V_\\text{out}$ will still be equal to .$u_\\text{mid}$, even with the addition of these new resistors. To measure an output voltage, we need to put some device at the open circuit labeled .$V_\\text{out}$.  Interesting Circuit #   These are two parallel voltage dividers, thus we can write: $$u_2 = \\frac{kR_1}{R_1 + k R_1} V_s = \\frac{k}{1+k}V_S$$ $$u_3 = \\frac{kR_2}{R_2 + k R_2} V_S = \\frac{k}{1+k}V_S$$\n We see that regardless of the resistances .$R_1$ and .$R_2$, the potentials .$u_2$ and .$u_3$ are the same! This holds as long as .$k$ is constant: $$u_2 = u_3 = \\frac{k}{1+k}V_S$$           We can add .$R_3$ and it won\u0026rsquo;t change the circuit behavior Since .$u_2 = u_3$, there is no .$\\Delta V$, thus no current flows through the resistor.  We can also find this with KCL: .$R_3 i_3 = u_2 - u_3 = 0 \\therefore i_3 = 0$   This means that .$R_3$ is at the special .$(0, 0)$ point on the .$I$-.$V$ plot, where it behaves the same way as a wire or open circuit  That is, we could replace .$R_3$ with an open circuit and nothing would change      2D Resistive Touchscreen #   Now, let’s introduce the physical structure of a 2D touchscreen: it consists of a top red plate and a bottom black plate. When a finger touches the screen, the top red plate is pushed into contact with the bottom black plate at the touch point. The top and bottom ends of the top red plate as well as the left and right ends of the bottom black plate are made of materials that have very low resistivities .$\\rho$, we can treat them as ideal wires (.$\\rho = 0$). The materials of the transparent screen that we touch in the middle have much higher resistivity.      Top Plate #     We can treat the red plate as a bunch of vertical resistor strips, where each vertical strip is connected to the strips next to it by horizontal resistors as well. When we touch the plate, we split it into a top and bottom half, or .$R_\\text{rest}$ and .$R_\\text{touch}$. Rather than considering many vertical strips, we will divide the red plate into just three equal vertical segments represented by resistors, which are connected by horizontal resistors .$R_{h1}$ and .$R_{h2}$.     Adding a voltage supply .$V_S$ we can see this is the same interesting circuit as before! Since .$R_\\text{rest}$ and .$R_\\text{touch}$. are the same for each segment, we know that .$u_2 = u_3 = u_4$. As with the “interesting circuit” can replace horizontal resistors .$R_{h1}, R_{h2}$ with open circuits.  $$u_3 = \\frac{R_\\text{touch}}{R_\\text{rest} + R_\\text{touch}}V_S$$ $$\\dots = \\frac{\\rho \\frac{L_\\text{touch}}{A}}{\\rho \\frac{L_\\text{touch}}{A} + \\rho \\frac{L_\\text{rest}}{A}}$$     $$\\dots = \\frac{L_\\text{touch}}{L}V_S \\text{ for } L_\\text{touch} = L_\\text{touch, vertical}$$\n This means that .$u_3$ is mapped to the vertical position touched in the same way as the 1D touchscreen. When measuring the vertical position touched (.$L_\\text{touch, vertical}$), the bottom black plate connects to a voltmeter and measures .$u_3$, the same way it did in the 1D touchscreen  Note that, although we have represented the top red plate by three segments of equal width in the circuit model we built, the value of .$u_3$ will remain the same if we choose to represent the top red plate by an infinite number of segments.    Bottom Plate #     We know from linear algebra that if we want to find two values (i.e. vertical and horizontal position), we will need two measurements. To find the horizontal position, we connect the supply voltage source .$V_S$ to the bottom black plate, and connect the top red plate to a voltmeter. As before, we choose to represent the bottom black plate by three segments of equal width which are connected in between by vertical resistors .$R_{v1}, R_{v2}$.  $$u_3 = \\frac{R_\\text{touch}}{R_\\text{touch} + R_\\text{rest}} V_S = \\frac{L_\\text{touch}}{L}V_S$$    The important simplification used is replacing .$R_{h1}, R_{h2}$. with open circuits for the .$L_\\text{touch}$, horizontal measurement and .$R_{v1}, R_{v2}$. for the .$L_\\text{touch}$, vertical measurement.  However, this kind of simplification is valid only if the resistor is at .$(0, 0)$ on the .$I$-.$V$ plot, which means the resistor has zero current flow and therefore zero voltage drop (.$IR = V$).     From the .$I$-.$V$ plots, although a resistor, a wire and an open circuit can behave quite differently, their behaviors are exactly the same at .$(0, 0)$.  This means that at .$(0, 0)$, these three circuit elements can be replaced by one another and the same behavior .$(I = 0, V = 0)$ is still expected.        Fast Analysis #   Prior, we used the fact that all of the segments had .$R_\\text{rest} = R_\\text{touch}$. In this section, we’ll consider a similar circuit where the resistances are all different\n  Write equations for the nodes with voltage sources between them.  Here, the ground node and .$u_1$ have .$V_S$ between them, so .$u_1 = V_S$   Write KCL for any unknown nodes, using the .$V = IR$ relationship, and taking into account any current sources connected to the node  If we consider node .$u_2$, the sum of the currents flowing out of .$u_2$ through .$R_1, R_5, R_3$ is 0. $$ \\frac{u_2 - V_S}{R_1} + \\frac{u_2}{R_3} + \\frac{u_2 - u_3}{R_5} = 0,$$ $$\\frac{u_3 - V_S}{R_2} + \\frac{u_3}{R_4} + \\frac{u_3 - u_2}{R_5} = 0$$ Now, we have just two equations and two unknowns (.$u_2$ and .$u_3$) so all the remains to be done is to solve the equations by hand.       You can check that the signs of your voltage drops are correct by checking that the node in question is always positive in the numerators. So in the first equation, .$u_2$ is positive, while in the second equation, .$u_3$ is positive\n   What if we have a current source? How do we KCL? #   Remember that we treat all currents as flowing out of the node. We should also take the direction of the current source into account. In this case, the left branch of .$u_1$ has a current source .$I_S$ flowing in, so .$−I_S$ current flows out. So our equation is\n$$-I_S + \\frac{u_1 - u_2}{R_1} + \\frac{u_1 - u_3}{R_2} = 0$$\n     03-10: Superposition and Equivalence #  Equivalence #   If we pick two terminals within a circuit, we say that another circuit is equivalent to the original circuit if it exhibits the same .$I$-.$V$ relationship at those two terminals.\n An example of an .$I$−.$V$ is that of a resistor, i.e., .$V = IR$ or .$I= \\frac{V}{R}$ We can do this since voltage and current are governed by a linear relationship (in 16A), and a line can be uniquely determined by exactly two points, we can capture the original circuit with a simplified circuit that has exactly two components: a voltage (or current) source and a resistor   If we look at the .$I$-.$V$ plot of a voltage source .$V_S$, where .$I$ is the current going through the voltage source, then the plot would be a vertical line: $V_S = 0$ means that it allows any current to go through, however the voltage drop always remains zero. This is exactly what a wire element (sometimes called a short circuit) does.  If we plot the .$I$-.$V$ graph of a current source .$I_S$, we get the a horizontal line: If we turn off the current source, .$I_S = 0$, which means no matter what voltage you apply, there will be no current. This is equivalent to an open circuit.    Motivation #   When we add a new component to a circuit, it interacts through only 2 parameters: current .$I$ and voltage .$V$. Equivalent circuits are used to simplify interactions between circuits.\nLet’s take the simplest case where interactions are only through one pair of nodes. In that case, we just have two possible quantities: the voltage across the nodes and the current flowing through the connections. The relationship between this current and this voltage would then fully define the interactions between the circuits. This is where the idea of equivalence comes in. If we have a circuit that exhibits the same .$I$−.$V$ relationship from the standpoint of a pair of nodes, the other circuit (the one you are interacting with) can’t tell the difference.\nThe idea of equivalence is to be able to replace one (or both) of the interacting circuits with a simpler circuit that will give us the same overall behavior.\n Clarifications #   Equivalence tells us nothing about the power in a circuit and one should be careful not to assume it does. From the standpoint of any other nodes in the circuit (i.e. any pairs of nodes), the circuit may or may not be equivalent  That is, looking at the same circuit but examining a different pair of terminals may not produce equivalent .$I$−.$V$ relationship.    Series \u0026amp; Parallel #   These are proven starting page 10 of notes We cannot use these to simplify our circuit if there are dependent sources. Remember that only independent sources are zeroed out, and there are no resistor formulas for dependent sources. In addition, some resistor configurations cannot be decomposed into combinations of parallel and series resistances.    Series:  The voltage is the sum of the voltage drops of the individual components: $$V = V_1 + \\dots + V_n = I (R_\\text{total})$$ From KCL we know elements will have the exact same current through them: $$I = I_1 = \\dots = I_n$$ Resistance is the sum of their individual resistances: $$R_\\text{total} = R_1 + \\dots R_n$$       Parallel:  From KVL we know elements will have the exact same voltage across them: $$V = V_1 = \\dots = V_n$$ The current in each individual element is found by Ohm\u0026rsquo;s law: $$I = I_1 + \\dots + I_n = V R_\\text{total}$$ Total resistance will always be less than the value of the smallest resistance $$\\frac{1}{R_\\text{total}} = \\sum_{i=1}^n \\frac{1}{R_i}$$  Notation: We use .$\\parallel$ to denote parallel components       Thevenin #   Any linear two-terminal circuit can be replaced at terminals .$A$–.$B$ by an equivalent combination of a voltage source .$V_{Th}$ in a series connection with a resistance .$R_{Th}$ \u0026ndash; wiki\n      Find .$V_{Th}$: Connect an open circuit across the two output terminals and measure the voltage across them. This measured .$V_{oc}$ equals .$V_{Th}$. Find .$R_{Th}$: Zero out any independent sources. Remember, this means voltage sources turn into a wire and current sources turn into an open circuit. Then apply either a test current into the terminal and measure the resultant voltage, or apply a test voltage and measure the resultant current. .$R_{Th}= \\frac{V_{test}}{I_{test}}$      Norton #   Any linear two-terminal circuit can be replaced by a current source and a single resistor in parallel \u0026ndash; wiki\n      Find .$I_{No}$: Connect a short circuit across the two output terminals and measure the current through it. This measured .$I_{Sc}$ equals .$I_{No}$. Find .$R_{No}$: Zero out any independent sources. Remember, this means voltage sources turn into a short circuit and current sources turn into an open circuit. Then apply either a test current into the terminal and measure the resultant voltage, or apply a test voltage and measure the resultant current. .$R_{Th}= \\frac{V_{test}}{I_{test}}$  Note that the second step doesn’t change because .$R_{No}$ is equal to .$R_{Th}$!        Relation / Conversion #  A Norton equivalent circuit is related to the Thévenin equivalent by\n$$R = R_{Th} = R_{No}$$ $$V_{Th} = I_{No}R$$ $$I_{No} = \\frac{V_{Th}}{R} $$\n      Note that .$R_{No}$ is equal to .$R_{Th}$, since the slope of the .$I$-.$V$ curve is the same. Now, instead of looking at the .$V$-axis intercept, we find the intersection with the .$I$-axis: At the intersection with the .$I$-axis, the voltage drop between .$A$ and .$B$ is zero, which is equivalent to placing a wire between .$A$ and .$B$ (i.e. shorting .$A$ and .$B$). We denote the current through the wire be .$I_{No}$.\n Why this works:\n Since the .$I$-.$V$ relationship is linear, we can calculate the slope (which is the reciprocal of resistance) from any two points. .$V_{Th}$ and .$I_{No}$ are the points where the .$I$-.$V$ curve crosses the.$V$ and .$I$ axes, respectively (see the left-hand figure).       However, this method does not work if .$V_{Th}$ and .$I_{No}$ do not provide two unique points on the .$I$-.$V$ curve (see the right-hand figure).  Specifically, this method only works if there is at least one independent source in the circuit. When there are no independent sources, .$V_{Th} = I_{No} = 0$ which does not provide enough information to calculate Req.    Superposition #    Recall two weeks back: To solve for the currents and node potentials in a circuit, we set up a matrix problem of the form .$A\\vec x =\\vec b$ where .$\\vec x$ contained the unknown currents and node potentials, .$\\vec b$ contained the independent current and voltage sources, and .$A$ described the relationship between them. Since this matrix equation describes a real system, we know that there is a unique solution. Therefore, .$A$ is invertible: $$\\vec x = A^{−1} \\vec b$$ This means that we can describe any current or node potential (ie. any element of .$\\vec x$) as a linear combination of the independent current and voltage sources (the elements of .$\\vec b$).\nFor example, consider a circuit with .$n$ independent sources voltage sources .$V_{s1} \\dots V_{sn}$, and .$m$ independent current sources .$I_{s1} \\dots I_{sm}$. An arbitrary node potential .$u_i$ (or equivalently, an arbitrary current .$i_i$) can be written as $$u_i = \\alpha_1 V_{s1} + \\dots +\\alpha_n V_{sn} + \\beta_1 I_{s1} + \\dots \\beta_m I_{sm}$$ where the .$\\alpha$’s and .$\\beta$’s are coefficients from inverting .$A$. Since this equation is linear, we can calculate each term of this equation separately and then add them together at the end.\nFor example, if we want to calculate the first term, .$\\alpha_1 V_{s1}$ we can set all of the other voltage and current sources to zero, then solve for .$u_i$. Repeating this for every source then adding the results is equivalent to calculating .$u_i$ with all of the sources present. However, splitting up the calculations can help us see simplifications and patterns that might be less obvious with all of the sources present.\n TL;DR:\n For each independent source .$k$ (either voltage source or current source)  Set all other independent sources to .$0$  Voltage source: replace with a wire Current source: replace with an open circuit   Compute the circuit voltages and currents due to this source .$k$   Compute .$V_\\text{out}$ by summing the .$V_{\\text{out; }k }$s for all .$k$.   We can apply the idea of replacing elements with equivalent elements (e.g. replacing a .$V_S = 0$ voltage source with a wire) to resistors as well. When do resistors have an equivalent representation? Recall that by Ohm’s law, the .$I$-.$V$ graph across a resistor. From this we can see:\n Zero voltage source and zero resistance are equivalent to wires (i.e. short circuits); Zero current source and infinite resistance are equivalent to open circuits      "},{"id":21,"href":"/e-29/6/","title":"Weeks 6 \u0026 7: Joining processes","section":"Engineering 29","content":"   \\(\\)  Joining Processes #  Welding-based #   There are many ways of assembling mechanical components to create mechanisms and structures. Examples of joining processes include the use of fasteners such as bolts and rivets, adhesives, and push fits, in which interference is used to connect components together. Welding, meanwhile, involves fusing two components by melting the material near their interface, and possibly introducing additional material of the same kind to fill any gaps between the components. Metallic and polymeric materials can be welded, and the techniques used to melt the material vary with the properties of the materials being joined.\n  It is important to note that welding involves complete fusion of the components being joined: the joint is made of the same material as the components and thus can be extremely strong relative to other joining techniques because it enables us to eliminate inter-material interfaces along which cracks might propagate. Drawbacks of welding, however, include the fact that because we are heating a portion of the components above their melting point, dimensional distortion of the components may occur, and even if distortion does not occur there may be modification of the material’s mechanical properties in a heat affected zone (HAZ) around the weld. This property modification may involve recrystallization or annealing of metallic materials, softening the component after it cools.\n Welding terminology #   A heat source emits heat some distance from the weld. A fraction .$f_1$ of this heat reaches the material, and a fraction .$f_2$ of the heat that arrives is retained within the weld region, and actually is used in melting material. The remainder of the heat is lost either to the surroundings, or conducted through the solid components where it may modi.$f_y$ the microstructure without melting the material. The energy required for melting a unit volume of the material may be approximated as being proportional to the square of the absolute melting temperature. If we know the rate of heat generation and the heat transfer factor .$f_1$ and melting factor .$f_2$, we can thus determine the volumetric rate at which material can be melted and thus how fast a weld with a given cross-sectional area can be created\n   Proportion of total heat from source contributing to melting of metal: .$f_1 f_2 H$ .$H$: Heat from source .$f_1$: Heat transfer factor \u0026ndash; amount of heat that goes into welding material .$f_2$: Melting factor \u0026ndash; amount of heat that goes into welding region   Energy required for melting: $$U_m = K T^2_m$$ .$U_m$: Melting energy (J/mm.$^3$) .$K = 3.33 \\cdot 10^{-6}$ J/(mm.$^3$K.$^2$) .$T_m$: Melting temp (K)    Power for melting: $$U_m A_w v = f_1 f_2 IE$$ .$IE$: Electric Power .$I$: Current (Amps) .$E$: Voltage (Volts)     Rates of melting material: $$R_{H,w} = f_1 f_2 R_H = U_m R_{w, V} = U_m A_w v$$  .$R_{H,w}$: Rate of heat delivery to weld [.$W$atts] .$R_H$: Power of heat source .$R_{w,V}$: Volume rate of melting    .$U_m$: Melting energy (J/mm.$^3$) .$A_w$: Cross-section area of weld .$v$: Velocity of heat source      Oxyacetylene welding #   This versatile technique has been used for many decades to weld metals, and involves a two-stage reaction, first the combustion of acetylene to produce carbon monoxide, hydrogen and heat, and second the reaction of the CO with hydrogen and oxygen to produce carbon dioxide, water, and more heat.\nThis approach lends itself to welding in remote locations (all that is needed is a gas tank and torch) and because of the high temperature of the flame, many materials can be welded. Can also be done underwater.\nOne well known challenge with this technique is hydrogen embrittlement where the hydrogen gas generated can become incorporated into the microstructure of the component, weakening it.\n      @ 1:00\n Arc welding #   In arc welding of any kind, a voltage is applied between the workpiece and an electrode which are separated by a gap of a few millimeters. The electric field across this gap is large enough to ionize the gas and generate a plasma in the gap. This plasma is electrically conductive, yet still highly resistive so that heat is generated as the current passes through the plasma. It is this heat that melts the material. Because the plasma is so highly localized and the heat is generated within a millimeter or so of the weld, the welded region can be precisely controlled.\n Manual Metal Arc (Stick) Welding #   In Manual arc welding, the electrode is a hand-held rod of the same material as the workpiece, and it melts as the weld forms, providing material to fill the gap between components. The rod has a length of several inches, so the length of weld that can be produced in one welding operation is limited. This limits the speed of the technique. The rod is usually coated with a flux, which melts during welding to produce an acidic liquid on the surface of the work, etching away naturally occurring oxides to expose the metal surface and enable a strong, continuous metallic weld to be produced.\n      @ 1:37\n Submerged arc welding #   This process is suitable for producing long, straight welds in larger components. The electrode is a consumable wire that is fed into the system from a spool, and a powdered flux is fed in front of the advancing weld from a hopper. The weld region lies submerged by the flux, which helps to prevent sparks and strong ultraviolet radiation from the weld escaping from to the surroundings. The flux and electrode handling mechanism is usually mounted on a motorized carriage that moves along the component at a constant rate.\n      @ 3:06\n Metal Inert Gas (MIG) Welding #   Here, the electrode is consumable and fed from a continuous spool of wire. Instead of flux, an inert gas such as Argon is fed around the electrode as a shield, to prevent oxidation of the workpiece surface.\n      @ 5:50\n Dip vs Spray Transfer in MIG Welding #       @ 6:50 + 8:30\n Tungsten Inert Gas (TIG) Welding #   Like MIG welding, an inert gas shield is used, but instead of a consumable electrode, a tungsten electrode with much higher melting point is used. If filler material is needed it is introduced from the side using rods of materials. The electrode can maintain a sharp shape (less than a millimeter diameter), so that highly precise and consistent welds can be produced. This also makes it much harder to learn.\n      @ 11:25\n  DC (Direct Current)  Electrode is held negative Suitable for all metals except Al and its alloys   AC (Alternating Current)  Used for Al and alloys because of the robust oxide that aluminum forms which needs to be removed to enable a clean weld Frequencies 20-150 Hz used Positive-electrode part of cycle helps strip oxide from the weld pool but leads to electrode heading Negative-electrode part of cycle heats workpiece    Electrical Resistance Welding #   Electrodes are clamped across a stack of metal sheets to be welded. A current is passed through the stack, resistively heating the material between the electrodes. Material at the center of the stack heats up the most, because the thermal conduction path by which generated heat can escape to the surroundings is the longest there. The amount of heat energy generated can be precisely controlled, which makes this excellent for joining thin sheets that could be destroyed by a flame or an arc. The weld region is sometimes referred to as a nugget and the process is called a spot weld. Seam welding is a continuous form of spot welding whereby the sheet material passes between two conductive rollers and a series of overlapping spot welds are made in rapid succession. This process is suitable for creating sealed metal containers.\n  Spot welding  Sheets clamped between electrodes Current passes through Lozenge of material melts around the interface   Seam welding  Sheets pass between conductive rollers Current is pulsed Continuous weld is formed from overlapping spot welds       @ 16:48 \u0026amp; 17:20\n     Friction (Stir) Welding #   Two components are rotated relative to each other at high speed under load (e.g. by mounting in a lathe). The heat generated by friction softens both components’ surfaces and they fuse.\n  Two components undergo relative rotational motion in contact Heat resulting from friction at the interface leads to melting Components are pressed together until they fuse and cool          @ 20:48\n Ultrasonic Welding #   A horn couples ~40 kHz vibrations into the components Oscillatory compression of the components translates to shear motion at the intended joint, and dissipation of energy as heat via friction \u0026ldquo;Energy directors\u0026rdquo; are features at the welded interface that lower contact area, and concentrate the loads, promoting material melting        Laser Welding #   Focused laser beam provides the heat Readily automated weld paths Extremely precise welds (sub-mm-size) are possible         Electron Beam Welding #   Focused beam of electrons (produced, e.g., by thermionic emission) is accelerated and steered towards workpiece by electromagnetic field reaching an electron energy of ~30-100 keV Loss of kinetic energy of electrons upon collision with workpiece generates heat Carried out in vacuum: as low as ~10-4 Torr (0.01 Pa) As with laser welding, extremely high-precision and small welds are possible Similar pros and cons as for e- beam melting additive m.$f_g$ vs selective laser melting Can make especially deep, narrow welds        Typical Power Densities in Welding #   Power density reaching material surface     Type of welding Typical power density (W/mm.$^2$)     Oxyacetylene 10   Arc 50   Resistance (electrical) 1000   Laser 9000   Electron beam 10000    Modeling Heating in Welding #   It is helpful to be able to predict the size of the weld pool and HAZ for given process parameters Rosenthal developed a simple equation for how temperature varies around a heat source $$T(w,y,z) = - T_0 = \\frac{q}{2\\pi kR} e^{-\\left(\\frac{v(w+R)}{2a}\\right)}; R = \\sqrt{w^2 + y^2 + z^2}$$  $T_0$: Temperature of work at start $v = \\frac{dw}{dt}$: Velocity of beam $q$: Rate of heat delivery [Watts]    $R$: Distance along weld $k$: Thermal conductivity $a$: Thermal diffusivity        Time .$t_{8/5}$ for temperature to fall from 800 °C to 500 °C as the heat source passes is a key parameter for determining condition of HAZ: ideally about 10-25 s for carbon steels      Non-Welding Joining Methods #   Other joining methods that involve introducing molten material to an interface are soldering and brazing, but in both these processes the gap-filling material is an alloy with a lower melting point than the components being joined. Soldering is used, for example, to join electrical components to printed circuit boards or to connect pipes in plumbing. Brazing is simply the term used for soldering when the filler melts above 400˚C. There is some inter-mingling of atoms of the filler and component material near the interfaces, which lends the joints strength, but soldered/brazed joints are still not as strong as welded ones can be.\n Brazing #   Filler is a metal or eutectic alloy with lower melting point than the work Advantages cf welding  Good for thin walls Less heat required Suitable for joining dissimilar metals Avoid HAZ Use capillary forces to fill inaccessible joints   Disadvantages cf welding  Lower strength Appearance: differing colors Weakens at high service temperatures   Applications  Piping, preparing cutting tools e.g. cemented carbide        Types of adhesive #   Pressure-sensitive  Viscoelastic solid \u0026ndash; forms under load Conforms to target solid  Maximize van der Waals interactions Promotes mechanical interlocking     Thermoplastic  e.g. hot-melt glue   Irreversible liquid-solid transition  Radical-driven crosslinking: UV or thermally cured Epoxy resins (2-part; reacts when mixed to cure) Thermosetting silicones Cyanoacrylate:rapidly polymerizes in presence of water        Fasteners: Riveting #   Simple to process and automate Can\u0026rsquo;t be loosed by vibration (used in aircrafts) Typically cheaper (doesn\u0026rsquo;t need to be toleranced precisely) Doesn\u0026rsquo;t need the depth that threaded components do   Fasteners: Screws and Bolts #   Screw characterized by:  Major, minor diameters Pitch (inverse of turns per inch), thread angle Length   Conventional formats:  [Diameter]-[Turns / unit] x [Length] #4-40 x 0.5: Imperial; #4 diameter, 40 turns per inch, 0.5 length (in) 1/4-20 x 5/8: Imperial; 1/4 \u0026hellip;, 20 \u0026hellip;, 5/8 M3-0.50 x 10: Metric; 3 mm radius, 0.50 Pitch (mm), 10 length (mm)   Various head styles available  Square, counterbore, countersunk, round etc   Important to protect against loosening in use  Sprung, split washers Glue        "},{"id":22,"href":"/cogsci-c100/memory/","title":"Memory","section":"CogSci C100","content":"Three-Stage Model of Memory #   Three-stage modal model of memory (Atkinson-Shiffrin model):  Sensory memory Working memory or short-term memory Long-term memory   Old model that\u0026rsquo;s not used today  Sensory memory is seen as a type of perception Short term is similar to attention   Interesting to study to see how our model evolved and how memories are processed   Sensory memory #    Holds sensory information very briefly (1/2 to 4 secs)  If you stare at an image then close your eyes you can still see the image Large capacity store Sensory input is held very briefly in sensory memory to allow selection and processing of information Now often considered to be a part of perception    (a) was flashed, then (b), and people reported seeing (c) [Eriksen \u0026amp; Collins, 1967]\n      Two types of sensory memory:\n Iconic memory (photographic memory): visual sensory memory \u0026ndash; doesn\u0026rsquo;t go away after four seconds but functions like sensory Echoic memory: auditory sensory memory    Eidetic imagery (photographic memory): #   Characterized by relatively long-lasting and detailed images of visual scenes that can sometimes be scanned and \u0026ldquo;looked at\u0026rdquo; as if they had real existence  Eidetic imagery is relatively rare \u0026ndash; only 5% or so of tested schoolchildren have it and proportion is much smaller in adults It is not an especially useful form of mental activity.  Contrary to popular lore, memory experts don’t generally have eidetic imagery; their skill is in organizing material in memory, rather than in storing it in picture form.     Group of schoolchildren was shown a picture for 30 seconds. Picture was taken away, and children asked whether they could still see anything and, if so, to describe what they saw. Some children showed evidence of this kind of memory.  10-year-old boy, looking at blank easel from which a picture of Alice in Wonderland had just been removed, is asked whether he sees something there (on the blank easel) Participant (P): I see the tree, gray tree with three limbs. I see the cat with stripes around its tail. Experimenter (E): Can you count those stripes? Participant (P): I see the tree, gray tree with three limbs. I see the cat with stripes around its tail. Experimenter (E): Can you count those stripes? P: Yes (pause). There’s about 16. E: You’re counting what? Black, white or both? P: Both.       E: Tell me what else you see. P: And I can see the flowers on the bottom. There’s about three stems but you can see two pairs of flowers. One on the right has green leaves, red flower on bottom with yellow on top. And I can see the girl with a green dress. She’s got blond hair and a red hair band and there are some leaves in the upper left-hand corner where the tree is. (Leask, Haber, \u0026amp; Haber, 1969)    Short-term memory (STM) / Working Memory #   Holds items that are actively being thought about  That is, intentionally rehearsing information   Has limited capacity  7 +/- 2 items, e.g., letters, words, dots, though this number can vary by task Number of words you can speak in 1.5 seconds (those who speak faster can recall more)   Also limited in time, but longer than sensory memory  Lasts 5 to 30 seconds Information decays rapidly unless maintained in consciousness through rehearsal     Working memory (Baddeley) is now the preferred term because it emphasizes that this is an active, rather than a passive, process  Includes a phonological loop (associated with the left hemisphere) that briefly stores sounds, and a visuospatial sketchpad (associated with the right hemisphere) that stores visual and spatial information  Just recall left is associated with language and right is generally \u0026lsquo;wholistic\u0026rsquo; Two visuospatial tasks will interfere with each other if performed simultaneously, as will two items in the phonological loop However, people can perform a verbal task and a spatial task simultaneously Aside: Feynman        Episodic buffer: another component of working memory that can hold and combine information from phonological loop, visuospatial sketchpad and long-term memory to form a story \u0026ndash; important in time sequencing  E.x. if you\u0026rsquo;re trying to recall how someone reacted to a joke you made last night; you think about what you said / how you said it / how they reacted / etc.        Central executive: integrates information from phonological loop, visuospatial sketchpad, and episodic buffer  Similar to attention/sensory memory in Atkinson Shriffin model    Long-term memory (LTM) #   Repository of all one’s knowledge Unlimited in the amount it can store No time limit  Serial position effect #   Evidence for short-term memory and long- term memory: serial position effect Six lists test (first five are fruits, last is animals)  There is a tendency for people to remember best the items learned first (because of LTM) and the items learned last (because of STM) Proactive interference: words from previous lists interfere with your ability to learn new words of a similar nature (doing progressively worse on Lists 2-5) Release from PI [proactive interference]: items are different so no interference memory for these items should be good (doing well on list 6) Retroactive interference: words from later list interfere with recall of a prior list (difficulty recalling items from list 1 at the end)       Experiment also shows that semantic similarity of items affects recall  VEGT is harder to recall than ANQR      Medical applications of primacy-recency effect  Our memories of how painful an experience was tends to depend on the peak intensity and how much pain was felt at the end  Participants in experiment were asked to immerse one hand in painfully cold ice water for 60 secs, then other hand in same ice water for 60 secs followed by a slightly less painful 30 secs more (Finn, 2011)  When asked which trial they would prefer to repeat, most participants preferred the longer trial, with more net pain \u0026ndash; but less pain at the end     Strategy of tapering off pain (though this means increasing net pain experienced) has been implemented in painful medical procedures like colonoscopies      Primacy-recency can color our memory of pleasures too  In one experiment, participants, on receiving a fifth and last piece of chocolate, were told it was their \u0026ldquo;next\u0026rdquo; one Others were told it was their \u0026ldquo;last\u0026rdquo; piece The latter liked the chocolate better and also rated the whole experiment as being more enjoyable (O’Brien \u0026amp; Elsworth, 2012)   Possible applications to romantic relationships?      Types of long-term memory #  Explicit memory #   Explicit/declarative memory (with conscious recall): recall or recognition of information; can be verbally transmitted  Episodic memory: recall of personal facts (autobiographical) Semantic memory: recall of general facts   Implicit/non-declarative memory (without conscious recall): memory that influences one’s behavior or thought but does not itself enter consciousness; cannot be verbally transmitted  e.x. you can\u0026rsquo;t teach someone how to ride a bike by explaining to them Procedural memory: Recall of how to do things Also includes conditioning effects \u0026ndash; see Édouard Claparède\u0026rsquo;s experiment        Implicit Association Test #     implicit.harvard.edu  80% of those who have ever taken the test end up having pro- white associations, including about 50% of African Americans   Does the IAT correlate with specific behaviors?  White college students who had more implicit negative stereotypes of Black people showed significantly more nonverbal signs of discomfort (e.g., standing further away, making less eye contact, stumbling over words more, smiling less) when interviewed by Black interviewers People with a stronger pro-White bias on the IAT were also more likely to perceive anger and apparent threat in Black faces (Greenwald, Banaji, \u0026amp; Nosek, 2015; Hugenberg \u0026amp; Bodenhausen, 2003)   How can implicit stereotyping be reduced?  In case of black-white implicit stereotyping, thinking about admired out-group member (Tiger Woods) and disliked in-group member (Jeffrey Dahmer) can reduce implicit IAT bias for up to 24 hours  Imagining counter-stereotypic women (e.g., strong women) similarly reduces implicit stereotyping   Students enrolled in a prejudice and conflict seminar taught by a black professor show a reduction in implicit biases after participation in course, as compared with controls (Devine, P.G., 2001) (Rudman, Ashmore, \u0026amp; Gary, 2001)  Long-term impact     The power of implicit attitudes: Newlyweds’ implicit and explicit attitudes toward their new spouses were measured  Explicit measure: spouses asked to report extent to which they would describe their marriage using 15 pairs of opposing adjectives (e.g., \u0026ldquo;good\u0026rdquo; vs. \u0026ldquo;bad,\u0026rdquo; \u0026ldquo;satisfied vs. \u0026ldquo;dissatisfied\u0026rdquo;) Implicit measure: version of IAT that required spouse to indicate as quickly as possible the valence of positively and negative valenced words after being exposed to 300-ms primes of photos of their partner and various control individuals Marital satisfaction was tracked over 4 year period   Implicit attitudes were a better predictor of future marital happiness than their explicit attitudes (McNulty, Olson, Meltzer et al., 2013)    Neurobiology of memory processing #  Where in the brain is long-term memory stored? #   Karl Lashley (1950)  Rats learn maze Lesion cortex (of different location each time) Test memory  Still performed better than brand new rat   Thus, Memories do not reside in single, specific spots          Long-term potentiation (LTP) #     Long-term potentiation (LTP): mechanism through which learning occurs in brain  A long-term increase in the excitability of a neuron to a particular synaptic input caused by repeated high-frequency activity of that input  Stimulating a particular neural circuit will increase the sensitivity of neurons in that circuit, increasing the probability that they will fire again   Process involves binding of glutamate to NMDA receptor  More glutamate can be bound More synapses can be formed Make NMDA receptor more sensitive to binding         What LTP means psychologically: Both positive and negative thoughts tend to be self-reinforcing  The more it snows (Tiddely pom),\nThe more it goes (Tiddely pom),\nThe more it goes (Tiddely pom),\nOn snowing. And nobody knows (Tiddely pom),\nHow cold my toes (Tiddely pom),\nHow cold my toes (Tiddely pom),\nAre growing.\n– The House at Pooh Corner\n      \u0026ldquo;Passing mental states become lasting neural traits\u0026rdquo; \u0026ndash; Rick Hanson\n   The hippocampus and frontal lobes #   Two structures that play particularly important roles in the processing and storing of new explicit memories are  Frontal lobes: recalling information and holding it in working memory Hippocampus: \u0026ldquo;save\u0026rdquo; button for explicit memories  Used to believe that this is were memories were stored We now understand the hippocampus acts as a \u0026rsquo;loading dock\u0026rsquo; where the brain temporarily holds to-be-remembered information Items then migrate for storage elsewhere in process called memory consolidation       Example:  Removing a rat’s hippocampus 3 hours after it learns the location of some tasty new food prevents long-term memory formation Removal 48 hours later does not (Tse, Langston, Kakeyama et al., 2007)     After a training experience, the greater one’s heart rate efficiency and hippocampus activity during sleep, the better the next day’s memory will be (Peigneux, Laureys, Fuchs et al., 2004; Whitehurst, Cellini, McDevitt et al., 2016)  Memory disorders: Evidence for separate memory systems #   Dissociation: when brain damage affects two behaviors very differently, this suggests that the two behaviors are produced by different processes  Clive Wearing, an English musician, suffered damage to his hippocampus as result of encephalitis  If you walk out of the room, then come back 10 minutes late, he won’t remember you But, he can still conduct a choir and play the piano and harpsichord beautifully Due to damage to the hippocampus Ala Memento      Explicit memories: the hippocampus #   The hippocampus is central to the formation of explicit memories  People with full temporal lobe amnesia (damage to the hippocampus and surrounding areas) cannot form new explicit memories though they can form new implicit memories They often have normal IQs and can carry on a normal conversation but cannot remember anything that happened more than a few minutes previously         The posterior hippocampus contains place cells, neurons involved in spatial navigation  Volume of posterior hippocampus is positively correlated with amount of time spent as a taxi driver Follow-up study  London cabbies have to pass centuries old test, \u0026ldquo; The Knowledge,\u0026rdquo; to get their license They spend 3-4 years memorizing 25,000 streets Voxel-based morphometry (VBM) was used to assess hippocampal volume before and after learning Cabbies who passed the test showed significant growth in their posterior hippocampus, whereas controls did not (Maguire, Gadian, Johnsrude et al., 2000) (Woollett and Maguire, 2011)          Implicit memories #   Two structures that play important roles in the formation of implicit memories are\u0026hellip;   Cerebellum: involved in learning of procedural memories for skills\n Makes sense, implicit is mostly procedural memories      Basal ganglia: deep brain structure important in motor sequencing\n Parkinson’s disease involves degeneration of parts of the basal ganglia e.x. you want to get out of a chair but don\u0026rsquo;t know how       Cases of organic amnesia have provided evidence for the distinction between different memory systems (e.g., implicit and explicit)   Summary #    ACT-R: Hybrid Cognitive Architecture #  Controversies in Cognitive Science #   To what extent is the mind modular, that is, organized in special information-processing modules?\n  If memory is modular, how do the modules interact? How might this be represented in a computational model of mind?    ACT-R: One of the most famous cogsci models: about how memory/information is stored and organized \u0026ldquo;Adaptive control of thought \u0026ndash; rational\u0026rdquo; Cognitive architecture with modular organization that was developed by John R. Anderson in 1976 It is hybrid in sense that it incorporates both symbolic and subsymbolic information processing ACT-R buffer  Workspace: what you\u0026rsquo;re paying attention to Serves to integrate outer and inner, between modules on different layers Acts like control system: Theres a feedback loop where you send a command/signal and then get information back which you use to adjust subsequent commands   Perceptual-motor layer  Perceptual module in turn consists of a visual module, audition module, etc. Motor module consists of speech module, manual module, etc. E.x you can decide to move in a certain direction (motor movements, perceptual \u0026ndash; you choose what to look at)       Cognitive layer  Declarative memory is organized in \u0026ldquo;chunks\u0026rdquo; Procedural memory is encoded as production rules: actions for the system to perform, e.g., retrieve a chunk from memory, send a command to the motor module to perform an action  Production rules can be nested within each other, so that output of a given production rule will trigger firing of another production rule         All of the above modules are encoded in the form of physical symbols    What makes ACT-R a hybrid architecture is that the symbolic, modular architecture is run on a subsymbolic base  ACT-R is designed to operate serially, so that at any given moment, only one production rule can be active, but how does it select that one?  The pattern-matching module controls which production rule gains access to the buffer by working out which production rule has the highest utility at the moment of selection, as determined by  How likely the system is to achieve its current goal if the production rule is activated The cost of activating the production rule   These calculations are subsymbolic and use an artificial neural networks approach         Subsymbolic equations are also used to model how accessible information is in declarative memory  The basic units of declarative memory are chunks, but each chunk is associated with a particular activation level, which is determined by  How useful the chunk has been in the past How relevant the chunk is to the current situation and context          The general information processing that takes place in the buffers is symbolic In contrast, the calculations that determine whether or not a particular item of knowledge ends up in a buffer are subsymbolic   Types of memory disorders #   Anterograde amnesia: inability to form lasting memories for new experiences Retrograde amnesia: inability to remember events that occurred before the onset of condition  Organic amnesia: physical cause #   Brain injury through accident or stroke Korsakoff’s amnesia (Wernicke-Korsakoff syndrome): amnesia caused by brain damage resulting from thiamine deficiency, usually as a result of chronic alcoholism  Not the alcohol, but lack of thiamine (nutritionally deficient) Patient staggers, develops abnormal eye movements, becomes confused, and experiences severe loss of memory for recent and relatively long-term events Patients tend to make things up (confabulate) rather than admit they can’t remember  N.B.: In most cases of trauma-induced organic amnesia, there is spontaneous recovery after matter of minutes or hours\n      Tends to affect women (despite most alcoholics being men) since they have less of an enzyme to metabolize the alcohol      Psychogenic (\u0026ldquo;hysterical\u0026rdquo;) amnesia: psychological cause #   Dissociative identity disorder (multiple personality disorder): disorder in which a person exhibits two or more distinct and alternating personalities Dissociative amnesia: inability to recall important personal information, usually precipitated by a traumatic experience  Hypnosis may be used to help recover memories   Dissociative fugue: disorder in which person has sudden, unexpected episode of travel from home during which he can’t remember some or all of his past life  Study found that incidence of this rises sharply whenever popular film depicting this subject is released        Alzheimer’s disease #   Organic Disease occurring in latter part of life that is characterized by deterioration of memory, reasoning, and language abilities Common form of neurocognitive disorder (deterioration of intellectual abilities; another common cause is vascular dementia)  Occurs in 7% of population above age of 65 and up to 40% of people older than 80 years   Associated with loss of neurons in cortical and sub-cortical regions: ventricles may be enlarged \u0026ndash; patients might end up losing as much of 50% of their brain mass  Produces severe degeneration of large parts of the brain: can eventually destroy most of the hippocampus and cortical gray matter   Sometimes gets confused with dementia, parkinson\u0026rsquo;s, or other disorders Deficiencies of acetylcholine: failure to show eyeblink conditioning     Brains of patients contain many amyloid plaques, which contain a core of misfolded b-amyloid protein surrounded by degenerating axons and dendrites, and neurofibrillary tangles, dying neurons that contain twisted filaments of tau protein    Causes #   Genetic component \u0026ndash; in only ~10% of cases  People with down syndrome tend to develop it   Higher risk of disease in those who have previously suffered a stroke or head trauma  Wear a helmet!   Conditions associated with cardiovascular disease, e.g., obesity, diabetes, high blood pressure, high cholesterol, smoking, and lack of exercise, increase risk Associated with low levels of vitamin D and certain B vitamins  Eat veggies for vitamins (prevents strokes too)   Exposure to lead and toxic substances, such as air pollutants, may increase risk Article published in Lancet in 2017 noted that hearing loss is now known to be the largest modifiable risk factor for developing dementia, exceeding that of smoking, high blood pressure, lack of exercise, and social isolation Research indicates that use of anticholinergics (in many drugs) is associated with reduced brain volume and lower levels of glucose metabolism, particularly in the hippocampus  Anticholinergics include Tylenol PM, Benadryl, Claritin, Dimetapp, Paxil, and Xanax  Researchers concluded that these drugs could trigger or worsen Alzheimer’s (Gray, Anderson, Dublin et al., 2015)   Those on anticholinergics also showed poorer performance on cognitive tests   Also, studies have found that older people with tooth and gum disease score lower on memory and cognition tests  Experts speculate that inflammation in diseased mouths migrates to the brain    Preventing #   Those who stay physically active and are non-obese have lower risk of developing disease  Heart health =\u0026gt; brain health   Studies have found that people who keep their minds active tend to show less loss of intellectual functioning in general as they age  Study of nuns in convent (Snowdon, 1997) found that education and intellectual activity seem to protect against Alzheimer’s Study also found that degree of sentence complexity and amount of positive affect expressed in writing samples when subjects were in their 20’s were negatively associated with incidence of disease and positively associated with longevity  There have been cases where autopsies showed presence of disease but no symptoms had been present   Use it so you don’t lose it!        Do Plaques and Tangles Really Cause Alzheimer’s? #   Claudia Kawas’ 90+ study on the “oldest old”  Team of medical experts were asked to examine years of medical records to determine if each of participants had Alzheimer’s 40% of participants that they concluded had Alzheimer’s did not have any amyloid plaques or neurofibrillary tangles at death On the other hand, about half of participants who died without symptoms of dementia had plaques and tangles         Conclusion?  Maybe plaques and tangles have nothing to do Alzheimer’s (unlikely) There may be multiple factors (e.g., lack of physical exercise, lack of cognitive stimulation, history of head trauma, etc.) that contribute to the development of Alzheimer’s\u0026hellip;  Whether people develop the disease may depend on the number of \u0026ldquo;hits\u0026rdquo; they take from these various factors      Q\u0026amp;A #    Q: Which regions of the brain are thicker in successful agers than in regular agers? Those regulating cognition or emotion? A: Those regulating emotions, e.g., the midcingulate cortex and anterior insula.     Q: What type of activities will increase your chances of remaining sharp into old age? A: Those that require hard work and cause you to feel somewhat tired, stymied, frustrated, e.g., grappling with a math problem or pushing yourself to your physical limits. (From research by Dr. Lisa Feldman Barrett)     Q: What factor most lowered people’s risk of getting dementia? A: Tiny strokes called microinfarcts  Some participants had hundreds or thousands of them       Q: What caused symptoms of dementia in those who died without plaques and tangles? A: Not vitamins, not alcohol, not caffeine, not exercise\u0026hellip;. but high blood pressure!  High blood pressure =\u0026gt; less likely Note though that this study focused exclusively on people over 90 years of age \u0026ndash; results may be different for younger people     Hyperthymesia #   Hyperthymesia of Superior Autobiographical Memory: Rare condition in which one has virtually perfect memory from about age of 10  Larry Cahill and James McGaugh constructed extensive memory tests to assess extent of each memory of each of six subjects   What was the date of the fall of the Berlin wall? How many times did it rain in 1986?    Associated with enlarged hippocampus and caudate nucleus: standard deviation of 7 or 8 \u0026ndash; equivalent to a 10-foot tall person, as opposed to 5’9\u0026quot; Often associated with OCD type behavior; only 1 of 6 are married        "},{"id":23,"href":"/e-29/7/","title":"Week 7-8: Visualization","section":"Engineering 29","content":"Orthographic projections #  Formal (working) drawings: purpose #   Need a formal way of documenting designs  Legal documents i.e patents; contracts may rely on them   Must stand on their own \u0026ndash; readable to any human  No subsequent explanation No verbal assists No ambiguity   Solution: multi-view orthographic projection  World-wide engineering standard Can easily include tolerances        What is a projection? #   Projection of a 3D object’s edge onto a 2D plane by rays perpendicular to that plane such that they are parallel to one another (unlike real-world)  Dashed lines represent hidden detials   Projections are independent of projection distance    Projection depends on part orientation #   Use judgement to select most useful/informative orientation  Often, a projection is clearest when a significant flat surface of the object is parallel to the projection plane   Left is a better pictorial view (it\u0026rsquo;s more 3D) Right is better because it\u0026rsquo;s face is parallel      Multi-view orthographic projection #   Usually can’t convey all information about an object using a single projection Use multiple projections from different viewpoints  What is an orthographic projection? #   Orthos: Greek for \u0026ldquo;right\u0026rdquo;, \u0026ldquo;true\u0026rdquo;, or \u0026ldquo;correct\u0026rdquo;  Each projection is formed by rays perpendicular (at right angles) to its projection plane The different views of a multi-view drawing are taken from viewpoints at right angles to each other Multi-view orthographic projection is a standardized, accepted form of representing objects   Graphos: drawing  \u0026ldquo;Glass-box\u0026rdquo; interpretation #   Need an agreed way to organize different projections on the page Imagine projecting object onto sides of a box Unfold the box onto the page So-called \u0026ldquo;third-angle\u0026rdquo; projection Will not necessarily show all six projections Projections are aligned      Example of multi-view orthographic projection #   Lines connecting a given point in adjacent views are always perpendicular to the \u0026ldquo;unfolding\u0026rdquo; line (of the \u0026ldquo;glass box\u0026rdquo;)           View interpretation #   Need to consider how many views needed to remove ambiguity   Multiview characteristics #   Inclined face  Face in 2 views Line in 3rd view       Oblique face  Face in 3 views       Which is the oblique face? #   How many views? #    Example: cut from sheet material Unlikely to be multiple levels of relief Projections of edges therefore unnecessary Grooves or etched patterns would be labeled as such       In this case, two views not enough to describe geometry completely \u0026ndash; we need 3\n    Thick enough material that there could conceivably be multiple levels of relief: side view needed In this particular example, all features pass through the full thickness of the material       Would any two views be enough to describe the geometry completely?\n   Example of hidden lines #   First- vs third-angle orthographic projection #   3rd angle projection used in U.S.  glass box convention       1st angle projection (Europe, Japan, India)  top/bottom and left/right arrangement reversed        Example of why specifying 1st or 3rd angle matters   ANSI standards (Y14.5) #   Adopted by drafters and engineers to expedite the transfer of information Maximum information with the minimum drawing Will only cover highlights here Views  At least two views (except flat sheet) Add views as required so the dimensions of the object can be defined entirely in true length measurements Add views as necessary for presentation clarity   Solid lines  Assumed to be intersections of planes or optical limits of cylinders Tangent edges are usually not shown, or shown using phantom lines   Hidden lines  Use to add information, clarity (good practice not to over-use) Use views requiring the fewest hidden lines   Center lines  Use to mark the centers of holes, or cylindrical surfaces ≥180º   Circles  Assumed to be intersections of cylinders and orthogonal planes   Section views  Used for clarification of internal geometries Explained in a later lecture      Small cuts on curved surfaces\n    Small radii, intersections of blended planar surfaces shown as a line\n   Representing threads use schematic representations\n   Parts with odd rotational symmetry Simplify to a symmetrical view even though that is not a strictly accurate projection\n   Tangent and non-tangent surfaces\n A line drawn where a curved surface meets a planar surface indicates no tangency: i.e. there is an abrupt change in the angle of the surface No drawn line indicates tangency: i.e.surface angle is continuous/smooth        Pictorial views #  Review of isometric, oblique, and perspective #           Color; shading #      Section views #                                     Advanced projections #    Auxiliary views #         Additional notation #  Dimensioning #       Showing welds #          "},{"id":24,"href":"/math-53/10/","title":"10: Parametric Equations and Polar Coordinates","section":"Math 53","content":"10.1 Curves Defined by Parametric Equations #   Parametric equations are written as .$(f(t), g(t))$ They define curves (not functions!) Time  .$t \\in [t_i, t_f]$ Initial point: .$\\big(f(t_i), g(t_i)\\big)$ Terminal point: .$\\big(f(t_f), g(t_f)\\big)$   For parametric equation in form .$\\big(h + r \\cdot \\sin(t), k + r \\cdot \\cos(t)\\big)$ on .$t \\in [0, 2\\pi]$ , the resulting curve is a circle clockwise centered around the point .$(h,k)$  Likewise, .$(r \\cdot \\cos(t), r \\cdot \\sin(t))$ is counter clockwise    Useful Desmos calculator If we need to graph an equation in form .$x = g(y)$ , we can use parametric equations .$x = g(t)$ and .$y = t$  10.2 Calculus with Parametric Curves #  Tangents #   Given .$x = f(t)$ and .$y = g(t)$ where both .$f$ and .$g$ are differentiable, we can get the tangent line to the curve by finding .$\\frac{dy}{dx}$ We can find .$\\frac{dy}{dt}$ using the chain rule: $$\\frac{dy}{dx} \\cdot \\frac{dx}{dt}$$ If .$\\frac{dx}{dt} \\neq 0$ , then we can solve .$\\frac{dy}{dt}$ : $$\\frac{dy}{dx} = \\frac{\\frac{dy}{dt}}{\\frac{dx}{dt}}$$ Horizontal tangents exist when .$\\frac{dy}{dt}= 0$ (assuming .$\\frac{dx}{dt} \\neq 0$ ) Vertical tangents exist when .$\\frac{dx}{dt}= 0$ (assuming .$\\frac{dy}{dt} \\neq 0$ )  Double Derivative #  $$\\frac{d^2y}{dx^2} = \\frac{d}{dx}\\Big(\\frac{dy}{dx}\\Big) = \\frac{d}{dt}\\cdot\\frac{dt}{dx}\\Big(\\frac{dy}{dx}\\Big) = \\frac{\\frac{d}{dt}\\Big(\\frac{dy}{dx}\\Big)}{\\frac{dx}{dt}}$$\nAreas #  Given .$x = f(t)$ and .$y = g(t)$ over .$t \\in (\\alpha, \\beta)$ , we can calculate the area between .$C$ and the .$x$ -axis with the following equation $$A = \\int_\\alpha^\\beta f\u0026rsquo;(t) \\cdot g(t)\\ dt $$ Likewise, between .$C$ and the .$y$-axis we derive the parametric equation for .$y$ : $$A = \\int_\\alpha^\\beta f(t) \\cdot g\u0026rsquo;(t)\\ dt $$\nArc Length #  To find length .$L$ of curve .$C$ given in form .$x = f(t)$ and .$y = g(t)$ on .$t \\in [\\alpha, \\beta]$ where .$\\frac{dx}{dt} = f\u0026rsquo;(t) \u0026gt; 0$ (meaning that .$C$ is traversed once from left to right as .$t$ increases from .$\\alpha$ to .$\\beta$ ) and where .$f\u0026rsquo;$ and .$g\u0026rsquo;$ are continuous on .$[\\alpha, \\beta]$ : $$L = \\int_\\alpha^\\beta \\sqrt{\\Big(\\frac{dx}{dt}\\Big)^2 + \\Big(\\frac{dy}{dt}\\Big)^2}\\ dt$$ Note that trig functions (.$\\sin, \\cos, \\text{etc.})$ ) loop every .$\\frac{\\pi}{2}$ because of the formula finds the absolute value.\nSurface Area #  Suppose the curve .$C$ given the equations .$x = f(t)$ and .$y = g(t)$ on .$\\ t \\in [\\alpha, \\beta]$ where .$f\u0026rsquo;$ and .$g\u0026rsquo;$ are continuous, and .$g(t) \u0026gt; 0$ , is rotated about the .$x$ -axis. If .$C$ is traversed exactly once, then the area of the resulting surface is given by $$S = 2\\pi \\int_\\alpha^\\beta y(t) \\sqrt{\\Big(\\frac{dx}{dt}\\Big)^2 + \\Big(\\frac{dy}{dt}\\Big)^2}\\ dt$$ Similarly, if instead .$C$ is rotated about the .$y$ -axis instead we use the following: $$S = 2\\pi \\int_\\alpha^\\beta x(t) \\sqrt{\\Big(\\frac{dx}{dt}\\Big)^2 + \\Big(\\frac{dy}{dt}\\Big)^2}\\ dt$$\n10.3 Polar Coordinates #   Pole = origin; labeled .$O$ Polar axis = line through .$O$ Polar coordinates = .$r, \\theta$ .$r$ is distance from point .$P$ and .$O$ .$\\theta$ is the angle between the polar axis and the line .$OP$ .$(r, \\theta) = (-r, \\theta + \\pi)$  Converting between Cartesian #   .$x = r\\cdot \\cos\\theta$ .$y = r\\cdot \\sin\\theta$ .$r^2 = x^2 + y^2$ .$\\tan\\theta = \\frac{y}{x}$  Symmetry #   If polar equation is the same when .$\\theta = -\\theta$ , the curve is symmetric about the polar axis If polar equation is the same when .$r = -r$ or when .$\\theta = \\theta + \\pi$ , the curve is symmetric about the pole If polar equation is the same when .$\\theta = \\pi-\\theta$ , then the curve is symmetric about the vertical line .$\\theta = \\pi/2$  Polar Tangents #  Knowing that $$x = r \\cdot \\cos\\theta = f(\\theta)\\cdot\\cos\\theta$$ $$y = r \\cdot \\sin\\theta = g(\\theta)\\cdot\\sin\\theta$$ We can use the product rule to find the tangent equation $$\\frac{dy}{dx} = \\frac{\\frac{dy}{d\\theta}}{\\frac{dx}{d\\theta}} = \\frac{\\frac{dr}{d\\theta} \\sin\\theta + r\\cos\\theta}{\\frac{dr}{d\\theta}\\cos\\theta - r \\sin\\theta} $$\n Horizontal Tangent: .$\\frac{dy}{d\\theta} = 0$ (when .$\\frac{dx}{d\\theta} \\neq 0$ ) Vertical Tangent: .$\\frac{dx}{d\\theta} = 0$ (when .$\\frac{dy}{d\\theta} \\neq 0$ ) Notice that for .$r = 0$ , then .$\\frac{dy}{dx} = \\tan\\theta$ if .$\\frac{dr}{d\\theta} \\neq 0$ We can then write the full formula: $$y-y_0 = \\frac{dy}{dx}\\Big(\\theta\\Big)(x-x_0)$$  10.4 Area and Lengths in Polar Coordinates #  Area of Polar Region #  Knowing that the area of a \u0026ldquo;slice\u0026rdquo; can be written as .$A = \\frac{1}{2}r^2\\theta$ , we can expand this to the case where the curve is a function .$r = f(\\theta)$ : $$A = \\int_a^b \\frac{1}{2} r^2\\ d\\theta$$\nArc Length of Polar Curve #  Given a polar curve .$r = f(\\theta), a \\leq \\theta \\leq b$ , we can re-write our base equations as $$x = r\\cos\\theta = f(\\theta)\\cos\\theta$$ $$y = r\\sin\\theta = f(\\theta)\\sin\\theta$$ Thus we can use the product rule when differentiating to get $$\\frac{dx}{d\\theta} = \\frac{dr}{d\\theta}\\cos\\theta - r\\sin\\theta$$ $$\\frac{dy}{d\\theta} = \\frac{dr}{d\\theta}\\sin\\theta + r\\cos\\theta$$ and using .$\\cos^2\\theta + \\sin^2\\theta = 1$ , we have $$\\Big(\\frac{dx}{d\\theta}\\Big)^2 + \\Big(\\frac{dy}{d\\theta}\\Big)^2 = [\\text{ugly stuff, see page 711}] = \\Big(\\frac{dr}{d\\theta}\\Big)^2 + r^2$$ so when .$f\u0026rsquo;$ is continuous, we can write the arc length equation as $$L = \\int_a^b \\sqrt{\\Big(\\frac{dx}{d\\theta}\\Big)^2 + \\Big(\\frac{dy}{d\\theta}\\Big)^2} d\\theta = \\int_a^b \\sqrt{r^2 + \\Big(\\frac{dr}{d\\theta}\\Big)^2}d\\theta$$\nCommon shapes #  Rose #   $$a\\cdot[\\sin \\text{or} \\cos](k\\cdot\\theta)$$\n .$r$ = .$a$ .$\\sin$ = Symmetry over .$\\theta = 0$ .$\\cos$ = Symmetry over .$\\theta = \\pi/2$ If .$k$ is even, rose will have .$2k$ petals. If .$k$ is odd, rose will have .$k$ petals. .$T = 2\\pi/k$ is range of a petal\u0026rsquo;s cycle .$2\\pi/T = k$ cycles displayed in graph .$A_{\\text{petal}} = \\frac{\\pi a^2}{4k}$  Cardioid #   $$r(\\theta) = a(1-\\cos\\theta)$$ $$A = \\frac{3}{2}\\pi a^2$$ $$L = 8a$$\nLimaçon #   $$r = b+a\\cos\\theta$$ Other equations I\u0026rsquo;m too lazy to type out\n"},{"id":25,"href":"/docs/math-53/","title":"Math 53","section":"Docs","content":"Chapters #   10: Parametric Equations and Polar Coordinates 12: Vectors \u0026amp; Geometry of Space 13: Vector Functions 14: Partial Derivatives 15: Multiple Integrals 16: Vector Calculus  "},{"id":26,"href":"/docs/physics-7b/","title":"Physics 7B","section":"Docs","content":"Chapters #   17: Temperature, Thermal Expansion, \u0026amp; Ideal Gas Law 18: Kinetic Theory of Gases 19: Heat \u0026amp; First Law of Thermo 20: Second Law of Thermo 21: Electric Charges \u0026amp; Fields 22: Flux \u0026amp; Gauss\u0026#39;s Law 23: Electric Potential 24: Capacitance, Dielectrics, Electric Energy Storage 25: Electric Current and Resistance 26: DC Circuits 27: Magnetism 28: Sources of Magnetic Field 29: Electromagnetic Induction \u0026amp; Faraday\u0026#39;s Law 30: Inductance, Electromagnetic Oscillations, \u0026amp; AC Circuits  "},{"id":27,"href":"/asamst-20a/","title":"ASAMST 20A","section":"Docs","content":"Week 1 (January 18 \u0026amp; 20): Introduction to the course. History, Memory, and Racialization #  Reading: Tataki, Strangers from a Different Shore, Preface and Ch. 1: “From a Different Shore.”\nWhat is Asian American Studies?\n Panethnicity  \u0026ldquo;pan\u0026rdquo; - a conglomeration \u0026ldquo;ethnicity\u0026rdquo; - belonging to a social group Panethnic identity example: Asian American   Panethnicity Cultural Literacy  One\u0026rsquo;s competency about their implicit biases    Reading:\n Angel Island versus Ellis Island  Angel Island was the west coast immigration entry point for people coming from the west (mainly Asian migration) Ellis Island was the entry point for many immigrrants from the east (mainly European)   \u0026ldquo;Multiculuralism was a find of fear and optimism around how we are a very mixed country and what binds us together is this appreciation of different ethnic backgrounds, but we also assimilate under some cultural practice/viewpoint\u0026rdquo; - Michael Chang\n   Ron Tataki on Multiculturalism (side note - \u0026ldquo;Reasonable minds may differ\u0026rdquo;)\n What is \u0026ldquo;epistemology\u0026rdquo;: Theory of knowledge. Asks the question:  \u0026ldquo;How do you know what you know?\u0026rdquo;\n   Race is socially constructed\n Through history socio-econmic, labor, and capital conflicts Any type of social norm is dependent upon contestation between people in the majority and minority. The power is asymmetric: Majority \u0026gt; Minority.  Cultual Literacy\n In studying Asian American history we are learning to understand how we have come to understand American history.  What are the source we have been taught? What are the viewpoints presented in the curriculum we have been taught as history? How do we believe in cultural literacy, in that we are literate in a diverse range of viewpoints representing the true multicultural background of the United States?    Arthur Schlesinger\u0026rsquo;s The Disuniting of America: Reflections on a Multicultural Country\n A very different view of multiculturalism:  The concern of a \u0026ldquo;breaking apart\u0026rdquo; or \u0026lsquo;Balkanization\u0026rsquo; due to conflicts Association with multiculturalism with ethnic conflict Reassertion of national unity around assimilation paradigm The concern of the \u0026ldquo;race problem.\u0026rdquo; The \u0026ldquo;American Creed\u0026rdquo; Schlesinger on \u0026ldquo;disuniting\u0026rdquo;    Two different viewpoints: Ron Tataki and Arthur Schlesinger\nDiscussion Questions:\n Takaki’s formulation of multiculturalism aligns with the concept of diversity, equity and inclusion of the 2000’s.  How is Diversity related to multiculturalism? What does the term \u0026ldquo;American Exceptionalism\u0026rdquo; mean to you?  Schlesinger was a proponent of “American Exceptionalism” the idea that America has provided safe harbor to many different groups of people. And that here in America, class, and lineage are not important.   How do Asian Americans fit into these models of diversity, multiculturalism and \u0026ldquo;American Exceptionalism\u0026rdquo;    Asian Americans fastest-growing electorate\n A naturalized citizen = someone who immigrated to the U.S. and gained citizenship   “More than 11 million will be able to vote this year, making up nearly 5% of the nation’s eligible voters (for this analysis, U.S. citizens ages 18 and older). They are also the only major racial or ethnic group in which naturalized citizens – rather than the U.S. born – make up a majority of eligible voters, according to a Pew Research Center analysis of Census Bureau data.”\n  Many Asian Americans have limited English proficiency  image    Aliens Ineligible for Citizenship and the 14th Amendment\n 1790 Immigrration and Nationality Act (INA): Asian Americans were restricted from naturalized citizenship from 1790 into the 1940s and until the 1950\u0026rsquo;s depending on Asian ethnic groups. At the same time the 14th Amendment was passed in 1867 as an important legal tool against discrimination by state and local governments.  Included an important clause stating that states cannot treat people differently on the basis of race (now it includes gender)  \u0026ldquo;Simply stated, all persons must be treated equally without regard to their race, color, or national origin.\u0026rdquo;\n    Legislation in 1965: Effectively ended the immigration restrictions and quotas against many Asian immigrants. Removed race and national origin as a restriction for naturalization.  As you move through the readings\u0026hellip;\n Consider what \u0026ldquo;power\u0026rdquo;, \u0026ldquo;agency\u0026rdquo; and \u0026ldquo;contestation\u0026rdquo; mean in the context of the history that you reading. Those who are constructed in history as \u0026ldquo;minority\u0026rdquo; also have agency while those with majority power must contend with the contestationo of majority control. How did the process occur in the U.S.? What are the legal and socio-cultural institutions and practices that result in a given standard of a moment in time, and in change?  Racial Formation\n Michael Omi \u0026amp; Howard Winant, Introduction, Racial Formation in the United States. 2014. HO  Dynamic-constantly in flux Reproduction of political interests  Aligns with the notion that within a diverse society, there will be multiple stakeholders (different groups and persons bringing forth different interests). The social construction around access to property and citizenship.   Race is socially constructed: came out from social contestation, geopolitics, etc.   Racial formation theory explains the fluidity of racial categories and the interest and forces that shape them. These pieces provide historical examples of how “white” identity came to be legally constructed through court cases and through the socio-economic forces supporting these legal outcomes.  Do the courts drive the outcome? Legal institions? 1690: the brewing slave trade 1790: contestation around what “white” meant. Before the slave trade was active, the primary source of labor was young Irish women. Came as indentured servants (a form of labor in which a person is contracted to work without salary for a specific number of years). Example of instability around what being “white” meant.   Sociologists Omi and Winant describe the fluidity of racial constructions over time dependent on political interests and socio-economic forces, as \u0026ldquo;racial formation.\u0026rdquo; What is Omi and Winant\u0026rsquo;s concept of \u0026ldquo;common sense\u0026rdquo;?  “Common sense” derives from Italian philosopher and political economist Antonio Gramsci’s theories on asymmetry in political power and the interest conflicts that may emerge as a result.  I.e. today’s “Common sense” surrounding gender is that gender is a social construct as opposed to one’s sex. Gramsci wrote about hegemony as in “how does power operate when there is one party that maintains much of the mechanisms of culture and state?”  You have agency. A consensus that results from an agreement (not so much voluntary, but through negotiation)        What is a \u0026ldquo;Race\u0026rdquo; versus an \u0026ldquo;Ethnicity\u0026rdquo;? Consider the challenge of formally categorizing groups:\n The U.S. Census Bureau uses the term \u0026ldquo;Hispanis\u0026rdquo;  Who are \u0026ldquo;Hispanics\u0026rdquo;? Who ae \u0026ldquo;Latinos\u0026rdquo;?   Is \u0026ldquo;Asian AMerican\u0026rdquo; a race descriptor? Is \u0026ldquo;Hmong American\u0026rdquo; a race or an ethnicity descriptor?  Taki referred to the popular perception of Asian Americans as:\n Model Minority: A trope that gained traction in the 1960s that stresses the prototypical Asian’s high achievement in socioeconomic status and focuses on their culture to explain their “success”; denies racism and other hardships that are experienced by Asian Americans; comparison between one minority group and another Perpetual Foreigner: stereotype in which naturalized and even native-born citizens are perceived by some members of the majority as foreign because they belong to a minority ethnic or racial group.  Twin pillars of how Asian Americans are constructed\n How do these sterotypes and categories affect cultural and legal outcomes for Asian Americans?\n The Social Construction of Race\n The idea that race is socially constructed emerged as a response to the view that race is based on biology  What does it mean to say that race is not based on biology? Does it mean that there are no biological or genetic bases to difference? What is the difference between difference and race? Blood quantum: the idea that if you have any drop of African American ancestry, in that jurisdiction/state, you are legally classified as black  For whites to maintain racial purity, property, power, and perpetuated the classification/segregation of people on the basis of race      Class Question: How has federal jurisdiction driven civil rights protections from the time of early Asian immigrants to the U.S. to the 2020s?\n For example, the Interstate Commerce Act addressed the problem of railroad monopolies by setting guidelines for how the railroads could do business.  Insiders and Outsiders\n As cited in footnote 4 of the U.S. Supreme Court\u0026rsquo;s Carolene Products the Tainted Milk, case:   “prejudice directed against discrete and insular minorities may call for “more searching judicial inquiry.”\n  Ensured that former slave-holding states would abide by this 14th amendment that said that African Americans had to have citizenship rights Created a legal authority when the former slave-holding states tried to reinstitute some form of slavery  Racial formation construction?  Sojourners vs. Immigrants\n Labor and capital interests drove demand for cheap labor during U.S. industrialization  Push and Pull\n Geopolitical political economic factors  Alienation of Migration Guangdong Chinese Women sang\n Dear husband, ever since you sojourned. In a foreign land. I\u0026rsquo;ve lost interest in all matters. All day long, I stay inside the bedroom, My brows knitted; ten thousand Thoughts bring me endless remorse, in Grief, in silence. I cannot fall asleep on my lonely pillow.\n 1882 Chinese Exclusion Act\n Racialized labor conflict and competition The main landmark that stems from aliens ineligible for citizenship  Agency, Resistance and Contestation\n Yick Wo v. Hopkins, USC 1996  Provides the basis for the important legal evidence standard of \u0026ldquo;disparate impact\u0026rdquo; Supreme Court said that San Francisco zoning law is in violation of the 14th Amendment    120,000 Americans of Japanese descent on the Western U.S. seaboard were sent to internment camps. 75% of internees were American citizens by birth.\nWeek 2 (January 25 \u0026amp; 27): The racialization of Asian Americans: contemporary images and historical transformations. #  Reading: Okihiro, Common Ground, Preface \u0026amp; Ch. 2: “White and Black.”\nClass Question: Okihiro writes in his preface that his book Common Ground is about the \u0026ldquo;creation of the American character and subject.\u0026rdquo;\nWhat does he mean by that?\n the social construction of the nation  Binaries as convenient cognitive and socio-political constructs\n Binaries offer coherence, especially during times of social upheaval. They preserve rule amidst apparaent chaos, and stability amidst rapid change, such as during the late eighteenth, nineteenth, and twntieth centuries (i.e industrial revolution, enlightenment, romanticism). Those periods of American history occasioned social reconstitutions of geographies, race, gender, sexuality and nationality that helped to define and regulate identities, the state, and the social formation.  Break out question: What are some modern-day binaries and what socio-political institutions or relationships and hierarchies do they support?\n gender norms, environmental conservation, wealth inequality  What are some binary ideas or myths based on the social construction of an East vs. West divide?\n Rudyard Kipling The Ballad of East and West, 1889  Oh, East is East, and West is West, and never the twain shall meet, Till Earth and Sky stand presently at God\u0026rsquo;s great Judgment Seat; But there is neither East nor West, Border, nor Breed, nor Birth, When two strong men stand face to face, though they come from the ends of the earth!\n  These poems pervade our perceptions and are descriptors for historical moments in time. They are important signifiers of binaries    Model Minority vs. Perpetual Foreigner\n Are these two poles of the social construction of Asian Americans binary? How do they serve to construct the \u0026ldquo;Asian American subject?\u0026rdquo;  Korematsu v. United States\n \u0026ldquo;In response to the Japanese attack on Pearl Harbor during World War II, the U.S. government decided to require Japanese-Americans to move into relocation camps as a matter of national security. President Franklin Roosevelt signed Executive Order 9066 in February 1942, two months after Pearl Harbor. A Japanese-American man living in San Leandro, Fred Korematsu, chose to stay at his residence rather than obey the order to relocate. Korematsu was arrested and convicted of violating the order. He responded by arguing that Executive Order 9066 violated the Fifth Amendment. The Ninth Circuit affirmed Korematsu\u0026rsquo;s conviction.\u0026rdquo; - Oyez\n  Conclusion: The Court ruled against Korematsu. The Court believed that the decision was valid because it was a necessity amid the danger of espionage and sabotage.  Common ground vs. Margins as the Mainstream\n Okihiro writes that his book seeks to reject binaries and to advocate for a \u0026ldquo;open, borderless\u0026rdquo; common ground\u0026quot; versus his prior argument that the mainstream norms, rights, values of America were created by the margins.  meaning that the margins create the mainstream.    Race Conscious Judicial Review and Black/White Paradigm\n Race relations in the United States have rapidly evolved in recent decades however, race scholars often point to a persistent paradigm that views racial difference primarily through the construction of black and white relations.  Binarism and Black White as a paradigm\n Okirhiro says that the American race paradigm views race relations in terms of black and white.  Separate but Equal: Plessy v. Ferguson (1896)\n Louisiana\u0026rsquo;s Separate Car Act challenged under the 14th Amendment   \u0026ldquo;Louisiana enacted the Separate Car Act, which required separate railway cars for blacks and whites. In 1892, Homer Plessy – who was seven-eighths Caucasian – agreed to participate in a test to challenge the Act. He was solicited by the Comite des Citoyens (Committee of Citizens), a group of New Orleans residents who sought to repeal the Act. They asked Plessy, who was technically black under Louisiana law, to sit in a \u0026ldquo;whites only\u0026rdquo; car of a Louisiana train\u0026hellip;When Plessy was told to vacate the whites-only car, he refused and was arrested\u0026hellip;Plessy was convicted.\u0026rdquo; - Oyez\n  Conclusion: The Court declared the state law constitutional. In essence, segregation did not constitute unlawful discrimination.  Constructive blacks\n Law scholar Frank Wu argues that our legal system construes \u0026ldquo;racial groups as white, blacks, \u0026ldquo;honorary whites or constructive blacks.\u0026rdquo;  What does \u0026ldquo;constructive\u0026rdquo; mean?  The legal system has treated Asians, mostly as blacks. Applied the same rules to Asians as they would to Blacks.     He says historically, the U.S. legal system has treated Asians mostly as \u0026ldquo;constructive blacks.\u0026rdquo;  People v. Hall, 1854 (CA state court attributed black status to Asians in enforcing a statue (passed by a legislative body) prohibiting the testimony of blacks, reasoning that \u0026ldquo;blacks\u0026rdquo; was a generic term for all nonwhites). Gong Lum v. Rice, 1927 (USC upheld segregated public schools for Asians connoting no difference between segregation for blacks to those of the \u0026ldquo;yellow races\u0026rdquo;).    1790 Immigration and Naturalization Act revisited\n Held that only \u0026ldquo;free white persons\u0026rdquo; of \u0026ldquo;good moral character\u0026rdquo; could become naturalized citizens. After the Civil War, African Americans who were former slaves, gained official citizenship status.  Ozawa v. U.S., 1922 (USC ruled Japanese American were not white for naturalization but lauded performance of white middle class attributes such as attending Cal, Church, and speaking English at home) U.S. v. Thind., 1923 (USC ruled Asian Indian Immigrants not white for naturalization, noting that though anthropologists deemed Indians \u0026ldquo;Aryan\u0026rdquo; this was not the same in the common sense understanding of a white person) Racial bar for naturalization not lifted until the Immigration and Naturalization Act of 1952 (McCarran-Walter Act), and abolished the race restriction of the 1790 INA, though it retained a quota system for nationalities and regions.    Are Asians White or Black? Do the Right Thing, Spike Lee (1989)\n Asians as \u0026ldquo;Middle Man minority\u0026rdquo;  i.e. Your grandparents may have businesses in neighborhoods that are African-American or Latinx that are in the grey-economic zone.   Asians as Other Non-Whites:  Social construction of race\n Systematic racism vs. Individual discrimination Rapid change in federal position over a matter of months    Trump Executive Order on Diversity  Biden Executive Order on Diversity  Biden Executive Order on Asian Americans  The 1992 Los Angeles Uprising/Riots L.A. Burning: The Riots 25 Years Later\n The filmed video of African American Rodney King beating was probably on of the first \u0026ldquo;viral video\u0026rdquo; of police excessive force with serious consequences for race relations. Days after the videotaped beating of Rodney King, a Korean American grocery shop owner, Soon Ja Dul, shot and killed a 15 year African American who she mistook for stealing, and grabbed her sweater and backpack and Harlins punched her. Soon Ja Dul went behind the counter to retrieve a shotgun and shot Harlins in the back of her head. Following the acquittal in April of 1992, of Los Angeles Police Department officers on trial for the beating, Los Angeles experienced six days of civil unrest that resulted in the burning of many businesses, including those in Korea town which is located in and near historically black neighborhoods. The Harlins killing has also been attributed as contributing to civil unrest that occurred after the acquittal.  Sa I Gu Sa I Gu (official full version)\n A very specific view of the 1992 Los Angeles Uprising/Riots from the perspective of (mostly) Korean American women who were shop owners Afterthoughts:  Where do the views of the witnesses in this movie sit? Can we square the views of the Korean American witnesses here with one of diversity and equity? What racial tensions or divides might exist here between KA and African Americans? Is this a race issue or a class issue? Is this a race issue or an immigration issue?    The Cold War Construction of the Model Minority Myth\n What does \u0026ldquo;model minority\u0026rdquo; mean? Why Do We Call Asian Americans The Model Minority? | AJ+ Black/White paradigm:  Does the \u0026ldquo;model minority\u0026rdquo; stereotype support the black/white paradigm? How does it support an assimilationist paradigm?   Scholar Robert Lee says that the stereotype supports a view of minorities compliance with \u0026ldquo;accommodation\u0026rdquo; to assimilationist and status quo norms rather than militancy.  Lee describes this as a \u0026ldquo;disjuncture between the newly articulated ideals of racial egalitarianism and the practice of racial discrimination\u0026rdquo; as evidence by the USC\u0026rsquo;s decisions in the Japanese interment cases.    Disjuncture?\n What does Lee mean by this disjuncture?  How is this supposed \u0026ldquo;disjuncture\u0026rdquo; exemplified by Cold War politics?  1966 NYT\u0026rsquo;s Magazine article on \u0026ldquo;Success Store: Japanese American Style,\u0026rdquo; and in December of that year, \u0026ldquo;Success Story of One Minority in the U.S.\u0026rdquo; At a similar moment, U.S. Senator Daniel Patrick Moynihan published the influential Report on the Black Family (1965) which was an attempty to use data and sociological methods to understand poverty and income inequality in the African American community but which used the term \u0026ldquo;tangle of pathology\u0026rdquo; and referenced single parent families in the African American community as a source of the generational poverty. How are these relevant to this idea of \u0026ldquo;disjuncture\u0026rdquo;?      Week 3 (February 1 \u0026amp; 3): U.S.-Asia relations and early immigration. #    Discussion topics:\n Were al the national/ethnic groups who are considered \u0026ldquo;white\u0026rdquo; today considered \u0026ldquo;white\u0026rdquo; in the 1800\u0026rsquo;s? What was the connection between a person\u0026rsquo;s labor/class status and their racial identity according ot Tataki? What does it mean to \u0026ldquo;perform\u0026rdquo; a racial identity. Are you just who you are racially? Are race relations in the U.S. based on a black and white framework? How do Asian Americans fit into a black and white framework? How do Asian Americans not fit into a black and white framework? What is legal discrimination? What is \u0026ldquo;disparate impact\u0026rdquo; versus \u0026ldquo;intentional motivation\u0026rdquo; or \u0026ldquo;animus\u0026rdquo;? What is \u0026ldquo;color-blind\u0026rdquo; legla doctrine?    Overblown with Hope\n  Gam Saan = \u0026ldquo;gold mountain\u0026rdquo;\n 1848 shortly after the discovery of gold at John Sutter\u0026rsquo;s Mill, a young man in Canton China wrote to his brother in Boston,   \u0026ldquo;Good many Americans speak of California. Oh! Very rich country! I hear good many Americans and Europeans go there. Oh! They find hold very quickly, so I hear \u0026hellip; I feel as if I should like to go there very much. I think I shall go to California next summer\u0026rdquo;\n   Immigrant Labor\n Contract Laborers  Emigration brokers representing sugar planters provided \u0026ldquo;free passage\u0026rdquo; where immigrants would sign labor contracts with a planter for 5 years with wages, shelter, food and medical care.   Free Laborers  A credit-ticket system, a broker lends money to a migrant for the ticket for passage. The migrant would pay off the loan with interest out of his earnings in the U.S.      Chung Kun Ai on money lending\n \u0026ldquo;One condition of his loan of $60 was that each borrower was to pay back $120 as soon as he was able to do so. In all, grandfather must have helped 70 young men from our village and nearby villages to migrate to North and South American and also Australia.\u0026rdquo;\n   Gender and Migrant Labor: Chinese traditional Culture, Labor and Capital Strucutres, Geopolitics, and race\n How did traditional Chinese culture affect the gender demographics of Chinese labor migrants?  the wife was in a subordinate positon the wife served as an incentive for their husband to return      Hawaii vs. U.S. Mainland\n Hawaii encouraged the husband to bring their families over, whereas the U.S. Mainland (California) only wanted the men.    Complexity in Chinese immigrants\n Hakka did not practice footbinding Hawaii made some efforts to promote migration of Chinese women.      \u0026ldquo;A Race so Different from Our Own\u0026rdquo; - Justice Harlan, dissenting, Plessy v. Ferguson\n  Segregation under the law\n Citizenship Rights are the primary pivot for access to recognition by government and thus rights attached to citizenship Segregation upheld only separation but negative status associated with slavery  Randall Kennedy on One Drop Rule and the complexity of Black identity    Early Segregation Historical Milestones\n 1790: Immigration and Naturalization Act 1857: Dred Scott v. Sandford 1862: Emancipation Proclamation Executive Order 1865: Civil War ends 1882: Chinese Exclusion Act 1886: Yick Wo v. Hopkins 1889: Chae Chan Ping v. U.S. 1896: Plessy v. Ferguson     Dred Scott v. Stafford (1857)\n The Court denies citizenship on the basis of deference to the political branches. Pre-Civil War the Supreme Court reified negative status of Blacks Court holds Blacks are not citizens and are thus subject to legislative laws on slaves as chattel (property)     Plessy v. Ferguson\n A legal caste system based on race is created on a fiction of separate but equal. Post-Civil War Supreme Court, holds that segregation of African Americans and Whites does not violate the Fourteenth Amendment. Harlan’s Dissent raises the contradiction of assumedly not segregating Chinese who are excluded from naturalized citizenship while segregating of African Americans who “fought for the union.”     Yick Wo v. Hopkins\n A theory of evidence for systemic discrimination is created. Supreme Court established disparate\u000boutcome (impact) as basis for establishing racial discrimination.     Chae Chan Ping v. United States\n Supreme Court held that Chinese Exclusion Act of 1882, passed while Chinese man was abroad, applied and revoked his re-entry permit)    With law the past is always in the present\n  Why is Chae Chan Ping relevant today?    Plenary Power Doctrine\n \u0026ldquo;The plenary power doctrine protects the federal government from claims that it is violating an individual\u0026rsquo;s constitutional right to equal protection when it imposes discriminatory burdens on non-US citizens.\u0026rdquo; - CUNY School of Law  i.e. Congress has \u0026lsquo;planery power\u0026rsquo; over who can enter and exit the U.S.      Demographic Complexity/An Explosion of Immigrants\n Asian Immigrants  (incomplete) 370,000 \u0026ldquo;arrivals\u0026rdquo; of Chinese to Hawaii and CA from late 1940\u0026rsquo;s and early 1880\u0026rsquo;s. 1880\u0026rsquo;s to about 1910: 400,000 \u0026ldquo;arrivals\u0026rdquo; of Japnese to Hawaii and the West Coast. 1900-1933: 7,000 \u0026ldquo;arrivals\u0026rdquo; of Korean, 7,000 Asian Indian, 180,000 Filipinos to Hawaii and mainland.   European Immigrants  1850-1930: 35 million European immigrants.      Geoolitics and Push and Pull\n Colonialism and internal instability  European colnial involvement American colonial involvement Internal instability in the modern nation-state era   Labor and Capital  Racialization of Labor allegations of unfair wage and job competition increases.      War and internal instability in China\n Anglo-Chinese War of 1856-60  Piracy change against British citizen leading to war Ports and missionaries   Taiping Rebellion 1850-1864  Christianized Chinese believing brother of Jesus led rebellion across Central and South China, impacting Guangdong in particular. Estimated 10 million deaths.      Inequity at home tied to colonialism pushes and pulls Filipinos out\n Spanish-American War of 1898; and resultant Treaty of Paris resulted in U.S. possession of Phillipines. Takaki writes that Filipino peasants found that the rich rice lands they cultivated were becoming owned by wealthy men, turning them into sharecroppers.    Immigration Laws and Challenges\n Labor and Capital  As Chan notes, colonial administrators needed cheap physical labor for their projects, thus the migrants to such colonies were disproportionately young men. In the U.S. mainland context this resulted in labor competition with European Americans in particular, in the immediate post-Civil War era.   Legal Outcomes  The Chinese Exclusion Act triggered a range of challenges by Asian Americans, Chinese in particular early on, supported by funds from co-ethnic organizations such as the Chinatown based Chinese Benevolent Association.      Citizenship: Assimilation vs. Segregation\n What does the exclusion exeprience of Asian Americans (early Chinese in particular) from citizenship say about the segregation of African Americans and vice versa?    A \u0026ldquo;neutral principle\u0026rdquo; in the \u0026ldquo;Rule of Law\u0026rdquo; and the assertion of Fourteenth Amendment protections for Carolene Products \u0026lsquo;discrete and insular minorities\u0026rsquo;\u0026rdquo;\n Neutral Principle  \u0026ldquo;Rule of Law\u0026rdquo;: Often stated as a broader checks and balances based principle with strong consideration of the authirity of each branch as well as the limitations on such authority. Historically asserted by the judicial branch to avoid ruling on \u0026ldquo;political\u0026rdquo; questions.   Fourteenth Amendment  As a tool to remedy discrimination, (specifically race early in U.S. history). Carolene Products\u0026rsquo; asserted view that allegations of discrimination against \u0026ldquo;discrete and insular minorities\u0026rdquo; requires close scrutiny by courts. This lead into the standard applied in Korematsu (1944).      The American Federation of Labor\u0026rsquo;s \u0026ldquo;Meat vs. Rice: American Manhood vs. Asiatic Cooliesim\u0026rdquo;\n Labor and Capital Conflict  Social Construction of Race, Gender, and Class Close tie between rise of American unionism and trade associations with racialization through Samual Gompers-elected first president of the AFl in 1886.      AFK-CIO June 17, 2020 \u0026ldquo;Condemning and Combatting Anti-Asian Racism\u0026rdquo; statement\n \u0026ldquo;As a labor movement, we must acknowledge our own painful past on this and other racial justice issues. In 1882, then-American Federation of Labor (AFL) President Samuel Gompers pushed for the passage of the Chinese Exclusion Act, citing the dangers of \u0026ldquo;Asiatic\u0026rdquo; men in an essay published by the AFL and submitted as Senate testimony. Fear among White workers propelled this legislation, the first to bar an entire race from legslly entering the United States.\n   The \u0026ldquo;Citizenship Clause\u0026rdquo;\n Section 1: \u0026ldquo;All persons born or naturalized in the United States and subject to the jurisdiction thereof, are citizens of the United States and of the State wehrein they reside.\u0026rdquo;    The Fourteenth Amendment\u0026rsquo;s \u0026ldquo;Citizenship Clause\u0026rdquo;: Asian American citizenship rights tied again to slavery and citizenship rights\n Prior to the 14th Amendment\u0026rsquo;s passage on June 8. 1866:  Dred Scott v. Sandford (1857), triggered federal legislative response with Civil Rights Act of 1866, asserting all persons born in U.S. or naturalized were citizens of U.S. and residence state Wong Kim Ark challenges his citizenship exlcusion 1898.      Born in the USA: Wong Kim Ark, 1898 Another Chinese Exlcusion Act Case\n Given the Chinese Exclusion Act of 1882, was a born in the USA person of Chinese descent a citizen?  \u0026ldquo;Because Wong was born in the United States and his parents were not “employed in any diplomatic or official capacity under the Emperor of China,” the Citizenship Clause of the Fourteenth Amendment automatically makes him a U.S. citizen.\u0026rdquo; - Oyez\n     Discussion: Week 4 #    Major Themes\n Early Asian Immigration/Emigration  Influx of Asians to the U.S. start during the mid-19th century  370,000 Chinese (early 1840s - late 1940s) 400,000 Japanese (1880s) 7,000 Koreans (early 1900s to mid-1900s) 7,000 Asian Indians (early 1800s) (incomplete)        Push and Pull Factors\n By definition: factors that caused large groups to emigrate out of a country and or immigrate to another country. China  Push  Economic Instability:  First Opium Wars (1839 - 1842) Second Opium Wars (1857 - 1859)   Internal instability  Taiping Rebellion   Natural Disasters:  Drought in Henan Province (1847) Flooding of Yangtze River Famine in Guangdong   (incomplete)        Japan\n Push: Economic instability Pull: Job opportunity (i.e. farming, fishing)    Philippines\n Push: Internal Instability (i.e. Spanish-American War of 1898 and the Treaty of Paris) Pull: Economic opportunities (incomplete)    U.S. taking advantage of early Asian migrants\n Cheap labor and capital  mostly men cheap physical labor labor competition with European Americans      U.S. - Asia Relations\n In early 19th century, white nativists spread xenophobic propaganda -\u0026gt; Chinese Exclusion Act  First law in the U.S. that barred immigration based on race   With World War II, President Roosevelt passed Executive Order 9066  Japanese Americans were incarcerated, many of whom were naturalized citizens      Current Event 1: How Covid-19 reignited long-standing xenophobia against Asians (Specifically Chinese)\n \u0026ldquo;Forever Foreigner\u0026rdquo; stereotype persists Anti-Chinese Rhetoric from political leaders fuels the fire Violence rates against Asians rose after Covid-19 hit the US (incomplete)    Current Event 2: The Model Minority Myth of Asian-American Workers Today\n Many Asian-Americans in workforce; less in higher positions \u0026ldquo;Bamboo Ceiling\u0026rdquo; - glass ceiling for Asian Americans Model Minority Myth: Asians painted as hardworking, smart and faithful but also deeemed workers who lacked the ambition, creativity and confidence that being a leader requires Where do we go from here?  Change the qualities of what someone in leadership looks like Give more positions to Asian-Americans What happens when there are more Asian-Amerians in the workplace?  Studies show a better environment        Current Event 3: Biden-Harris Administration Advances Equality and Opportunity for Asian American, Native Hawaiian, and Pacific Islander (incomplete)\n Advancing safety for Asian Americans  Combating hate and violence COVID-19 Hate Crimes Act  Helps local and state law enforcement accurately report hate crimes to the FBI Helps combat the potential language barrier stopping AAPI community members from reporting hate crimes   Research and Education (NSF)   Advancing Immigration Reform  United States Citizenship Act Promoting naturalization Addressing the backlog for U Visa Petitioners      Week 4 (February 8 \u0026amp;10): Chinese in the labor market. The context for exclusion: broad changes in the economy and polity of the United States. #    The Context for Exclusion\n Labor and Capital Conflicts  Intersectional across, race, class, and gender and situated in geopolitics and a pre-existing domestic race politics      Early Segregation Historical Milestones\n 1790: Immigration and Naturalization Act 1857: Dred Scott v. Sandford 1862: Emancipation Proclamation Executive Order 1865: Civil War ends; Start of Reconstruction 1868: 14th Amendment 1875: Page Act 1877: End of Reconstruction 1882: Chinese Exclusion Act 1886: Yick Wo v. Hopkins 1889: Chae Chan Ping v. U.S. 1896: Plessy v. Ferguson    Revisiting: Citizenship: Assimilation vs. Segregtion\n What does the exclusion experience of Asian Americans (early Chinese in particular) from citizenship say about the segregation of African Americans and vice versa?    Fourteenth Amendment 1868 Reminder\n All persons born or naturalized in the United States, and subject to the jurisdiction thereof, are citizens of the United States and of the State wherein they reside. No State shall make or enforce any law which shall abridge the privileges or immunities of citizens of the United States; nor shall any State deprive any person of life, liberty, or property, without due process of law; nor deny to any person within its jurisdiction the equal protection of the laws    Where does power lie?\n Agency and contestation by “discrete and insular minorities”    Revisiting: A ”neutral principle” in the “Rule of Law” and the assertion of Fourteenth Amendment protections for Carolene Products’ FN 4 ”discrete and insular minorities”\n Neutral Principle \u0026ldquo;Rule of Law\u0026rdquo;:  Often stated as a broader checks and balances based principle with strong consideration of the authority of each branch as well as the limitations on such authority. Historically asserted by the judicial branch to avoid ruling on ”political” questions.   Fourteenth Amendment  As a tool to remedy discrimination, (specifically race early in U.S. history). Carolene Products’ asserted view that allegations of discrimination against “discrete and insular minorities” requires close scrutiny by courts. This lead into the standard developed in Korematsu (1944).      What Happened to the Women?\n Race and sex sterotypes; Asian women    A long history of Asian American (women) activists\n How does history socially construct mainstream understandings of what it means to be an Asian American female?  Prof. Um and Fujino on Asian American activism:    Centering Women as Active Subjects of History\n Hune writes that one constructive approach to situating Asian American women in history is to view them “as active participants in history and agents of social change, negotiating complex structures of power”    Alternative spaces where agency was exercised\n Dominant historiography of Asian women focused on issues of work, control of labor by the husband’s family and immigration restrictions but other reasons explain absence of Chinese and Indian women in the U.S. They had “separate lives” with ties to kin, friends, and their own cultural worlds important to them which has been obscured by the dominant telling of history.    Little is known; Focus on the family unit as the \u0026ldquo;normative model\u0026rdquo; of migration should be questioned\n Migration of women along with their men “was the exception rather than the rule”    Social Construction of Asian Women as “Orientalized Chinese women as passive victims - of culture and patriarchy.” - Hune writes that little is known about the lives of Cantonese, Punjabi migrant women that is likely because many of our images of these women’s lives come from the nine-tenth century writings of European-American missionaries.\n  Male preference cultures in China and Punjab \u0026amp;\u000bDivergent economies of the home counties created complexity for class status of women affecting female migration\n Evolving patriarchal relations at a time when migrants from a range of counties (Shunde, Zhongshan, Panyu and Nanhai) became merchants in the Chinese American community while “Sze Yup migrants were often laborers and domestics.”    Chinese women presumptively sex workers\n Page Act of 1875 (Sect. 141, 18 Stat. 477, 3 March 1875)  A pre-Chinese Exclusion Act exclusionary law specifically based on gender      Chinese women immigration early on; Prostitution as ”yellow slavery”\u000bRace, culture and religion\n  Page Act introduced by Representative Horace Page to \u0026ldquo;end the danger of cheap Chinese labor and immoral Chinese women” barring “undesirable” immigrants defined as:  Forced laborer East Asian women engaged in prostitution Convicts      Immigration review and requirements in Hong Kong Wives vs. Prostitutes\n American consul reviewed background of Chinese women applying for immigration from Hong Kong with document and questions:  Photographic Identification Official declaration of purpose of emigration and personal morality statement. Review by hospital staff for character review. A multi-level review process from American consul in HK officials back to American consul day of departure. Questions about who fathers and husbands were.      Break out Questions\n Was the Page Act protective of trafficked Chinese women or was it exclusionary? What were the domestic and geopolitical factors that played a role in Chinese female sex workers and concubines? What are the factors that may have driven the concern around \u0026ldquo;yellow slavery\u0026rdquo;    Class Question\n How did political and socio-economic conflicts in Asia affect the migration of South Asians to the U.S.? How did political and socio-economic conflicts in Asia affect the migration of Chinese to the U.S.?    Hostility and Conflict; Racism and Nativism\n Chan notes 7 types of hostility against Asian Americans:  Prejudice: preconceived notions based on stereotypes ~ discrimination Economic Discrimination Political Disenfranchisement: often references voting rights Physical Violence Immigration Exclusion Social Segregation Incarceration      Geopolitical Drivers to Negative Stereotypes of Chinese\n Chan references Stewart Creighton Miller three groups of Americans who\u0026rsquo;s interactions in China propagated sterotypes of Chinese:  Diplomats resenting protocols of Chinese Court Merchants upset on limitations for freedom of trade Missionaries concerned about slow rate of Chinese conversion to Christianity      Range of CA law excluding Chinese: Criminal Proceedings Act of 1850\n Criminal Proceedings Act of 1850 (later covered civil as well) exclusing testimony of Blacks, \u0026ldquo;Mulattos\u0026rdquo; and Native Americans. \u0026ldquo;The 14th section of the Act of April 16th, 1850, regulating Criminal Proceedings, provides that \u0026lsquo;No black or mulatto person, or Indian, shall be allowed to give evidence in favor of, or against a white man.\u0026rdquo;    People v. Hall. CA. (1854)\n White prospector killed Chinese miner. While prosecuted for the murder, on appeal the conviction was overturned on the basis that Native Americans came over the Bering Strait from Asia and therefore were \u0026ldquo;Asiatics.\u0026rdquo; Thus, the 1850 Criminal Proceedings Act Applied to \u0026ldquo;the whole of the Mongolian race.\u0026rdquo; This prohibited all non-Whites from testifying against Whites not changed until the 1870\u0026rsquo;s.    Judicial Rationale in People v. Hall\n incomplete    Chinese Massacre of 1871 Massacre, Los Angeles\n incomplete    Rock Springs MAssacre, September 2, 1885\n Rock Springs Utah, massacre, 1885: Union Pacific railroad hired former Chinese railroad workers for coal mining work for less wages than White labor.    Labor Organization and Race\n Knights of Labor Mainstream history on labor history often passes over its origins in race and immigration exclusion    "},{"id":28,"href":"/math-53/12/","title":"12: Vectors \u0026 Geometry of Space","section":"Math 53","content":"12.1 3D Coordinate Systems #   Right hand rule: Index point to .$x$, thumb to .$z$, and write through .$y$ If you have point .$P(a,b,c)$ and drop a perpendicular dot on the .$xy$-plane at .$a,b,0$, you now have a projection of .$P$ onto the .$xy$-plane The distance .$|P_1 P_2|$ between two points .$P_1(x_1, y_1, z_1)$ and .$P_2(x_2, y_2, z_2)$ is $$|P_1 P_2| = \\sqrt{(x_2-x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2}$$ We can define the equation for a sphere with a center at .$C(h,k,l)$ and radius .$r$ as $$(x-h)^2 + (y-k)^2 + (z-l)^2 = r^2$$  12.2 Vectors #   Written as .$\\overrightarrow{AB}$ Has initial point .$A$ at the tail and the a terminal point .$B$ at the tip  If the initial point .$A$ is at .$(x_1, y_1, z_1)$ and terminal point .$B$ is at .$(x_2, y_2, z_2)$, then we can write .$\\overrightarrow{AB} = \\langle x_2 - x_1, y_2 - y_1, z_2 - z_1\\rangle$   Vectors with the same length/magnitude are called equivalent or equal, despite not necessarily having the same initial/termination points Vector addition (order doesn\u0026rsquo;t matter) $$ \\overrightarrow{AC} = \\overrightarrow{AB} + \\overrightarrow{BC} = \\overrightarrow{BC} + \\overrightarrow{AB}$$ $$ \\vec u - \\vec v = \\vec u + (- \\vec v)$$ $$ \\vec a + (\\vec b + \\vec c) = (\\vec a + \\vec b) + \\vec c$$ Vector multiplication  Given scalar .$c$ and vector .$\\vec v$, .$c\\cdot\\vec v$ is like .$\\vec v$ but with length changed by a factor of .$\\Vert c\\Vert$ If .$c\u0026lt;0$, then the vector is flipped around $$c\\cdot\\vec v = \\langle cv_x, cv_y, cv_z\\rangle$$   Magnitude for .$\\vec a = \\langle a_x, a_y, a_z \\rangle$:  $$ \\Vert \\vec a \\Vert = \\sqrt{a_x^2 + a_y^2 + a_z^3}$$   Unit vector  Has length of one If .$\\vec a \\neq 0$ then the unit vector .$\\vec u$ in the same direction as .$\\vec a$ is:  $$\\vec u = \\frac{\\vec a}{\\Vert \\vec a \\Vert} = \\frac{1}{\\Vert \\vec a \\Vert} \\vec a$$ Notice that .$\\frac{1}{\\Vert \\vec a \\Vert}$ is a scalar      12.3 Dot Product #   The dot product measures the extent which two vectors are parallel to one another  Two vectors are perpendicular/orthogonal .$\\perp$ (.$90^\\circ$ from one another) iff the dot product is 0   .$\\vec a \\cdot \\vec b$ is the length of .$\\vec a$ times the scalar projection of .$\\vec b$ onto .$\\vec a$ Notice that the dot product gives a scalar $$\\langle a_1, a_2, a_3 \\rangle \\cdot \\langle b_1, b_2, b_3 \\rangle = a_1b_1 + a_2b_2 + a_3b_3$$ $$\\vec a \\cdot (\\vec b + \\vec c) = \\vec a \\cdot \\vec b + \\vec a\\cdot \\vec c$$ $$ \\vec a \\cdot \\vec a = \\Vert \\vec a \\Vert ^2$$ $$ \\vec a \\cdot \\vec b = \\vec b \\cdot \\vec a $$ $$ (c \\vec a) \\cdot \\vec b = c (\\vec a \\cdot \\vec b) = \\vec a \\cdot (c \\vec b)$$  $$\\vec a \\cdot \\vec b = \\Vert\\vec a\\Vert\\ \\Vert\\vec b\\Vert \\cos \\theta$$ $$\\Vert\\vec a - \\vec b \\Vert^2 = \\Vert\\vec a\\Vert^2+\\Vert\\vec b\\Vert^2 - 2\\Vert\\vec a\\Vert \\Vert\\vec b\\Vert \\cos\\theta\\ $$ $$\u0026hellip; = \\Vert\\vec a\\Vert\\ \\Vert\\vec b\\Vert \\cos \\theta$$ $$\\cos\\theta = \\frac{\\vec a \\cdot \\vec b}{\\Vert\\vec a\\Vert\\ \\Vert\\vec b\\Vert}$$   $$\\cos \\theta = \\frac{\\vec a}{\\Vert \\vec a \\Vert} \\cdot \\frac{\\vec b}{\\Vert \\vec b \\Vert} \\Longrightarrow \\cos^{-1}\\bigg(\\frac{\\vec a}{\\Vert \\vec a \\Vert} \\cdot \\frac{\\vec b}{\\Vert \\vec b \\Vert} \\bigg) = \\theta $$   Direction Vectors #   The direction angles of a nonzero vector .$\\vec a$ are the .$\\alpha, \\beta, \\gamma$ that a makes with the positive .$x,y,z$-axes respectively $$\\cos\\alpha = \\frac{\\vec a \\cdot \\vec i}{\\Vert \\vec a \\Vert \\Vert \\vec i \\Vert} = \\frac{a_1}{\\Vert \\vec a \\Vert}$$ $$\\vec a = \\Vert \\vec a \\Vert \\langle \\cos \\alpha, \\cos \\beta, \\cos \\gamma \\rangle$$  Projections #   Scalar projection of .$\\vec b$ onto .$\\vec a$: $$\\text{comp}_\\vec a\\vec b = \\frac{\\vec a\\cdot\\vec b}{\\Vert\\vec a\\Vert}$$ Vector projection of .$\\vec b$ onto .$\\vec a$: $$\\text{proj}_\\vec a\\vec b = \\bigg(\\frac{\\vec a\\cdot\\vec b}{\\Vert\\vec a\\Vert}\\bigg)\\frac{\\vec a}{\\Vert\\vec a\\Vert} = \\frac{\\vec a\\cdot\\vec b}{\\Vert\\vec a\\Vert^2}\\vec a$$   12.4 Cross Product #   The cross product measures how orthogonal two vectors are  Therefore, .$(\\vec a \\times \\vec b) \\cdot \\vec b = 0$ because measures how similar (close to .$0^\\circ$) two vectors are and cross product outputs a vector orthogonal (.$90^\\circ$ to both .$\\vec a, \\vec b$) Two nonzero vectors are only parallel iff their cross product is zero The magnitude is also the area of a parallelogram formed by the two vectors  We can find the volume of the 3D parallelogram formed by three vectors with the following equation: $$\\vec a \\cdot (\\vec b \\times \\vec c) = (\\vec a \\times \\vec b) \\cdot \\vec c$$  Realize that if the resulting area is .$0$, then all of the points exist on the same plane     Notice that the cross product gives a vector that is orthogonal to both original vectors  Direction is determined with the right-hand rule   We can also calculate the determinant with the unit vectors .$\\langle \\hat i, \\hat j, \\hat k \\rangle$to find the cross product $$\\langle a_1, a_2, a_3 \\rangle \\times \\langle b_1, b_2, b_3 \\rangle = \\langle a_2b_3 - a_3 b_2, -(a1_b3 - a_3 b_1), a_1b_2 - a_2 b_1 \\rangle$$ $$\\vec a \\times \\vec b = \\Vert \\vec a \\Vert \\Vert \\vec b \\Vert \\sin\\theta$$ $$(\\vec a \\times \\vec b) \\times \\vec c \\neq \\vec a \\times (\\vec b \\times \\vec c) \\Longrightarrow \\vec a \\times (\\vec b \\times \\vec c) = (\\vec a \\cdot \\vec c) \\vec b - (\\vec a \\cdot \\vec b ) \\vec c$$ $$\\vec a \\times \\vec b \\neq \\vec b \\times \\vec b \\Longrightarrow \\vec a \\times \\vec b = - \\vec b \\times \\vec a$$ $$(c \\vec a) \\times \\vec b = c(\\vec a \\times \\vec b) = \\vec a \\times (c \\vec b)$$  $$\\vec a \\times (\\vec b + \\vec c) = \\vec a \\times \\vec b + \\vec a \\times \\vec c$$ $$(\\vec a + \\vec b) \\times \\vec c = \\vec a \\times \\vec c + \\vec b \\times \\vec c$$   $$\\Vert \\vec a \\times \\vec b \\Vert ^2 = \\Vert \\vec a \\Vert^2 \\Vert \\vec b \\Vert^2 - (\\vec a \\cdot \\vec b)^2 = \\Vert \\vec a \\Vert^2 \\Vert \\vec b \\Vert^2 \\sin^2 \\theta$$ $$\u0026hellip; \\Longrightarrow \\Vert \\vec a \\times \\vec b \\Vert \\Vert \\vec a \\Vert \\Vert \\vec b \\Vert \\sin \\theta$$  12.5 Equation of Lines and Planes #  Line #   If given a point .$P_0 (x_0, y_0, z_0)$ and a vector .$\\vec v = \\langle a,b,c \\rangle$ that passes through said point (parallel), we can write a line equation as: $$\\langle x, y, z \\rangle = P_0 + t \\vec v = \\langle x_0 + ta, y_0 +tb, z_0 + tc \\rangle;\\ \\ t \\in \\mathbb{R}$$ We can then isolate .$t$ to find the symmetric equation of the line $$ t = \\frac{x-x_0}{a} = \\frac{y-y_0}{b} = \\frac{z-z_0}{c} $$ And we can extrapolate this to write an equation we can use to verify if two points are on a line: $$ t = \\frac{x-x_0}{x_1-x_0} = \\frac{y-y_0}{y_1-y_0} = \\frac{z-z_0}{z_1-z_0} $$  Note: If we have no change in an axis (such as .$x$), then .$x_1-x_0$ is zero. Therefore, we can write .$x = x_0$ (because we know it never changes) and the other relations for .$y$ and .$z$ still work   We can also write our original equation in vector form as $$\\vec r(t) = \\vec r_0 + t\\vec v$$ Which we can use to write a specific line between point .$A$ and .$B$ from .$t \\in [0,1]$ as $$\\overrightarrow{AB} = \\langle x_1 - x_0, y_1 - y_0, z_1 - z_0 \\rangle$$ $$r(t) = \\vec A(1-t) + \\vec B(t)$$ Two vectors are equal iff corresponding components are equal 3D Lines can be parallel (same direction vector), intersect at one point (.$r_1 = r_2\\ @\\ t_1, t_2$), or skew (not intersecting nor parallel \u0026ndash; not possible in 2D)  Planes #   Planes need a point and direction  Point .$P_0 (x_0, y_0, z_0)$ is trivial; a plane is a set of various points Direction is described by the normal vector .$\\vec n = \\langle a,b,c \\rangle$; only one normal unit vector per plane  Given three points .$P_1, P_2, P_3$ on the plane, we can write two vectors .$\\vec a = \\overrightarrow{P_1 P_2}, \\vec b = \\overrightarrow{P_1, P_3}$ as we can find the normal vector as .$\\vec n = \\vec a \\times \\vec b$     Knowing this, we can write a vector equation: $$ \\vec n \\cdot \\overrightarrow{P_0 P} = 0$$ $$ \\vec n \\cdot (\\vec r - \\vec r_0) = 0$$ This can also be parameterized as both the scalar and linear equation respectively: $$a(x-x_0) + b(y-y_0) + c(z-z_0) = 0$$ $$ax + yz + cz + d = 0$$ Planes are parallel if their normal vectors are parallel Otherwise, they intersect and form a straight line  Common Questions #   Intersection point(s) of plane and parametric curve  Given parametric curve .$C = \\langle \\alpha + a\\cdot t, \\beta + b\\cdot t, \\gamma + c \\cdot t \\rangle$ and plane equation .$P = x + y + z + d = 0$ \u0026hellip;   Plug in each component of .$C$ as .$x,y,z$ in the .$P$ equation Solve for .$t$(s), then plug (it/them) into the prior equation to get intersection point(s)   Angle between planes  Given two planes with .$\\vec n_1, \\vec n_2$ respectively   Use .$\\theta = \\cos^{-1}\\Big(\\frac{\\vec n_1 \\cdot \\vec n_2}{\\Vert \\vec n_1 \\Vert \\Vert \\vec n_2 \\Vert}\\Big)$ to find .$\\theta$   Angle between parametric lines that intercept at point .$P_3$  Given parametric equations .$L_1 = P_1 + t\\vec v_1$ and .$L_2 = P_2 + s\\vec v_2$   Find the .$t_3$ and .$s_3$ for when .$L_1 = P_3$ and .$L_2 = P_3$ (point of intersection) Use .$\\theta = \\cos^{-1}\\Big(\\frac{\\vec v_1\u0026rsquo;(t_3) \\cdot \\vec v_2\u0026rsquo;(s_3)}{\\Vert \\vec v_1\u0026rsquo;(t_3) \\Vert \\Vert \\vec v_2\u0026rsquo;(s_3) \\Vert}\\Big)$ to find .$\\theta$   Intersection of two lines:  .$L_1: \\langle x_1, y_1, z_1 \\rangle + t \\cdot \\langle a_1, b_1, c_1\\rangle; L_2: \\langle x_2, y_2, z_2 \\rangle + s \\cdot \\langle a_2, b_2, c_2 \\rangle;$ First, check if they are parallel by checking if the directions of the two lines are scalar multiples of one another. Second, check if they intersect by setting the two parametric equations equal to one another:  .$x_1 + t a_1 = x_2 + s a_2; y_1 + t b_1 = y_2 + s b_2; z_1 + t c_1 = z_2 + s c_2$ If an equation exists (that is, there is a valid .$t$ and .$s$) then they intersect at .$L_1(t)$ or .$L_2(s)$     Intersection line .$L$ of two planes  Set one of the 3D variables to zero (e.x. .$z = 0$) to find where the two planes intersect the remaining plane (in this case the .$z$ plane) We find the intersection point .$P (\\alpha, \\beta, 0)$ by solving when our plane equations in the prior equation are equal Since the line .$L$ is orthogonal to both planes\u0026rsquo; normal vectors, our direction vector is .$\\vec v = n_1 \\times n_2 = \\langle a,b,c \\rangle$ We can then plug in everything into the symmetric equation: .$\\frac{x-\\alpha}{a} = \\frac{y-\\beta}{b} = \\frac{z-0}{c}$   Distance from point to plane  Given point .$P_1(x_1, y_1, z_1)$ and plane .$ax+by+cz+d = 0$ $$D = \\Vert \\text{comp}_{\\vec n}{\\vec b} \\Vert = \\frac{\\vert ax_1 + by_1 + cz_1 +d\\vert}{\\sqrt{a^2 + b^2 + c^2}}$$   Distance from skew line to skew line  Given .$L_1 = \\langle x_1, y_1, z_1 \\rangle + t \\vec v_1$ and .$L_2 = \u0026hellip;$   Find the plane containing .$L_2$ that is parallel to .$L_1$. .$P_3 = \\langle x- x_2, y - y_2, z - z_2 \\rangle \\cdot (v_1 \\times v_2)$ Find the .$D$istance from .$x_1, y_1, z_1$ on .$L_1$ to the plane .$P_3$ above $$D = \\frac{\\vert a_3 x_1 + b_3 y_1 + c_3 z_1 +d\\vert}{\\sqrt{a_3^2 + b_3^2 + c_3^2}}$$   Distance from point to line  Given line .$L = \\langle x_0, y_0, z_0 \\rangle + \\langle a, b, c \\rangle$ and point .$P = \\langle P_x, P_y, P_z \\rangle$   Write a distance equation as .$D^2 = ((x_0 + ta) - P_x)^2 + ((y_0 + tb) - P_y)^2 + ((z_0 + tc) - P_z)^2$ Find the minimum value of .$t$ and plug in into the equation above and find .$D$ (but not .$D^2$!)    12.6 Cylinders and Quadratic Surfaces #  Traces #    Cross sections of a surface found by taking a three-variable equation and setting one of the equations variables equal to a constant. Help us visualize 3D curves by thinking about them from different axis $$z = \\frac{x^2}{4} + \\frac{y^2}{9} \\Longrightarrow k = \\frac{x^2}{4} + \\frac{y^2}{9}$$  $$\u0026hellip; \\Longrightarrow z = \\frac{x^2}{4} + \\frac{k^2}{9}$$    In the left example, for every .$z$ value we have a ellipse In the right example, we have a parabola for every .$y$ value    Cylinder #   A cylinder is a surface that consists of all rulings that at parallel to a given line that passes through a given plane curve Two variable equation in 3D space  E.x. .$y =\\sin x, z = x^2$    Quadratic Surfaces #   A quadric surface is the graph of a second-degree equation with three variables Two standard forms (when centered about origin): $$Ax^2 + By^2 + Cz^2 + J = 0$$ $$Ax^2 + By^2 + Iz = 0$$   "},{"id":29,"href":"/math-53/13/","title":"13: Vector Functions","section":"Math 53","content":"13.1 Vector Functions and Space Curves #  Vector Functions #   We can write a vector function as $$\\vec r(t) = \\langle f(t), g(t), h(t) \\rangle = f(t) \\hat i + g(t) \\hat j + h(t) \\hat k$$ The domain of .$\\vec r$ consists of all values of .$t$ for which each of the terms are defined The limit of a vector function is $$\\lim_{t\\to a} \\vec r(t) = \\big\\langle \\lim_{t\\to a} f(t), \\lim_{t\\to a} g(t), \\lim_{t\\to a} h(t) \\big\\rangle$$ .$\\vec r$ is continuous at time .$a$ if .$\\lim_{t\\to a} \\vec r(t) = \\vec r(a)$  Space Curve #   The set .$C$ of all points defined by a vector function .$\\vec r$ over interval .$I$ is called a space curve. Think of .$C$ as being traced out by a moving particle whose position follows .$\\vec r$ Space curves are parametrized by a vector function but isn\u0026rsquo;t necessarily that vector function!  E.x. .$\\vec r(t) \\langle \\cos t, \\sin t, t \\rangle \\neq \\vec q(t) = \\langle \\cos 3t, \\sin 3t, 3t \\rangle$ Space curves exist on the same point, but don\u0026rsquo;t grow at the same rate    13.2 Derivatives and Integrals of Vector Functions #  Derivatives #  $$\\frac{d\\vec r}{dt} = \\vec r\u0026rsquo;(t) = \\lim_{h \\to 0} \\frac{\\vec r(t+h) - r(t)}{h}$$ $$\u0026hellip; = \\big\\langle f\u0026rsquo;(t), g\u0026rsquo;(t), h\u0026rsquo;(t) \\big\\rangle$$\n Note that the last equation only works if each component is differentiable The direction is the tangent line and the magnitude is the rate at which the particle is moving at that point If we just want the tangent line, we can write the unit tangent vector: $$\\vec T(t) = \\frac{\\vec r\u0026rsquo;(t)}{\\Vert \\vec r \u0026rsquo; (t) \\Vert}$$ Differentiation rules (notice .$f(t)$ is a scalar function) $$ \\frac{d}{dt} \\big[f(t) \\vec u(t) \\big] = f\u0026rsquo;(t) \\vec u(t) + f(t) \\vec u\u0026rsquo;(t)$$ $$ \\frac{d}{dt}\\big[\\vec u(t) \\cdot \\vec v(t)\\big] = \\vec u\u0026rsquo;(t) \\cdot \\vec v(t) + \\vec u(t) \\cdot \\vec v\u0026rsquo;(t) $$ $$ \\frac{d}{dt} \\big[\\vec u(t) \\times \\vec v(t)\\big] = \\vec u\u0026rsquo; (t) \\times \\vec v(t) + \\vec u(t) + \\vec v\u0026rsquo;(t)$$ $$ \\frac{d}{dt} \\big[ \\vec u(f(t)) \\big] = f\u0026rsquo;(t) \\vec u\u0026rsquo; (f(t))$$  Integrals #   Let .$\\vec r (t) = \\langle f(t), g(t), h(t) \\rangle$, then $$\\int_a^b \\vec r(t)\\ dt = \\bigg\\langle \\int_a^b f(t)\\ dt, \\int_a^b g(t) \\ dt, \\int_a^b h(t)\\ dt \\bigg\\rangle$$ Fundamental theorem: If .$\\vec R(t)$ is an anti-derivative of .$\\vec r(t)$, (i.e. .$\\vec R\u0026rsquo;(t) = \\vec r(t)$), then $$ \\int_a^b \\vec r(t) \\ dt = \\Big[\\vec R(t)\\Big]_a^b = \\vec R(b) - \\vec R(a)$$  "},{"id":30,"href":"/math-53/14/","title":"14: Partial Derivatives","section":"Math 53","content":"14.1 Functions of Several Variables #   In the real world, most things don\u0026rsquo;t depend on a single variable  Temperature may depend on the .$(x,y)$ (latitude/longitude) position Volume of a cylinder depends on radius .$r$ and height .$h$: .$V =\\pi r^2 h$   Formal Definition: A function .$f$ of two variables is a rule that assigns to each ordered pair of real numbers .$(x,y)$ in a set .$D$ a unique real number denoted by .$f(x,y)$. The set .$D$ is the domain of .$f$ and its range is the set of values that .$f$ takes on, that is, .$\\{f(x,y)\\ |\\ (x,y) \\in D \\}$.  E.x. for .$f(x,y) = \\frac{\\sqrt{x+y+1}}{x-1}$, the domain is .$D = \\{(x,y)\\ |\\ x + y + 1 \\geq 0, x \\neq 1\\}$ which can be graphed with a solid line following .$y =-x-1$ with a dotted line at .$x = 1$ E.x. for .$f(x,y) = x\\ln(y^2-x)$, the domain is .$D =\\{(x,y)\\ |\\ x\u0026lt;y^2\\}$. This can be graphed with a dotted line following the curve .$x = y^2$   For the equation .$z = f(x,y)$, .$x,y$ are the independent variables and .$z$ is the dependent variable \u0026ndash; similar to single variable equations We can visualize functions of two variables (i.e .$f(x,y)$) by graphing them in 3D as .$(x,y,f(x,y))$  We can then write level curves for the function by setting .$f(x,y) = k$ for some .$k$onstant in the range of .$f$. This will result in a graph similar to a Topographic map Level Curve: The level curves of a function .$f$ of two variables are the curves with equations .$f(x,y) = k$, where .$k$ is a constant (in the range of .$f$).      14.2 Limits and Continuity #  Limits #   Vector Limit: Let .$f$ be a function of two variables whose domain .$D$ includes points arbitrarily close to .$(a, b)$. Then we say that the limit of .$f(x, y)$ as .$(x, y)$ approaches .$a, b.$ is .$L$ and we write $$\\lim_{(x,y)\\to(a,b)} f(x,y) = L$$ if for every number .$\\varepsilon \u0026lt; 0$ there is a corresponding number .$\\delta \u0026lt; 0$ such that if .$(x, y) \\in D$ and .$0 \u0026lt; \\sqrt{(x-a)^2 + (y-b)^2} \u0026lt; \\delta$ then .$\\vert f(x,y) - L \\vert \u0026lt; \\varepsilon$   Notice that .$\\vert f(x,y) - L \\vert$ is the distance between the numbers .$f(x, y)$ and .$L$, and .$\\sqrt{(x-a)^2 + (y-b)^2}$ is the distance between the point .$(x, y)$ and the point .$(a, b)$. If .$f(x,y) \\to L_1$ as .$(x,y) \\to (a,b)$ along a path .$C_1$ and .$f(x,y) \\to L_2$ as .$(x,y) \\to (a,b)$ along a path .$C_2$, where .$L_1 \\neq L_2$, then .$\\lim_{(x,y)\\to(a,b)} f(x,y)$, does not exist.  We can test this by setting .$x$ and .$y$ to various different values (e.x. .$x = 0, y = 0, x = y, \u0026hellip;,$ etc)    Continuity #  A function .$f$ of two variables is called continuous at .$(a,b)$ if $$\\lim_{(x,y)\\to (a,b)} f(x,y) = f(a,b)$$ We say .$f$ is continuous on .$D$ if .$f$ is continuous at every point .$(a,b)$ in .$D$.   That is, we need the limit to exist ands for .$f(a,b)$ to be defined Continuous functions: .$x,y, c, \\text{ trig (on domain)}$ Arithmetic, composition, exponent all preserve continuity (on domain!) Dividing doesn\u0026rsquo;t necessarily preserve continuity  14.3 Partial Derivatives #  If .$f$ is a function of two variables, its partial derivatives are the functions .$f_x$ and .$f_y$ defined by $$f_x(x,y) = \\frac{\\delta f}{\\delta x} = \\lim_{h\\to0} \\frac{f(x+h,y)-f(x,y)}{h}$$ $$f_y(x,y) = \\frac{\\delta f}{\\delta y} = \\lim_{h\\to0} \\frac{f(x,y+h)-f(x,y)}{h}$$   Notice we use .$\\delta$ instead of .$d$ for partial derivatives These can be written at a single point .$(a,b)$ with respect to .$x$ and .$y$ by treating the remaining variables as a constant $$f_x(a,b) = g\u0026rsquo;(a); \\ \\ \\ g(x) = f(x,b)$$ $$f_y(a,b) = h\u0026rsquo;(b); \\ \\ \\ h(y) = f(a,y)$$ Which can be extrapolated for 3 (or more) variables: $$f_z(a,b,c) = k\u0026rsquo;(c); \\ \\ \\ k(z) = f(a,b,z)$$  Higher Derivatives #   Just like regular derivatives, we can do many partial derivatives For example, the following are second partial derivatives of .$z = f(x,y)$: $$(f_x)_x = f_{xx} = \\frac{\\delta }{\\delta x}\\bigg(\\frac{\\delta f}{\\delta x}\\bigg) = \\frac{\\delta^2f}{\\delta x^2}$$ $$(f_x)_y = f_{xy} = \\frac{\\delta }{\\delta y}\\bigg(\\frac{\\delta f}{\\delta x}\\bigg) = \\frac{\\delta^2f}{\\delta y \\delta x}$$ $$(f_y)_x = f_{yx} = \\frac{\\delta }{\\delta x}\\bigg(\\frac{\\delta f}{\\delta y}\\bigg) = \\frac{\\delta^2f}{\\delta x \\delta y}$$ $$(f_y)_y = f_{yy} = \\frac{\\delta }{\\delta y}\\bigg(\\frac{\\delta f}{\\delta y}\\bigg) = \\frac{\\delta^2f}{\\delta y^2}$$  Clairaut\u0026rsquo;s Theorem Suppose .$f$ is defined on a disk .$D$ that contains the point .$(a,b)$. If the functions .$f_{xy}$ and .$f_{yx}$ are both continuous on .$D$, then $$f_{xy}(a,b) = f_{yx}(a,b)$$  Partial Differential Equations #   In the sciences, we typically want to find how a system changes with respect to multiple variables Partial derivatives occur in partial differential equations, e.x Laplace\u0026rsquo;s Equation: $$ \\frac{\\delta^2 u}{\\delta x^2} + \\frac{\\delta^2 u}{\\delta y^2} = 0$$  Solutions to Laplace\u0026rsquo;s are always harmonic functions, such as .$u = e^x \\sin(y)$    14.4 Tangent Planes and Linear Approximations #  Tangent Planes #   Tangent planes are to surfaces as tangent lines are to curves  Tangent planes contain both the partial derivative lines w.r.t .$x$ and .$y$   All we need to know to write a tangent plane is a point .$(a,b)$ and direction of the two partial derivatives .$\\langle 1,0, f_x(a,b)\\rangle, \\langle 0,1, f_y(a,b)\\rangle$  Direction vector can be found with .$\\langle 1,0, f_x(a,b)\\rangle \\times \\langle 0,1, f_y(a,b)\\rangle = \\langle -f_x, -f_y, 1 \\rangle$ which we can dot with .$\\langle x-x_0, y-y_0, z-f(x_0,y_0) \\rangle$ Suppose .$f$ has continuous partial derivatives. An equation of the tangent plane to the surface .$z = f(x, y)$ at the point .$P(x_0,y_0,z_0)$ is $$z-f(x_0, y_0) = f_x(x_0,y_0)(x-x_0) + f_y(x_0, y_0)(y-y_0)$$      Linear Approximations #   As we get very close to the surface, then the tangent plane (at point .$(a,b)$) looks more and more like the surface  Thus, we can use it to for making approximations when we are near near .$(a,b)$ If .$z = f(x,y)$, then .$f$ is differentiable at .$(a,b)$ if .$\\Delta z$ can be expressed in the form $$\\Delta z = f_x(a,b)\\Delta x + f_y(a,b)\\Delta y + \\varepsilon_1 \\Delta x + \\varepsilon_2 \\Delta y$$ where the error terms, .$\\varepsilon_1$ and .$\\varepsilon_2 \\to 0$ as .$(\\Delta x, \\Delta y) \\to (0,0)$ and the other terms are the linearization of the function.     Rewriting this, we can use the given .$f(x,y)$ to write the linear approximation which is an estimate for point/state at .$f(a,b)$ $$f(x,y) \\approx f(a,b) + f_x(a,b) (x-a) + f_y(a,b)(y-b)$$ We can similarly define the 3D linear approximation, increment of .$w$, and differential .$dw$ as: $$f(x,y,z) \\approx f(a,b,c) + f_x(a,b,c) (x-a) + f_y(a,b,c)(y-b) + f_z(a,b,c) (z-c)$$ $$\\Delta w = f(x+\\Delta x, y + \\Delta y, z + \\Delta z) - f(x,y,z)$$ $$dw = \\frac{\\delta w}{\\delta x}dx + \\frac{\\delta w}{\\delta y}dy + \\frac{\\delta w}{\\delta z}dz$$  Differentials #   With one variable functions, i.e. .$y = f(x)$, we defined the differential .$dx$ to be independent so we had to write .$dy$ as .$dy = f\u0026rsquo;(x)\\ dx$ Given a differentiable function of two variables, i.e. .$z = f(x,y)$, we know both .$dx$ and .$dy$ are independent so we write: $$dz = f_x(x,y)\\ dx + f_y(x,y)\\ dy = \\frac{\\delta z}{\\delta x}dx + \\frac{\\delta z}{\\delta y}dy$$ If the partial derivatives .$f_x$ and .$f_y$ exist near .$(a,b)$ and are continuous at .$(a,b)$, then .$f$ is differentiable at .$(a,b)$.  14.5 Chain Rule #  Chain Rule #  Suppose that .$z = f(g_1 (x_1,_{\\dots}, x_m), g_2 (x_1,_{\\dots}, x_m), g_n (x_1,_{\\dots}, x_m))$ is a differentiable function of the .$n$ variables .$g_1,_{\\dots}, g_n$ and is .$g_j$ is a differentiable function of the .$m$ variables .$x_1,_{\\dots}, x_m$. Then .$z$ is a function of .$x_1,_{\\dots}, x_m$ and $$ \\frac{\\delta f}{\\delta x_i} = \\frac{\\delta f}{\\delta g_1} \\frac{\\delta g_1}{\\delta x_i} + \\frac{\\delta f}{\\delta g_2} \\frac{\\delta g_2}{\\delta x_i} + \\dots + \\frac{\\delta f}{\\delta g_m} \\frac{\\delta g_m}{\\delta x_i}$$ for each .$i = 1,2,\\dots,m$  Implicit Differentiation #    If .$F(x,y) = 0$ defines .$y$ implicitly as a function of .$x$ (that is, .$y = f(x)$, where .$F(x,f(x))= 0$ for all .$x$ in the domain of .$f$), then $$ \\frac{dy}{dx} = - \\frac{\\frac{\\delta F}{\\delta x}}{ \\frac{\\delta F}{\\delta y}} = - \\frac{F_x}{F_y}$$\n  If .$F(x,y,z) = 0$ defines .$z$ implicitly as a function of .$x,y$, then\n  $$ \\frac{dz}{dx} = - \\frac{\\frac{\\delta F}{\\delta x}}{ \\frac{\\delta F}{\\delta z}} = - \\frac{F_x}{F_z};\\ \\ \\frac{dz}{dy} = - \\frac{\\frac{\\delta F}{\\delta y}}{ \\frac{\\delta F}{\\delta z}} = - \\frac{F_y}{F_z}$$\n14.6 Directional Derivatives and the Gradient Vector #  Directional Derivatives #  Direction Derivative For function .$f$ at .$(x_0, y_0)$ in the direction of unit vector .$\\hat u = \\langle a, b \\rangle$ is $$D_{\\hat u} f(x_0, y_0) = \\lim_{h\\to 0} \\frac{f(x_0 + ha, y_0 + hb) - f(x_0, y_0)}{h} = $$ $$\\dots = \\nabla f \\cdot \\hat u = f_x (x,y) a + f_y (x,y) b$$ if the limit exists (for the former) and if .$f$ is a differentiable function of .$x$ and .$y$ (for the latter)   That is, .$\\hat u = \\hat i = \\langle 1, 0 \\rangle$ for .$D_\\hat{i} = f_x$ and .$\\hat u = \\hat j = \\langle 0, 1 \\rangle$ for .$D_\\hat{j} = f_y$ Differentiability is important because it means that as you approach the surface very closely, it looks more and more like the tangent plane. Directional derivatives can be thought of as the slope of the tangent line at a given point This definition can be extrapolated to (three variables/higher dimensions) trivially, shown below with gradient vectors  Gradient Vector #  Gradient: If .$f$ is a function of variable .$x,y,z$, then the gradient of .$f$ is the vector function .$\\nabla f$ defined by $$\\nabla f(x,y,z) = \\big\\langle f_x(x,y,z), f_y (x,y,z), f_z (x,y,z) \\big\\rangle = \\frac{\\delta f}{\\delta x}\\hat i + \\frac{\\delta f}{\\delta y}\\hat j + \\frac{\\delta f}{\\delta z}\\hat k$$   We can now use the gradient to re-write our directional derivative equation as $$D_{\\hat u} f(x,y,z,\\dots) = \\nabla f(x,y,z,\\dots) \\cdot \\hat u$$ We can re-write this using the definition of the dot product as $$D_{\\hat u} f(x,y,z,\\dots) = \\Vert \\nabla f \\Vert \\Vert \\hat u \\Vert \\cos\\theta =\\Vert \\nabla f \\Vert \\cos\\theta $$  Maximizing the Directional Derivative #  Suppose .$f$ is a differentiable function of two or three variables. The maximum value of the directional derivatives .$D_\\hat{u} f(\\vec x)$ is .$\\Vert \\nabla f(\\vec x ) \\Vert$ and it occurs when .$\\hat u$ has the same direction as the gradient vector .$\\nabla f(\\vec x)$   We can see from the definition above that since the max of .$\\cos\\theta$ is .$1$ when .$\\theta = 0$, therefore the max of the directional derivative occurs at the same angle (when .$\\hat u$ has the same direction of .$\\nabla f$ ) TL;DR: .$D_\\hat{u} f(\\vec x)$ is maximized if .$\\vec u = \\frac{\\nabla f}{\\Vert \\nabla f \\Vert}\\bigg\\vert_\\vec{p}$ at point .$\\vec p$  Tangent Planes to Level Surfaces #   If .$f(x,y) = k$ is a curve, then .$F(x,y,z) = k$ is a surface Let .$\\vec r(t)$ be a space curve on the surface .$F(x,y,z) = k$  Let .$\\vec r(t_0) = \\langle x_0, y_0, z_0 \\rangle$ for some .$t_0$ (at some time, the space curve passes through some point which is on the surface) We know .$F(\\vec r(t)) = k$, thus, using the chain rule: $$0 = \\frac{\\delta F}{\\delta x} \\frac{\\delta x}{\\delta t} + \\frac{\\delta F}{\\delta y} \\frac{\\delta y}{\\delta t} + \\frac{\\delta F}{\\delta z} \\frac{\\delta z}{\\delta t} = \\nabla F(x_0, y_0, z_0) \\cdot (\\vec r(t_0))\u0026rsquo;$$   The gradient vector at .$P$, .$F(x_0, y_0, z_0)$, is perpendicular to the tangent vector .$\\vec r\u0026rsquo;(t)$ to any curve .$C$ on .$S$ that passes through .$P$  In English: The direction of the gradient is always perpendicular to the level surface at every point   We can then define the tangent plane to the level surface .$F(x,y,z) = k$ at .$P(x_0, y_0, z_0)$ as the plane that passes through .$P$ and has normal vector .$\\nabla F(x_0, y_0, z_0)$: $$\\nabla F\\big\\vert_{(x_0, y_0, z_0)} \\cdot \\langle x-x_0, y-y_0, z-z_0 \\rangle = 0$$ We can also write this in the symmetric equation form: $$\\frac{x-x_0}{F_x(x_0, y_0, z_0)} = \\frac{y-y_0}{F_y(x_0, y_0, z_0)} = \\frac{z-z_0}{F_z(x_0, y_0, z_0)}$$  14.7 Maximum and Minimum Values #  Critical Points #  A function of two variables has a local maximum at .$(a,b)$ if .$f(x,y) \\leq f(a,b)$ when .$(x,y)$ is near .$(a,b)$ [This means that for .$f(x,y) \\leq f(a,b)$ for all points .$(x,y)$ in some disk with center .$(a,b)$.] The number .$f(a,b)$ is called a local maximum value. If .$f(x,y) \\geq f(a,b)$ when .$(x,y)$ is near .$(a,b)$, then .$f$ has a local minimum at .$(a,b)$ and .$(x,y)$ is a local minimum value.   If the inequalities above hold for all points .$(x,y)$ in the domain of .$f$, then .$f$ has an absolute maximum (or absolute minimum) at .$(a,b)$ If .$f$ has a local maximum or minimum at .$(a,b)$ and the first-order partial derivatives of .$f$ exist there, then .$f_x(a,b) = 0$ and .$f_y(a,b) = 0$.  If the graph of .$f$ has a tangent plane at a local maximum or minimum, then the tangent plane must be horizontal   .$(a,b)$ is a Critical Point of .$f$ if .$f_x(a,b) = 0$ and .$f_y(a,b) = 0$, or if one of these partial derivatives does not exist  Thus, if .$f$ has a local maximum or minimum at .$(a,b)$, then .$(a,b)$ is a critical point of .$f$ In other words, at a critical point, a function could have a local maximum or a local minimum or neither (saddle point).    Second Derivatives Test: Suppose the second partial derivatives of .$f$ are continuous on a disk with center .$(a, b)$, and suppose that .$f_x(a, b) = 0$ and .$f_y(a, b) = 0$ (that is, .$(a, b)$ is a critical point of .$f$ ). Let $$D = D(a, b) = \\begin{vmatrix}f_{xx} \u0026amp; f_{xy}\\\\ f_{yx} \u0026amp; f_{yy}\\end{vmatrix} = f_{xx}(a, b) f_{yy}(a, b) - (f_{xy}(a, b))^2$$\n If .$D \u0026gt; 0$ and .$f_{xx}(a, b) \u0026gt; 0$ (or .$f_{yy}(a, b) \u0026gt; 0$), then .$f(a, b)$ is a local minimum. If .$D \u0026gt; 0$ and .$f_{xx}(a, b) \u0026lt; 0$ (or .$f_{yy}(a, b) \u0026lt; 0$), then .$f(a, b)$ is a local maximum. If .$D \u0026lt; 0$, then .$f(a, b)$ is a saddle point If .$D = 0$, the test gives no information: .$f$ could be any of the above    Note that in the first two tests, it\u0026rsquo;s implied that .$f_{xx}$ and .$f_{yy}$ have the same sign The determinant is a Hessian matrix  Extreme Points #   Just as a closed interval contains its endpoints, a closed set in .$\\mathbb{R}^2$ is one that contains all its boundary points.  For instance, the disk .$D = \\{(x,y) \\vert x^2 + y^2 \\leq 1 \\}$ is a closed set because it contains all of its boundary points (which are the points on the circle .$r = 1$) But if even one point on the boundary curve were omitted, the set would not be closed   A bounded set in .$\\mathbb{R}^2$ is one that is contained within some disk \u0026ndash; it is finite in extent     Extreme Value Theorem for Functions of Two Variables: If .$f$ is continuous on a closed, bounded set .$D$ in .$\\mathbb{R}^2$, then .$f$ attains an absolute maximum value .$f(x_1, y_1)$ and an absolute minimum value .$f(x_2, y_2)$ at some points .$(x_1, y_1)$ and .$(x_2, y_2)$ in .$D$.   If .$f$ has an extreme value at .$(x_1, y_1)$, then .$(x_1, y_1)$ is either a critical point of .$f$ or a boundary point of .$d$. To find the absolute maximum and minimum values of a continuous function .$f$ on a closed, bounded set .$D$:  Find the values of .$f$ at the critical points of .$f$ in .$D$. Find the extreme values of .$f$ on the boundary of .$D$. The largest of the values from steps 1 and 2 is the absolute maximum value; the smallest of these values is the absolute minimum value.    14.8 Lagrange Multipliers #   We use Lagrange Multipliers to find critical points of a surface .$f$ given some constraining surface .$g$ Method of Lagrange Multipliers To find the maximum and minimum values of .$f(x,y,z)$ subject to the constraint .$g(x,y,z) = k$ [assuming that these extreme values exist and .$\\nabla \\neq 0$ on the surface .$g(x,y,z) = k$]:\n Find all values of .$x, y, z$, and .$\\lambda$ such that $$\\nabla f(x,y,z) = \\lambda \\nabla g(x,y,z)$$ $$g(x,y,z) = k$$ Evaluate .$f$ at all the points .$(x, y, z)$ that result from the first step. The largest of these values is the maximum value of .$f$; the smallest is the minimum value of .$f$.    We can decompose the first equation and use the second equation to get $$f_x = \\lambda g_x;\\ \\ f_y = \\lambda g_y;\\ \\ f_z = \\lambda g_z;\\ \\ g(x,y,z) = k$$ Notice we don\u0026rsquo;t care what .$\\lambda$ is, only that it exists  Two Constraints #   We can use Lagrange multipliers for two constraints .$f$ and .$g$ too: $$\\nabla f(x_0, y_0, z_0) = \\lambda \\nabla g(x_0, y_0, z_0) + \\mu \\nabla h(x_0, y_0, z_0)$$ Likewise, we can decompose the equation above to get the following five equations:  $$f_x = \\lambda g_x + \\mu h_x$$ $$f_y = \\lambda g_y + \\mu h_y$$ $$f_z = \\lambda g_z + \\mu h_z$$ $$g(x,y,z) = k$$ $$h(x,y,z) = c$$       "},{"id":31,"href":"/math-53/15/","title":"15: Multiple Integrals","section":"Math 53","content":"15.1 Double Integrals over Rectangles #   We describe closed rectangles in the form .$R = [a,b] \\times [c,b] = \\{(x,y) \\in \\mathbb{R}^2 \\vert a \\leq x \\leq b, c \\leq y \\leq d\\}$ Then we can write the solid .$S$ that lies above .$R$ as .$S = \\{(x,y,z) \\in \\mathbb{R}^3 \\vert 0 \\leq z \\leq f(x,y), (x,y) \\in R\\}$ To find the volume of this surface, we take a double integral $$V = \\iint_R f(x,y)\\ dA$$  Fubini\u0026rsquo;s Theorem: If .$f$ is continuous on the rectangle .$R = \\{(x,y) \\vert a \\leq x \\leq b, c \\leq y \\leq d\\}$, then $$\\iint_R f(x,y)\\ dA = \\int_a^b \\int_c^d f(x,y)\\ dy\\ dx = \\int_c^d \\int_a^b f(x,y)\\ dx\\ dy$$ More generally, this is true if we assume that .$f$ is bounded on .$R$, .$f$ is discontinuous only on a finite number of smooth curves, and the iterated integrals exist.  Average Value #   In the 2D case we could write the average as $$f_\\text{avg} = \\frac{1}{b-a} \\int_a^b f(x) dx$$ For 3D, instead of dividing by the change in just .$y$ (which was .$b-a$), we divide over the total area: $$f_\\text{avg} = \\frac{1}{A(R)}\\iint_R f(x,y)\\ dA$$  15.2 Double Integrals over General Regions #  Type I #  If .$f$ is continuous on a type I region .$D$ such that $$D = \\{(x,y)\\ \\vert\\ a \\leq x \\leq b,\\ g_1(x) \\leq y \\leq g_2(x)\\ \\}$$ then $$\\int_D f(x,y)\\ dA = \\int_a^b \\int_{g_1(x)}^{g_2(x)} f(x,y)\\ dy\\ dx$$   Type II #  If .$f$ is continuous on a type II region .$D$ such that $$D = \\{(x,y)\\ \\vert\\ c \\leq y \\leq d,\\ h_1(y) \\leq x \\leq h_2(y)\\ \\}$$ then $$\\int_D f(x,y)\\ dA = \\int_c^d \\int_{h_1(y)}^{h_2(y)} f(x,y)\\ dx\\ dy$$  Properties of Double Integrals #   $$\\iint_D \\Big[ f(x,y) + g(x,y)\\Big]\\ dA = \\iint_{D} f(x,y)\\ dA + \\iint_{D} g(x,y)\\ dA$$ $$\\iint_D c\\cdot f(x,y)\\ dA = c \\iint_D f(x,y)\\ dA\\ \\text{ where $c$ is a constant}$$ $$\\iint_D f(x,y)\\ dA \\geq \\iint_D g(x,y)\\ dA \\ \\text{ if $f(x,y) \\geq g(x,y)$ for all $(x,y) \\in D$}$$ $$\\iint_D f(x,y)\\ dA = \\iint_{D_1} f(x,y)\\ dA + \\iint_{D_2} f(x,y)\\ dA\\ \\text{ for $D = D_1 \\cup D_2$}$$ $$mA(D) \\leq \\iint_D f(x,y)\\ dA \\leq MA(D)$$  If .$m \\leq f(x,y) \\leq M$ for all .$(x,y) \\in D$    15.3 Double Integrals in Polar Coordinates #   Recall that we can convert cartesian to polar with the following equations: $$r^2 = x^2 +y^2$$  $$x = r\\cos\\theta$$  $$y = r\\sin\\theta$$      We multiply .$r$ because an \u0026ldquo;infinitesimal\u0026rdquo; polar rectangle as an ordinary rectangle with dimensions .$r\\ d\\theta$ and .$dr$ and therefore has area .$dA = r\\ dr\\ d\\theta$ That is, the further out the polar rectangle is (the larger the .$r$), the larger the area of that rectangle is (this scale is .$\\propto r$)     If .$f$ is continuous on a polar region of the form $$D = \\{(r,\\theta)\\ \\vert\\ \\alpha \\leq \\theta \\leq \\beta, h_1(\\theta) \\leq r \\leq h_2(\\theta) \\}$$ then $$\\iint_D f(x,y)\\ dA = \\int_\\alpha^\\beta \\int_{h_1(\\theta}^{h_2(\\theta)} r \\cdot f(r\\cos\\theta, r\\sin\\theta)\\ dr\\ d\\theta$$  15.5 Surface Area #  The area of the surface with equation .$z = f(x,y), (x,y) \\in D$, where .$f_x$ and .$f_y$ are continuous, is $$A(S) = \\iint_D \\sqrt{\\big[f_x(x,y)\\big]^2 + \\big[f_y(x,y)\\big]^2 + 1}\\ dA$$   Notice the similarities between the SA function and the line integral function, .$L = \\int_a^b \\sqrt{1 + \\big( \\frac{dy}{dx} \\big)^2}\\ dx$  15.6 Triple Integrals #  Fubini\u0026rsquo;s Theorem for Triple Integrals If f is continuous on the rectangular box B − fa, bg 3 fc, dg 3 fr, sg, then $$\\iiint_B f(x,y,z)\\ dV = \\int_r^s\\int_c^d\\int_a^b f(x,y,z)\\ dx\\ dy\\ dz$$   The iterated integral on the right side of Fubini\u0026rsquo;s Theorem means that we integrate first with respect to .$x$ (keeping .$y$ and .$z$ fixed), then we integrate with respect to .$y$ (keeping .$z$ fixed), and finally we integrate with respect to .$z$. Note that if .$f$ is separable this just becomes the product of three single-dimensional integrals, or one two-dimensional integral and two one-dimensional integrals. Fubini\u0026rsquo;s theorem still applies.  Type 1 #  $$\\iiint_E f(x,y,z)\\ dV$ = \\iint_D \\bigg[\\int_{u_1(x,y)}^{u_2(x,y)}f(x,y,z)\\ dz\\bigg]\\ dA$$\nType I #   $$\\dots = \\int_a^b \\int_{g_1(x)}^{g_2(x)} \\int_{u_1(x,y)}^{u_2(x,y)}f(x,y,z)\\ dz\\ dx\\ dy$$  Type II #   $$\\dots = \\int_c^d \\int_{h_1(y)}^{h_2(y)} \\int_{u_1(x,y)}^{u_2(x,y)}f(x,y,z)\\ dz\\ dy\\ dx$$   Type 2 #  $$\\iiint_E f(x,y,z)\\ dV$ = \\iint_D \\bigg[\\int_{u_1(y,z)}^{u_2(y,z)}f(x,y,z)\\ dx\\bigg]\\ dA$$\nType 3 #  $$\\iiint_E f(x,y,z)\\ dV$ = \\iint_D \\bigg[\\int_{u_1(x,z)}^{u_2(x,z)}f(x,y,z)\\ dy\\bigg]\\ dA$$\n15.7 Triple Integrals in Cylindrical Coordinates #  Cylindrical to Cartesian #   $$x = r\\cos\\theta$$ $$y = r\\sin\\theta$$ $$z = z$$  Cartesian to Cylindrical #   $$r^2 = x^2 + y^2$$ $$\\tan\\theta = \\frac{y}{x}$$ $$z = z$$    Now we deal with integration in cylindrical coordinates.  We have .$dV = dx\\ dy\\ dz$ Since .$z$ is the same, .$dz$ is the same. However, we can convert .$dx, dy$ to .$r\\ dr, dθ.$ since it is the same transformation as in polar coordinates. Thus the volume element in cylindrical coordinates is .$dV = r\\ dr\\ dθ\\ dz$.       $$\\iiint_D f(x,y,z) dx\\ dy\\ dz = \\iiint_D f(r\\cos\\theta, r\\sin\\theta, z)\\cdot r\\ dr\\ d\\theta\\ dz$$ $$\\dots = \\int_\\alpha^\\beta \\int_{h_1(\\theta)}^{h_2(\\theta)} \\int_{u_1(r\\cos\\theta, r\\sin\\theta)}^{u_2(r\\cos\\theta, r\\sin\\theta)} f(r\\cos\\theta, r\\sin\\theta, z)\\cdot r\\ dz\\ dr\\ d\\theta$$  15.8 Triple Integrals in Spherical Coordinates #   Spherical Coordinates map .$(x,y,z) \\Longrightarrow (\\rho, \\theta, \\phi)$  .$\\rho$ is the distance between the origin and point; .$\\rho \\geq 0$ .$\\theta$ is the angle on the .$xy$ plane; .$\\theta \\in [0, 2\\pi]$ .$\\phi$ is the angle between the .$z$ axis and the .$xy$ plane; .$\\phi \\in [0, \\pi]$  We only need to consider half the sphere; the other half is already counted by the varying .$\\theta$.         Spherical to Cartesian #   $$x =\\rho \\sin \\phi \\cos \\theta$$ $$y =\\rho \\sin \\phi \\sin \\theta$$ $$z =\\rho \\cos \\phi$$  Cylindrical to Spherical #   $$x =\\rho \\sin \\phi$$ $$\\theta = \\theta$$ $$z =\\rho \\cos \\phi$$  Cartesian to Spherical #   $$\\rho = \\sqrt{x^2 + y^2 + z^2}$$ $$\\tan \\theta = \\frac{y}{x}$$ $$\\tan \\phi = \\frac{z}{\\sqrt{x^2 + y^2}}$$   $$\\iiint_E f(x,y,z)\\ dV = \\dots$$ $$\\dots = \\int_c^d \\int_\\alpha^\\beta \\int_a^b f(\\rho\\sin\\phi\\cos\\theta, \\rho\\sin\\phi\\sin\\theta, \\rho\\cos\\phi) \\cdot \\rho^2 \\sin\\phi\\ d\\rho\\ d\\theta\\ d\\phi$$   We have the volume element .$dV = dx\\ dy\\ dz$. By converting to cylindrical coordinates and doing some algebraic conversions we have .$dV = \\rho^2 \\sin\\phi d\\rho\\ d\\theta\\ d\\phi$:     15.9 Change of Variable in Multiple Integrals #   We\u0026rsquo;ve done .$u$-sub before in single variable, as well as cartesian .$\\iff$ polar .$\\iff$ spherical in multivariable More generally, we can consider a change of variables that is given by a transformation .$T$ from the .$uv$-plane to the .$xy$-plane:  .$T(u,v) = (x,y)$ where .$x = g(u,v), y = h(u,v)$  .$x,y$ must be differentiable in .$S$   We usually assume that .$T$ is a .$C^1$ transformation: .$g$ and .$h$ have continuous first-order partial derivatives  A transformation .$T$ is really just a function whose domain and range are both subsets of .$\\mathbb{R}^2$ If .$T(u_1, v_1 = (x_1, y_1)$, then the point .$(x_1,y_1)$ is called the image of the point .$(u_1, v_1)$  That is, .$T$ transforms .$S$ into a region .$R$ in the .$xy$-plane called the image of .$S$, consisting of the images of all points in .$S$   If no two points have the same image, .$T$ is called one-to-one ( wiki)  If .$T$ is a one-to-one transformation, then it has an inverse transformation .$T^{-1}$ from the .$xy$-plane to the .$uv$-plane + it may be possible to solve for .$u$ and .$v$ in terms of .$x$ and .$y$: .$u = G(x,y), v = H(x,y)$ If not one-to-one, then the transformation would \u0026ldquo;fold\u0026rdquo; over itself \u0026ndash; we would double-count some amount of area          This change in variable affects the size of the region (the area/integral)  The vector .$\\vec r (u, v) = g(u, v) \\hat i + h(u, v) \\hat j$ is the position vector of the image of the point .$(u, v)$.  The tangent vector at .$(x_0, y_0)$ to the image curve of the lower side (.$v = v_0$) of .$S$: $$\\vec r_v = \\frac{\\delta x}{\\delta v} \\hat i + \\frac{\\delta y}{\\delta v} \\hat j$$    Similarly, the tangent vector at .$(x_0, y_0)$ to the image curve of the left side (.$u = u_0$) of .$S$: $$\\vec r_u = \\frac{\\delta x}{\\delta u} \\hat i + \\frac{\\delta y}{\\delta u} \\hat j$$         We can then find the area by calculating the cross product: $$\\vec r_u \\times \\vec r_v = \\begin{vmatrix} \\frac{\\delta x}{\\delta u} \u0026amp; \\frac{\\delta x}{\\delta v} \\\\ \\frac{\\delta y}{\\delta u} \u0026amp; \\frac{\\delta y}{\\delta v} \\end{vmatrix}$$ $$\\dots = \\frac{\\delta (x,y)}{\\delta (u,v)} = \\frac{\\delta x}{\\delta u} \\frac{\\delta y}{\\delta v} - \\frac{\\delta x}{\\delta v}\\frac{\\delta y}{\\delta u}$$ This is the Jacobian of the transformation .$T$ given by .$x = g(u,v)$ and .$y = h(u,v)$     Formally, Suppose that .$T$ is a .$C^1$ transformation whose Jacobian is nonzero and that .$T$ maps a region .$S$ in the .$uv$-plane onto a region .$R$ in the .$xy$-plane. Suppose that .$f$ is continuous on .$R$ and that .$R$ and .$S$ are type I or type II plane regions. Suppose also that .$T$ is one-to-one, except perhaps on the boundary of .$S$. Then, $$\\iint_R f(x,y) dA = \\iint_S f(x(u,v), y(u,v)) \\Bigg\\vert \\frac{\\delta (x,y)}{\\delta (u,v)} \\Bigg\\vert\\ du\\ dv$$   That is, .$dA = \\Bigg\\vert \\frac{\\delta (x,y)}{\\delta (u,v)} \\Bigg\\vert\\ du\\ dv$  General Solving Steps #   Write down transformations (.$x$ and .$y$ in terms of .$u$ and .$v$) Find the Jacobian Rewrite the equations with .$u$ and .$v$ Sketch the new region + find new bounds Integrate on the new field with Jacobian   Triple Integrals #   We can also let .$T$ be a transformation that maps a region .$S$ in .$uvw$-space onto a region .$R$ in .$xyz$-space by means of the equations: $$x = g(u,v,w)$$  $$y = h(u,v,w)$$  $$z = k(u,v,w)$$    Then, the Jacobian is a .$3 \\times 3$ determinant: $$ \\frac{\\delta (x,y,z)}{\\delta (u,v,w)} = \\begin{vmatrix} \\frac{\\delta x}{\\delta u} \u0026amp; \\frac{\\delta x}{\\delta v} \u0026amp; \\frac{\\delta x}{\\delta w} \\\\ \\frac{\\delta y}{\\delta u} \u0026amp; \\frac{\\delta y}{\\delta v} \u0026amp; \\frac{\\delta y}{\\delta w} \\\\ \\frac{\\delta z}{\\delta u} \u0026amp; \\frac{\\delta z}{\\delta v} \u0026amp; \\frac{\\delta z}{\\delta w} \\end{vmatrix} = dA$$  "},{"id":32,"href":"/math-53/16/","title":"16: Vector Calculus","section":"Math 53","content":"16.1 Vector Fields #   A vector field in .$\\mathbb{R}^3$ is a function .$\\vec F$ on region .$E \\in \\mathbb{R}^3$ that assigns each point .$(x,y,z)$ a vector .$F(x,y,z)$ .$\\vec F$ is made up of component function: .$\\vec F(x,y,z) = \\langle P(x,y,z)\\hat i, Q(x,y,z) \\hat j, R(x,y,z) \\hat k\\rangle$  .$\\vec F$ is continuos iff its component vectors are continuos   .$\\vec F$ is  conservative (path taken doesn\u0026rsquo;t change work) iff potential function .$f(x,y,z)$ is a partial of .$\\vec F$ $$\\vec F = \\nabla f$$  Notice that the gradient lines are always perpendicular to the level sets  If the function .$f$ is differentiable, .$\\nabla f$ at a point is either zero or perpendicular to the level set of .$f$ at that point.   That is, that the gradient of a function is called a gradient field which is always conservative (the fundamental theorem of calculus for line integrals)  Conversely, a (continuous) conservative vector field is always the gradient of a function      16.2 Line Integrals #   We know that the distance (length) normally is .$L = \\int_a^b \\sqrt{(dx/dt)^2 + (dy/dt)^2}\\ dt$ Over a vector field, we can think of the function being the density of the line (or height of particle). Therefore, we say .$ds = \\int_a^b \\sqrt{(dx/dt)^2 + (dy/dt)^2}\\ dt$ and can write $$\\int_C f(x,y) ds = \\int_a^bf(x(t), y(t)) \\cdot \\sqrt{\\bigg(\\frac{dx}{dt}\\bigg)^2 + \\bigg(\\frac{dy}{dt}\\bigg)^2} dt$$ and for 3D in a slightly different form: $$\\int_a^b f (\\vec r (t) ) \\vert \\vec r\u0026rsquo;(t) \\vert \\Longrightarrow \\int_a^b f(x(t), y(t), z(t)) \\cdot \\sqrt{x\u0026rsquo;(t)^2 + y\u0026rsquo;(t)^2 + z\u0026rsquo;(t)^2} dt$$  We can write .$\\vec a \\to \\vec b$ as .$(1-t)\\vec a + t\\vec b$ with .$t\\in[0,1]$ Just like usual, we can break up un-integrable smooth curves, i.e $$\\int_a^z f (x,y) = \\int_a^b f_1(x,y) + \\int_b^c f_2(x,y) + \\dots \\int_{\\dots}^z f_n(x,y)$$  wrt variable #  Opposed to the line integrals on .$f$ along .$C$ with respect to .$x$ both and .$y$, we can write line integral with respect to arc length as follows:\n$$\\int_C f(x,y) dx = \\int_a^b f(x(t), y(t)) \\cdot y\u0026rsquo;(t) dt$$ $$\\int_C f(x,y) dy = \\int_a^b f(x(t), y(t)) \\cdot x\u0026rsquo;(t) dt$$\nIt frequently happens that line integrals with respect to .$x$ and .$y$ occur together which we abbr as\n$$\\int_C P(x,y)\\ dx + \\int_C Q(x,y)\\ dy = \\int_C P(x,y)\\ dx + Q(x,y)\\ dy$$\nOrientation #   When we parameterize a curve, we give it a direction  Positive: Enclosed region .$D$ is always on the left as we traverse curve .$C$ (counter-clockwise) Negative: Enclosed region .$D$ is always on the right as we traverse curve .$C$ (clockwise)   The orientation represents the direction of the line  The positive direction corresponding to increasing values of the parameter .$t$ Doesn\u0026rsquo;t matter for regular line integrals: .$\\int_C f(x,y) ds = \\int_C f(x,y) ds$  Deals with distance, .$ds$, which doesn\u0026rsquo;t depend on direction   Does matter for field line integrals: .$\\int_C f(x,y) dx \\neq \\int_C f(x,y) dy$  Deals with displacement, .$dx/dy$, which depends on direction      Let .$\\vec F$ be a continuous vector field defined on a smooth curve .$C$ given by a vector function .$\\vec r(t), t\\in[a,b]$. Then the line integral of .$\\vec F$ along .$C$ is $$W = \\int_C \\vec F \\cdot d\\vec r = \\int_a^b \\vec F ( \\vec r (t) ) \\cdot (\\vec r (t))\u0026rsquo;\\ dt = \\int_C \\vec F \\cdot \\vec T\\ ds$$\n .$\\vec T(x,y,z)$ is the unit tangent vector at the point .$(x,y,z)$ on .$C$ .$\\vec F \\cdot \\vec T = \\vec F(x,y,z) \\cdot \\vec T(x,y,z)$    This equation says that work is the line integral with respect to arc length of the tangential component of the force. Then, for a non-conservative force i.e .$F = \\langle P(x,y,z), Q(x,y,z), R(x,y,z) \\rangle$ $$W = \\int_a^b P(\\vec r(t)) \\cdot x\u0026rsquo;(t) + Q(\\vec r(t)) \\cdot y\u0026rsquo;(t) + R(\\vec r(t)) \\cdot z\u0026rsquo;(t)$$ $$ \\Longrightarrow \\int_C P\\ dx + Q\\ dy + R\\ dz$$ If we flip the curve\u0026hellip;  \u0026hellip;and integrate with respect to just .$x$ or .$y$ then the value flips: $$\\int_{-C}f(x,y)\\ dx = - \\int_C f(x,y)\\ dx$$ Since .$\\Delta x$ and .$\\Delta y$ change sign when we reverse the orientation of .$C$.    \u0026hellip;and integrate with respect to arc length, the value of the line integral does not change when we reverse the orientation of the curve: $$\\int_{-C}f(x,y)\\ ds = \\int_C f(x,y)\\ ds$$ This is because .$\\Delta s$ is always positive.      16.3 Fundamental Thm for Line Integrals #  Let .$C$ be a smooth curve given by the vector function .$\\vec r (t), t\\in[a,b]$. Let .$f$ be a differentiable function of two or three variables whose gradient vector .$\\nabla f$ is continuous on .$C$. Then $$\\int_C \\nabla f \\cdot d\\vec r =\\int_C \\vec F \\cdot d\\vec r = f(\\vec r(b) ) f(\\vec r(a))$$  Independence of Path #   Suppose .$C_1$ and .$C_2$ are two piecewise-smooth curves (which are called paths) that have the same initial point .$A$ and terminal point .$B$.  Therefore, .$\\int_{C_1} \\nabla f \\cdot d\\vec r = \\int_{C_2} \\nabla f \\cdot d\\vec r$ whenever .$\\nabla f$ is continuous In other words, line integrals of conservative vector fields are independent of path (they only depend on the start and end points)    Plane Curves #  .$\\int_C \\vec F \\cdot d\\vec r$ is independent of path in .$D$ iff .$\\int_C \\vec F \\cdot d\\vec r = 0$ for every closed path .$C$ in .$D$   Closed: A curve with the same end and start points: .$\\vec r(b) = \\vec r(a)$ That is, only vector fields that are independent of path are conservative.     Space Curves #  Suppose .$\\vec F$ is a vector field that is continuous on an open connected region .$D$. If .$\\int_C \\vec F \\cdot d\\vec r$ is independent of path in .$D$, then .$\\vec F$ is a conservative vector field on .$D$; that is, there exists a function .$f$ such that .$\\nabla f = \\vec F$.   Open: For every point .$P$ in .$D$ there is a disk with center .$P$ that lies entirely in .$D$. (So .$D$ doesn\u0026rsquo;t contain any of its boundary points.) Connected: Any two points in .$D$ can be joined by a path that lies in .$D$.   $$$$     If .$\\vec F (x,y) = P(x,y) \\hat i + Q(x,y) \\hat j$ is a conservative vector field, where .$P$ and .$Q$ have continuous first-order partial derivatives on a domain .$D$, then throughout .$D$ we have $$ \\frac{\\delta P}{\\delta y} = \\frac{\\delta Q}{\\delta x}$$ The converse of the theorem above is true on only simple curves: curves that don\u0026rsquo;t intersect itself anywhere between its endpoints A simply-connected region in the plane is a connected region .$D$ such that every simple closed curve in .$D$ encloses only points that are in .$D$  Intuitively speaking, a simply-connected region contains no hole and can\u0026rsquo;t consist of two separate pieces.    .$\\vec F = \\langle P, Q \\rangle$ is a conservative vector field on an open simply-connected region .$D$ iff both .$P$ and .$Q$ have continuous first-order partial derivatives and $$ \\frac{\\delta P}{\\delta y} = \\frac{\\delta Q}{\\delta x} \\text{ throughout } D$$    16.4 Green\u0026rsquo;s Theorem #  Green\u0026rsquo;s Theorem: Let .$C$ be a positively oriented, piecewise-smooth, simple closed curve in the plane and let .$D$ be the region bounded by .$C$. If .$P$ and .$Q$ have continuous partial derivatives on an open region that contains .$D$, then $$\\int_C \\vec F \\cdot d\\vec r = \\oint_C P\\ dx + Q\\ dy = \\iint_D \\bigg(\\frac{\\delta Q}{\\delta x} - \\frac{\\delta P}{\\delta y}\\bigg) dA$$\n .$dA = dx\\ dy = r \\cdot dr\\ d\\theta = \\dots$ .$\\vec F(x,y) = \\langle P(x,y), Q(x,y)\\rangle$ .$\\oint$ implies an integral over a closed curve    The proof (for Green\u0026rsquo;s thm + remaining sections) is (are) too much for me to write out here, the book does a good job  One important takeaway is the the shape doesn\u0026rsquo;t have to be \u0026ldquo;nice\u0026rdquo; \u0026ndash; we can break up any shape into parts that are either Type I or II. Even though we will have overlapping lines, they cancel one another out (leaving only the boundaries) because of orientation   Green\u0026rsquo;s Theorem should be regarded as the counterpart of the Fundamental Theorem of Calculus for double integrals  Recall the Fundamental Theorem of Calculus is .$\\int_a^b F\u0026rsquo;(x)\\ dx = F(b) - F(a)$ In both cases there is an integral involving derivatives (.$F\u0026rsquo;, \\delta Q/\\delta x, \\delta P/\\delta y$) on the left side of the equation. And in both cases the right side involves the values of the original functions (.$F, Q, P$) only on the boundary of the domain.  (In the one-dimensional case, the domain is an interval .$[a,b]$ whose boundary consists of just two points, .$a$ and .$b$.)      Application: Finding Area #   Since the area of .$D$ is .$\\iint_D 1 dA$, we wish to choose .$P$ and .$Q$ so that $$ \\frac{\\delta Q}{\\delta x} - \\frac{\\delta P}{\\delta y} = 1$$ Some examples of .$P/Q$ combos are $$P(x,y)= 0$$ $$Q(x,y)= x$$ $$A = \\oint_C x\\ dy$$  $$P(x,y)=-y$$ $$Q(x,y)= 0$$ $$A = -\\oint_C y\\ dx$$  $$P(x,y)=-y/2$$ $$Q(x,y)= x/2$$ $$A = \\frac{1}{2} \\oint_C x\\ dy - y\\ dx$$     Planimeters (a measuring instrument used to determine the area of an arbitrary two-dimensional shape) is an example of an application of Green Theorem We can also use Green\u0026rsquo;s to prove main  div  article  div:nth-child(22)  div:nth-child(2)  blockquote\").scrollIntoView()'our last equation found in 16.3: $$\\oint_C \\vec F \\cdot d \\vec r = \\oint_C P\\ dx + Q\\ dy = \\iint_R \\bigg( \\frac{\\delta Q}{\\delta x} - \\frac{\\delta P}{\\delta y}\\bigg)\\ dA = \\iint_R 0\\ dA = 0$$  A curve that is not simple crosses itself at one or more points and can be broken up into a number of simple curves. We have shown that the line integrals of .$\\vec F$ around these simple curves are all .$0$ and, adding these integrals, we see that .$\\int_C \\vec F \\cdot d\\vec r = 0$ for any closed curve .$C$. Therefore .$\\int_C \\vec F \\cdot d\\vec r$ is independent of path in .$D$. It follows that .$F$ is a conservative vector field.\n   16.5 Curl and Divergence #   Recall that .$\\nabla = \\langle \\frac{\\delta}{\\delta x} \\frac{\\delta}{\\delta y} \\frac{\\delta}{\\delta z} \\rangle$  3b1b video going over this section  Curl #   Vector of the rotation caused by the field at a given point $$\\nabla \\times \\vec F(x,y,z) = \\begin{bmatrix}\\hat i \u0026amp; \\hat j \u0026amp; \\hat k\\\\ \\frac{\\delta}{\\delta x} \u0026amp; \\frac{\\delta}{\\delta y} \u0026amp; \\frac{\\delta}{\\delta z}\\\\ P \u0026amp; Q \u0026amp; R\\end{bmatrix} = \\dots $$ If .$\\vec F$ is conservative then .$\\text{curl($\\vec F$) = 0}$  We know if .$\\vec F$ is conservative then .$\\vec F = \\nabla f$ for some .$f(x,y,z)$ Crossing .$\\nabla F$ with .$\\nabla$ we get .$\\langle \\frac{\\delta^2 f}{\\delta y \\delta z} - \\frac{\\delta^2 f}{\\delta z \\delta y}, \\dots \\rangle = \\langle 0, 0,0 \\rangle$    Divergence #   If .$\\vec F (x,y,z)$ is the velocity of a fluid (or gas), then .$\\text{div}(\\vec F (x,y,z))$ represents the net rate of change (wrt time) of the mass of fluid (or gas) flowing from the point .$(x,y,z)$ per unit volume.  In other words, .$\\text{div}(\\vec F (x,y,z))$ measures the tendency of the fluid to diverge from the point .$(x,y,z)$. If .$\\text{div}(\\vec F (x,y,z)) = 0$, then .$F$ is said to be incompressible.   Scalar of the amount of \u0026ldquo;flow\u0026rdquo; at a given point \u0026ndash; how much does the field expand/contract at a given point? $$\\nabla \\cdot \\vec F(x,y,z) = \\langle \\frac{\\delta}{\\delta x} \\frac{\\delta}{\\delta y} \\frac{\\delta}{\\delta z} \\rangle \\cdot \\langle P, Q, R \\rangle$$    Fun fact: .$\\text{(div(curl($\\vec F$)))} = \\nabla \\cdot (\\nabla \\times \\vec F)= 0$  We can use this fact to find if there exists a vector field .$\\vec G$ such that .$\\text{curl($\\vec G$)} = \\vec H$ because .$\\text{div(curl($\\vec G$))} = \\text{div($\\vec H$)} = 0$    Vector Form of Green\u0026rsquo;s #  $$\\oint_C \\vec F \\cdot d \\vec r = \\iint_D \\text{(curl ($\\vec F$))} \\cdot \\hat k\\ dA = \\bigg( \\frac{\\delta Q}{\\delta x} - \\frac{\\delta P}{\\delta y} \\bigg) \\hat k$$\n This equation expresses the line integral of the tangential component of .$\\vec F$ along .$C$ as the double integral of the vertical component of .$\\text{curl($\\vec F$)}$ over the region .$D$ enclosed by .$C$.      We can write this using the normal component of .$\\vec F$ too:  With .$\\vec r(t) = \\langle x(t), y(t) \\rangle; t \\in [a,b]$ Recall the unit tangent vector: .$\\vec T(t) = \\frac{1}{\\vert \\vec r \u0026rsquo; (t) \\vert} \\langle x\u0026rsquo;(t), y\u0026rsquo;(t) \\rangle$ The outward unit normal vector to .$C$ is given by .$\\vec n (t) = \\frac{1}{\\vert \\vec r \u0026rsquo; (t) \\vert} \\langle y\u0026rsquo;(t), -x\u0026rsquo;(t) \\rangle$ We can then evaluate $$\\oint_C \\vec F \\cdot \\vec n\\ ds = \\int_a^b (\\vec F \\cdot \\vec n)(t) \\vert \\vec r\u0026rsquo;(t) \\vert\\ dt = \\iint_D \\bigg( \\frac{\\delta P}{\\delta x} - \\frac{\\delta Q}{\\delta y} \\bigg)\\ dA = \\iint_D \\text{div $\\vec F (x,y)$}\\ dA$$ This says that the line integral of the normal component of .$\\vec F$ along .$C$ is equal to the double integral of the divergence of .$\\vec F$ over the region .$D$ enclosed by .$C$.    16.6 Parametric Surfaces and Their Area #  Parametric Surfaces #    Just like how we can describe curves with single parameter (variable) function .$\\vec r(t)$, we can describe surfaces with a vector function .$\\vec r(u,v) = \\langle x(u,v), y(u,v), z(u,v) \\rangle$  .$\\vec r(u,v)$ is called a vector-valued function defined on a region .$D$ in the .$uv$-plane .$x,y,z$ are the component functions of .$\\vec r$, each of which have domain .$D$   In general, a surface given as the graph of a function of .$x$ and .$y$, that is, with an equation of the form .$z = f(x,y)$, can always be regarded as a parametric surface by taking .$x$ and .$y$ as parameters and writing the parametric equations as .$x = x; y = y; z = f(x,y)$  E.x. the plane with point .$(x_0, y_0, z_0)$ and vectors .$\\langle a,b,c \\rangle$ .$\\langle \\alpha,\\beta,\\gamma \\rangle$ is .$\\vec r(u,v) = \\langle x_0, y_0, z_0 \\rangle + u\\langle a,b,c \\rangle + v\\langle \\alpha,\\beta,\\gamma \\rangle$ or .$0 = (\\langle x - x_0, y - y_0, z - z_0 \\rangle) \\cdot (\\langle a,b,c \\rangle \\times \\langle \\alpha,\\beta,\\gamma \\rangle)$    Surfaces of Revolution #    We can write surfaces of revolution as parametric equations too Consider surface .$S$ obtained by rotating the curve .$y = f(x)$ about the .$x$-axis (with .$f(x) \\geq 0$) Therefore, we get the following parameterization:  $$x = x$$  $$y = f(x)\\cos\\theta$$  $$z = f(x)\\sin\\theta$$     Tangent Planes #   Employing the same method as before, we can find the tangent plane to a param surface .$S$ by finding the initial point and the normal vector Given some parameterization .$\\vec r(u,v) = \\langle x(u,v), y(u,v), x(u,v) \\rangle$ and initial point .$P_0 = (x_0, y_0)$\u0026hellip;  Find point .$P_0$ by setting .$x(u,v) = x_0, y(u,v) = y_0, \\dots$ and solving for .$u_0,v_0$ Find normal vector .$\\vec n$ by deriving to get, then cross, the parameterization: .$\\vec n = \\vec r_u \\times \\vec r_v$  If the normal vector isn\u0026rsquo;t zero, the tangent plane is at .$\\vec n (u_0, v_0)$ If it is, then the surface .$S$ isn\u0026rsquo;t smooth (it is at a \u0026ldquo;corner\u0026rdquo;)   The tangent plane can then be expressed as $$(\\vec r_u \\times \\vec r_v)_{(u_0, v_0)} \\cdot (\\langle x,y,z \\rangle - \\langle x_0, y_0, z_0 \\rangle)$$    Surface Area #    The image of the subrectangle .$R_{ij}$ is the patch .$S_{ij}$.\n  Recall that the magnitude of the cross product is the area of a parallelogram formed by two vectors We can think of this as the jacobian of the transformation  If a smooth parametric surface .$S$ is given by the equation $$\\vec r(u,v) = \\langle x(u,v), y(u,v), z(u,v) \\rangle; (u,v) \\in D$$ and .$S$ is covered just once as .$(u,v)$ ranges throughout the parameter domain .$D$, then the surface area of .$S$ is $$A(S) = \\iint_D \\vert \\vec r_u \\times \\vec r_v \\vert\\ dA$$ where $$\\vec r_u = \\langle \\frac{\\delta x}{\\delta u}, \\frac{\\delta y}{\\delta u}, \\frac{\\delta z}{\\delta u} \\rangle; \\vec r_v = \\langle \\frac{\\delta x}{\\delta v}, \\frac{\\delta y}{\\delta v}, \\frac{\\delta z}{\\delta v} \\rangle$$  Surface Area of the Graph of a Function #   For the special case of a surface .$S$ with equation .$z = f(x,y)$, where .$(x,y)$ lies in .$D$ and .$f$ has continuous partial derivatives, we take .$x$ and .$y$ as parameters.  That is, the parametric equations are .$x = x; y = y; z = f(x,y)$ Therefore .$\\vec r_x = \\langle 1, 0, \\frac{\\delta f}{\\delta x} \\rangle; \\vec r_y = \\langle 0, 1, \\frac{\\delta f}{\\delta y};$ and .$\\vec n = \\sqrt{1 + \\frac{\\delta f}{\\delta x}^2 + \\frac{\\delta f}{\\delta y}^2}$ Thus, the surface area becomes $$A(S) = \\iint_D \\sqrt{1 + \\frac{\\delta f}{\\delta x}^2 + \\frac{\\delta f}{\\delta y}^2}\\ dA$$   Notice the similarity between the surface area formula above and the arc length formula  16.7 Surface Integral #  Surface Integral #   The relationship between surface integrals and surface area is much the same as the relationship between line integrals and arc length.  The arc length is a line integral where the density (or weight) function .$f(x,y,z) = 1$  That is, .$\\int_C f(x,y,z)\\ ds = \\int_a^b f(\\vec r(t)) \\vert \\vec r\u0026rsquo;(t) \\vert$   Similarly, the surface area is found taking the surface integral with density function .$f(x,y,z) = 1$  That is, .$\\iint_S 1\\ dS = \\iint_D \\vert \\vec r_u \\times \\vec r_v \\vert\\ dA = A(S)$     If we define .$\\vec r(u,v) = \\langle x(u,v), y(u,v), z(u,v) \\rangle; (u,v) \\in D$ $$\\iint_S f(x,y,z)\\ dS = \\iint_D f(\\vec r(u,v)) \\vert \\vec r_u \\times \\vec r_v \\vert\\ dA$$  Graphs of Functions #   Any surface .$S$ with equation .$z = g(x,y)$ can be regarded as a parametric surface with parametric equations $$x = x$$  $$y = y$$  $$z = g(x,y)$$    Thus, $$\\vec r_x = \\bigg\\langle 1, 0, \\frac{\\delta g}{\\delta x}\\bigg\\rangle$$  $$\\vec r_y = \\bigg\\langle 0, 1, \\frac{\\delta g}{\\delta y}\\bigg\\rangle$$   $$\\vec r_x \\times \\vec r_y = \\bigg\\langle -\\frac{\\delta g}{\\delta x}, -\\frac{\\delta g}{\\delta y}, 1\\bigg\\rangle$$  $$\\vec n = \\sqrt{\\bigg(\\frac{\\delta z}{\\delta x}\\bigg)^2 + \\bigg(\\frac{\\delta z}{\\delta y}\\bigg)^2 + 1}$$    Therefore, $$\\iint_S f(x,y,z)\\ dS = \\iint_D f(x,y,g(x,y)) \\sqrt{\\bigg(\\frac{\\delta z}{\\delta x}\\bigg)^2 + \\bigg(\\frac{\\delta z}{\\delta y}\\bigg)^2 + 1}\\ dA$$  Similar formulas apply when it is more convenient to project .$S$ onto the .$yz$-plane or .$xz$-plane.    Oriented Surfaces #    With the exception of the Möbius strip, most surfaces are two-sided, meaning they\u0026rsquo;re Orientable surfaces  We start with a surface .$S$ that has a tangent plane at every point .$(x,y,z)$ on .$S$ (except at any boundary point). There are two unit normal vectors .$\\hat n_1$ and .$\\hat n_2 = -\\vec n_1$ at .$(x,y,z)$ If it is possible to choose a unit normal vector .$\\hat n$ at every such point .$(x,y,z)$ so that .$\\hat n$ varies continuously over .$S$, then .$S$ is called an oriented surface  The choice of .$\\hat n$ provides .$S$ with an orientation. There are two possible orientations for any orientable surface For a closed surface, the positive orientation has the normal vectors pointing outward and vis-versa         If .$S$ is a smooth orientable surface given in parametric form by a vector function .$\\vec r (u,v)$ then it is automatically supplied with the orientation of the unit normal vector $$\\hat n = \\frac{\\vec r_u \\times \\vec r_v}{\\vert \\vec r_u \\times \\vec r_v \\vert}$$ E.x., going back to a surface .$z = g(x,y)$ given as the graph of .$g$, the normal unit vector is $$\\hat n = \\frac{\\big\\langle -\\frac{\\delta g}{\\delta x}, -\\frac{\\delta g}{\\delta y}, 1\\big\\rangle}{\\sqrt{\\big(\\frac{\\delta z}{\\delta x}\\big)^2 + \\big(\\frac{\\delta z}{\\delta y}\\big)^2 + 1}}$$  Since the .$\\hat k$-component is positive, this gives the upward orientation of the surface.    Surface Integrals of Vector Fields (Flux) #  If .$\\vec F$ is a continuous vector field defined on an oriented surface .$S$ with unit normal vector .$\\hat n$, then the surface integral of .$\\vec F$ over .$S$ is $$\\iint_S \\vec F \\cdot d\\vec S = \\iint_S \\vec F \\cdot \\hat n \\ dS = \\iint_D \\vec F \\cdot (\\vec r_u \\times \\vec r_v)\\ dA$$ This integral is also called the flux of .$\\vec F$ across .$S$.   In words, the surface integral of a vector field .$\\vec F$ over .$S$ is equal to the surface integral of its normal component over .$S$ (as previously defined). We can apply this to fluids:  Imagine a fluid with density .$\\rho (x,y,z)$ and velocity field .$\\vec v (x,y,z)$ flowing through .$S$. Think of .$S$ as an imaginary surface that doesn\u0026rsquo;t impede the fluid flow, like a fishing net across a stream. Then the rate of flow (mass per unit time) per unit area is .$\\vec F = \\vec v \\rho$ The flux can be interpreted physically as the rate of flow through .$S$.    16.8 Stokes\u0026rsquo; Theorem #   Just as Green\u0026rsquo;s Theorem relates a double integral over a plane region .$D$ to a line integral around its plane boundary curve, Stokes\u0026rsquo; Theorem relates a surface integral over surface .$S$ to a line integral around the boundary curve of .$S$ (which is a space curve) Stokes\u0026rsquo; Theorem: Let .$S$ be an oriented piecewise-smooth surface that is bounded by a simple, closed, piecewise-smooth boundary curve .$C$ with positive orientation. Let .$\\vec F$ be a vector field whose components have continuous partial derivatives on an open region in .$\\mathbb{R}^3$ that contains .$S$. Then $$\\int_C \\vec F \\cdot d \\vec r = \\iint_S \\text{curl } \\vec F \\cdot d\\vec S$$   In words, Stokes\u0026rsquo; Theorem says that the line integral around the boundary curve of .$S$ (some curve.$C$) of the tangential component of .$\\vec F$ is equal to the surface integral over .$S$ of the normal component of the curl of .$F$ This is since $$\\int_C \\vec F \\cdot d \\vec r = \\int_C \\vec F \\cdot \\vec T\\ ds \\ \\ \\ \\text{ and }\\ \\ \\iint_S \\text{curl } \\vec F \\cdot d\\vec S = \\iint_S \\text{curl } \\vec F \\cdot \\hat n\\ dS$$  16.9 Divergence Theorem #  Divergence Theorem: Let .$E$ be a simple solid region and .$S$ be the boundary surface of .$E$, given with positive (outward) orientation. Let .$\\vec F$ be a vector field whose component functions have continuous partial derivatives on an open region that contains .$E$. Then $$\\iint_S \\vec F \\cdot d\\vec S = \\iiint_E \\text{div } \\vec F\\ dV$$   In words, we can say that the Divergence Theorem says that (under the given conditions) the flux of .$\\vec F$ across the boundary surface of .$E$ is equal to the triple integral of the divergence of .$\\vec F$ over .$E$.  "},{"id":33,"href":"/physics-7b/17/","title":"17: Temperature, Thermal Expansion, \u0026 Ideal Gas Law","section":"Physics 7B","content":"17.1: Atomic Theory #   Atoms are the smallest unit of matter Atomic unit: .$\\text{u} = 1.66\\cdot 10^{-27}$ kg  E.x. Hydrogen weighs .$1.0078 \\text{u}$   Molecular mass of a compound is the sum of the particles (atoms) in the compound  Terms #   Element: Substance that cannot be broken down into smaller substances (gold) Molecule: Group of atoms held together by covalent bonds Compound: Substance made from atoms combined in specific ratios  Brownian Motion #   Random movement seen in pollen/dust, as well as atoms Using Brownian motion, Einstein found the size of an atom to be .$10^{-10}$ meters  Forces #   Atoms and molecules exert an (electric) attractive force on one another by default If an atom/molecule gets too close to another, they exert a repelling force on one another Matter states:  Solid:  Atoms held in matrix formation by strong attractive forces. Atoms vibrate around their mean position   Liquid:  Force between atoms is weaker so atoms move more rapidly within   Gas:  Atom attractive forces are so weak compared to their kinetic energy that they move randomly If two atoms collide, the attractive force is so weak that they may just bounce off one another      17.2: Temperature and Thermometers #   Matter property changes under different temperatures  Sidewalks expand under the sun Electric resistance increases with heat Lightbulb filament glows    Thermometers Types #   Originally used alcohol which expands linearly with heat (water doesn\u0026rsquo;t) Bimetalic strips bend at slightly different rates under heat Electronic thermometers measure resistance change and often have digital screens  Scales #   Fahrenheit: Water freezes at 32 and boils at 212 deg Celsius: Water freezes at 0 and boils at 100 deg Kelvin: Celsius + 273.15K. Written without degree sign. Absolute = 0K Conversions: $$T(^\\circ C) = \\frac{5}{9}(T(^\\circ F)-32)$$ $$T(^\\circ F) = \\frac{9}{5}(T(^\\circ C)) + 32$$ Different materials expand at different rates ro we use constant-volume thermos because it\u0026rsquo;s pressure linearly relates to the temperature  17.3 0th Law of Thermodynamics #   If objects .$A$ and .$B$ are at equilibrium with object .$C$ , then .$A$ and .$B$ are also at equilibrium with one another Systems naturally reach equilibrium over time  Thermal Expansion #   Most materials expand when heated Expansion amount depends on the material Equations (assuming a constant volume .$V$ )  Linear Expansion:  .$\\alpha$ is the coefficient of linear expansion and depends on the material with units .$(^\\circ C)^{-1}$ $$\\Delta l \\approxeq \\alpha l_0 \\cdot \\Delta T$$ $$l_i + \\Delta l = l_f = l_i ( 1 + \\alpha\\Delta T)$$ $$\\frac{dl}{dT} = \\alpha(T)\\cdot l$$ If .$\\Delta T$ is too large such that the temperature dependence of .$\\alpha$ is too large, we can do the following: $$\\int_{l_i}^{l_f} \\frac{1}{l}dl = \\int_{T_i}^{T_f} \\alpha(T) dT$$   Volume Expansion: $$\\beta = \\frac{1}{V} \\frac{dV}{dT}$$ $$V_f \\approxeq V_0 ( 1 + \\beta\\Delta T)$$  .$\\beta \\approx 3\\cdot\\alpha$ = coefficient of volume expansion.   Coefficient of expansion varies at extremely high heats so it only works with small .$\\Delta T$ \u0026rsquo;s Materials must be isotropic (have same expansion properties in all directions) for us to say .$\\alpha \\approx 3\\cdot\\beta$ (Linear) expansion doesn\u0026rsquo;t exist for gas or liquids because they have no fixed space like solids.   Weird water property  .$0 - 4 ^\\circ C$ : Water increases in density .$\\rho^+\\Longrightarrow$ decreases in volume .$V^-$ .$4^\\circ C +$ : Water acts \u0026ldquo;normally\u0026rdquo;: increase in volume .$V$ proportional to temperature .$T$ This explains why pipes burst when frozen and why ice cubes float    17.5 Thermal Stresses #   When the ends a solid (rod) are fixed (such as in beams), temperature changes induce thermal stress due to the clamp limiting expansion/contraction Process Steps:  Beam tries to expand/contract by .$\\Delta l$ Mount reacts with an opposite reactive force, keeping it at it\u0026rsquo;s original length: $$\\Delta l = \\frac{1}{E} \\cdot \\frac{F}{A} \\cdot l_0$$ where .$E$ is Young\u0026rsquo;s modulus for the material. We can also re-write for stress: $$\\frac{F}{A} = \\Delta l \\cdot E \\cdot \\frac{1}{l_0} = (\\alpha l_0 \\Delta T) E \\cdot \\frac{1}{l_0} = \\alpha E \\Delta T$$    17.6 Gas Laws and Absolute Temperature #   Equation at State describes how pressure varies with Temperature, Number of Particles (Molecules), and Volume State is the physical condition of a system Equilibrium State: .$T, N, \\\u0026amp;\\ V = \\text{Constant}$  Laws #   Assume that gasses aren\u0026rsquo;t too dense (so .$P \\sim$ atmospheric pressure) and that they aren\u0026rsquo;t close to liquefaction (boiling) point either (for oxygen, this is .$~183^\\circ \\text{C}$.)      Boyle\u0026rsquo;s Law  .$V \\propto P^{-1}$ [Constant Temperature] .$P$ is absolute, not gauge, pressure Alternatively, .$PV =$ const or .$P_1V_1 = P_2V_2$    Charles\u0026rsquo;s Law  .$V \\propto T$ [Constant Pressure] Alternatively, .$\\frac{V_1}{T_1} = \\frac{V_2}{T_2}$    Gay Lussac\u0026rsquo;s Law  .$P \\propto T$ [Constant Volume] Alternatively, .$\\frac{P_1}{T_1} = \\frac{P_2}{T_2}$      17.7 Ideal Gas Law #  $$PV = nRT = n k_B N_a T = N k_B T$$   .$P$ is the pressure of the gas [Pascals] .$V$ is the volume of the gas [Cubic Meters] .$T$ is the absolute temperature of the gas [Kelvins] .$N$ is the number of molecules of gas   .$n$ is the amount of substance of gas (number of moles) [Moles] .$R$ is the ideal, or universal, gas constant, equal to .$k_B \\cdot N_a = 8.314 \\frac{J}{K\\cdot \\text{mol}}$  Using mass of a gas, different gasses have different proportionality constants So we used number of moles, in which case .$R$ becomes the constant for all gasses      .$k_B $ is the Boltzmann constant  Relates the average relative kinetic energy of particles in a gas with the thermodynamic temperature of the gas   .$N_a$ is the Avogadro constant  The number of particles that are contained in one mole of gas .$n = N/N_A$       This equation is Ideal in that the equation only works for gasses around atmospheric pressure and not excessive temperatures  Moles #   Mole is the SI unit for amount of substance 1 mole = Number of particles in .$\\text{12g}$ of Carbon 1 mole = Number of grams of a substance numerically equal to the molar mass $$n \\text{(moles)} = \\frac{\\text{mass (grams)}}{\\text{molecular mass (g/mol)}}$$  17.8 Problem Solving with .$PV = nRT$ #  STP: Standard Temperature and Pressure #   .$T = 273 \\text{K}$ .$P = 1.00 \\text{atm} = 1.013\\cdot10^5 \\text{N/m}^2 = 101.3 \\text{kPA}$ .$1 \\text{mol of ideal gas} = 22.4\\text{L}$ in volume If P is in liters and V is in atm, then we can use .$R = 0.0821 \\frac{\\text{L} \\cdot \\text{atm}}{\\text{mol} \\cdot \\text{K}}$ Since .$n$ and .$R$ are constants, we can say: $$\\frac{P_1 V_1}{T_1} = \\frac{P_2 V_2}{T_2}$$  17.9 Ideal Gas with Avogadro\u0026rsquo;s Number #   Avogadro\u0026rsquo;s hypothesis:  Equal volume of gas with the same .$P$ and .$T$ have an equal .$n$ umber of particles (molecules) .$N_a$ is avogadro\u0026rsquo;s number: the number of particles that are contained in one mole of gas (or one gram of hydrogen).  .$N_a = 6.022 \\cdot 10^{23}\\ \\text{particles/mole}$   Therefore, if .$N$ is the number of molecules of a gas sample and .$n$ is the number of moles, then $$N = n\\cdot N_A \\Longrightarrow n = \\frac{N}{N_A} \\Longrightarrow PV = \\frac{N}{N_A}RT = Nk_B T$$ where .$k_B $ is Boltzmann\u0026rsquo;s constant .$\\frac{R}{N_A} = 1.38 \\cdot 10^{-23} \\frac{\\text{J}}{\\text{K}}$    17.10 Ideal Gas Temperature #   Triple point: A precise temperature and pressure where the three phases (gas, liquid, and solid) of a substance can coexist in thermodynamic equilibrium. .$P_3 = 4.88\\ \\text{torr};\\ T_3 = 0.01^\\circ C$ for water Ideal Gas, constant volume: $$T = (273.16 K)\\bigg(\\frac{P}{P_3}\\bigg)$$ Constant volume: $$T = (273.16 K)\\lim_{P_3 \\to 0}\\bigg(\\frac{P}{P_3}\\bigg)$$     A typical phase diagram. The solid green line applies to most substances; the dashed green line gives the anomalous behavior of water. For more see 18.4\n   "},{"id":34,"href":"/physics-7b/18/","title":"18: Kinetic Theory of Gases","section":"Physics 7B","content":"18.1 Ideal Gas Laws and Molecular Interpolation #  Ideal Gas Law Assumptions #   There are a large number of molecules, .$N$, each of mass .$m$ that move in random directions at random speeds Molecules are, on average, sufficiently far away from one another (separation .$\\gg$ diameter) Molecules obey classical mechanics so .$KE \\gg PE$ when colliding Collisions are perfectly elastic  Micro and Macroscopic views related through Energy #   In a system with .$N$ molecules each of mass .$m$ and average speed .$\\bar{v}^2$ (also denoted as .$\\langle v^2 \\rangle$), we can combine the ideal gas law with the .$\\overline{KE}$ equation: $$\\overline{K} = \\frac{1}{2} m \\bar{v}^2 = \\frac{3}{2}k_B T$$  This shows .$\\overline{KE} \\propto T$ which makes sense intuitively; cold = slow particle motion E.x: A container is filled with a light and heavy molecule. Which has a greater speed? The lighter molecules do because they are less massive.   And since the system\u0026rsquo;s internal energy .$E_{\\text{int}} = N \\cdot \\overline{K}$ then we can write an important .$PV$ relation + find the gas.$E_{\\text{int}}$: $$T = \\frac{\\frac{1}{2} m\\bar{v}^2}{\\frac{3}{2}k_B} = \\frac{2}{3} \\cdot \\frac{E_{\\text{int}}}{N k_B} \\Longrightarrow PV = \\frac{2}{3}E_{\\text{int}}$$ $$E_{\\text{int}} = N\\cdot \\frac{1}{2}m\\bar{v}^2 \\Longrightarrow PV = \\frac{Nm}{3}\\bar{v}^2 $$ Which shows us that .$(P,V)$ is a representation of (kinetic) energy!  We can think of any point on a .$PV$ diagram in terms of energy    Absolute 0 #    Before, we said .$T = 0K$ exists when .$P = 0$\n  Now we can also see that .$KE = 0$ when .$T = 0$ as well. This would mean that at absolute 0, there is no particle movement\n  We can then write an equation for the root-mean-square (or RMS): $$\\overline{K} = \\frac{3}{2}k_B T \\Longrightarrow \\frac{1}{2}m\\bar{v}^2 = \\frac{3}{2}k_B T;\\ v_{\\text{rms}} = \\sqrt{\\bar{v}^2} = \\sqrt{3k_B\\frac{T}{m}} = \\sqrt{3 R\\frac{T}{M}} $$ $$\\bar v ^2 = \\frac{1}{N}\\sum_i^N n_i v_i^2 \\Longrightarrow v_{\\text{rms}} = \\frac{1}{\\sqrt N} \\sqrt{\\int_0^\\infty n(v)\\cdot v^2 dv} $$\n This is the typical velocity of particles that make up the gas/liquid .$M$ is the molar mass of the gas [kilograms per mole] .$v_{\\text{rms}}$ is also called the thermal velocity, .$v_{\\text{th}}$ Fun fact: Less than 1% of particles of particles exceed .$v_{\\text{rms}}$ Example problems:  If a sample is quasistatically shrunk to half it\u0026rsquo;s original volume with no change in pressure, the new root-mean-square speed is .$1/\\sqrt{2}$ times the original rms speed If we double the root-mean-square speed (thermal speed) of the molecules of a gas, then its temperature must increase by a factor of 4      18.2 Distribution of Molecular Speeds #   $$f(v) = 4\\pi N \\bigg( \\frac{m}{2 \\pi k_B T}\\bigg)^{3/2} v^2 e^{ -\\frac{1}{2} \\cdot \\frac{mv^2}{k_B T}}$$   Recognize that .$f(v) \\propto T^{-3/2}, v^2$ and exponentially .$\\propto KE/T$  If .$T$ increases, so does .$KE$ and .$v$ thus variance .$\\sigma^2$ increases and the distribution becomes \u0026ldquo;stretched\u0026rdquo; (lower max, thicker tail) Spread of important values (.$v_p, v_{\\text{avg}}, \\text{etc.}$) are spread out further from one another Area stays constant (always equal to .$N$)   .$f(v)\\ dv$ represents the number of molecules with .$v \\in [v, v+dv]$  That is, .$\\int_0^\\infty f(v) dv = N$   .$\\sigma^2$ is the variance, or standard deviation squared, which can be found from the equation .$\\langle v^2 \\rangle - \\langle v \\rangle ^2$ Chemical Reactions  Some reactions only occur at a certain energy levels (activation energy) Warmer conditions lead to faster moving particles which have energy That\u0026rsquo;s why reaction speed .$\\propto$ temperature    Important Values #  $$v_p = 1.41 \\sqrt{k_B\\frac{T}{m}}$$  $$v_{\\text{avg}} = 1.60 \\sqrt{k_B\\frac{T}{m}}$$  $$v_{\\text{rms}} = \\sqrt{3 k_B \\frac{T}{m}}$$    Notice how .$v \\propto m^{-1/2}$, which explains why it\u0026rsquo;s easier for lighter particles to escape earth\u0026rsquo;s atmosphere!  18.3 Real Gases and Phase Changes #    (a) Each curve represents the relationship between .$P$ and .$V$ at a fixed temperature; the upper curves are at higher temperatures. The lower curves are not hyperbolas, because the gas is no longer an ideal gas. (b) An expanded portion of the diagram for low temperatures, where the phase can change from a gas to a liquid.\n  Phase changes can only be explained if we\u0026rsquo;re considering the behavior of a real \u0026ndash; not ideal \u0026ndash; gas  This is because phase changes involve intermolecular bonds which we only factor in when considering real gases   At high enough pressures, gases take up less volume than expected.  This effect is magnified with lower temperatures   At lower temperatures, the .$PE$ attractive forces between particles aren\u0026rsquo;t negligible with respect to .$KE$ At the critical points (when .$PV$ curve is horizontal), gases may no longer change to liquid under any pressure  This point varies by substance Gas below the critical point is vapor Gas above the critical point is just gas   Sublimation: When substance changes from solid to gas, skipping liquefaction step     Ideal gases would have a straight line along a .$PV/nRT \\text{ vs } P$ graph Real gases vary don\u0026rsquo;t follow this line and deviate from it proportional to their molecule size and weight (resulting in higher .$a$ and .$b$ values respectively \u0026ndash; see 18.5)  18.4 Vapor, Pressure, and Humidity (not covered) #  Evaporation #   Molecules in liquid are held tightly together with intermolecular attractive forces (covalent hydrogen bonds) Some molecules may momentarily leave the liquid if their velocity is fast enough  If velocity isn\u0026rsquo;t too large, then the particle will be pulled back to the liquid surface If velocity is large enough, then the particle will break the intermolecular bonds and leave the liquid to enter their gas form  Low probability of occurring     Because .$v_{\\text{particle}} \\propto T$, the .$\\text{evaporation rate} \\propto T$ As fast moving (thus hot) particles leave the liquid, the liquid\u0026rsquo;s temperature decreases  That is, evaporation is a cooling process    Vapor Pressure #   A typical phase diagram. The solid green line applies to most substances; the dashed green line gives the anomalous behavior of water\n Green line = SL Line; transition between solid .$\\iff$ liquid (melting/freezing) Red line = SV; transition between solid .$\\iff$ vapor (sublimation/deposition) Blue line = LV; transition between liquid .$\\iff$ vapor (vaporizing/condensing)        When evaporation particles go from gas to liquid, it\u0026rsquo;s called condensation The number of particles in vapor increases until the rate of particles condensing is equal to the number of particles becoming vapor (equilibrium!)  When this state is reached, the space above the water is considered saturated Pressure of vapor saturation is called (saturated) vapor pressure   Saturated Vapor Pressure varies with the volume of container  If volume above the liquid was reduced, then the density would increase so particles would condense back to liquid Assuming .$T$ is constant, vapor pressure would stay constant too   Since at high temperatures there are more particles (entering/already in) the vapor phase, higher pressure is required for equilibrium When the volume is large, it\u0026rsquo;s likely that all the liquid evaporates before equilibrium  Boiling #   Boiling occurs when saturated vapor pressure equals external pressure Bubbling forms as temperature approaches boiling temperature  If the pressure in the bubbles are less than the external pressure, the bubbles are crushed Otherwise, bubbles are able to rise to surface   Boiling point is proportional to pressure  Lower pressure = lower temperature required for boiling point    Partial Pressure and Humidity #   In gases composed of multiple other gases, the total pressure is the sum of all partial pressures for each of other sub gas Partial Pressure is the pressure a single gas would exert by itself  The partial pressure of water in the air can be as low as zero and vary up to a maximum equal to the saturated vapor pressure (of water at the given temperature)   Relative Humidity: ratio of partial pressure of water vapor to the saturated vapor pressure at a given temperature $$\\text{Relative Humidity} = \\frac{\\text{partial pressure of }H_2O}{\\text{saturated vapor pressure of }H_2O} \\cdot 100\\%$$ Super Saturation: .$P_{\\text{partial}} \u0026gt; P_{\\text{saturated vapor pressure}}$  Happens when temperature decreases Excess water condenses as dew / mist    18.5 Van der Waals Equation of State #  Microscopic (molecular) view accounts for\u0026hellip;\n Finite size of molecules (before we assumed separation .$\\gg$ diameter, ignoring density)  Since gas particles aren\u0026rsquo;t negligible in size, we can\u0026rsquo;t use all of our volume Particles are solid spheres that can\u0026rsquo;t get closer than .$2r$ to one another  That means .$V$ is over-estimated: .$V_{\\text{real}} \u0026lt; V_{\\text{ideal}}$ Lower volume mean more collisions, leading to pressure being higher than estimated with the ideal gas law: .$P_{\\text{real}} \u0026gt; P_{\\text{ideal}}$   The unavailable volume due to particles, .$b$, depends on the .$n$umber of moles $$ P(V-nb) = nRT \\Longrightarrow P\\bigg(\\frac{V}{n} - b\\bigg) = RT\\ \\ \\ \\big[\\text{Clausius Equation of State}\\big]$$ Where .$b$ is the volume consumed by 1 mol of gas with the units .$\\text{V/mols}$   Forces between molecules (before we assumed that forces only played an effect in collisions)  At low .$T$, electric attractive forces aren\u0026rsquo;t 0  Particles towards the edge are slowed down by the other particles attractive forces For that reason, our pressure is lower than estimated with the ideal gas law: .$P_{\\text{real}} \u0026lt; P_{\\text{ideal}}$   On the contrary, with higher temperatures gases appear more ideal because .$KE$ is greater than the intermolecular .$PE$ \u0026ldquo;Slow down\u0026rdquo; is proportional to the gas density  M ore dense means more molecules means more intermolecular forces   Pressure reduced by the following equation where .$n/V$ is the gas density and .$a$ is a constant unique to the gas that measures the attractive forces between particles $$ a\\bigg( \\frac{n}{V}\\bigg)^2$$ .$a \\propto m$ and boiling point because the lower the boiling point, the less energy is required to break the internal bonds     Thus, we can rewrite the ideal gas law with the last two equations as $$ \\bigg(P+ \\frac{a}{(V/n)^2}\\bigg)\\bigg(\\frac{V}{n} - b\\bigg) = RT \\ \\ \\big[\\text{Van der Waals Eq of State}\\big]$$  Note that these equations aren\u0026rsquo;t accurate in all cases, but they\u0026rsquo;re the best generalization we can do and they show the relation With low densities, .$a\\big/(V/n)^2 \\ll P$ and .$b \\ll V/n$ so Van der Waals equation reduces to the ideal gas law    18.6 Mean Free Path #   Molecules bump into each other a lot which slow them down Mean free path: Average distance between collisions is proportional to .$\\rho ^{-1}, r^{-1}$ $$l_m = \\frac{1}{4\\pi \\sqrt{2}r^2 (N/V)}$$  18.7 Diffusion (not covered) #   Particles diffuse from high to low concentrations until equilibrium is reached (when .$\\rho$ is constant throughout) Given a tube with a cross section area .$A$, two concentrations, .$C_1$ and .$C_2$, separated by .$\\Delta x$, we can write the rate of diffusion, .$J$, as $$J = DA \\frac{C_1 - C_2}{\\Delta x} = DA \\frac{dC}{dx} \\ \\ \\text{[Fick\u0026rsquo;s Law]}$$ .$D$ is the diffusion constant  Varies with temperature, viscosity, and particle size    "},{"id":35,"href":"/physics-7b/19/","title":"19: Heat \u0026 First Law of Thermo","section":"Physics 7B","content":"   \\(\\)  19.1 Heat as Energy Transfer #  Units #   Heat unit is calorie (cal)  The amount of heat needed to raise the temperature of 1 gram of water by 1 celsius $$4.186 \\text{ J} = 1 \\text{ cal}$$   Kilocalorie (kcal, Calorie) is more common  Amount of heat needed to raise 1 kg of water by 1 celsius $$4.186 \\text{ kJ} = 1 \\text{ kcal}$$      British system of units has British thermal units (Btu)  One Btu is the heat needed to raise the temperature of 1 lb of water by 1 Fahrenheit $$1 \\text{ Btu} = 0.252 \\text{ kcal} = 1056 \\text{ J}$$ Gas companies use the unit therm: .$10^5 \\text{ Btu}$      Heat #   Heat is energy transferred from one object to another because of a difference in temperature.  Energy transfers from hot to cold object until equilibrium   The SI units for heat is the joule: this is because heat is a form of energy!  19.2 Internal Energy #   Internal Energy: The sum of all the energy of all the molecules in an object  Sometimes called thermal energy    Difference between Temp, Heat, and Internal Energy #   Temperature is the average kinetic energy of all of the molecules Internal energy is the sum of the energy of all of the molecules  E.x. Two equal-mass iron ingots could the same temperature as a single ingot, but the two would have double the internal energy   Heat refers to the transfer of energy from one object to another due to a difference in temperatures  Direction of transfer depends on temperature, not internal energy E.x. .$50\\text{ g}$ of .$30^\\circ\\text{ C}$ water mixed with .$200 \\text{ g}$ of .$25^\\circ \\text{ C}$ water results with heat transferring from the smaller sample with less internal energy to the larger sample with more internal energy.    Calculating Internal Energy #   Internal energy is the sum of all the translational kinetic energy of the molecules in a monatomic gas  Monatomic: Gas with one atom per molecule   We can re-write this as the average KE per molecule times the total number of molecules, .$N$ $$E_{\\text{int}} = N \\bigg(\\frac{1}{2}m\\bar{v}^2\\bigg) = \\frac{3}{2}Nk_B T = \\frac{3}{2}nRT$$ We can see that internal energy for a monatomic gas depends only on the temperature and number of moles If a gas isn\u0026rsquo;t monatomic, then we need to consider the rotational and vibrational energy of the molecules  Non-monatomic gasses result in a internal energy at a given temperature compared to a monatomic   The internal energy of real gases depends mainly on temperature  There are some exceptions of gases depending on pressure and volume as well   Internal energy of liquids and solids is more complex  It includes electric potential energy of the chemical bonds    19.3 Specific Heat #   Amount of heat required to change the temperature of a material is found with the following: $$\\Delta Q = mc \\Delta T$$  .$c$ specific heat capacity that depends on the material .$[\\text{J}/(\\text{C}^\\circ\\text{ kg})]$   For water at .$15 ^\\circ \\text{ C}$ and constant pressure .$1 \\text{atm}$, .$c = 4168 \\text{ J}/(\\text{C}^\\circ\\text{ kg}) = 1.00 \\text{ kcal}/(\\text{C}^\\circ \\text{ kg})$  .$c$ does vary to some extent with temperature (and slightly pressure), but for small .$\\Delta T$ we can say .$c$ is a constant   Relative to other materials/substances, water has a high specific heat capacity  19.4 Calorimetry #  Types of Systems #   System: Any (set of) object(s) we choose to consider Closed System: Mass is constant, but energy may be exchanged within environment  Isolated: If no energy in any form passes across its boundaries We idealize systems to be closed systems, which is rare in the real world Heat will flow from hot to cold region of system until equilibrium We can assume that no energy is lost; heat lost in one part = heat gained in another part or .$\\Sigma Q = 0$   Open System: Mass and energy may enter/leave  Calorimeter #   Calorimetry: Quantitative measure of heat exchange Calorimeter tend to have insulation so that no heat is exchanged with the surrounding air Often use thermometer to measure change the temperature E.x. a substance sample will be heated up, measured, then quickly placed inside cool water of calorimeter  The heat lost from the sample will be gained by the water and the calorimeter cup Measuring final temperature of the mixture lets us calculate the specific heat   Assume that small masses like the thermometer/stirrer are negligible  19.5 Latent Heat #   Change of Phase: When a material changes from solid to liquid or liquid to gas.  A certain energy is required for a phase change During phase changes, temperature stops increasing and all energy goes into the phase change Latent heat is lost during phase change (often in the form of heat) Heat of fusion  .$L_F$: Heat required to change .$1.0 \\text{ kg}$ of a substance from solid to liquid state Heat fusion of water is .$79.7 \\text{kcal/kg} = 333 \\text{kJ/kg}$   Heat of Vaporization  .$L_V$: Heat required to change a substance from liquid to vapor phase Heat vaporization is .$539 \\text{kcal/kg} = 2260 \\text{kJ/kg}$      Heat involved in the phase change depends on the mass and latent heat: $$\\Delta Q = mL$$ Therefore, when considering the change in a system involving heating a substance to a phase change (e.g. boiling at temperature .$T$), we can write: $$\\Delta Q_{\\text{total}} = m_L c \\Delta T + m_S L$$  .$m_L$ is the total mass of the substance before the phase change (e.x. initial mass of substance, don\u0026rsquo;t subtract amount that vaporized) .$m_S$ is the mass of the substance that underwent a phase change (e.x. mass that vaporized)    Evaporation #   Heat of Vaporization of water increases slightly with a decrease in Temperature At .$20^\\circ \\text{ C}$, it\u0026rsquo;s .$585 \\text{ kcal/kg}$ When liquid evaporates, the remaining liquid cools because the heat/energy comes from the water itself Therefore, internal energy decreases with evaporation  Kinetic Theory of Latent Heats #   At melting point, the latent heat of fusion doesn\u0026rsquo;t increase the average KE / temperature Rather, the energy goes into overcoming the PE associated with the forces between the molecules  Once the molecules in a solid are broken from there lattice formation, they can freely roll over one another as a liquid   More energy is required for liquid to gas phase because the average distance between the molecules is greatly increased  The larger the distance that the molecules have to be separated, the more work has to be done to pull them apart    19.6 First Law of Thermo #   Heat and work are different  Heat is the transfer of energy due to a difference in temperature \u0026ndash; hot/cold bath around gas chamber Work is the transfer of energy not due to a temperature difference \u0026ndash; piston applying force to a gas   Internal energy and temperature are both proportional to heat and work though with the First law equation: $$\\Delta E_{\\text{int}} = Q - W = E_{\\text{int, 2}} - E_{\\text{int, 1}} \\ \\ \\ \\text{[First Law of Thermo.]}$$  .$W$ is net work done by the system  Work done by system is .$\\texttt{+}$ Work done on the system is .$\\texttt{-}$ Gas expands .$\\Longrightarrow$ sys looses energy      .$Q$ is net heat added to the system  Heat added is .$\\texttt{+}$ Heat lost is .$\\texttt{-}$ Gas is heated .$\\Longrightarrow$ sys gains energy       .$Q$ and .$W$ are not state variables in that a static state doesn\u0026rsquo;t have \u0026ldquo;heat\u0026rdquo; or \u0026ldquo;work\u0026rdquo; \u0026ndash; only when the system changes through thermodynamic process can we measure heat/work.  This is unlike .$P, V, T$ and .$E_{\\text{int}}$ which are state variables (can be measured at all states)   We can also extend the first law to include systems that have KE and PE: $$\\Delta K + \\Delta U + \\Delta E_{\\text{int}} = Q - W = E_{\\text{int, 2}} - E_{\\text{int, 1}}$$  19.7 Thermodynamic Process and the 1st Law #  Isothermal Process (.$\\Delta T = 0$) #    When temperature is constant, .$PV$ is constant too Each label of points in the graph above represent the systems states (it\u0026rsquo;s pressure and temperatures) Isotherms: curves in PV diagram  At a lower temperature, an isothermal process would be represented by the isotherm .$A\u0026rsquo;B'$   We also assume that the container is a heat reservoir: a body whose mass is so big that the temperature doesn\u0026rsquo;t change when heat is exchanged We increase internal energy by doing work, such as by decreasing the volume of the container with by applying a force to a piston over some distance  We assume that expansion/compression is  quasistatic: we decrease the volume slow enough that we can consider it a series of equilibrium states all at the same temperature   E.x. if we started with state .$A$ and added heat .$Q$ to the system, the system would reach point .$B$  If .$T$ remain constant, the volume will expand, both doing work .$W$ on the environment and decreasing the .$P$ We know .$E_\\text{int} = \\frac{3}{2}nR\\Delta T$, and since .$\\Delta T = 0 \\Longrightarrow E_\\text{int} = 0$ Thus, .$E_\\text{int} = Q - W \\Longrightarrow W = Q$    $$$$ $$$$ $$W = \\int_{V_A}^{V_B} P \\ dV$$ $$\u0026hellip; = nRT \\int_{V_A}^{V_B} \\frac{dV}{V}$$ $$\u0026hellip; = nRT \\ln{\\frac{V_B}{V_A}}$$    Adiabatic Process (.$\\Delta Q = 0$) #   No heat allowed to flow in our out of system. This can happen if\u0026hellip;  Process happens so quickly that heat, a slow process, has no time to flow in/out  E.x. a combustion engine happens quickly it\u0026rsquo;s nearly adiabatic   System is well insulated   If a system experiences an adiabatic process slowly, it will look similar to curve .$AC$ Since .$Q = 0 \\Longrightarrow \\Delta E_\\text{int} = -W$ In a reverse processes represented by .$CA$ (adiabatic compression), work is done on the gas so .$E_\\text{int}$ and .$T$ rise    $$$$ $$$$ $$W = \\int_{V_A}^{V_B} P \\ dV$$ $$\u0026hellip; = P_A V_A ^\\gamma \\int_{V_A}^{V_B} \\frac{1}{V^\\gamma}\\ dV$$ $$\u0026hellip; = \\frac{P_A V_A - P_B V_B}{1-\\gamma}$$   19.9 Adiabatic Expansions #   The .$PV$ curve for adiabatic expansion (.$Q = 0$) is slightly less steep than isothermal processes (.$\\Delta T = 0$)  This means that for the same change in volume, the pressure will be greater in adiabatic processes Therefore, the temperature of a gas must drop in adiabatic expansion and rise in adiabatic compression Likewise, if during an adiabatic process the volume increases then the internal energy must decrease   We can relate .$P$ and .$V$ for a quasistatic expansion / compression with $$PV^\\gamma = \\text{[constant] for } \\gamma = \\frac{C_P}{C_V} = 1 + \\frac{R}{C_V}$$ \u0026hellip;which can also be written as the following (with .$d$ = degrees of freedom) $$T_A^{C_V/R} V_A = T_B^{C_V/R} V_B$$  $$C_V = \\frac{d}{2}R$$  $$C_P = \\frac{d+2}{2}R$$  $$\\gamma = \\frac{d+2}{d}$$     Free Expansion #   A type of adiabatic process where gas is allowed to expand in a volume without doing any work Must be done with insulated containers so that no heat is able to flow in/out; .$Q = 0$ No work is done either because no object is moved; .$W = 0$ Thus, .$\\Delta E_\\text{int} = 0$ and .$\\Delta T = 0$ In reality, we see temperature slightly drops meaning internal energy does depend on pressure or volume as well as temperature.  Isobaric and Isovolumetric .$(\\Delta P = 0, \\Delta V = 0)$ #     Isobaric: .$\\Delta P = 0 \\Longrightarrow Q = \\Delta E_\\text{int} + W = \\Delta E_\\text{int} + P\\Delta V$. The heat transferred to the system does work, but also changes the internal energy of the system  Isovolumetric: .$\\Delta V = 0 \\Longrightarrow W = 0 \\Longrightarrow Q = \\Delta E_\\text{int}$. The thermodynamic process is the addition or removal of heat. First law of thermo holds for both of these processes  $$$$ $$$$ $$W_{\\text{Isovol.}} = 0$$ $$W_{\\text{Isobaric}} = \\int_{V_A}^{V_B} P \\ dV$$ $$\u0026hellip; = P \\Delta V$$ $$\u0026hellip; = P_B(V_B - V_A)$$ $$\u0026hellip; = nRT_B(1 - \\frac{V_A}{V_B})$$     Work done in volume changes .$(\\Delta V \\neq 0)$ #   For quasistatic processes: $$dW = \\vec{F} \\cdot d\\vec{l} = PA d\\vec{l} = P\\ dV \\ \\ \\ \\text{(1)}$$ $$W = \\int dW = \\int_{V_A}^{V_B} P\\ dV \\ \\ \\ \\text{(2)}$$ .$\\text{(1)}$ Where .$F = PA$ is the force the gas exerts on the piston and .$d\\vec{l}$ is the (small) distance the piston moves .$\\text{(2)}$ This shows that the work done is the area under the .$PV$ curve  This equations are valid for work done in any volume change (solid, liquids, gas)   .$W$ (and even .$Q$) depends on the initial and final states and also on the process (or path)  19.8 Molar Specific Heats for Gases and Equipartition of Energy #  Molar Specific Heat #   Specific heat for gases depends heavily on the process and how it\u0026rsquo;s carried out Specific heat for constant pressure and constant volume vary We use molar specific heat for gases: .$C_V$ and .$C_P$ which are defined as the heat required to raise .$1 \\text{ mol}$ of gas by .$1^\\circ \\text{ C}$ at a constant volume or pressure respectively. We then use .$n$ instead of .$m$ in our heat equations: $$\\Delta Q = nC_V \\Delta T = mc_V \\Delta T\\ \\ \\ \\text{[Constant Volume]}$$ $$\\Delta Q = nC_P \\Delta T = mc_P \\Delta T\\ \\ \\ \\text{[Constant Pressure]}$$ which we can then relate to the specific heat with .$M$ as the molecular mass of the gas, .$m/n$ in grams/mol: $$C_V = Mc_V$$  $$C_p = Mc_p$$    In a heating process, when .$\\Delta V = 0$ then the heat added, .$Q_V$ goes entirely into internal energy: .$Q_V = \\Delta E_\\text{int}$ However, when pressure is constant work is done. Thus, heat added, .$Q_P$, goes towards increasing internal energy and work: .$W = P\\Delta V$  Therefore, more heat is needed for a constant pressure system: .$Q_P = \\Delta E_\\text{int} + P\\Delta V$   Since .$\\Delta E_\\text{int}$ is the same for both processes, we can write .$Q_P - Q_V = P \\Delta V$  With an ideal gas, we know .$V = nRT/P$ so .$\\Delta V = nR\\Delta T/P$ which we can combine with the prior equations to get: $$nC_P\\Delta T - nC_V \\Delta T = P\\bigg(\\frac{nR\\Delta T}{P}\\bigg) \\Longrightarrow C_P - C_V = R$$   We can also relate internal energy to molar specific heat for gases at constant volumes: $$\\Delta E_\\text{int} = Q_V \\Longrightarrow \\frac{\\text{[Deg. of Freedom]}}{2}nRT = nC_V\\Delta T \\Longrightarrow C_V = \\frac{3}{2}R$$ We can then plug in our new value for .$C_V$ into the second to last equation .$C_P - C_V = R$ to get .$C_P = \\frac{5}{2}R$ for a monatomic gas. We can also combine our equations to write a relation between internal energy and temperature again: $$\\Delta E_\\text{int} = nC_V \\Delta T$$  Equipartition of Energy #    Degrees of Freedom: The number of independent ways a molecule can posses energy  Degrees of freedom depend on the temperature At low temperatures, the only degree of freedom is from translational .$KE$  Starting after .$0K$ Diatomic gas: .$C_V = \\frac{3}{2}R$ (3 for each axis) Sum of .$\\frac{1}{2}m \\langle v_x, v_y, v_z \\rangle$   At \u0026ldquo;regular\u0026rdquo; temperatures, the molecules posses rotation energy  Around .$50K$ Diatomic gas: .$C_V = \\frac{5}{2}R$ Sum of .$\\frac{1}{2}I \\langle 0, \\omega_y, \\omega_z \\rangle$ (since it\u0026rsquo;s rotating about .$\\hat x$ meaning .$E_{\\text{rotational, }x}) = 0$   At higher temperatures, the molecules gain energy associated with their vibrations:  Around .$1000K$ One from KE of the molecules vibrating back and forth: .$\\frac{1}{2}mv_{\\text{COM}}^2$ The second from PE of the vibrational motion (think of this as a spring\u0026rsquo;s PE): .$\\frac{1}{2}kx^2$   Solids:  The molar temperature of solids at high temperatures is close to .$3R$. At high temperatures, there are six degrees of freedom: three from vibrational KE in the .$x, y,$ and .$z$ axis and three more from spring PE in the same axis Some of these degrees of freedom aren\u0026rsquo;t active at lower temperatures     Principle of Equipartition of Energy: Energy is shared equally among degrees of freedom and each degrees has energy .$\\frac{1}{2}k_B T$  Thus, for a particle with three degrees of freedom (such as a monatomic gas) .$C_V = \\frac{3}{2}R$ Diatomic gases have five degrees so they have .$C_V = \\frac{5}{2}R = 4.97 \\text{ cal/(mol K)}$ and have .$E_\\text{int} = N(\\frac{5}{2}k_B T) = n C_V \\Delta T = \\frac{5}{2}nRT$ where .$n$ is the number of moles and .$N$ is the number of molecules    19.10 Heat Transfer #  Conduction #   Heat transfer by contact Conduction can be visualized thinking of molecular collisions  The hot end of an object has fast moving molecules These molecules bump into other molecules, transferring them some of their own KE This keeps repeating down the object   Free electrons are the primary source of these collisions Heat conduction only occurs when there is a difference in temperatures Heat conduction rate is proportional to the difference in temperatures: $$\\frac{\\Delta Q}{\\Delta t} = - kA\\frac{T_1 - T_2}{l}$$ Where .$A$ is the cross section area, .$l$ is the distance between the two ends, and .$k$ is a constant called thermal conductivity that depends on the material  Good insulator / poor thermal conductors have a low .$k$  Metals have .$k\u0026gt;1$ Wood, plastics have small .$k$s   Building materials sometimes list the thermal resistance, .$R$, which is equal to .$R = \\frac{l}{k}$ where .$l$ is the material\u0026rsquo;s thickness  Larger .$R$ means better insulation     If .$k$ or .$A$ isn\u0026rsquo;t constant, we consider a small thickness: $$ \\frac{dQ}{dt} = -kA \\frac{dT}{dx}$$ .$\\frac{T_1 - T_2}{l} \\text{ and } \\frac{dT}{dx}$ are called the temperature gradients We have a negative sign in the equation above because the direction of heat flow is opposite to the temperature gradient A steady system state is reached when heat flow through each layer of an object is equal  Convection #   Heat flow by movement of mass Convection involves heat flowing by the bulk movement of molecules from one place to another Whereas conduction involved molecules/electrons moving over small distances, convection involves the movement of a large number of molecules over a long distance Natural Convection occurs in systems where a cold substance (air, water) is warmed and subsequently expands, decreasing density and thus rising Warm fluid/gases are less dense, thus they rise compared to colder fluid/gas  Radiation #   Whereas conduction and convection require a medium, radiation doesn\u0026rsquo;t  The sun\u0026rsquo;s rays are a form of heat and travel through (nearly empty) space  Radiation of the sun\u0026rsquo;s rays arrive on a clear day at a rate around .$1000 \\text{W/m}^2$   Most of the time radiation consists of electromagnetic waves, but infrared (IR) wavelengths are responsible for heating Earth   The rate at which energy leaves a radiation object, .$Q/t$, is $$ \\frac{\\Delta Q}{\\Delta t} \\varepsilon \\sigma A T^4$$  .$\\varepsilon$ is called emissivity.  Between 0 and 1 Characteristic of the surface of the radiating material Black surfaces close to one, shiny metal surfaces close to zero Depends slightly on the temperature of the material A good absorber is also a good emitter  A black tee shirt gets very hot because it absorbs nearly all the radiation that hits it     .$\\sigma$ is the Stefan-Boltzmann constant: .$\\sigma = 5.67 \\cdot 10^{-8} \\text{ W/(m}^2 \\text{K}^4\\text{)}$   Objects also absorb heat of surrounding objects. This net heat flow can be found by $$ \\frac{\\Delta Q}{\\Delta t} \\varepsilon \\sigma A (T_1^4 - T_2^4)$$  Where .$T_1$ is the object\u0026rsquo;s temperature and .$T_2$ is the surrounding environment\u0026rsquo;s temperature .$T_1 \u0026gt; T_2$: net flow of heat is from object to the surroundings .$T_1 \u0026lt; T_2$: net flow of heat is from surroundings into object, raising the object temperature    "},{"id":36,"href":"/physics-7b/20/","title":"20: Second Law of Thermo","section":"Physics 7B","content":"20.1 Intro #   Second law states that systems only increase in entropy over time That is, most systems are on directional  E.x. mixing salt and pepper together result in an mixture. No matter how much you keep mixing it, they won\u0026rsquo;t naturally separate and return to the initial state even though it follows first law of thermo (conserving energy)   (Specific) Second Law of Thermo  Heat can flow spontaneously from a hot object to a cold object; heat will not flow spontaneously from a cold object to a hot object.\n   20.2 Heat Engines #   Heat Engine: Any device that changes thermal energy into mechanical work, such as steam or car engine  Show importance in developing the second law of thermo   Mechanical energy can only be obtained from thermal energy when heat is allowed to flow from high temp to low temp  During this process, some of the heat can be transformed to mechanical work   Heat engines run in a repeating cycle: the system returns repeatedly to its starting point and thus can run continuously   In each cycle .$\\Delta E_{\\text{int}} = 0$ because it returns to the initial state Thus, heat input .$Q_H$ at a .$T_H$ is partly transformed into work .$W$ and partly exhausted as heat .$Q_L$ at .$T_L$ By conservation of energy, .$Q_H = W+Q_L$. Operating Temperatures: The high and low temperatures, .$T_H, T_L$ .$Q_H, Q_L, W \u0026gt; 0$       Change in temperature is required for a change in pressure  Gas exhaust is cooled to a lower temperature and condensed so that the exhaust pressure is less than intake pressure Thus, the work the piston must do on the gas to expel it is less than the work done by the gas on the piston during the intake    20.3 (Ir)reversible Processes; Carnot Engine #   Carnot engine is ideal: doesn\u0026rsquo;t take into account turbulence in gas, friction, etc. Consist of four processes done in a cycle  Isothermal expansion (.$\\Delta T = 0$) with the addition of heat .$Q_H$ along path .$ab$ at temperature .$T_H$ Adiabatic expansion (.$Q = 0$) lowering temperature to .$T_L$ along path .$bc$ Isothermal compression (.$\\Delta T = 0$) leads to heat .$Q_L$ flowing out along path .$cd$ Adiabatic compression (.$Q = 0$) occurs path .$da$, returning to temperature .$T_H$   Each process is reversible; that is, each occurs infinitely slowly so that the process could be considered a series of equilibrium states  Real processes are irreversible      Work done in a cycle is proportional to area enclosed by the curve representing the cycle on a .$PV$ diagram (.$abcd$) Efficiency is given by .$e = 1-\\frac{Q_L}{Q_H} \\Longrightarrow e_{\\text{ideal}} = 1 - \\frac{T_L}{T_H}$ Carnot\u0026rsquo;s Theorem:  All reversible engines operating between the same two constant temperatures .$T_H$ and .$T_L$ have the same efficiency. Any irreversible engine operating between the same two fixed temperatures will have an efficiency less than this.\n  Only at absolute zero would 100% efficiency be reachable. But getting to absolute zero is a practical (as well as theoretical) impossibility Kelvin-Planck statement of the second law of thermodynamics:  no device is possible whose sole effect is to transform a given amount of heat completely into work.\n   20.4 Refrigerators, AC, Heat Pumps #   Refrigerators, air conditioners, and heat pumps are just the reverse of heat engines  Each transfer heat ouf of a cool environments into a warm environment   A perfect fridge (no work required to take heat from low temp to high temp) is impossible  No device is possible whose sole effect is to transfer heat from one region at a temperature .$T_L$ into a second region at a higher temperature .$T_H$ (Clausius statement)\n         Coefficient of Performance (COP): .$\\text{COP} = \\frac{Q_L}{W}$\n The more heat .$Q_L$ removed from a fridge for a given amount of work, the more efficient it is Energy is conserved, so we can write .$Q_L + W = Q_H$ or .$W = Q_H-Q_L$ We can then write .$\\text{COP} = \\frac{Q_L}{W} = \\frac{Q_L}{Q_H-Q_L} \\Longrightarrow \\text{COP}_{\\text{ideal}} = \\frac{T_L}{T_H-T_L}$    Heat pump\n Electric motor does work .$W$ to take heat .$Q_L$ from outside at low temperature and delivers heat .$Q_H$ to inside at a hot temperature Whereas fridges cool (remove .$Q_L$), heat pumps heat (deliver .$Q_H$) Thus, COP uses .$Q_H$ instead of .$Q_L$: .$\\text{COP} = \\frac{Q_H}{W}$ COP is greater than 1 because .$W+Q_L = Q_H$     20.5 Entropy #   Entropy, unlike heat, is a state variable and measures the (dis)order of a system When heat is added to a system by a reversible process then change in entropy is $$\\Delta S = \\frac{Q}{T} \\ \\ \\text{[Constant T]} \\Longrightarrow dS = \\frac{dQ}{T} \\ \\ \\text{[Non-const T]}$$ The change of entropy between two states doesn\u0026rsquo;t depend on the process. Thus, $$\\Delta S = S_b - S_a = \\int_a^b dS = \\int_a^b \\frac{dQ}{T}$$  20.6 Entropy and Second Law #   In an isolated system with two objects that eventually reach equilibrium, we can write the change (increase) in entropy as $$\\Delta S = \\Delta S_H + \\Delta S_L = - \\frac{Q}{T_{HM}} + \\frac{Q}{T_{LM}}$$ .$T_{HM}$ is the average temperature between .$T_H$ and .$T_M$ where .$T_M$ is the average between .$T_H$ and .$T_L$  E.x. if .$T_H = 0^\\circ C, T_L = 0^\\circ C$, then .$T_M = 4^\\circ C$ so .$T_{HM} = 6^\\circ C$ and .$T_{LM} = 2^\\circ C$. Also, we use .$Q = mc \\Delta T$ to find heat and use half .$T_{M}$ (in this case .$4^\\circ C$) for .$\\Delta T$ Since .$T_{HM} \u0026gt; T_{LM}, \\Delta S \u0026gt; 0$ is always true While one system may decrease in entropy, the other one always increases more so net always increases   For adiabatic processes, we know .$dQ = dW = P dV$, thus $$\\Delta S_\\text{gas} = \\int \\frac{dQ}{T} = \\frac{1}{T} \\int_{V_1}^{V_2} P\\ dV$$ and since we know through the idea gas law that .$P = nRT/V$ so $$\u0026hellip;= \\frac{1}{T} \\int_{V_1}^{V_2} \\frac{nRT}{V}\\ dV = nR \\ \\ln \\bigg(\\frac{V_2}{V_1}\\bigg)$$  20.7 Order to Disorder (not covered) #   If we say that entropy is a measure of (dis)order in a system, we can write the second law as  Natural processes tend to move toward a state of greater disorder\n  When ice melts to water at 0°C, the entropy of the water increases.  Intuitively, we can think of solid water, ice, as being more ordered than the less orderly fluid state which can flow all over the place. This change from order to disorder can be seen more clearly from the molecular point of view: the orderly arrangement of water molecules in an ice crystal has changed to the disorderly and somewhat random motion of the molecules in the fluid state.   When a hot substance is put in contact with a cold substance, heat flows from the high temperature to the low until the two substances reach the same intermediate temperature.  At the beginning of the process we can distinguish two classes of molecules: those with a high average kinetic energy (the hot object), and those with a low average kinetic energy (the cooler object). After the process in which heat flows, all the molecules are in one class with the same average kinetic energy; we no longer have the more orderly arrangement of molecules in two classes \u0026ndash; Order has gone to disorder Furthermore, the separate hot and cold objects could serve as the hot and cold-temperature regions of a heat engine, and thus could be used to obtain useful work. But once the two objects are put in contact and reach the same temperature, no work can be obtained. Disorder has increased, because a system that has the ability to perform work must surely be considered to have a higher order than a system no longer able to do work.   When a stone falls to the ground, its macroscopic kinetic energy is transformed to thermal energy.  Thermal energy is associated with the disorderly random motion of molecules, but the molecules in the falling stone all have the same velocity downward in addition to their own random velocities. Thus, the more orderly kinetic energy of the stone as a whole (which could do useful work) is changed to disordered thermal energy when the stone strikes the ground. Disorder increases in this process, as it does in all processes that occur in nature.    20.8 Unavailability of Energy; Heat Death (not covered) #   In any natural process, some energy becomes unavailable to do useful work\n  That is, as time goes on, both energy is degraded and entropy increases  A rock that falls to the ground could instead used it\u0026rsquo;s energy towards useful work versus exerting kinetic/thermal energy while falling Two separate hot and cold objects could serves as the high and low temperature regions for a heat engine (obtaining useful work). Instead, if the tow objects are put in contact with one another, they\u0026rsquo;ll eventually reach the same uniform temperature and not be able to do any work.   Heat Death: All energy of the universe degrades into thermal energy  Very far out Scientists are unsure whether this is inevitable or whether we can even extrapolate the 2nd law to the scale of our universe    20.9 Statistical Interpretation of Entropy/2nd (not covered) #   We can only realistically observe macrostates and not microstates  However, we can make inferences about microstates with probabilities Each microstate is equally probable of occurring Thus, the number of microstates that give the same macrostate correspond to the relative probability of that macrostate occurring   The most probable state of a gas is one in which the molecules take up the whole spaces and move about randomly (in a maxwell distribution) At the same time, the very orderly arrangement of all molecules located in one corner of the room and all moving with the same velocity is extremely unlikely Therefore, the probability is directly related to the disorder and hence entropy of the system  The most probably state is the one with greatest entropy or greatest disorder and randomness It\u0026rsquo;s also the macrostate that corresponds to the most microstates   The netropy of a system in a given macro state can be written as: $$ S = k \\ \\ln\\mathscr{W}$$ .$k$ is the Boltzmann\u0026rsquo;s constant and .$\\mathscr{W}$ is the number of microstates corresponding to the given macrostate  That is, .$\\mathscr{W}$ is proportional to the probability of occurrence of that state .$\\mathscr{W}$ is also called the thermodynamic probability or the disorder parameter    20.10 Thermo Temperature; Third Law (not covered) #   Ideal Carnot Cycles always have the ratio $$\\frac{Q_L}{Q_H} = \\frac{T_L}{T_H}$$ Note that this relation doesn\u0026rsquo;t depend on the working substance, thus it can server as the basis for the Kelvin scale The closer a temperature is to abs zero, the more difficult it is to reduce the temp further Third Law:  It is not possible to reach absolute zero in any finite number of processes\n  Thus, since .$e = 1 - \\frac{T_L}{T_H}$ and because .$T_L$ can\u0026rsquo;t ever be zero then 100% efficiency is never possible  "},{"id":37,"href":"/physics-7b/21/","title":"21: Electric Charges \u0026 Fields","section":"Physics 7B","content":"21.1 Static Electricity; Electric Charge and its Conservation #   \u0026ldquo;Charged\u0026rdquo; objects posses a net electric charge Unlike charges attract; like charges repel  Charges on glass are positive, charges on plastic is negative   Law of Conservation of Electric Charge:  Whenever a certain amount of charge is produced in one object, an equal amount of the opposite type of charge is produced in another object  Charges cannot be destroyed or created   E.x. a plastic ruler is rubbed with a paper towel. The plastic acquires a negative charge and the towel obtains an equal positive charge In other words, the net amount of electric charge produced in any process is zero: .$\\Sigma Q = 0$    21.2 Electric Charge in the Atom #   Atoms are made up of positive nucleus surrounded by at least one negatively charged electron.  Inside the nucleus are protons which are positively charged and neutrons which have no charge The charges of electrons and protons are equal in magnitude   E.x. neutral atoms with no charge contain an equal number of protons and electrons When an atom gains a charge (by losing/gaining electrons), it then has a net charge and is called an ion Neutral objects have a net charge of zero  Over time, objects left alone with a charge tend to lose their charge This is because over time, electrons are exchanged with water molecules in the air  Water molecules are polar: They are neutral, their charges aren\u0026rsquo;t equally distributed   Thus, on rainy days it\u0026rsquo;s harder for an object to maintain a charge for too long    21.3 Insulators and Conductors #   Conductor: Material that allow charge to flow between objects  Metals tend to be good conductors Electrons (charges) are relatively lose: can move freely within metal, but can\u0026rsquo;t leave easily  Called free or conduction electrons     Insulator: Opposite of conductors; don\u0026rsquo;t easily allow a flow of charge  Most materials other than metals tend to be good insulators  Notably rubber and wood   Electrons are bound very tightly to the nuclei Almost no free electrons   Semiconductors: Somewhere between the two former  Silicon, germanium Less free electrons than a conductor, but more than an insulator    21.4 Induced Charge; Electroscope #   Conduction: Charge transfer by physical contact  E.x. a positively charged metal rod touches a neutral metal rod. Free electrons from the neutral rod will then flow (transfer) to the charged rod, leaving the formerly neutral rod now slightly positively charged   Induction: Charge distribution altered by bringing two objects close, but not touching  Unlike conduction, induction doesn\u0026rsquo;t alter the net charge of objects when the inducer is taken away However, induction can redistribute the existing charges on the induced object   Grounded Objects  Objects can be ground to the earth with a conducting wire The earth is very large and can conduct, so it easily accepts/gives up electrons Therefore, when an object is induced by another charged object, the original objects will become charged If the wire is ever cut when the object is under induction, the charge will stay in the object    Electroscope  .$\\vec F \\propto \\text{angle of deflection}$ .$y$-axis: .$F_{T1} \\sin \\theta_1 = F_{21}$ .$x$-axis: .$F_{T1} \\cos \\theta_0 = m_1 g$ .$F_{21} = m_1 g \\tan \\theta_1 \\approx m_1 g \\theta_1$ .$F_{21} = - F_{12}$ ( Newton\u0026rsquo;s Third) .$ \\Longrightarrow \\theta_1/\\theta_2 = m_2/m_1$ .$d = l (\\theta_1 + \\theta_2)$       21.5 Coulomb\u0026rsquo;s Law #  Coulomb\u0026rsquo;s Law: $$E_\\text{source} = k \\frac{Q_\\text{source}}{r^2} \\Longrightarrow F = EQ = \\bigg(k \\frac{Q_1}{r^2}\\bigg) (Q_2) = k\\frac{Q_1 Q_2}{r^2}$$ where .$k$ is a constant equal to .$\\frac{1}{4\\pi\\varepsilon_0} = 8.988 \\cdot 10^9 \\text{ N m$^2$/C$^2$}$   Very similar to universal gravitation equation  However\u0026hellip;  .$F_C$ can repel, whereas .$F_G$ is always attractive .$F_C$ only acts on charged objects, whereas .$F_G$ acts on neutral objects too   .$F_G/F_C \\approx 10^{-40} \\Longrightarrow F_C \\gg F_G$   The coulomb (.$\\text{C}$) is the SI unit for charge Properties of Coulomb Force:  It can be attractive and repulsive It is not a contact force Inversely proportional to .$r^2$ Proportional to amount of charge .$Q$   The smallest charge we\u0026rsquo;ve observed is the elementary charge: .$e = 1.6022 \\cdot 10^{-19} \\text{ C}$  Electrons have a charge equal to .$-e$ Protons have a charge equal to .$+e = -Q_\\text{electron}$ Charges are Quantized  That is, all charges are multiples of .$e$ Since electrons are elementary particles, by definition they can\u0026rsquo;t be divided.     .$k$ can also be written as .$\\frac{1}{4\\pi\\varepsilon_0}$  .$\\varepsilon_0$ is called the permittivity of free space .$\\varepsilon_0 = \\frac{1}{4\\pi k} = 8.85 \\cdot 10^{-12} \\text{C$^2$/N m$^2$}$    21.6 Electric Field #   Electric fields extend outward from every charge and permeates all of space $$\\overrightarrow E = \\lim_{q\\to0}\\frac{\\overrightarrow F}{q} \\Longrightarrow \\overrightarrow F = q \\overrightarrow E$$  .$q$ is a positive charge .$\\overrightarrow F$ is the forces the field exserts on .$q$ Has units newtons per coulomb (.$\\text{N/C}$)   We can combine this with Coulomb\u0026rsquo;s law to get $$\\overrightarrow E = \\frac{kqQ/r^2}{q} = k \\frac{Q}{r^2} = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r^2}$$  We see that .$\\overrightarrow E$ is independent of the non-source particle .$q$ .$Q$ is the particle that is responsible for the field in the first place   An electric field at a given point is the sum of all other electric fields that act on that point $$\\overrightarrow E = \\overrightarrow E_1 + \\overrightarrow E_2 + \u0026hellip;$$  21.7 Electric Field Calculations for Continuous Charge Distributions #   We can extend our previous definition to calculus as $$\\overrightarrow E = \\int d \\overrightarrow E = k \\int \\frac{1}{r^2}\\ dq = \\frac{1}{4\\pi\\varepsilon_0} \\int \\frac{1}{r^2}\\ dq$$  .$dq = \\lambda\\ dl \\text{ (line)} = \\sigma\\ dA \\text{ (disk)} = \\rho\\ dV \\text{ (sphere)}$    Calculating field generated by a continuous charge distribution\n Draw an arbitrary \u0026ldquo;piece\u0026rdquo; of charge distribution; don\u0026rsquo;t choose a special point such as the end or exact middle. The piece should be infinitesimally long and/or wide. Thus, its length or width will be something like .$dx$ or .$ds$ Write an expression for .$dq$, the corresponding infinitesimal charge of that piece in terms of .$dx$ or .$ds$ or whatever. Recall .$dq = \\frac{\\text{total charge}}{\\text{total length}} \\times \\text{(tiny length of piece)}$ Using Coulomb\u0026rsquo;s law, find the infinitesimal electric field at that point of interest (e.x. some point .$P$) generated by the piece chosen in step 1. When necessary, break .$d\\vec E$ into components, .$dE_x$ and .$dE_y$ Integrate .$dE_x$ or .$dE_y$ over the whole charge distribution to obtain the total electric field in the .$x$ or .$y$ direction respectively    When solving problems, it\u0026rsquo;s a good idea to use symmetry, check charge direction, and (when applicable) use bounds of .$r \\in [0, \\infty]$ We can write equation for an infinite plane holding a uniform surface charge density .$\\sigma$ $$2A \\cdot \\overrightarrow E = \\frac{\\sigma A}{\\varepsilon_0} \\Longrightarrow \\overrightarrow E = \\frac{\\sigma}{2\\varepsilon_0}$$  This also applies in the case where a charge is close to an infinite surface (so that the distance to the surface is much greater than the distance to the edges) In the case where there are two oppositely charged sheets parallel to one another, the field is .$\\vec E = \\frac{\\sigma}{\\varepsilon_0}$ since there are two charges creating the field   The case involving an infinitely long wire can be written generally as $$\\overrightarrow E \\cdot 2\\pi RL = \\frac{\\lambda L}{\\varepsilon_0} \\Longrightarrow \\overrightarrow E = \\frac{\\lambda}{2\\pi\\varepsilon_0 \\cdot r}$$  .$r$ is the distance from a particle to the wire    21.8 Field Lines #   To visualize electric fields, we draw electric field lines or lines of force Three properties of Electric Field Lines:  Electric field lines indicate the direction of the electric field; the field points are in the direction tangent to the field line at any point \u0026ndash; see point .$P$ in .$\\text{(a)}$ The lines are drawn so that the magnitude of the electric field, .$E$, is proportional to the number of lines crossing unit area perpendicular to the lines (i.e. a circle \u0026lsquo;hugging\u0026rsquo; a point charge). The closer together the lines, the stronger the field. Electric field lines start on positive charges and end on negative charges; and the number starting or ending is proportional to the magnitude of the charge.  .$\\text{Density} = \\frac{\\text{number of lines crossing surface}}{\\text{area surface}}$ .$\\text{1 Coulomb} = \\frac{1}{\\varepsilon_0} \\cdot \\text{ lines}$ .$\\therefore \\text{Density} = \\frac{q}{\\varepsilon_0 4\\pi r^2} \\Longrightarrow \\vec E$     In the case of two oppositely charged parallel \u0026amp; equally spaces plates \u0026ndash; such as case .$\\text{(d)}$ \u0026ndash; we can write the field as $$\\overrightarrow E =\\text{const.} = \\frac{\\sigma}{\\varepsilon_0}=\\frac{Q}{\\varepsilon_0 A}$$  .$Q =\\sigma A$ is the charge on one plate of area .$A$   Field lines never cross because it wouldn\u0026rsquo;t make sense for an electric field to have two directions at the same point.      Electric Dipole #   A combination of two equal but opposite charges next to one another \u0026ndash; see .$(\\text{a})$ above  Dipole Moment is when represented by vector .$\\vec{p}$ of magnitude .$Ql$  Molecules that have dipole moments are called polar molecules      A dipole in a uniform electric field feels no net force, but does have a net torque (unless .$\\vec p \\parallel \\vec E$) If .$\\vec p \\not \\parallel \\vec E$, .$W =\\int_{\\theta_1}^{\\theta_2} \\tau d\\theta$ where .$\\tau = -\\vec p\\vec E\\sin\\theta = \\vec p \\times \\vec E$  Simplifies to .$W =\\vec p\\vec E(\\cos\\theta_2 - \\cos\\theta_1)$ Thus, work/torque is most at .$\\theta = 90^\\circ$ or .$180^\\circ$ depending on .$\\vec E$ direction Pay attention to right hand rule when solving   If .$r \\gg l \\Longrightarrow \\overrightarrow E \\propto 1/r^3$    21.9 Electric Fields and Conductors #   The static electric field inside a conductor is zero (in static situations where electrons have had time to stop moving)  For that reason, any net charge on a conductor distributes itself on the surface Charges inside conductors act as if the conductor isn\u0026rsquo;t there   All the electric field lines just outside a charged conductor are perpendicular to the surface  21.10 Motion of Charged Particle #   Vector Form of Forces $$\\overrightarrow F_{12} = k \\frac{q_1 q_2}{r^2} \\cdot \\widehat r_{21}$$  Notation:  .$\\overrightarrow F_{12}$ means force on .$q_1$ by .$q_2$ since .$q_2$ is the source charge .$\\widehat r_{21} = - \\widehat r_{12} \\Longrightarrow \\overrightarrow F_{12} = -\\overrightarrow F_{21}$   Direction  If .$q_1 q_2 \u0026gt; 0$ (same sign, repulse), then the force and unitary vectors both point away from the two charges          If .$q_1 q_2 \u0026lt; 0$ (opposite sign, attract), then the force vector points towards the two charges and the unitary direction vector still points away from the two charges      Superposition Principle  In a system considering multiple (3+) charges, forces acting on .$q_1$ by .$q_2$ (.$F_{12}$) is independent from whether other charges are present Total forces acting on .$Q_1$ can be written as .$\\overrightarrow F = \\overrightarrow F_{12} + \\overrightarrow F_{13} + \\dots$  Remember to break down the vectors into .$x/y$ components when adding them  E.x. .$F_{1x} = F_{12x} + F_{13x} + \\dots$   Realize that the axis are arbitrary   .$\\theta = \\tan^{-1}\\Big(\\frac{F_x}{F_y}\\Big)$   Charges in Fields  Charge moving with .$\\vec v$ that is parallel to uniform field .$\\overrightarrow E$  .$\\overrightarrow F = q \\overrightarrow E = m \\vec a \\Longrightarrow a_x = \\frac{q}{m}\\overrightarrow E = \\text{const.}$ .$\\vec v = \\sqrt{2a_x \\vec d} = \\sqrt{\\frac{2q}{m}\\overrightarrow E_x \\vec d}$   Charge moving with .$\\vec v$ that is orthogonal to uniform field .$\\overrightarrow E$  Similar to projectile in gravitational field: .$\\vec g \\sim \\overrightarrow E$ .$\\overrightarrow F_x = 0 \\Longrightarrow v_{x2} = v_{x1};\\ \\ a_x = 0$ .$\\overrightarrow F_y = q \\overrightarrow E = m a_y;\\ \\ a_y = \\vec a = \\frac{q}{m}\\overrightarrow E = \\text{const.}$ .$y(t) = \\frac{1}{2} \\frac{q\\overrightarrow E}{m}t^2$      21.11 Electric Dipoles #   Notes for this chapter are under 21.8 \u0026ndash; Electric Dipole  "},{"id":38,"href":"/physics-7b/22/","title":"22: Flux \u0026 Gauss's Law","section":"Physics 7B","content":"22.1 Electric Flux #   Electric Flux: Electric field that passes through a given area  E.x. for a uniform field .$\\vec E$ passing through an area .$A$ at angle .$\\theta$ between the field direction and line perpendicular to the area, the flux is defined as $$\\Phi_\\vec{E} = \\vec E_\\perp A = \\vec EA_\\perp = \\vec E A \\cos \\theta = \\vec E \\cdot \\vec A$$    The .$N$umber of field lines passing through unit area perpendicular to the field .$A_\\perp$ is proportional to the magnitude of the field .$\\vec E$ $$\\vec E \\propto N/A_\\perp \\Longrightarrow N \\propto \\vec EA_\\perp = \\Phi_\\vec{E}$$ For non-uniform fields:  We divide up the surface into .$n$ small elements of surface whose areas are .$dA$ where .$dA$ is small enough (1) to be considered flat and (2) so .$E$ varies so little it can considered uniform $$\\Phi_\\vec{E} = \\oint_A \\vec E \\cdot d\\vec A$$ If .$\\Phi \u0026gt; 0$, flux is entering the volume and .$\\Phi \u0026lt; 0$ is flux leaving   Direction:  For closed surfaces, .$\\vec A$ points outwards from the enclosed volume, so flux is positive Further, .$\\theta$ (angle between .$d\\vec A$ and .$E$) should always be, for electric field\u0026hellip;  Leaving the volume: Less than .$\\pi/2$ (so .$\\cos\\theta \u0026gt; 0$) and .$\\Phi \u0026gt; 0$) Entering the volume: Greater than .$\\pi/2$ (so .$\\cos\\theta \u0026lt; 0$ and .$\\Phi \u0026lt; 0$)         Net Flux  In the example above, every line that enters also leaves so .$\\Phi = 0$ meaning there is no net flux into or out of the enclosed surface Flux will only be nonzero if one of more lines start or end within the surface  Flux through .$A_1$ is positive, .$A_2$ is negative    Net flux through .$A$ is negative        22.2 Gauss\u0026rsquo;s Law #    Gauss\u0026rsquo;s Law: We can relate flux through a surface and net charge enclosed within said surface by $$\\Phi = \\oint \\vec E \\cdot d\\vec A = \\frac{Q_\\text{enclosed}}{\\varepsilon_0}$$\n This tells us the difference between the input and output flux of the electric field over any surface is due to charge within that surface. This is because we defined .$1 \\text{ Coulomb} = \\varepsilon_0^{-1} \\text{ field lines}$ Notice that it doesn\u0026rsquo;t matter the distribution of the charge inside the surface A charge outside the chosen surface may affect the position of the electric field lines, but it won\u0026rsquo;t affect the number of lines entering of leaving the surface    Irregular Surfaces:   Since flux is proportional to the flux lines passing in/out, and the number of lines is the same for .$A_1$ and .$A_2$, so $$\\oint_{A_1} \\vec E \\cdot d \\vec A = \\oint_{A_2} \\vec E \\cdot d \\vec A = \\frac{Q}{\\varepsilon_0}$$ Therefore, this is true for any surface surrounding a single point charge .$Q$      The superposition principle from last chapter also applies to Gauss\u0026rsquo;s law: The total field .$\\vec E$ is equal to the sum of the fields due to each separate charge: $$\\oint \\vec E_i \\cdot d \\vec A = \\oint \\Big(\\Sigma \\vec E_i \\Big) \\cdot d \\vec A = \\sum \\frac{Q_i}{\\varepsilon_0} = \\frac{Q_\\text{enclosed}}{\\varepsilon_0}$$\n  22.3 Applications of Gauss\u0026rsquo;s #  Gauss\u0026rsquo;s Law to calculate electric fields\n Using symmetry and intuition, draw the electric field lines. Enclose all or part of the charge distribution with a Gaussian surface. The electric field should have the same strength at all points on (at least part of) the surface. Apply Gauss\u0026rsquo;s law: .$\\Phi_\\vec{E} = \\oint \\vec E \\cdot d\\vec A = \\frac{Q_\\text{enclosed}}{\\varepsilon_0}$. If .$E$ is constant over (part of) the Gaussian surface, you can pull it outside the integral. This simplification is what allows you to solve for the field.  Recall .$Q_\\text{enclosed} = \\frac{\\text{(total charge)}}{\\text{(total area)}}\\times \\text{(area enclosed by Gaussian surface)}$ If you can\u0026rsquo;t pull .$E$ outside the flux integral, then Gauss\u0026rsquo;s law don\u0026rsquo;t work! Use the continuous charge distribution strategy from the prior chapter.     Uniformly Charged Solid Spherical Conductor #   Charge Outside:  .$\\vec E$ will have the same magnitude at all points along the surface .$A_1$ Since .$\\vec E$ is always orthogonal to the surface, the cosine is always .$1$ $$\\Longrightarrow E = \\frac{1}{4\\pi\\varepsilon_0}\\frac{Q}{r^2}$$ We see that the field outside is as if all of the charge was from a single point   Charge Inside:  .$\\vec E$ will have the same magnitude at all points along the surface .$A_2$ Thus, .$Q = 0$ because the charge inside the surface .$A_2$ is zero Hence, .$E = 0$ for .$r \u0026lt; r_0$      Initial radius is .$r_0$; outside radius is .$r$ Enclosed charge has charge .$Q$  This result is the same for both hollow and solid spheres because all the charge would lie in a thin layer at the surface.     If .$Q \\neq 0$, current would flow inside the conductor which would build up charge on the exterior of the conductor. This charge would oppose the field, ultimately (in a few nanoseconds for a metal) canceling the field to zero.  Solid Sphere of Charge #   Charge .$Q$ is distributed uniformly throughout a nonconducting sphere of radius .$r_0$     Charge Outside:  Same rational as before, $$\\oint \\vec E \\cdot d\\vec A = E (4\\pi r^2) = \\frac{Q}{\\varepsilon_0}$$ $$\\Longrightarrow E = \\frac{1}{4\\pi\\varepsilon_0}\\frac{Q}{r^2}$$ Again, the field outside is the same as for a point charge in center of sphere   Charge Inside: $$\\oint \\vec E \\cdot d\\vec A = E (4\\pi r^2) = \\frac{Q_{\\text{enclosed in }A_2}}{\\varepsilon_0}$$  Since .$Q_{\\text{enclosed\u0026hellip;}} \\neq Q$, we define the charge density .$\\rho_E$ as the charge per unit volume (.$dQ/dV$) which is constant We can then write $$Q_{\\text{enclosed}} = Q \\cdot \\frac{\\frac{4}{3}\\pi r^3 \\rho_E}{\\frac{4}{3}\\pi r_0^3 \\rho_E} = Q\\cdot \\frac{r^3}{r^3_0}$$ $$ \\Longrightarrow E = \\frac{1}{4\\pi\\varepsilon_0}\\frac{Q}{r_0^3}r$$ $$$$      "},{"id":39,"href":"/physics-7b/23/","title":"23: Electric Potential","section":"Physics 7B","content":"23.1 Electric Potential Energy and Difference #   PE can only be defined for conservative forces  That is, work done by said force is independent of the path taken  Coulomb\u0026rsquo;s Law is conservative because the dependence on position is conservative   Hence, we define .$\\Delta U = -W$ with  .$\\Delta U = U_b - U_a$ is for a situation where a point charge .$q$ moves from point .$a$ to point .$b$ This is equal to negative work, .$-W = -\\vec F d = -(q\\vec E) d$ (for a uniform .$\\vec E$)    23.2 Relation between Electric Potential and Field #   Electric Potential: Electric PE per unit charge, such as for a charge at point .$a$ $$V_a = \\frac{U_a}{q}$$ We only really care about difference though, which is defined as $$V_{ba} = \\Delta V = \\frac{U_b - U_a}{q} = - \\frac{W_{ba}}{q}$$ We can now also define PE in terms of electric potential: $$\\Delta U = U_b - U_a = q(V_b - V_a) = qV_{ba}$$ Electric potential difference is a measure of how much energy an electric charge can acquire in a given situation. Since energy is the ability to do work, the electric potential difference is also a measure of how much work a given charge can do.  The exact amount of energy or work depends both on the potential difference and on the charge.   If a positive charge is free, it will tend to move from high to low potential  Inverse for opposite charge    23.3 Potential due to Point Charges #  $$\\Delta U = U_b - U_a = - \\int_a^b \\vec F \\cdot d \\vec l$$\n .$dl$ is an infinitesimal increment of displacement along the path from .$a$ to .$b$  Keep in mind that .$\\vec F$ must be conservative Thus the integral can be taken along any path from point .$a$ to point .$b$.   Knowing .$\\vec E = \\vec F / q$ and .$V_{ba} = (U_b - U_a) / q$, we can write the electric potential equation as\u0026hellip;  $$V_{ba} = V_b - V_a = - \\int_a^b \\vec E \\cdot d \\vec l$$ $$V_{ba, \\text{uniform $\\vec E$}} = -E\\int_a^b d\\vec l = -Ed$$ \u0026hellip;where .$d$ is the distance of a straight line from point .$a$ to .$b$     Charged Conducting Sphere #  1. Electric Potential Outside Sphere #   We know .$\\vec E = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r^2}$ for outside a conducting sphere (.$r \u0026gt; r_0$) Therefore, we can write $$V_{ba} = - \\int_{r_a}^{r_b} \\vec E \\cdot d \\vec l = - \\frac{Q}{4\\pi\\varepsilon_0}\\int_{r_a}^{r_b} \\frac{dr}{r^2}$$ $$\\dots = \\frac{Q}{4\\pi\\varepsilon_0} \\bigg(\\frac{1}{r_b} - \\frac{1}{r_a}\\bigg)$$ $$\\dots = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r} \\text{ [$r_b = \\infty$]}$$     2. Electric Potential On Sphere #   From .$(a)$, as .$r$ approaches .$r_0$, we see $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r_0}$$ at the surface of the sphere. This makes sense because the charge is distributed on the surface of the sphere.   3. Electric Potential Inside Sphere #   Inside the conductor, .$\\vec E = 0$ Therefore, there is no change in .$\\vec E$ from .$0$ to .$r_0$ (or any point within the conductor) gives zero change in .$V$ Hence, within the conductor, .$V$ is a constant: $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r_0}$$     Thus, the whole conductor, not just its surface, is at this same potential. We can also generalize the first case to the electric potential .$r$ from a single point charge .$Q$  Coulomb potential #   The potential outside a uniformly charged sphere is the same as if all the charge were concentrated at its center  The potential near a positive charge is large, and it decreases toward zero at very large distances    For a negative charge, the potential is negative and increases toward zero at large distances      23.4 Potential due to Any Charge Distribution #   If .$\\vec E$ is a function of position (or otherwise unknown), we can find .$V$ by calculating the potential due to the many tiny charges that make up .$\\vec E$: $$V = \\frac{1}{4\\pi\\varepsilon_0} \\int \\frac{dq}{r}$$ where .$r$ is the distance from a tiny element of charge .$dq$ to the point where .$V$ is being determined  23.5 Equipotential Lines and Surfaces #   The electric potential can be represented by drawing equipotential lines, or, in three dimensions, equipotential surfaces An equipotential surface has all points at the same potential.  That is, the potential difference between any two points on the surface is zero Thus, no work is required to move a charge from one point on the surface to another.   Equipotential surfaces are perpendicular to the electric field (field lines) For a positive point charge, the equipotential surface with the largest potential is closest to the positive charge Unlike electric field lines, which start and end on electric charges, equipotential lines/surfaces are always continuous and never end   Electric field lines and equipotential surfaces for a point charge.    Equipotential lines (green, dashed) are always perpendicular to the electric field lines (solid red) shown here for two equal but oppositely charged particles (an electric dipole).    23.6 Potential Due to Dipole (Moment) #  $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r} + \\frac{1}{4\\pi\\varepsilon_0} \\frac{(-Q)}{(r+\\Delta r)} = \\frac{Q}{4\\pi\\varepsilon_0} \\frac{\\Delta r}{r(r + \\Delta r)}$$\n .$r$ is the distance from (some arbitrary point) .$P$ to the positive charge and .$r + \\Delta r$ is the distance to the negative charge  If .$r \\gg l$, then .$r \\gg \\Delta r \\approx l \\cos \\theta$ so we can neglect .$\\Delta r$ $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Ql \\cos\\theta}{r^2} = \\frac{1}{4\\pi\\varepsilon_0} \\frac{p \\cos\\theta}{r^2} $$ Notice the potential decreases .$\\propto r^2$, whereas for a single point charge the potential decreases .$\\propto r$ It is not surprising that the potential should fall off faster for a dipole:  When you are far from a dipole, the two equal but opposite charges appear so close together as to tend to neutralize each other      --      23.7 .$\\vec E$ Determined from .$V$ #   We know that .$V_b - V_a = - \\int_a^b \\vec E \\cdot d\\vec l$, which we can write in differential form as .$dV = -\\vec E \\cdot d\\vec l = - E_l dl$. This can be written as $$E_l = - \\frac{dV}{dl}$$ .$dV$ is the tiny difference in potential between two points a distance .$dl$ apart, and .$E_l$ is the component of the electric field in the direction of the tiny displacement .$d\\vec l$ This is called the gradient of .$V$ in a particular direction: The general case is $$\\vec E = - \\nabla \\vec V = - \\bigg\\langle \\frac{\\delta V}{\\delta x}, \\frac{\\delta V}{\\delta y}, \\frac{\\delta V}{\\delta z} \\bigg\\rangle$$ This states that the electric field points \u0026ldquo;downhill\u0026rdquo; towards lower voltages (where there is lower potential)  23.8 Electrostatic PE; The Electron Volt #   The electric potential and energy potential due to one point charge .$Q_1$ on another point charge .$Q_2$ separated by .$r_{12}$ are $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q_1}{r_{12}}$$ $$U = Q_2 V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q_1 Q_2}{r_{12}}$$ The PE is the negative work needed to separate the two charges to infinity. For three points, we can use the superposition principle like we have prior to write $$U = \\frac{1}{4\\pi\\varepsilon_0}\\bigg( \\frac{Q_1 Q_2}{r_{12}}+ \\frac{Q_1 Q_3}{r_{13}} + \\frac{Q_2 Q_3}{r_{23}} \\bigg)$$  Electron Volt #   Joules are a very large unit for dealing with energy of the electron scale; as such, the electron volt (.$eV$) is often used One electron volt is the energy acquired by a particle carrying a charge .$e$ (the magnitude of an electron) as a result of moving through a potential difference of .$1 V$ $$1 \\text{ eV} = 1.6022 \\cdot 10^{-19} \\text{ J}$$ E.x., an electron (charge .$e = 1.6\\cdot10^{-19}$) that accelerates through a potential difference of .$1000 \\text{ V}$ will lose .$1000 \\text{ eV}$ of potential energy and gain .$1000 \\text{ eV}$ of kinetic energy  23.9 Digital; Binary Numbers; Signal Voltage (not covered) #   Batteries and wall sockets provide a steady supply voltage as power Signal voltage provide/carry information  Analog signal voltage has voltage that varies continuously (i.e .$\\sin$) Digital signals are more complicated and encode information, often in binary  Bytes have 8 bits which allow .$2^8 = 256$ numbers Digital signals are transmitted at some rate (bit-rate) given in .$\\text{Mb/s}$       Analog to digital converters, ADCs, convert analog signals to boxy digital waves  The difference between the original continuous and it\u0026rsquo;s digital approximation is called the quantization error / loss This error varies by primarily:  Resolution or bit depth which is the number of bits for the voltage of each sample Sampling rate which is the number of times per second the original analog voltage is measured (sampled)   E.x., CDs are sampled at .$44.1 \\text{ kHz}$ with a bit depth of .$16 \\text{ bits per sample}$      The red analog sine wave, which is at a 100-Hz frequency (1 wavelength is done in 0.010 s), has been converted to a 2-bit (4 level) digital signal (blue).     Digital Signals  Digital to Analog, DACs, exist too because some appliances require an analog signal Digital signals can be compressed: Repeated information can be reduced so that less memory (bits) is needed  Fun fact: Bit is the contraction of \u0026ldquo;binary digit\u0026rdquo;, leaving out the 8 letters between   Digital signals are more resistant from noise, which badly corrupts analog signals  Any electronic signal involves electric charges whose electric field can affect charges in another nearby signal External fields, as from high voltage wires, motors, or fluorescent lamps, can produce noise Thermal noise refers to random motion of electrons, much like the “thermal motion” of the molecules in a gas Moving electrons can be affected by the medium (wire, etc.), altering the signal      "},{"id":40,"href":"/physics-7b/24/","title":"24: Capacitance, Dielectrics, Electric Energy Storage","section":"Physics 7B","content":"24.1 Capacitors #   Capacitors are devices that store an electric charge  Normally consists of two conducting objects; plates, sheets  When a voltage is applied, the two plates become charged: one positive, one negative   Conductors are placed near one another, but not touching  This distance is typically due to an insulator between sheets Capacitors are typically rolled so that they take up less room     Two main use cases  Storing energy for later use; e.x. camera flash Block surges of charge and energy to protect circuits   The amount of charge .$Q$ acquired by each plate is proportional to  .$V$: The potential difference of the two plates (Volts) .$C$: The constant capacitance of the capacitor (Coulombs per volt, farad) $$Q = CV$$    24.2 Determination of Capacitance #   In the real world, capacitance is determined experimentally by using the prior equations For ideal cases where the sheets are separated by a vacuum or air, however, we can use the following equations For a parallel-plate capacitor where .$A$ is the area of each plate and .$d$ is the distance between plates: $$E = \\frac{\\sigma}{\\varepsilon_0} = \\frac{Q}{\\varepsilon_0 A}$$  We also know this because .$E = \\sigma / \\varepsilon_0$ and .$\\sigma = Q/A$   Since .$V = \\int E\\ dl = \\frac{Qd}{\\varepsilon_0 A}$, we can relate it to .$C$ as $$C = \\frac{Q}{V} = \\varepsilon_0 \\cdot \\frac{A}{d}$$  Capacitance-finding strategy\n Assign an arbitrary charge .$\\pm q$ to the two plates. Using Gauss\u0026rsquo;s law or other techniques, calculate the electric field between these two plates From that electric field, calculate the potential difference between the plates, .$V = -\\int \\vec E \\cdot d \\vec s$ Calculate the capacitance using .$C = q/V$. The arbitrary charge .$q$ from (1) should cancel out.   24.3 Capacitors in Series and Parallel #  Series #   The current/charge on each capacitor has the same magnitude: $$Q = Q_1 = Q_2 = \\dots$$   The total voltage across all capacitors is sumo of the voltage drops of the individual components: $$V = V_1 + V_2 + \\dots = I(R_1 + R_2 + \\dots)$$ And since .$V = Q/C$, capacitance is then $$\\frac{Q}{C_\\text{eq}} = \\frac{Q}{C_1} + \\frac{Q}{C_2} + \\dots \\Longrightarrow \\frac{1}{C_\\text{eq}} = \\frac{1}{C_1} + \\frac{1}{C_2} + \\dots $$  Notice that the equivalence capacitance is smaller than the smallest contributing capacitance    Parallel #   The total current/charge is the sum of the currents flowing through each component $$Q = Q_1 + Q_2 + \\dots = V (R^{-1}_1 + R^{-1}_2 + \\dots)$$   Voltage (potential difference) is the same across all paths/capacitors $$V = V_1 = V_2 = \\dots$$ Therefore, we can use .$V = Q/C$ to write the equivalent capacitance as $$Q = C_1 V + C_2 V + \\dots$$ $$Q = C_\\text{eq} V = (C_1 + \\dots)V \\Longrightarrow C_\\text{eq} = C_1 + \\dots$$  The net effect of connecting capacitors in parallel is to increase the capacitance  Makes sense: We\u0026rsquo;re essentially increasing area of the plates   The overall working voltage is always limited by the smallest working voltage of an individual capacitor.    24.4 Storage of Electric Energy #   The energy stored in a capacitor is equal to the work done to charge it.  Initially, an uncharged capacitor requires no work to move the first few bits of charge As more charge is stored, more work is needed to add more charge of the same sign because of the electric repulsion That is, the more charge already on a plate, the more work required to add additional charge   Since we know .$dW = V\\ dq$ and .$V = q/C$, we can write the work needed to store charge .$Q$ as $$W = \\int_0^Q V\\ dq = \\frac{1}{C}\\int_0^Q q \\ dq = \\frac{1}{2} \\frac{Q^2}{C}$$ Since .$U = W$ and .$Q = CV$, we can write the energy stored in a capacitor with charges .$+Q$ and .$-Q$ on its two conductors as $$U = \\frac{1}{2} \\frac{Q^2}{C} = \\frac{1}{2}CV^2 = \\frac{1}{2}QV$$ It is useful to think of the energy stored in a capacitor as being stored in the electric field between the plates.  E.x. lets find the energy stored in a parallel-plate capacitor in terms of the electric field  We know for two close parallel plates we can find the potential difference as .$V = Ed$ where .$d$ is distance between plates We also know .$C = \\varepsilon_0 A/d$ for parallel plate capacitors, thus we can write $$U = \\frac{1}{2}CV^2 = \\frac{1}{2}\\bigg(\\frac{\\varepsilon_0 A}{d}\\bigg)(E^2 d^2) = \\frac{1}{2} \\varepsilon_0 E^2 Ad$$ We can recognize .$Ad$ as the volume between the plates where .$E$ exists If we divide both sides of by this volume, we can an equation for the energy density .$u$: $$u = \\frac{\\text{energy}}{\\text{volume}} = \\frac{1}{2}\\varepsilon_0 E^2$$   Thus, electric energy stored per unit volume in any region of space is proportional to the square of the electric field We proved this with parallel plates, but this can be shown for any region with an electric field    24.5 Dielectrics #   Dielectrics are the insulating material sheet placed between conductors They serve to  Because they don\u0026rsquo;t break down, they allow electric charge to flow as easily as air so higher voltages can be applied without charge passing across the gap Allow the plates to be placed closer together without touching, allowing an increased capacitance because the thickness .$d$ is smaller Dielectrics increase the capacitance by a factor .$K$ (known as the dielectric constant) $$C = KC_0$$  .$C_0$ is the capacitance when the space is a vacuum/air .$C$ is the capacitance with the dielectric filling the space     For parallel-plate capacitors, we use .$C = Q/V = \\varepsilon_0 A/d$ and .$C = KC_0$ $$C = K \\varepsilon_0 \\frac{A}{d}$$ Energy density also changes with a dielectric as $$u = \\frac{1}{2}K \\varepsilon_0 E^2 = \\frac{1}{2}\\varepsilon E^2$$ Likewise, .$E$ and .$V$ are both also altered:  With no dielectric, the field is .$E_0 = \\frac{V_0}{d}$ where .$V_0$ is the potential difference If the capacitor is isolated (i.e. not connected to a battery) so that the charge stays constant, potential difference drops: .$V = V_0/K$ Therefore, .$E = \\frac{V}{d} = \\frac{V_0}{Kd} = \\frac{E_0}{K}$ .$\\varepsilon$ is the permittivity of the dielectric material defined as .$\\varepsilon = K \\varepsilon_0$    "},{"id":41,"href":"/physics-7b/25/","title":"25: Electric Current and Resistance","section":"Physics 7B","content":"25.1 The Electric Battery #   Batteries produce electricity by transforming chemical energy into electric energy Simple battery (cells) contain two plates or rods of dissimilar metals called electrodes  The portion of rods outside of the solution are called the terminals Anode: The positive electrode Cathode: The negative electrode   These electrodes are emersed in the electrolyte: a solution such as a dilute acid  Chemical Process:\n The acid dissolve the zinc electrode, causing zinc atoms to leave two electrons behind on the electrode and enters the solution as a positive ion. The zinc electrode thus acquires a negative charge. Then the electrolyte becomes positively charged and can pull electrons off the carbon electrode. Thus the carbon electrode becomes positively charged. Because there is an opposite charge on the two electrodes, there is a potential difference between the two terminals.       When a battery isn\u0026rsquo;t connected, only a small amount of zinc is dissolved  The zinc electrode becomes increasingly negative Thus, any new positive zinc ions produced are attracted back to the electrode   That is, if a charge is allowed to flow then the zinc can dissolve The voltage depends ot the electrodes\u0026rsquo; material and their relative ability to give up electrons  25.2 Electric Current #   When a circuit is formed, charge can move (flow) through the wires from one terminal to the other  Any flow of charge is called an electric current Flow can only occur on a continuos conducting path (a complete circuit) If there\u0026rsquo;s any break, our circuit is called an open circuit and no current flows   The symbol for battery is the following:     Conventional current from .$+$ to .$-$ is equivalent to a negative electron flow from .$-$ to .$+$     Current in a wire is defined as the net amount of charge that passes through the wire\u0026rsquo;s full cross section at any point in time: $$\\bar I = \\frac{\\Delta Q}{\\Delta t} \\Longrightarrow I = \\frac{dQ}{dt}$$ Current is measured in coulombs per second; ampere (amp): .$\\text{1 A = 1 C/s}$  25.3 Ohm\u0026rsquo;s Law: Resistance and Resistors #   For a current to exist, there must be a potential difference (e.g. between the terminals of a battery) That is, the current is proportional to the potential difference: $$I \\propto V$$  E.x., a wire connected to a .$6V$ battery results in a current twice that of a .$3V$ battery   The current depends on the resistance that the wires offers  The electron flow is impeded partly due to the atoms in the wire .$R$ is this proportionality factor between voltage and current Thus, we get Ohm\u0026rsquo;s Law: $$V = IR$$   Ohm\u0026rsquo;s law only works for when .$R$ is a constant, i.e a metal conductor  In reality, .$R$ isn\u0026rsquo;t constant if temperature changes much Materials that follow Ohm\u0026rsquo;s law are labeled as \u0026ldquo;ohmic\u0026rdquo; Resistance has the units/notation .$\\text{1 $\\Omega$ = 1 V/A}$   Resistors are used to limit/control the current in a circuit  toolbox.mehvix.com/resistor As a current passes through a resistor, the charge/current stays the same but the electric potential decreases  Clarifications of Behavior\n Current\u0026rsquo;s magnitude depends on that device\u0026rsquo;s resistance  Can be though of as the \u0026ldquo;response\u0026rdquo; to the voltage: increases if voltage increases or resistance decreases Current is constant \u0026ndash; it\u0026rsquo;s energy so it cannot be destroyed by components and it\u0026rsquo;s not created by a battery   Resistance is a property of the device/wire Voltage is external to the wire of device \u0026ndash; it\u0026rsquo;s applied across the two ends of the wire  Batteries maintain a constant potential difference \u0026ndash; act as a source of voltage     25.4 Resistivity #   Resistivity has experimentally been found as $$R = \\rho \\frac{l}{A}$$  .$\\rho$ is the resistivity (constant of proportionality) and depends on the material  Has units .$\\Omega \\cdot \\text{m = V/A $\\cdot $ m}$   .$l$ is the wire length .$A$ is the cross-section area   The reciprocal of resistivity is conductivity: .$\\sigma = \\rho^{-1}$  Temperature #   Resistivity varies (generally increasing) with temperature $$\\rho_T = \\rho_0 = \\bigg[ 1+ \\alpha (T-T_0)\\bigg]$$  .$\\rho_0$ is the resistivity at some reference temperature .$T_0$ (i.e .$0^\\circ \\text{ C}$) .$\\rho_T$ is the new resistivity at the current (higher) temperature .$T$ .$\\alpha$ is the temperature coefficient of resistivity that depends on material   Note that the temperature coefficient for semiconductors can be negative.  At higher temperatures, some of the electrons that are normally not free in a semiconductor can become free and contribute to the current. Thus, the resistance of a semiconductor can decrease with an increase in temperature.    25.5 Electric Power #   Electric energy is transformed into thermal energy (and light) in stove burners, toasters, etc.  The current creates collisions between the moving electrons and the atoms in the wire That is, the KE from the wire\u0026rsquo;s atoms increases meaning the temperature increases too $$P = \\frac{dU}{dt} = \\frac{dq}{dt}\\cdot V$$  This is because energy is transformed when a tiny charge .$dq$ moves through a potential difference .$V$ is .$dU = V\\ dq$     The charge that flows per second, .$dq/dt$, is the electric current .$I$: $$P = IV = I^2 R = \\frac{V^2}{R}$$  The SI unit for power is the watt: .$\\text{1 W = 1 J/s}$ We get the last two equations by plugging in .$V = IR$    25.7 Alternating Current #   When a battery is connected to a circuit, the current moves steadily in one direction (DC: Direct Current) Electric generators at power plants produce AC: alternating current  Reverses direction many times per second and is commonly sinusoidal $$V = V_0 \\sin(2\\pi ft) = V_0 \\sin(\\omega t)$$ .$\\omega$ = .$2\\pi f$ .$f$ is the frequency: number of complete oscillations per second  Commonly .$\\text{60 Hz}$ in NA   Potential .$V$ oscillates between .$\\pm V_0$, the peak voltage   Current equation still works: $$I = \\frac{V}{R} = \\frac{V_0}{R}\\sin\\omega t = I_0 \\sin\\omega t$$  .$I_0 = V_0/R$ is the peak current Avg current is 0; it\u0026rsquo;s positive and negative for an equal amount of time  Doesn\u0026rsquo;t mean that no heat is created or no power is needed Electrons are still moving though!     Power is also consistent $$P = I^2R = I_0^2 R \\sin\\omega t = \\frac{V_0^2}{R} \\sin\\omega t$$  Power is always positive because current is squared Since the .$\\sin\\dots$ oscillates between 1 and 0, the average power is $$\\overline P = \\frac{1}{2}I_0^2R = \\frac{1}{2} \\frac{V_0^2}{R}$$ This can also be calculated by using the RMS values for .$I$ and .$V$ $$I_\\text{rms} = \\sqrt{\\overline I^2} = \\frac{I_0}{\\sqrt{2}} \\approx 0.707 I_0$$ $$V_\\text{rms} = \\sqrt{\\overline V^2} = \\frac{V_0}{\\sqrt{2}} \\approx 0.707 V_0$$ $$\\dots \\Longrightarrow \\overline P = I_\\text{rms} V_\\text{rms} = I_\\text{rms}^2 R = \\frac{V_\\text{rms}^2}{R}$$ Fun fact: we can use the rms of a value to find the peak of it, e.x. $$V_0 = \\sqrt{2} V_\\text{rms}$$ Keep in mind that this is the average power. Instantaneous power varies from .$0$ to .$2\\overline P$    25.8 Microscopic View of Current #   We\u0026rsquo;ve seen that electric current can be carried by negatively charged electrons in metal wires, and that in liquid solutions current can also be carried by positive and/or negatively charged ions When a potential difference is applied to the two ends of a wire, the direction of the electric field .$\\vec E$ is parallel to the walls of the wire  This field within the conducting wire does not contradict our earlier result that .$\\vec E = 0$ inside a conductor in the electrostatic case, as we are no longer dealing with the static case. That is, charges are free to move in a conductor, and hence can move under the action of the electric field.  If all the charges are at rest, then .$\\vec E = 0$       Current Density #   Current density, .$\\vec j$, is the current per area $$j = \\frac{I}{A} \\Longrightarrow I = \\int \\vec j \\cdot d \\vec A$$  .$I$ is the current through the whole surface .$d\\vec A$ is an element of surface area over which the integration is taken Direction of the density is the same direction as .$\\vec E$ \u0026ndash; the direction that a positive charge would move    Drift Speed #   Inside a wire, we can imagine the free electrons as moving about randomly at high speeds, bouncing off the metal atoms of the wire  Somewhat like the molecules of a gas   When an electric field exists in the wire the electrons feel a force and initially begin to accelerate but they soon reach a more or less steady average speed, known as their drift speed .$v_d$  Collisions with atoms in the wire keep them from accelerating further The drift speed is normally very much smaller than the electrons\u0026rsquo; average random speed inside the metal wire     Black zagged line represents the motion of an electron in a metal wire due to an electric field. The field .$\\vec E$ gives electrons in random motion a net drift velocity .$\\vec v_d$. Its direction (the net charge flow) is in the opposite direction of .$\\vec E$ because electrons have a negative charge and .$\\vec F = q \\vec E$   We can relate drift speed with the macroscopic view:  In some time, the electrons travel (the average) distance .$l = v_d \\Delta t$ In that same time, electrons in volume .$V = Al = A v_d \\Delta t$ pass through area .$A$ of the wire If there are .$n$ free electrons each of charge .$-e$ per unit volume, then the total electrons is .$N = nV$ Thus, the charge is $$\\Delta Q = \\text{(number of charges, $N$)$\\times$(charge per particle, $-e$)}$$ $$\\dots = (nV)(-e) = -(nAv_d\\Delta T)(e)$$ We can then easily find the current (density): $$I = \\frac{\\Delta Q}{\\Delta t} = -neAv_d$$ $$j = \\frac{I}{A} = -nev_d$$ Notice that the negative sign indicates that the direction of (positive) current flow is opposite to the drift speed of electrons.    Field inside a Wire #   Voltage can be written in terms of microscopic values (in addition to the macro: .$V = IR$) Recall that resistance is related to density by .$R = \\rho \\frac{l}{A}$ We can then write .$V$, .$I$ and .$j$ as $$V = El = IR = (jA)\\bigg(\\rho \\frac{l}{A}\\bigg) = j \\rho l$$  $$I = jA$$  $$j = \\frac{1}{\\rho}E = \\sigma E$$    .$\\sigma$ is the conductivity of the wire .$\\rho, \\sigma$ do not vary with .$V$ and thus neither .$E$   We can then write the microscopic statement of Ohm\u0026rsquo;s Law: $$\\vec j = \\sigma \\vec E = \\frac{\\vec E}{\\rho}$$  25.9 Superconductivity #   At very low temperatures, the resistivity of certain metals and certain compounds or alloys becomes zero Materials in such a state are said to be superconducting In general, superconductors become superconducting only below a certain transition (critical) temperature, .$T_C$   "},{"id":42,"href":"/physics-7b/26/","title":"26: DC Circuits","section":"Physics 7B","content":"26.1 EMF and Terminal Voltage #  EMF #   To have a current, we need an emf (electromotive force) device to transform one type of energy (chemical, mechanical, light) into electric energy  The term “electromotive force” is a misnomer: it does not refer to a “force,” which is measured in newtons. To avoid confusion, we use the abbreviation, emf.   EMF of the Source: The potential difference between the terminals of a source when no current flows to an external circuit .$\\mathscr{E}$ is used for emf and it\u0026rsquo;s units is (V)olts  Batteries #   Batteries don\u0026rsquo;t have constant current (it varies with resistance of the circuit) Voltage is nearly constant, but decreases when battery cannot supply charge fast enough to maintain full emf  This occurs because the charge must move between/through the electrodes in the battery Additionally, the battery has some internal resistance, .$r$   Batteries are treated as a perfect emf .$\\mathscr{E}$ in a series with a resistor .$r$  The terminal voltage is .$V_\\text{ab} = V_a - V_b$  When a battery is being charged, a current is forced to pass through it; we then have to write .$V_\\text{ab} = \\mathscr{E} + Ir$   When no current is drawn, .$V_\\text{ab} = \\mathscr{E} - Ir$  .$Ir$ comes from the fact that when .$I$ flows from the battery it causes an internal voltage drop .$Ir$   Since .$\\mathscr{E} - Ir = IR \\Longrightarrow \\mathscr{E} = I(R+r)$ for .$R$ as the resistance of the circuit    26.2 Resistors in Series and Parallel #  Series #   Any charge that passes through one resistor passes through all  Hence, the same current .$I$ passes through each too (constant) If this wasn\u0026rsquo;t true, then it would imply the charge was not conserved   Voltage from the battery is split between each resistor proportional to .$R$ $$V = V_1 + V_2 + \\dots = I R_1 + I R_2 + \\dots = I(R_1 + R_2 + \\dots)$$  Thus, .$R_\\text{eq} = R_1 + R_2 + \\dots$   Note that when you add more resistance to the circuit\u0026hellip;  The current that passes through each resistor decreases The equivalent resistance increases Voltage stays the same since the battery is unaltered    Parallel #   Current is split from the source path into branches  Thus, paths outside of one\u0026rsquo;s branch doesn\u0026rsquo;t impact/interrupt current The current from each branch must equal the total current; i.e $$I = I_1 + I_2 + \\dots$$   Voltage across each resistor is equivalent; $$I_1 = \\frac{V}{R_1}, I_2 = \\frac{V}{R_2}, \\dots \\Longrightarrow I_\\text{eq} = \\frac{V}{R_\\text{eq}}$$  Thus, .$R_\\text{eq}$ is equal to $$ \\frac{1}{R_\\text{eq}} = \\frac{1}{R_1} + \\frac{1}{R_2} + \\dots$$   Note that when you add another resistor to the circuit\u0026hellip;  Net resistance goes down  Adding another resistor adds another path causing current to decrease   Voltage stays the same since the battery is unaltered Consistent with .$R = \\rho l/A$ definition of resistance  Series is effectively increasing the length Parallel increases the area through which current flows      26.3 Kirchhoff\u0026rsquo;s Rules #  We use Kirchhoff\u0026rsquo;s two rules when circuits get too complex for trivial analysis\n1. Junction Rule: At any junction point, the sum of all currents entering the junction must equal the sum of all currents leaving the junction.   That is, what goes out must come back in Based on conservation of electric charge Mathematically, $$\\sum_{k=1}^{n} I_k = 0$$  .$n$ is the total number of branches with currents flowing towards or away from the node.       The current entering any junction is equal to the current leaving that junction: .$I_2 + I_3 = I_1 + I_4$\n   2. Loop Rule: The sum of the changes in potential around any closed loop of a circuit must be zero.   That is, what goes up must come back down  There is as much up as there is down At the battery, the gain/loss on each terminal cancel one another along the closed circuit path   Based on conservation of energy Mathematically, $$\\sum_{k=1}^{n} V_k = 0$$  .$n$ is the total number of voltages measured.       The sum of all the voltages around a loop is equal to zero: .$V_1 + V_2 + V_3 + V_4 = 0$\n   26.4 EMFs in Series and Parallel; Charging a Battery #   (a) Two similarly arranged batteries in a series sum their voltages; e.x. 3V (b) Two oppositely arranged batteries in a series subtract their voltages; e.x. 8V  How battery charging works The 20V source is charging up the 12V battery Because of it\u0026rsquo;s greater voltage, the 20V is forcing charge back into the 12V   (c) Two batteries in parallel, which if the emfs are the same, can provide more energy when large currents are needed.  Each of the cells in parallel has to produce only a fraction of the total current, so the energy loss due to internal resistance is less than for a single cell Thus, the batteries will drain less quickly.        26.5 RC Circuits: Resistor \u0026amp; Capacitor in Series #  RC Circuits differ in that they have varying current\nCapacitor Charging #   After the switch .$S$ closes in the RC circuit shown in (a), the voltage across the capacitor increases with time as shown in (b), and the current through the resistor decreases with time as shown in (c).\n    (a) When closed, the current starts flowing through the circuit from the negative terminal through .$R$ and accumulate on the upper plate of the capacitor which creates potential difference equal to .$V_C = Q/C$  Current is then reduced because of this opposing voltage on the capacitor   (b) Eventually, the potential equals the emf, .$\\mathscr{E}$, and then no current flows and no potential difference across the resistor  Potential difference, .$V_C$, across the capacitor is equal to the charge on it, .$V_C = Q/C$ Because charge increases with time, so does voltage until this point The emf .$\\mathscr{E}$ of the battery will equal the sum of the voltage drops across the resistor and the capacitor: $$\\mathscr{E} = IR + \\frac{Q}{C}$$  .$R$ is total circuit resistance, including battery .$I$ is current at all points in the circuit at any instant .$Q$ is the charge of the capacitor at that same instant Notice: .$\\mathscr{E}, R, C$ are constants, .$Q, I$ are functions of time     (c) As charge builds up on the capacitor, the current decreases exponentially in time with a time constant .$\\tau$ equal to .$RC$     The rate at which charge flows thorough the resistor (.$I = dQ/dT$) is equal to the rate at which charge accumulates on the capacitor: $$ \\mathscr{E} = \\bigg(\\frac{dQ}{dt}\\bigg)R + \\frac{1}{C}Q$$ This can then be used to find an equation of .$Q$: $$ \\Longrightarrow \\frac{dQ}{C\\mathscr{E} - Q} = \\frac{dt}{RC} \\Longrightarrow \\int_0^Q \\frac{dQ}{C\\mathscr{E} - Q} = \\frac{1}{RC}\\int_0^t dt$$ $$ \\Longrightarrow \\ln\\bigg(1 - \\frac{Q}{C \\mathscr{E}}\\bigg) = - \\frac{t}{RC} \\Longrightarrow 1 - \\frac{Q}{C\\mathscr{E}} = e^{-t/RC}$$ $$ \\Longrightarrow Q = C\\mathscr{E}(1-e^{-t/RT}) = Q_0 (1-e^{-t/RT})$$  .$Q_0 = C \\mathscr{E}$ represents the maximum charge on the capacitor  .$Q_0 \\neq \\text{charge $(Q)$ at $t = 0$}$ The potential difference across the capacitor is .$V_C = Q/C$ so the maximum value is $$ V_C = \\mathscr{E}(1-e^{-t/RC})$$     .$\\tau = RC$ is the axis units on graph (b) and is aptly called the time constant of the circuit  Represents the time required for the capacitor to reach .$(1-e^{-1}) = 0.63 = 63\\text{%}$ of its full charge and voltage  Also represents the time for the current to drop to .$1/e \\approx 0.37$ of it\u0026rsquo;s initial value   Thus, it measures how quickly the capacitor becomes charged We use this as a measurement since the maximums only occur as we take .$t \\to \\infty$, but these values reach 86% of the way in .$2RC = 2\\tau$, 95% in .$3\\tau$, 98% in .$4\\tau$, so on   The current in the circuit at any time can be found by differentiating the following: $$I = \\frac{dQ}{dt} = \\frac{\\mathscr{E}}{R}e^{-t/RC}$$  This is an exponential decay function: when .$t = 0$, the current is largest because there is no charge on the capacitor to impede it That is, .$I = I_0 = \\mathscr{E}/R$ As charge builds up, the current decreases exponentially in time (as shown in (c))    Capacitor Discharging #   Now imagine the opposite case; we start fully charged at .$Q_0$ with voltage .$V_0$ and have to discharge through resistance .$R$ The voltage across the resistor at any instant equals that across the capacitor: $$V = IR = \\frac{Q}{C}$$ We can use this to find the functions for both .$Q_0$ and .$V_C$: $$ - \\frac{dQ}{dt} R = \\frac{Q}{C} \\Longrightarrow \\frac{dq}{Q} = - \\frac{dt}{RC}$$ $$ \\ln \\frac{Q}{Q_0} = - (t/RC) \\Longrightarrow Q = Q_0 e^{-t/RC}$$ $$ \\dots \\Longrightarrow V_C = V_0 e^{-t/RC}$$  For the RC circuit shown in (a), the voltage .$V_C$ across the capacitor decreases with time, as shown in (b), after the switch S is closed at .$t = 0$. The charge on the capacitor follows the same curve because .$Q \\propto V_C$   $$$$ $$$$\n .$V_0 = Q_0 / C$ is the initial voltage, related to initial charge We can see the charge on the capacitor, thus the voltage across it, decreases exponentially in time Current is found to be $$I = - \\frac{dQ}{dt} = \\frac{Q_0}{RC}e^{-t/RC} = I_0 e^{-t/RC}$$ The charge on the capacitor, the voltage across it, and the current in the resistor all decrease to 37% of their original value in one time constant .$t = \\tau \\ RC$      26.6 Electric Hazards and Safety (not covered) #   Current above .$\\text{1 mA}$ can be felt Current above .$\\text{10 mA}$ cause severe contraction of muscles (may not be able to let go of source) Current above .$\\text{80-100 mA}$ that passes through the torso (passing through the heart for a second) will cause ventricular fibrillation (heart stops pumping blood properly) It\u0026rsquo;s current that harms, even though voltage drives the current  The seriousness of a shock depends on the current and thus the applied voltage and the effective resistance of the body More voltage shocks, more current kills Wet skin has resistance of .$10^3 \\Omega$ while dry skin is around .$10^5 \\Omega$    26.7 Ammeters and Voltmeters: Measurement Affects Quantity Measured (not covered) #   Measuring is hard to do both precisely and consistently Ammeters measure current (amps) and voltmeters measure potential difference or voltage (volts) An analog ammeter or voltmeter uses a galvanometer  The full scale sensitivity, .$I_m$, is the electric current required to make the needle deflect a full scale; typically .$50 \\mu\\text{A}$     An ammeter is a galvanometer in parallel with a shunt resistor with low resistance, .$R_\\text{sh}$    A voltmeter is a galvanometer in series with a resistor with high resistance, .$R_\\text{ser}$     (b) Because an ammeter is used to measure the current flowing in the circuit, it must be inserted directly into the circuit, in series with the other elements. The smaller its internal resistance, the less it affects the circuit. (c) A voltmeter is connected “externally,” in parallel with the circuit element across which the voltage is to be measured. It measures the potential difference between two points. Its two wire “leads” (connecting wires) are connected to the two points.  Only .$R_1$ is being measured above        If the resistance of a voltmeter is much higher than the resistance of the circuit, it will have little effect and its readings can be more accurate  At least to the manufactured precision of the meter, which for analog meters is typically 3% to 4% of full-scale deflection.   Sensitivity: The sensitivity of a voltmeter is specified on its face as, for example, .$10,000\\ \\Omega/\\text{V}$. Then on the .$5\\text{V}$ scale, the voltmeter would have a resistance given by .$\\text{(5V)(10,000 $\\Omega$/V) = 50,000 $\\Omega$}$ Even an ammeter can interfere with a circuit, but the effect is minimal if its resistance is much less than that of the circuit as a whole. For both voltmeters and ammeters, the more sensitive the galvanometer, the less effect it will have on the circuit.  "},{"id":43,"href":"/physics-7b/27/","title":"27: Magnetism","section":"Physics 7B","content":"27.1 Magnets and Magnetic Fields #   Every magnet has two ends or faces called poles which are where the magnetic field is strongest  If a magnet is suspended so it can move freely, one pole will point north Aptly, this side is called the north pole   Magnetic poles aren\u0026rsquo;t like electric charge: Positive or negative charge can easily be isolated, but we can never isolate a magnetic pole  That is, if you cut a magnet is half you don\u0026rsquo;t obtain isolated north and south poles. Rather, you end up with two new magnets each with north and south poles   Ferromagnetic: Materials with a strong magnetic effect i.e. iron, cobalt, nickel, gadolinium Similar to how we picture electric fields around a charge, we can picture magnetic fields surround a magnet  Field lines should be drawn so that (1) the direction of the magnetic field is always tangent to a field line everywhere and (2) the number of lines per unit area is proportional to the magnetic field strength    (a) Visualizing magnetic field lines around a bar magnet, using iron filings and compass needles. The red end of the bar magnet is its north pole. The N pole of a nearby compass needle points away from the north pole of the magnet. (b) Diagram of magnetic field lines for a bar magnet.\n   Earth\u0026rsquo;s Magnetic Field #   Earth\u0026rsquo;s magnetic poles are not exactly through the geographic pole (axis of rotation) The angular difference between the direction of the compass needle (which points along the magnetic field lines) at any location and true (geographical) north varies between .$0 - 20^\\circ$ with location Earth\u0026rsquo;s magnetic field at most location is not tangent to earth\u0026rsquo;s surface  Angle of Dip: The angle that Earth\u0026rsquo;s magnetic field makes with the horizontal at any point       The Earth acts like a huge magnet. But its magnetic poles are not at the geographic poles (on the Earth\u0026rsquo;s rotation axis).\n   27.2 Electric Currents Produce Magnet Fields #    (a) Deflection of compass needles near a current-carrying wire, showing the presence and direction of the magnetic field. (b) Iron filings also align along the direction of the magnetic field lines near a straight current-carrying wire. (c) Diagram of the magnetic field lines around an electric current in a straight wire. (d) Right-hand-rule-1 for remembering the direction of the magnetic field: when the thumb points in the direction of the conventional current, the fingers wrapped around the wire point in the direction of the magnetic field. (.$\\vec B$ is the symbol for magnetic field).\n 27.3 Force on an Electric Current in a Magnetic Field #   By Newton\u0026rsquo;s third law, we can see that a magnet exerts a force on a current-carrying wire  The direction of the force is always perpendicular to the direction of the current and also perpendicular to the direction of the magnetic field .$\\vec B$ Use right hand rule! $$dF_\\vec{B} = dq (\\vec v \\times \\vec B) = dq\\bigg(\\frac{d\\vec l}{dt}\\times \\vec B\\bigg) = I (d\\vec l \\times \\vec B)$$ $$\\dots\\ \\vec F = I (\\vec l \\times \\vec B) = I l b \\sin\\theta$$ .$\\vec l$ is the vector whose magnitude is the length of the wire its direction is along the (straight) wire in the direction of the conventional (positive) current We use the last equation if .$\\vec B$ isn\u0026rsquo;t uniform or if the wire doesn\u0026rsquo;t form angle .$\\theta$ with .$\\vec B$ everywhere    27.4 Force on an Electric Charge Moving in a Magnetic Field #   Recall, .$N$ particles, each charge .$q$, pass by a given point in time .$t$, they constitute current .$I = N q/t$  Lets say in .$t$ time, a particle charge .$q$ moves distance .$l$ in a magnetic field .$\\vec B$ We know from kinematics that .$\\vec l = \\vec v t$ where .$\\vec v$ is the velocity of the particle Using the 27.3 equation, we can find the force on all of these .$N$ particles as $$\\vec F = I\\vec l \\times \\vec B = (Nq/t)(\\vec v t) \\times \\vec B = Nq\\vec v \\times \\vec B$$ Thus, the force on just one of the .$N$ particles is $$\\vec F = q \\vec v \\times \\vec B = qvB \\sin\\theta$$   Realize that we can save a lot of pain if we know that the magnetic field is uniform in which case .$\\vec F_\\vec{B} = 0$ because the forces on opposite segments (sides) cancel out  Uniform Field Path #    Force exerted by a uniform magnetic field on a moving charged particle (in this case, an electron) produces a circular path.\n   Notice the field goes into the paper, denoted with .$\\times$ Because force is always orthogonal to .$\\vec v$, the magnitude of .$\\vec v$ The centripetal acceleration has magnitude .$a = v^2/r$  Thus we can derive $$F = ma \\Longrightarrow qvB = m \\frac{v^2}{r}$$ $$\\dots \\Longrightarrow r = \\frac{mv}{qB}$$   The time .$T$ it takes a particle with charge .$q$ and speed .$v$ to make a revolution is $$T = \\frac{2\\pi\\cdot r}{v} = \\frac{2\\pi m}{qB}$$ $$f = \\frac{1}{T} = \\frac{qB}{2\\pi m}$$    Problem Solving #  Magnetic fields are somewhat analogous to the electric fields, but there are several important differences to recall:\n The force experienced by a charged particle moving in a magnetic field is orthogonal to the direction of the magnetic field (and to the direction of the velocity of the particle), whereas the force exerted by an electric field is parallel to the direction of the field (and independent of the velocity of the particle). The right hand rule, in its different forms, is intended to help you determine the direction of magnetic field, and the force a field exerts, and/or the directions of electric current or charged particle velocity. The right-hand rules to the right are designed to deal with the “perpendicular” nature of these quantities.      With Electric Field #   Lorentz Equation: A particle charge .$q$ moving with velocity .$\\vec v$ in the presence of both a magnetic field .$\\vec B$ and electric field .$\\vec E$ experiences a force $$\\vec F = q (\\vec E + \\vec v \\times \\vec B)$$ Realize that the magnetic field cannot alter speed (do work), it can only alter the direction!  To change an objects speed, you must apply a force along the objects direction of motion The magnetic field exerts a force on particles moving orthogonal to it Therefore, no work can be done because the particle can only move orthogonal to the magnetic field That being said, realize that this field is responsible for the circular, constant speed, motion This is why earth\u0026rsquo;s magnetic field deflects, but doesn\u0026rsquo;t slow down, charged particles from outer space    27.5 Torque on a Current Loop; Magnetic Dipole Moment #   Calculating the torque on a current loop in a magnetic field .$\\vec B$\n   (a) Loop face parallel to .$\\vec B$ field lines; (b) top view; (c) loop makes an angle to .$\\vec B$, reducing the torque since the lever arm is reduced. The vector .$\\vec \\mu$ is the “magnetic moment”.\n   When an electric current flows in a closed wire loop that\u0026rsquo;s in an external magnetic field, the magnetic force on the current can produce a torque $$\\tau = I aB \\frac{b}{2} + I aB \\frac{b}{2}$$ $$\\dots = IabB$$  .$A = ab$ is the area of the loop .$B$ is scalar of the magnetic field Notice, the vertical (orthogonal) sections of wire experience no force from the magnetic field   If we have a coil of .$N$ loops of wire, the current is then .$NI$ so torque becomes $$\\tau = NIAB$$  We call .$\\vec \\mu = NI \\vec A$ the magnetic dipole moment The direction of .$\\vec A$ (and thus .$\\vec \\mu$) is defined as perpendicular to the plane of the coil   We can then re-write our torque eq as $$\\vec \\tau = NI \\vec A \\times \\vec B$$ $$\\dots \\vec \\tau = \\vec \\mu \\times \\vec B$$ Dipoles have some potential energy, found by $$U = \\int \\tau d\\theta = \\int NIAB\\sin\\theta d \\theta$$ $$\\dots = -\\mu B \\cos\\theta = - \\vec \\mu \\cdot \\vec B$$    27.8 Hall Effect #   When a current-carrying conductor is held fixed in a magnetic field, the field exerts a sideways force on the charge moving in the conductor  E.x, if electrons move to the right in the rectangular conductor, the inward magnetic field will exert a downward force: (a) This force is .$F_B = -e\\vec v_d \\times \\vec B$  .$v_d$ is drift velocity     Thus, electrons tend to move towards side .$D$  This creates a potential difference (called the Hall emf), creating field .$\\vec E_H$ This field exerts force .$e\\vec E_H$ on the moving charge   These forces are equal, that is, $$e E_H = ev_d B$$ $$\\therefore E_H = v_d B$$ Hall emf is then, asm uniform .$E_H$, $$\\mathscr{E}_H = E_H d = v_d B d$$  .$d$ is the width of the conductor         The Hall effect. (a) Negative charges moving to the right as the current. (b) Positive charges moving to the left as the current.\n   27.9 Mass Spectrometer #     Mass spectrometers are used to measure the masses of atoms\n  Steps:    Ions are produced (by a current or heating) and they pass through slit .$S_1$ Ions then pass through a region with perpendicular electric and magnetic fields.  Here, .$F_E = qE$ is equal to .$F_B = qvB$ Therefore, .$v = \\frac{E}{B}$ for all ions that pass the slit into .$S_2$; the rest are deflected        Entering .$S_2$, there is only magnetic field .$B\u0026rsquo;$ so the ios follow a circular path  Newtons second gives us .$F = ma \\Longrightarrow qvB\u0026rsquo; = mv^2/r$ Since we know all terms, we can solve for mass: .$m = \\frac{qB\u0026rsquo;r}{v} = \\frac{qBB\u0026rsquo;r}{E}$    "},{"id":44,"href":"/physics-7b/28/","title":"28: Sources of Magnetic Field","section":"Physics 7B","content":"28.1 Magnetic Field Due to a Straight Wire #   Magnetic fields due to the electric current in a long straight wire forms circles with the wire at the center This field is proportional directly with current .$I$ and inversely with distance .$r$: $$B = \\frac{\\mu_0}{2\\pi} \\cdot \\frac{I}{r}$$  .$\\mu_0 = 4\\pi \\times 10^{-7} \\text{ T$\\cdot$m/A}$ is the permeability of free space       28.2 Force between Two Parallel Wires #    Since current-carrying wires feel a force in magnetic fields, and because current-carrying wires emit magnetic fields, current-carrying wires exert a force on one another Magnetic field .$B_1$ produced by .$I_1$ is given by $$B_1 = \\frac{\\mu_0}{2\\pi} \\cdot \\frac{I_1}{d}$$ Parallel currents in the same direction attract while antiparallel repel     Using .$F = IlB$ we can write the force .$F_2$ exerted by .$B_1$ on length .$l_2$ carrying .$I_2$ has magnitude: $$F_2 = I_2 l_2 B_1$$  Notice that the force on .$I_1$ is due to the field produced by .$I_1$ Thus, subbing .$B_1$ into the .$F_2$ formula we find the force on length .$l_2$: $$F_2 = \\frac{\\mu_0}{2\\pi} \\cdot \\frac{I_1 I_2}{d}l_2$$    28.3 Definitions of the Ampere and the Coulomb #  One ampere can be defined as that current flowing in each of two long parallel wires exactly 1 m apart, which results in a force of exactly .$2\\times10^{-7}$ N per meter of length of each wire   This was the standard we used prior because it is readily reproducible (that is, it\u0026rsquo;s called an operational definition) Coulomb is defined in terms of the ampere being exactly one ampere-second: .$\\text{1 C = A $\\cdot$ s}$  Now we define an ampere ampere by saying it\u0026rsquo;s .$\\text{1 C = A $\\cdot$ s}$ and we know the Coulomb because it\u0026rsquo;s mutually assigned the exact value .$e = 1.60176636 \\times 10^{-19}\\text{ C}$    28.4 Ampère\u0026rsquo;s Law #   If we don\u0026rsquo;t have a straight line, we use ampere\u0026rsquo;s law given below We take a infinite tiny segments and dot it with the field at the segment: $$\\oint \\vec B \\cdot d \\vec l = \\mu_0 I_\\text{encl}$$ Note that .$\\vec B$ in Ampere\u0026rsquo;s law isn\u0026rsquo;t necessarily due only to the current .$I_\\text{encl}$ As with Gauss\u0026rsquo;s law for the electric field, Ampere\u0026rsquo;s law practical value to calculate the magnetic field is limited, however, mainly to simple or symmetric situations.  Its importance is that it relates the magnetic field to the current in a direct and mathematically elegant way.        Ampère\u0026rsquo;s law is considered one of the basic laws of electricity and magnetism: It is valid for any situation where the currents and fields are steady and not changing in time, and no magnetic materials are present  Problem Solving: #   Ampère\u0026rsquo;s law, like Gauss\u0026rsquo;s law, is always a valid statement. But as a calculation tool it is limited mainly to systems with a high degree of symmetry. The first step in applying Ampère\u0026rsquo;s law is to identify useful symmetry. Choose an integration path that reflects the symmetry. Search for paths where .$\\vec B$ has constant magnitude along the entire path or along segments of the path. Make sure your integration path passes through the point where you wish to evaluate the magnetic field. Use symmetry to determine the direction of .$\\vec B$ along the integration path. With a smart choice of path, .$\\vec B$ will be either parallel or perpendicular to the path. Determine the enclosed current, .$I_\\text{encl}$. Be careful with signs. Let the fingers of your right hand curl along the direction of .$\\vec B$ so that your thumb shows the direction of positive current. If you have a solid conductor and your integration path does not enclose the full current, you can use the current density (current per unit area) multiplied by the enclosed area.   28.5 Magnetic Field of a Solenoid and a Toroid #   Solenoid: A long looping coil of wire carrying a dc current  The current in each loop produces a magnetic field The total magnetic field is the sum of the fields due to each loop Direction is determined by the right hand rule $$\\oint \\vec B \\cdot d \\vec l = \\mu_0 NI$$     Magnetic field due to a solenoid (a) a few loosely spaced loops; (b) for many closely spaced loops, the field is nearly uniform.\n   Cross-sectional view into a solenoid. The magnetic field inside is straight except at the ends. Red dashed lines indicate the path chosen for use in Ampère\u0026rsquo;s law. .$\\odot$ and .$\\otimes$ are electric current direction (in the wire loops) out of the page and into the page.\n $$\\int_c^d \\vec B \\cdot d \\vec l = Bl_{cd}$$\n   With .$n = N/l$ is number of loops per unit length we can simplify to $$B = \\mu_0 nI$$ Now, we see that the field does not depend on position within the solenoid, so .$\\vec B$ is uniform.  This is strictly true only for an infinite solenoid, but it is a good approximation for tightly wound real ones for points not close to the ends.    28.6 Biot-Savart Law #   A current .$I$ flowing in any path can be considered as many tiny current elements, such as .$d \\vec l$  Then, .$d\\vec B$ at any point .$P$ in space due to this element of current is given by Biot-Savart law: $$d\\vec B = \\frac{\\mu_0 I}{4\\pi} \\frac{d\\vec l \\times \\hat r}{r^2} = \\frac{\\mu_0 I}{4\\pi} \\frac{dl \\sin\\theta}{r^2}$$ .$\\vec r$ is the displacement vector from the element .$d \\vec l$ to the point .$P$ .$\\hat r$ is the unit vector in the direction .$\\vec r$ .$\\theta$ is the angle between .$d\\vec l$ and .$\\vec r$      Biot-Savart Law The field at P due to current element .$I d\\vec l$ is .$d \\vec B = (\\mu_0 I/4\\pi)(d\\vec l \\times \\hat r/r^2)$\n    An important difference between the Biot-Savart law and Ampère\u0026rsquo;s law is that the later, .$\\oint \\vec B \\cdot d\\vec l = \\mu_0 I_\\text{encl}$, .$\\vec B$ is not necessarily due only to the current enclosed by the path of integration. But in the Biot-Savart law the field .$d\\vec B$ is due only, and entirely, to the current element .$I d\\vec l$ \u0026ndash; that is, to find the total .$\\vec B$ at any point in space, it is necessary to include all currents.  Biot-Savart strategy for finding a magnetic field\n Select some tiny piece of wire .$d \\vec l$ and draw the vector .$\\vec r$ pointing from said piece to the location at which you\u0026rsquo;re finding the magnetic field Using Biot-Savart, calculate the magnitude and direction of the infinitesimal magnetic field .$d\\vec B$ generated by that piece Add up all those magnetic field contributions by integrating over the wire, using vector components if needed.   Straight Wire #  $$B = \\frac{\\mu_0 I}{4\\pi}\\int_{y =-\\infty}^{+\\infty} \\frac{dy \\sin\\theta}{r^2}$$ $$dy = dl; r^2 = R^2 + y^2$$ $$dy = \\dots = \\frac{r^2 d\\theta}{R}$$ $$B = \\frac{\\mu_0 I}{4\\pi}\\frac{1}{R}\\cdot \\bigg[-\\cos\\theta\\bigg]_{\\theta = 0}^\\pi $$ $$\\dots = B = \\frac{\\mu_0 I}{2\\pi R}$$   Current Loop #  $$dB = \\frac{\\mu_0 I dl}{4\\pi r^2}$$ $$d\\vec l \\perp \\vec r; \\vert d\\vec l \\times \\hat r \\vert = dl$$ $$B = \\int dB \\cos \\phi = \\int dB \\frac{R}{r}$$ $$\\dots = \\int dB \\frac{R}{(R^2 + x^2)^{\\frac{1}{2}}}$$ $$\\dots = \\frac{\\mu_0 I}{4\\pi}\\frac{R}{(R^2 + x^2)^{\\frac{3}{2}}} \\bigg[L\\bigg]_{L = 2\\pi R}$$ $$\\dots = \\frac{\\mu_0 I}{2R}$$ Quarter Wire Segment #  $$dB = \\frac{\\mu_0 I}{4\\pi}dl$$ $$B = \\frac{\\mu_0 I}{4\\pi} \\bigg[L\\bigg]_{L =\\frac{1}{4}\\cdot 2\\pi R}$$ $$\\dots = \\frac{\\mu_0 I}{8 R}$$\n  28.6.1 Magnetic Dipole Field #   Recall that a magnetic dipole is .$\\mu = NIA$ (number of loops, current, and area of coil) The magnetic field produced by magnetic dipoles is $$B = \\frac{\\mu_0 IR^2}{2(R^2 + x^2)^{\\frac{3}{2}}}$$ This can be written in tirms of the magnetic dipole .$\\mu = IA = I\\pi R^2$ for one loop: $$B = \\frac{\\mu_0}{2\\pi} \\frac{\\mu}{(R^2 +x^2)^{\\frac{3}{2}}}$$ and at distances far from the loop .$x \\gg R$ this becomes $$B \\approx \\frac{\\mu_0}{2\\pi} \\frac{\\mu}{x^3}$$     28.7 Magnetic Field Due to a Single Moving Charge #   Realize that Biot-Savart works only when considering constant currents that do not change in time significantly over a significant length of wire Additionally, the law is difficult to confirm experimentally:  Particles would shoot out of the field before they (and thus the field) could be measured for any significant .$B$.  If .$v$ is slow enough to be measured, .$B$ is small enough it\u0026rsquo;s going to be drowned out by experimental noise   From the particles frame, it\u0026rsquo;s at rest (not moving wrt itself). And since it\u0026rsquo;s at rest, it shouldn\u0026rsquo;t create a field. However, it\u0026rsquo;s moving because it\u0026rsquo;s creating a field!  Einstein explains this with special relativity Observers in two different reference frames, moving relative to each other, will not observe the same .$\\vec E$ and .$\\vec B$ fields        What see from the perspective other than the particle: The magnetic field at one single instant due to a single positive charge .$q$ moving at velocity .$\\vec v$.\n 28.8 Magnetic Materials—Ferromagnetism (not covered) #   Magnetic fields are produced by (1) magnets and (2) electric currents Ferromagnetism: Materials that are magnetic  At a small enough resolution (less than 1mm areas!), domains exist which behave like tiny magnets \u0026ndash; they have two poles The more domains that are aligned in one direction, the stronger the magnetic field   These domains can be moved around (through dropping or hammering the magnet) Heating also reduces magnetism \u0026ndash; increasing temp increases the random thermal motion of atoms  Above the Curie Temperature (1043K for iron), a magnet cannot be made at all As a consequence, at lower temperatures, some materials are magnetic       (a) An unmagnetized piece of iron is made up of domains that are randomly arranged. Each domain is like a tiny magnet; the arrows represent the magnetization direction, with the arrowhead being the N pole. (b) In a magnet, the domains are preferentially aligned in one direction (down in this case), and may be altered in size by the magnetization process.\n    Today, we believe that all magnetic fields come from electric currents  Electrons produce a (tiny) magnetic field, as if they and their electric charges were spinning about their own additional axes   Realize that while .$\\vec B$ lines form closed loops, .$\\vec E$ lines go from a positive to negative electron  28.9 Electromagnets and Solenoids—Applications (not covered) #    Solenoids act like magnets; they have poles (determined by the right hand rule)\n  Magnetic field of a solenoid. The north pole of this solenoid, thought of as a magnet, is on the right, and the south pole is on the left.\n   If a piece of iron is placed inside a solenoid, the magnetic field is increased greatly\n The domains of the iron are aligned by the magnetic field produced by the current; that is, the iron becomes a magnet. This system of the iron-core solenoid is called an electromagnet The resulting magnetic field is the sum of the field due to the solenoid\u0026rsquo;s current and the field due to the iron, and can be hundreds or thousands of times larger than the field due to the current alone     The alloys of iron used in electromagnets acquire and lose their magnetism quite readily when the current is turned on or off, and so are referred to as “soft iron.” (It is “soft” only in a magnetic sense.) Soft iron is usually used in electromagnets so that the field can be turned on and off readily.    Iron that holds its magnetism even when there is no externally applied field is called “hard iron.” Hard iron is used in permanent magnets. Whether iron is hard or soft depends on heat treatment, type of alloy, and other factors.     Sometimes an iron core is not present—the magnetic field then comes only from the current in the wire loops.  A large field .$B$ in this case requires a large current .$I$ which produces a large amount of waste heat since .$P = I^2 R$.   But if the current-carrying wires are made of superconducting material kept below the transition temperature then very high magnetic fields can be produced, and no electric power is needed to maintain the large current in the superconducting coils.  Note that energy is required to refrigerate the coils at the low temperatures where they superconduct.    28.10 Magnetic Fields in Magnetic Materials; Hysteresis (not covered) #   The solenoid field is produced just .$n$ loops per unit length is .$B_0 = \\mu_0 n I$ If a solenoid contains a ferromagnetic material (e.x. iron), then we need to consider it\u0026rsquo;s field .$B_M$ produced in our total field calculation: $$\\vec B = \\vec B_0 + \\vec B_M$$  Often, .$B_M \\gg B_0$   We can also write this equation as $$B = \\mu n I$$  .$\\mu$ is the magnetic permeability (not electric dipole moment!) However, while .$\\mu$ is a characteristic of the material, it is not constant for ferromagnetic materials; rather, it depends on the value of the “external field” .$B_0$ .$\\mu \\gg \\mu_0$ for ferromagnetic materials    "},{"id":45,"href":"/physics-7b/29/","title":"29: Electromagnetic Induction \u0026 Faraday's Law","section":"Physics 7B","content":"29–1 Induced EMF #   A changing magnetic field induces an emf  That is, changing .$\\vec B$, not .$\\vec B$ itself, induces current Constant magnetic fields produce no current in a conductor This process is called electromagnetic induction   It doesn\u0026rsquo;t matter if the magnet or coil moves, only that there is relative motion between the two    (a) A current is induced when a magnet is moved toward a coil, momentarily increasing the magnetic field through the coil. (b) The induced current is opposite when the magnet is moved away from the coil (.$\\vec B$ decreases). In (c), no current is induced if the magnet does not move relative to the coil. It is the relative motion that counts here: the magnet can be held steady and the coil moved, which also induces an emf.\n 29–2 Faraday\u0026rsquo;s Law of Induction; Lenz\u0026rsquo;s Law #   EMF is proportional to the rate of change of the magnetic flux .$\\Phi_B$ passing through the circuit or loop with area .$A$  Given a uniform magnetic field .$\\vec B$ we write $$\\Phi_B = B_\\perp A = BA \\cos\\theta = \\vec B \\cdot \\vec A$$    For non-uniform fields, we need to integrate: $$\\Phi_B = \\int \\vec B \\cdot d \\vec A$$     The unit of magnetic flux is the tesla-meter, called the weber: .$\\text{1 Wb = 1 T$\\cdot$ m$^2$}$ Faraday\u0026rsquo;s law of induction  The emf .$\\mathscr{E}$ induced in a circuit is equal to the rate of change of magnetic flux through the circuit: $$\\mathscr{E} = -N\\frac{d\\Phi_B}{dt}$$  .$N$ is the number of loops closely wrapped so the flux passes through each     Lenz\u0026rsquo;s Law  A current produced by an induced emf creates a magnetic field that opposes the original change in magnetic flux  Faraday\u0026rsquo;s law is negative accordingly   Realize that we know have to magnetic fields:  The changing magnetic field or flux that induces the current, and The magnetic field produced by the induced current (all currents produce a magnetic field) which opposes the charge in the first   Note: The magnetic field created by induced current opposes change in external flux, not necessarily opposing the external field   It is important to note that an emf is induced whenever there is a change in flux through the coil \u0026ndash; this can be done in three ways:  Changing the magnetic field Changing the area .$A$ of the loop in the field Changing the loop\u0026rsquo;s orientation .$\\theta$ wrt the field    Problem Solving \u0026ndash; Lenz\u0026rsquo;s Law #  Lenz\u0026rsquo;s law is used to determine the direction of the (conventional) electric current induced in a loop due to a change in magnetic flux inside the loop. (The loop may already be carrying its own ordinary current.) To produce an induced current you need (1) a closed conducting loop, and (2) an external magnetic flux through the loop that is changing in time.\n Determine whether the magnetic flux .$\\Phi_B = \\vec B \\cdot \\vec A$ inside the loop is decreasing, increasing, or unchanged. The magnetic field due to the induced current: (a) points in the same direction as the external field if the flux is decreasing; (b) points in the opposite direction from the external field if the flux is increasing; or (c) is zero if the flux is not changing. Once you know the direction of the induced magnetic field, use the right hand rule to find the direction of the induced current that would give this induced .$\\vec B$ Always keep in mind that there are two magnetic fields: (1) an external field whose flux must be changing if it is to induce an electric current, and (2) a magnetic field produced by the induced current. If a wire is already carrying an electric current, the total current while the magnetic field is changing will be the algebraic sum of the original current and the induced current.   29–3 EMF Induced in a Moving Conductor #   If a conductor begins to move in a magnetic field, an emf is induced  We can use Faraday\u0026rsquo;s law and kinematics to derive an equation: $$\\mathscr{E} = \\frac{d\\Phi_B}{dt} = \\frac{B dA}{dt} = \\frac{B (l\\cdot v\\ dt)}{dt} = Blv$$  .$v$ is the speed of the conductor .$dA = l\\ dx = lv\\ dt$ is the change in area over time .$t$   Be careful! This is a generalization where .$B, l, v$ are mutually perpendicular  If they aren\u0026rsquo;t, we use the component of each that are mutually perpendicular     An emf induced on a conductor moving ina magnetic field is sometimes called a motional emf We could also derive this using our force eq from ch27: $$\\vec F = q\\vec v \\times \\vec B$$\n When the conductor moves with .$v$, as do its electrons Since .$\\vec \\perp \\vec B$, each electron feels force .$F = qvB$  The direction determined by the right hand rule (red)   If the rod is not in contact with the conductor, electrons would collect at the upper end leaving the lower positive  Therefore, there must be an induced emf!   If the rod is in contact with the conductor, the electrons will flow into the conductor and there will be a clockwise current in the loop  To calculate emf, we determine the work .$W$ needed to move a charge .$q$ from one end of the rod to the other against this potential difference: $$W = F \\times d = (qvB) \\times (l)$$ $$\\mathscr{E} = W/q = qvBl/q = Blv$$       (a) A conducting rod is moved to the right on the smooth surface of a U-shaped conductor in a uniform magnetic field .$\\vec B$ that points out of the page. The induced current is clockwise. (b) Force on an electron in the metal rod (moving to the right) is upward due to .$\\vec B$ pointing out of the page. Hence electrons can collect at the top of the rod, leaving .$+$ charge at the bottom.\n     29–4 Electric Generators #   Electric generators produce electricity by transforming mechanical energy into electric energy  Also called dynamos Opposite of what a motor does   Consists of many wires wound around an armature that can rotate in a magnetic field  This axel is turned by mechanical means (belt, steam, water falling, etc.) and an emf is induced in the rotating coil An ac current is thus the output of a generator      An ac generator     Each brush is fixed and presses against a continuous slip ring that rotates with the armature If the armature is rotating clockwise; then, .$\\vec F = q \\vec v \\times \\vec B$ applied to a charged particles in the wire  Lenz\u0026rsquo;s law tells us that the (conventional) current in the wire .$b$ on the armature is outwards, towards us, thus, the current is outwards, through brush .$b$   After one-half revolution, wire .$b$ will be where .$a$ is now and the current at .$b$ will be inwards. Thus, the current produced is alternating! If the loop is made to rotate in a uniform field .$\\vec B$ with constant angular velocity .$\\omega$, the emf produced is $$\\mathscr{E} = - \\frac{d\\Phi_B}{dt} = - \\frac{d}{dt}\\int \\vec B \\cdot d \\vec A = -\\frac{d}{dt}\\big[BA\\cos\\theta\\big]$$  .$A$ is the area of the loop .$\\theta$ is the angle between .$\\vec B$ and .$\\vec A$   Since .$\\omega = d\\theta/dt \\Longrightarrow \\theta = \\theta_0 + \\omega t$, we choose .$\\theta_0 = 0$ so $$\\mathscr{E} = - N BA \\frac{d}{dt}(\\cos(\\omega t)) = N BA \\omega \\sin (\\omega t)$$  .$N$ is the number of loops in the rotating coil, assumed to be .$1$ unless stated otherwise Thus, the output wave is sinusoidal  Amplitude .$\\mathscr{E}_0 = NBA\\omega$ .$\\mathscr{E}_\\text{rms} = \\frac{\\mathscr{E}_0}{\\sqrt{2}}$ .$f = \\omega / 2\\pi$  .$\\text{60 Hz}$ for USA + Canada, .$\\text{50 Hz}$ for EU         dc generators  Same for ac, except the slip rings are replaced by split-ring commutators (just like a dc motor) The curve output becomes more smooth by placing a capacitor in parallel with the output  More commonly, is the use of many armature windings A capacitor tends to store charge and, if the time constant .$RC$ is long enough, helps to smooth out the voltage as shown in the figure to the right.         (a) A dc generator with one set of commutators, and (b) a dc generator with many sets of commutators and windings.\n   29–6 Transformers and Transmission of Power #   Transformer: Device used to increase or decrease an ac voltage  Made up of two coils know as the primary and secondary coil  Primary is the input, secondary is the output These can be interwoven (with insulated wire); or can be linked by an iron core that\u0026rsquo;s laminated   We assume energy losses (in resistance and hysteresis) can be ignored   When an ac voltage is applied to the primary coil, the changing magnetic field it produces will induce an ac voltage of the same .$f$requency in the secondary coil However, secondary voltage, .$V_S$, changes according to the number of turns or loops in each coil: $$V_S = N_S \\frac{d\\Phi_B}{dt}$$  .$N_S$ is the number of turns in the secondary coil .$\\Phi_B/dt$ is the rate at which the magnetic flux changes through each coil   The input voltage, .$V_P$, is related to this rate too: $$V_P = N_P \\frac{d\\Phi_B}{dt}$$  .$N_P$ is the number of turns in the primary coil This follows because the changing flux produce a back emf, .$N_P\\ d\\Phi_B / dt$, in the primary that exactly balances the applied voltage .$V_P$  This is because of Kirchhoff\u0026rsquo;s rules This is only the case if the resistance of the primary can be ignored (which we assume)     Then, we can divide these two equations, assuming little or no flux loss, to find $$\\frac{V_S}{V_P} = \\frac{N_S}{N_P}$$  .$V_S$ and .$V_P$ can be the rms or peak values for both Step-up (.$N_S \u0026gt; N_P$) increase voltage; step-down (.$N_S \u0026lt; N_P$) decrease This is called the transformer equation which tells us how the secondary (output) is related to the primary (input) DC voltages don\u0026rsquo;t work in a transformer because there\u0026rsquo;d be no change in magnetic flux   But muh conservation of energy!  Power output is essentially the power input since transformers tend to be 99%+ efficient  The little amount of energy lost is to heat   Since .$P = IV$ and .$P_P \\approx P_S$, we have $$I_P V_P = I_S V_S \\Longrightarrow \\frac{I_S}{I_P} = \\frac{V_S}{V_P} = \\frac{N_P}{N_S}$$    29–7 A Changing Magnetic Flux Produces an Electric Field #   A changing magnetic flux produces an electric field  This applies not only to wires and other conductors, but is a general result that applies to any region in space An electric field will be produced (induced) at any point in space where theres is a changing magnetic field These electric fields are not static, as are the electric fields due to electric charges at rest    Faraday\u0026rsquo;s Law \u0026ndash; General Form #  $$ \\mathscr{E} = \\oint \\vec E \\cdot d \\vec l = - \\frac{d\\Phi_B}{dt}$$\n The first two terms come from the fact that the emf .$\\mathscr{E}$ induced in a circuit is equal to the work done per unit charge by the electric field This is then combined with the relation of a changing magnetic flux to the the field it produces  Forces Due to Changing .$\\vec B$ are non-conservative #   Electric field lines produced by a changing magnetic field are continuous; they form closed loops That is, while a conservative force (such as a electrostatic magnetic field) integrated over a line integral is zero .$\\big(\\oint \\vec E_\\text{electrostatic} \\cdot d \\vec l = 0\\big)$, the electric field created by an magnetic field is not zero: .$\\oint \\vec E_\\text{non-static} \\cdot d \\vec l = - \\frac{d\\Phi_B}{dt}$ This implies that forces due to changing magnetic fields are non-conservative and we can\u0026rsquo;t define a potential energy (or even a potential function!) at a given point in space  "},{"id":46,"href":"/physics-7b/30/","title":"30: Inductance, Electromagnetic Oscillations, \u0026 AC Circuits","section":"Physics 7B","content":"30.1 Mutual Inductance #   When two wires are near one another, they induce an emf in one another  This emf is proportional to the rate of change of the flux passing through it The flux passing through the coil is generated by the other coil\u0026rsquo;s current     If the two coils are held in place then the total flux is proportional to the mutual inductance $$M = \\frac{N_2 \\Phi_{21}}{I_1}$$  .$\\Phi_{21}$ is the total flux passing through coil 2 (induced by the current in coil 1, .$I_1$) .$M$ depends on “geometric” factors such as the size, shape, number of turns, and relative positions of the two coils, and whether a ferromagnetic material is present The SI unit for mutual inductance is the Henry; .$\\text{1 H = 1 V$\\cdot$s/A = 1$\\Omega \\cdot$s}$       A changing current in one coil will induce a current in the second coil.\n    The emf induced in coil 2 due to a change in current 1 can be written now as $$\\mathscr{E_2} = -N_2 \\frac{d\\Phi_{21}}{dt} = -M \\frac{dI_1}{dt}$$  30.2 Self-Inductance; Inductors #   This concept also applies to isolated coils too  When a changing current passes through a coil (or solenoid), a changing magnetic flux is produced inside the coil, and this in turn induces an emf in that same coil. This induced emf opposes the change in flux (Lenz\u0026rsquo;s law).  If the current through the coil is increasing, the increasing magnetic flux induces an emf that opposes the original current and tends to retard its increase. If the current is decreasing in the coil, the decreasing flux induces an emf in the same direction as the current, thus tending to maintain the original current.   If this inductance (coil) is in a circuit, it thus can provide a source of emf, in addition to any battery present or other sources of emf.   Self-inductance .$L$ and the emf it induces is given by $$L = \\frac{N\\Phi_B}{I}$$  $$\\mathscr{E} = -N \\frac{d\\Phi_B}{dt} = -L \\frac{dI}{dt}$$    An ac circuit always contains some inductance, but often it is quite small unless the circuit contains a coil of many loops or turns. A coil that has significant self-inductance .$L$ is called an inductor  Inductance can serve a useful purpose in certain circuits, but it\u0026rsquo;s often just a nuisance in a circuit. If inductance is large, the change in the current will be small, and therefore the current itself if it is ac will be small.  The greater the inductance, the less the ac current. An inductance thus acts something like a “resistance” to impede the flow of alternating current.      Solenoid Self-Inductance #   The magnetic field of a solenoid is .$B = \\mu_0 nI$ where .$n = N/l$ Thus, the flux is .$\\Phi_B = BA = \\mu_0 NIA/l$ so we can derive $$L = \\frac{N \\Phi_B}{I} = \\frac{\\mu_0 N^2 A}{l}$$  30.3 Energy Stored in a Magnetic Field #   When an inductor with inductance .$L$ is carrying current .$I$ which is changing at the rate .$dI/dt$, energy is being supplied to the inductor at the rate $$P = I \\mathscr{E} = LI \\frac{dI}{dt}$$ Thus, the work needed to increase the current in an inductor from zero to some .$I$ is $$W = \\int P dt = \\int_0^I LI\\ dI = \\frac{1}{2}LI^2$$  This is also the (potential) energy stored in a conductor when it is carrying current .$I$   Just as the energy stored in a capacitor can be considered to reside in the electric field between its plates, so the energy in an inductor can be considered to be stored in its magnetic field.  E.x. the energy stored in a solenoid is $$U = \\frac{1}{2}LI^2 = \\frac{1}{2} \\bigg( \\frac{\\mu_0 N^2 A}{l} \\bigg)\\bigg( \\frac{Bl}{\\mu_0 N}\\bigg)^2 = \\frac{1}{2} \\frac{B^2}{\\mu_0}Al$$ We can think of this energy as residing in the volume enclosed by the windings; .$Al$ Then the energy density (energy per unit volume) is $$u = \\text{energy density} = \\frac{1}{2}\\frac{B^2}{\\mu_0}$$  This equation is analogous to that for an electric field, .$ \\frac{1}{2}ϵE^2$      30.4 LR Circuits #    (a) LR circuit; (b) growth of current when connected to battery.\n  At the instant the switch connecting the battery is closed, the current starts to flow.  It is opposed by the induced emf in the inductor because of the changing current. As soon as current starts to flow, there is also a voltage drop across the resistance; .$V = IR$ Hence, the voltage drop across the inductance is reduced and the current increases less rapidly as it approaches .$I_0 = V_0 / R$ as seen in (b)   The emfs in the circuit are the battery voltage .$V_0$ and the emf .$\\mathscr{E} = -L (dI/dt)$ in the inductor (which opposes the current)  Hence, we can find sum of potential charges around the loop where .$I$ is the current at any instance by using the loop rule: $$V_0 - IR - L \\frac{dI}{dt} = 0 \\Longrightarrow L \\frac{dI}{dt} + RI = V_0$$ We can integrate the later term from .$t = 0, I = 0$ to a later time .$t$ when current is .$I$: $$\\int_0^I \\frac{dI}{V_0 - IR} = \\int_0^t \\frac{1}{L}dt \\Longrightarrow - \\frac{1}{R} \\ln \\bigg( \\frac{V_0 - IR}{V_0} \\bigg) \\frac{t}{L}$$ $$\\dots \\Longrightarrow \\frac{V_0 - IR}{V_0} = e^{- \\frac{Rt}{L}} \\Longrightarrow I = \\frac{V_0}{R}(1-e^{-t/\\tau})$$  .$\\tau = \\frac{L}{R}$ is the time constant: the time required for the current .$I$ to reach 63% of it\u0026rsquo;s maximum value .$V_0/R$       When the battery is removed from the circuit\u0026hellip;  Voltage .$V_0$ becomes zero, so .$L \\frac{dI}{dt} + RI = 0$ We can integrate this and solve for .$I$ $$\\int_{I_0}^I \\frac{dI}{I} = - \\int_0^t \\frac{R}{L} dt$$ $$\\dots \\Longrightarrow I = I_0 e^{-t/\\tau}$$ - .$\\tau = L/R$ is the time it takes current to decrease to 37% of it\u0026rsquo;s initial       30.5 LC Circuits and Electromagnetic Oscillations #   Any electric circuit can contain the three basic components: resistance, capacitance, and inductance, in addition to a source of emf.    Suppose the adjacent circuit is initially charged so one plate has charge .$Q_0$ and the other .$-Q_0$ and that the potential difference is .$V = Q/C$ At .$t = 0$ the capacitor immediately begins to discharge. As it does so, the current .$I$ through the inductor increases. We now apply Kirchhoff\u0026rsquo;s loop rule (sum of potential changes around a loop is zero): $$-L \\frac{dI}{dt} + \\frac{Q}{C} = 0$$     Because charge leaves the positive plate on the capacitor to produce the current .$I = dQ/dt$ so we can rewrite the equation as $$\\dots \\Longrightarrow \\frac{d^2 Q}{dt^2} + \\frac{Q}{LC} = 0 \\Longrightarrow Q = Q_0 \\cos(\\omega t + \\phi)$$  .$Q_0$ and .$\\phi$ are constants that depend on the initial conditions .$\\omega t + \\phi$ is in radians.  Because we have .$\\phi$, the amplitude isn\u0026rsquo;t .$Q_0$ unless .$\\phi = 0$   .$\\omega = 2\\pi f = \\sqrt{ \\frac{1}{LC} }$     We can then plug in our sinusoidal equation to find a function for .$I$: $$I = -\\frac{dQ}{dt} = \\omega Q_0 \\sin(\\omega t + \\phi)$$ $$\\dots \\Longrightarrow I_0 \\sin(\\omega t + \\phi)$$ Energy stored in capacitor: $$U_E = \\frac{1}{2}\\frac{Q^2}{C} = \\frac{Q_0^2}{2C}\\cos^2(\\omega t + \\phi)$$ Energy stored in magnetic field: $$U_B = \\frac{1}{2}LI^2 = \\frac{Q_0^2}{2C}\\sin^2(\\omega t + \\phi)$$ Total energy stored: $$U = U_B + U_E = \\frac{Q_0^2}{2C}$$     Period: .$T = \\frac{1}{f} = \\frac{2\\pi}{\\omega} = 2\\pi \\sqrt{LC}$\n   "},{"id":47,"href":"/math-53/trig/","title":"Trig Identities","section":"Math 53","content":"Reciprocal Identities #  $$\\sin(x)=\\frac{1}{\\csc(x)}$$  $$\\cos(x)=\\frac{1}{\\sec(x)}$$  $$\\tan(x)=\\frac{\\sin(x)}{\\cos(x)}=\\frac{1}{\\cot(x)}$$   Pythagorean Identities #  $$\\sin^2(x) + \\cos^2(x) = 1$$  $$1+\\tan^2(x) = \\sec^2(x)$$  $$1+\\cot^2(x)=\\csc^2(x)$$   Cofunction Identities #  $$\\sin\\Big(\\frac{\\pi}{2}-x\\Big) = \\cos(x)$$ $$\\csc\\Big(\\frac{\\pi}{2}-x\\Big) = \\sec(x)$$  $$\\cos\\Big(\\frac{\\pi}{2}-x\\Big) = \\sin(x)$$ $$\\sec\\Big(\\frac{\\pi}{2}-x\\Big) = \\csc(x)$$  $$\\tan\\Big(\\frac{\\pi}{2}-x\\Big) = \\cot(x)$$ $$\\cot\\Big(\\frac{\\pi}{2}-x\\Big) = \\tan(x)$$   Even/Odd Identities #  $$ \\sin(-x) = -\\sin(x)$$ $$ \\csc(-x) = -\\csc(x)$$  $$ \\cos(-x) = \\cos(x)$$ $$ \\sec(-x) = \\sec(x)$$  $$ \\tan(-x) = - \\tan(x)$$ $$ \\cot(-x) = -\\cot(x)$$   Bonus fact: .$\\int_{-A}^A \\text{[odd]}(x)\\ dx = 0$; .$\\int_{-A}^A \\text{[even]}(x)\\ dx = \\int_0^A \\text{[even]}(x)\\ dx$  Sum and Difference Formulas #  $$ \\sin(u \\pm v) = \\sin(u) \\cdot \\cos(v) \\pm \\cos(u) \\cdot \\sin(v)$$ $$ \\cos(u \\pm v) = \\cos(u) \\cdot \\cos(v) \\pm \\sin(u) \\cdot \\sin(v)$$ $$\\tan(u \\pm v) = \\frac{\\tan(u) \\pm \\tan(v)}{1 \\mp \\tan(u) \\tan(v)}$$\nDouble-Angle Formula #  $$ \\sin(2u) = 2 \\sin(u) \\cos(u)$$  $$ \\cos(2u) = 2 \\cos^2(u) - 1$$ $$ \u0026hellip; = 1- 2 \\sin^2(u) $$ $$ \u0026hellip; = \\cos^2(u) - \\sin^2(u) $$  $$ \\tan(2u) = \\frac{2 \\tan(u)}{1 - \\tan^2(u)}$$   Power Reducing Formulas #  $$\\sin^2(u) = \\frac{1 - \\cos(2u)}{2}$$  $$\\cos^2(u) = \\frac{1 + \\cos(2u)}{2}$$  $$\\tan^2(u) = \\frac{1 - \\cos(2u)}{1 + \\cos(2u)}$$   Sum to Product Formulas #  $$\\sin(u) + \\sin(v) = 2\\sin\\bigg(\\frac{u + v}{2}\\bigg) \\cos\\bigg(\\frac{u - v}{2}\\bigg)\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $$ $$\\sin(u) - \\sin(v) = 2\\cos\\bigg(\\frac{u + v}{2}\\bigg) \\sin\\bigg(\\frac{u - v}{2}\\bigg)\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $$ $$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\cos(u) + \\cos(v) = 2\\cos\\bigg(\\frac{u + v}{2}\\bigg) \\cos\\bigg(\\frac{u - v}{2}\\bigg)$$ $$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\cos(u) - \\cos(v) = -2\\sin\\bigg(\\frac{u + v}{2}\\bigg) \\sin\\bigg(\\frac{u - v}{2}\\bigg)$$\nProduct to Sum Formulas #  $$\\sin(u) \\sin(v) = \\frac{1}{2}\\Big[\\cos(u - v) - \\cos(u + v)\\Big]\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $$ $$\\sin(u) \\cos(v) = \\frac{1}{2}\\Big[\\sin(u + v) + \\sin(u - v)\\Big]\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $$ $$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\cos(u) \\sin(v) = \\frac{1}{2}\\Big[\\sin(u + v) - \\sin(u - v)\\Big]$$ $$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\cos(u) \\cos(v) = \\frac{1}{2}\\Big[\\cos(u - v) + \\cos(u + v)\\Big]$$\n"},{"id":48,"href":"/math-53/trig-calc/","title":"Trig Calculus","section":"Math 53","content":"Derivatives #  $$\\frac{d}{dx} \\tan(x) = 1 + \\tan^2(x) = \\sec^2(x)$$ $$\\frac{d}{dx} \\csc(x) = -\\cot(x) \\cdot \\csc(x)$$ $$\\frac{d}{dx} \\sec(x) = \\frac{\\sin(x)}{\\cos^2(x)} = \\tan(x) \\cdot \\sec(x)$$ $$\\frac{d}{dx} \\cot(x) = -\\csc^2(x)$$ $$\\frac{d}{dx} \\log_a(x) = \\frac{1}{x\\cdot \\ln(a)}$$ $$\\frac{d}{dx} a^u = a^x \\cdot \\ln (a) du$$ $$\\frac{d}{dx} \\sin^2(x) = \\sin(2x)$$ $$\\frac{d}{dx} \\cos^2(x) = -\\sin(2x)$$ $$\\frac{d}{dx} \\tan^2(x) = 2\\tan(x)\\cdot \\sec^2(x)$$\nIntegrals #  $$\\int a^x dx = \\bigg(\\frac{1}{\\ln(a)}\\bigg) a^x + C $$ $$\\int \\tan(x) dx = -\\ln\\vert \\cos(x) \\vert + C$$ $$\\int \\tan^2(x) dx = \\tan(x) - x + C$$ $$\\int \\csc(x) dx = \\ln\\vert \\csc(x) - \\cot(x)\\vert + C = \\ln \\bigg\\vert \\tan\\bigg(\\frac{x}{2}\\bigg)\\bigg\\vert + C$$ $$\\int \\csc^2(x) dx = -\\cot(x) + C$$ $$\\int \\sec(x) dx = -\\ln\\vert \\sec(x) + \\tan(x)\\vert + C$$ $$\\int \\sec^2(x) dx = \\tan(x) + C$$ $$\\int \\cot(x) dx = \\ln\\vert \\sin(x) \\vert + C$$ $$\\int \\cot^2(x) dx = -\\cot(x) - x + C$$ $$\\int \\frac{1}{\\sin(ax)\\cos(ax)} = \\frac{1}{a} \\ln\\vert\\tan(ax)\\vert + C$$ $$\\int \\frac{1}{x\\sqrt{x^2-a^2}} dx = \\frac{1}{a} \\sec^{-1}\\bigg( \\frac{\\vert x \\vert}{a}\\bigg) + C$$ $$\\int \\frac{1}{\\sqrt{a^2-x^2}} dx = \\sin^{-1}\\bigg( \\frac{x}{a} \\bigg) + C$$ $$\\int \\frac{1}{a^2 + x^2} dx = \\frac{1}{a} \\tan^{-1}\\bigg( \\frac{x}{a} \\bigg) + C$$\n Many more integrals\nTriangle Sub #  $$\\sqrt{b^2x^2-a^2} \\Longrightarrow x = \\frac{a}{b}\\cdot\\sec\\theta; \\theta \\in [0, \\pi/2), (\\pi/2, \\pi]$$ $$\\sqrt{a^2-b^2x^2} \\Longrightarrow x = \\frac{a}{b}\\cdot\\sin\\theta; \\theta \\in [-\\pi/2, \\pi/2]$$ $$\\sqrt{a^2+b^2x^2} \\Longrightarrow x = \\frac{a}{b}\\cdot\\tan\\theta; \\theta \\in (-\\pi/2, \\pi/2)$$\n"},{"id":49,"href":"/ap/huge/","title":"AP Human Geography","section":"AP Notes","content":"The content of these notes are solid, but formatting is not since they\u0026rsquo;re exported from Notion.  🗺️ Unit 1 — Thinking Geographically #  Developing Understanding\n This first unit sets the foundation for the course by teaching students how geographers approach the study of places. Students are encouraged to reflect on the “why of where” to better understand geographic perspectives. Many other high school courses ask students to read and analyze data, but for this course, students also apply a spatial perspective when reading and analyzing qualitative and quantitative data. Students learn the ways information from data sources such as maps, tables, charts, satellite images, and infographics informs policy decisions such as voting redistricting or expanding transportation networks. They also learn about how people influence and are influenced by their environment; the resulting impact on topography, natural resources, and climate; and the differences between and consequences of environmental determinism and possibilism. Finally, students are introduced to the language of geography, learning discipline-specific terminology and applying that language to contemporary, real-world scenarios so they can better study population processes and patterns in the next unit.\n  BIG IDEA 1 Patterns and Spatial Organization (PSO)\n Why do geographers study relationships and patterns among and between places? BIG IDEA 2 Impacts and Interactions (IMP) How do geographers use maps to help them discover patterns and relationships in the world? BIG IDEA 3 Spatial Processes and Societal Change (SPS) How do geographers use a spatial perspective to analyze complex issues and relationships?   1.1 Introduction to Maps #   IMP 1A Geographers use maps and data to depict relationships of time, space, and scale.\n  Learning Objective: Identify types of maps, the types of information presented in maps, and different kinds of spatial patterns and relationships portrayed in maps. Essential Knowledge:  Types of maps include reference maps and thematic maps  reference maps  Serve to display general features of an area Topographic highway, atlas, etc   thematic maps  Server to display single type of information Types:  graduated circle  size of circle conveys quantitative statistic Example    dot  display pattern, distribution, dispersion of data in an area Example    choropleth  display an average value of data in an area Example          Types of spatial patterns represented on maps include absolute and relative distance and direction, clustering, dispersal, and elevation.  maps are a special form of model that depicts information in two dimensions and usually on paper. A model is a simplified generalization of something in real life relative distance (scale)  Scale: The ratio between the size of an area on a map and he actual size of that same area on the earth\u0026rsquo;s surface Scale gives a frame of reference Representation Factor (RF):  1 inch : 250,000 feet   Verbal:  One inch represents 250,000 feet   Visual  |——————|——————| 0 250,000\u0026rsquo; 500,000'     direction  absolute direction:  north south, compass   relative direction:  left right, forward backwards, up down based on perspective in certain location     clustering + dispersal  where groups are (not) centered around density vs concentration:  Density is the amount of an object within a certain area concentration is how these objects are distributed.  Box A the distribution is dispersed. There is a clear cluster of stars in the upper left corner for Box C. Box B has concentrations in the left and right sides Box D has a cluster (though not as clustered as C) in the middle left and one outlier.     elevation  Hight from set point, typically water level     All maps are selective in information; map projections inevitably distort spatial relationships in shape, area, distance, and direction  Maps are 1D representations (projection) of a 2D environment, so they\u0026rsquo;ll inherently have distortion Mercator  shape: fairly accurate area: distorts area near north and south pole direction: turns curves into straight lines   Goode\u0026rsquo;s  shape: accurate area: accurate direction: accurate hard to understand   Goode\u0026rsquo;s  shape: everything slightly distorted outwards from 0\u0026rsquo; 0' area: accurate direction: accurate         1.2 Geographic Data #   IMP 1B Geographers use maps and data to depict relationships of time, space, and scale.\n  Learning Objective: Identify different methods of geographic data collection. Essential Knowledge:  Data may be gathered in the field by organizations or by individuals. Geospatial technologies include geographic information systems (GIS), satellite navigation systems, remote sensing, and online mapping and visualization.  Remote sensing:  Record area from a distance People have used cameras with airplanes, kites, hot-air balloons, etc. for many years Nowadays use satellites Useful for any area that would be otherwise be difficult to travel record   geographic information systems (GIS)  merge mapping software with a database to overlay various data layers on a basic map grid     Spatial information can come from written accounts in the form of field observations, media reports, travel narratives, policy documents, personal interviews, landscape analysis, and photographic interpretation.     1.3 The Power of Geographic Data #   IMP 1C Geographers use maps and data to depict relationships of time, space, and scale.\n  Learning Objective: Explain the geographical effects of decisions made using geographical information. Essential Knowledge:  Geospatial and geographical data, including data and satellite imagery, are used at all scales for personal, business and organizational, and governmental decision making purposes.  Used to measure  climate change pollution spreads of fires military survalliance google maps / personal GPS delivering your packages         1.4 Spatial Concepts #   PSO-1 Geographers analyze relationships among and between places to reveal important spatial patterns.\n  Learning Objective: Define major geographic concepts that illustrate spatial relationships. Essential Knowledge:  Spatial concepts include absolute and relative location, space, place, flows, distance decay, time-space compression, and pattern.  location + place (same thing)  actual position on earth   space  area that is occupied by something can refer to physical and cultural objects on the surface of earth relative space is concerned with where something is in relation to something else and changes constantly as interrelationships between people, places, and things change absolute space is a measurable area with definite boundaries   site  physical location of a place   situation  location of a place based on its relation to other places   flows + patterns  trends of relationships(?)   distance decay  The declining degree of acceptance of an idea or innovation with increasing time and distance from its point of origin or source. Example: The number of phone calls made decreases with distance. Greater number of migrants settled at the edge of the country closer to the country of origin, compared to the number settled on the opposite edge of the country. The diminishing evidence of cultural traits by a group of people, if the explanation clearly shows a link to the fact that due to migration there is less contact between the migrants and their home country. Explanatory factor behind distance decay relationship (e.g., travel cost, information availability).   time-space compression (decrease in friction of distance)  the increasing sense of connectivity that seems to be bringing people closer together even thought their distances are the same. Space time compression is the solution to distance decay because technology (internet,cell phones) is allowing us to communicate more across longer distances.          1.5 Human–Environmental Interaction #   PSO-1 Geographers analyze relationships among and between places to reveal important spatial patterns.\n  Learning Objective: Explain how major geographic concepts illustrate spatial relationships Essential Knowledge:  Concepts of nature and society include sustainability, natural resources, and land use.  sustainability  the use of the earths renewable and nonrenewable natural resources in ways that ensure resource availability in the future 3 Pillars  Environmental  Having Conservation, Nonrenewable and renewable resources and Preservation   Social  Humans need shelter food and clothing to survive so make resources meet those needs   Economic  Having natural resources; supply and demand     Humans take resources that aren\u0026rsquo;t always needed or they take advantage of the resources that we have. But there is a lot of supply and demand and humans don\u0026rsquo;t know how to balance the resources.   natural resources  Resources that come directly from Earth Need to be used in moderation if they aren\u0026rsquo;t renewable   land use  to be sustainable, land has to be used efficiently to get enough value but not worked too hard to the point where it looses nutrients     Theories regarding the interaction of the natural environment with human societies have evolved from environmental determinism to possibilism.  Environmental determinism : The idea that physical environment caused social development Possibilism: (Replaces Environmental Determinism) The idea that environment may limit some human actions, but people have the ability to adapt to their environment       1.6 Scales of Analysis #   PSO-1 Geographers analyze relationships among and between places to reveal important spatial patterns.\n  Learning Objective: Define scales of analysis used by geographers. Essential Knowledge:  Scales of analysis is how information is clustered  global — worldwide regional — groups of states, e.g. North America national — single state, e.g. Wisconsin local — city or town, e.g. Middleton   Scale is what infomation is shown    Learning Objective: Explain what scales of analysis reveal. Essential Knowledge:  Patterns and processes at different scales reveal variations in, and different interpretations of, data.  To understand individual, local, regional, national, and global interrelationships, geographers compare and contrasts different scale views.     Downsides to large scale      1.7 Regional Analysis #   SPS 1 Geographers analyze complex issues and relationships with a distinctively spatial perspective\n  Learning Objective: Describe different ways that geographers define regions. Essential Knowledge:  Regions are defined on the basis of one or more unifying characteristics or on patterns of activity.  A region is an area characterized by similarity or by cohesiveness that sets it apart from other areas. Regions allow us to generalize about a common characteristic so we can better group them A region is an area on the earth identified by two common characteristics: physical and political geography. Physical regions are features such as deserts, mountains, and lakes. Political regions by establishing political boundaries like the borders of countries. Some regions are based on culture (language or religion), while physical geography defines others.   Types of regions include formal, functional, and perceptual/vernacular  Formal (Uniform)  Region with high level of consistency in a certain cultural or physical attribute E.g.  Dairying region of North America Political boundaries Tropical Regions     Functional (Nodal)  A region with a node, sometimes a hearth, surrounded by interconnecting linkages. Usually connections relate to trade, communication, transportation, etc. E.g.  Cell towers Newspaper Circulation School District Metropolitan Area     Perceptual (Vernacular)  A region defined by feelings and prejudices that may or may not be true. A construct of one\u0026rsquo;s mental map E.g.  Bible belt South       Regional boundaries are transitional and often contested and overlapping.  Regions of the world can and do overlap such as the areas of Southeast Asia and Asia. Regions also have transitional boundaries like between North Africa and Sub-Saharan Africa   Geographers apply regional analysis at local, national, and global scales  There is not total agreement, however, among geographers on how all regions are defined.  One geographer may place Chad in the region of North Africa, and another would classify Chad as part of Central Africa. Geographers will also use two different terms to describe the same area; the Middle East and Southwest Asia, for example.         👣 Unit 2 — Population and Migration Patterns and Processes #  Developing Understanding\n This unit addresses the patterns associated with human populations. Populations may increase or decrease as a result of a combination of natural changes (births and deaths) and migration patterns (emigration and immigration). Students examine population distributions at different scales—local, national, regional, and global. Population pyramids demonstrate age-sex structures, revealing the growth or decline of generations and allowing geographers to predict economic needs based on reproductive and aging patterns. Students learn about factors that influence changes in population as well as the long- and short-term effects of those population changes on a place’s economy, culture, and politics. For example, environmental degradation and natural hazards may prompt population redistribution at various scales, which in turn creates new pressures on the environment and on cultural, economic, and political institutions. The study of migration patterns allows students to examine factors contributing to voluntary and forced relocation and the impact of these migrating populations on existing settlements. Combined, the concepts and theories encountered in this unit help students develop connections and transfer their learning in upcoming units to course topics such as cultural patterns, the political organization of space, food production issues, natural resource use, and urban systems.\n  BIG IDEA 1 Patterns and Spatial Organization (PSO)\n How does where and how people live impact global cultural, political, and economic patterns? BIG IDEA 2 Impacts and Interactions (IMP) How does the interplay of environmental, economic, cultural, and political factors influence changes in population? BIG IDEA 3 Spatial Processes and Societal Change (SPS) How do changes in population affect a place’s economy, culture, and politics?   2.1 Population Distribution #   PSO-1 Understanding where and how people live is essential to understanding global cultural, political, and economic patterns.\n  Learning Objective: Identify the factors that influence the distribution of human populations at different scales. Essential Knowledge:  Physical factors (e.g., climate, landforms, water bodies) and human factors (e.g., culture, economics, history, politics) influence the distribution of population.  physical:  humans avoid areas that are  dry  too dry to plant food lack water for crops + regular consumption   wet + hot  combination of rain and heat deplete nutrients from soil typically near equator   cold + high altitude  to rough for easy transportation to cold for crops     places considered too harsh for occupancy have diminished over time people like to go to low-lying areas with fertile soil and temperate climate near a river or ocean is good too    cultural:  economics  history  politics   Factors that illustrate patterns of population distribution vary according to the scale of analysis.  Scale of analysis is the level of detail that a map goes into Demography: study of characteristics of human population, varies according to scale  75% of population live on 5% of land 50% of population live in urban areas Land inhabited called ecumene   most extreme cases occur at small scales  countries vary in size so aren\u0026rsquo;t great for seeing details, but they\u0026rsquo;re better than state        Learning Objective: Define methods geographers use to calculate population density. Essential Knowledge:  The three methods for calculating population density are arithmetic, physiological, and agricultural.  Artihmetic / crude - all people / all land Physiological - all people / agricultural land Agricultural - all farmers / agricultural land     Learning Objective: Explain the differences between and the impact of methods used to calculate population density. Essential Knowledge:  The method used to calculate population density reveals different information about the pressure the population exerts on the land.  High agricultural density implies that farmers aren\u0026rsquo;t extracting the most value from there land (better farmers need less farmers to fully use there land) Low agricultural density implies farmers are very efficient and probably developed High physiological density implies that there is either little farmland or that agricultural land is being used by more and may reach its output limit sooner than a country that has a lower density High arithmetic density implies there are a lot of people in a small area, aka urbanization      2.2 Consequences of Population Distribution #   PSO-2 Understanding where and how people live is essential to understanding global cultural, political, and economic patterns.\n  Learning Objective: Explain how population distribution and density affect society and the environment. Essential Knowledge:  Population distribution and density affects political, economic, and social processes, including the provision of services such as medical care.  redistricting / gerrymandering  Results    provision of services such as medical care  those closer to medical services are more likely be able to use them     Population distribution and density affect the environment and natural resources; this is known as carrying capacity  carrying capacity — how many people an area can support on a sustained basis  sustainability       2.3 Population Composition #   PSO-2 Understanding where and how people live is essential to understanding global cultural, political, and economic patterns.\n  Learning Objective: Describe elements of population composition used by geographers. Essential Knowledge:  Patterns of age structure and sex ratio vary across different regions and may be mapped and analyzed at different scales   most extreme cases occur at small scales  countries vary in size so aren\u0026rsquo;t great for seeing details, but they\u0026rsquo;re better than state   age structure  older in retirement areas younger in military / college towns helps predict how much money is needed for social services  old and young (dependent) require more money to support     sex ratio  more male in military training camps     Learning Objective: Explain ways that geographers depict and analyze population composition. Essential Knowledge:  Population pyramids are used to assess population growth and decline and to predict markets for goods and services.  a representation of a country’s population displayed by age and gender groups on a bar graph. Normally shows the % of the total pop in 5-year age brackets with youngest at base of pyramid and oldest at the top. The length of the bar represents the % of total pop in that group. Males on left, females on right. Young population (bulge at bottom)  Economic Risks  Potential for job shortage Shift in workforce and jobs that target young people   Social  Increasing demand on support for youth Preschools, parks, etc.   Health and Education  Have to be prepared for childhood diseases Increase spending on family planning programs   Middle (bulge in middle)  Economic:  Not enough upcoming workers Possible automation People work longer (later retirement)       Aging population (bulge at top)  Economic  Transition to tertiary jobs Income tax burden falls on a shrinking workforce Over 65 expect long term expensive healthcare Strain on pension system with fewer paying in Capital flow from aging countries shifting global economic power   Social Risks  Migration needed to satisfy labor needs           2.4 Population Dynamics #   IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\n  Learning Objective: Explain factors that account for contemporary and historical trends in population growth and decline. Essential Knowledge:  Demographic factors that determine a population’s growth and decline are fertility, mortality, and migration.  fertility  crude birth rate (CBR) — total live births in a year for every 1,000 people alive in society infant mortality rate (IMR) — annual number of deaths of infants under 1 year of age compared with number of live births  Decrease due to (life expectancy too)    total fertility rate (TFR) — average number of children a woman will have throughout her childbearing years (15-49)   mortality  crude death rate (CDR) — total number of deaths in a year for every 1,000 people alive in society life expectancy — number of years expected for a newborn to live   migration   Geographers use the rate of natural increase and population-doubling time to explain population growth and decline.  Natural increase rate (NIR) — Percentage by which a population grows in a year  CBR - CDR = NIR    Doubling Time — Number of years needed to double the population (assuming a steady rate of growth), is affected by NIR   Social, cultural, political, and economic factors influence fertility, mortality, and migration rates.  Social + cultural  norms  when to get married role of genders     political  laws  anti/pro abortion one child policy (China)          2.5 The Demographic Transition Model #   IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\n  Learning Objective: Explain theories of population growth and decline. Essential Knowledge:  The demographic transition model can be used to explain population change over time.  explains the rising and falling of NIR over time in a country no country has ever reverted back to a previous stage  Stage 1: Hunter-gatherers, scarcity of food Stage 2: Increase in healthcare, still lots of kids Stage 3: Rural to urban, less kids (due to less space / resources in urban area) Stage 4: Developed, stuff balances out Stage 5: Replacement rate isn\u0026rsquo;t enough to sustain population  Reasons for population drop off / decrease        The epidemiological transition explains causes of changing death rates.  stage 1 — prestillence and famine (high CDR):  principal cause of death: infectious and parasitic diseases   stage 2 — receding pandemic (rapidly declining CDR)  factors such as improved sanitation, nutrition, and medicine   stage 3 — degenerative disease (moderately declining CDR)  decrease in deaths by infectious diseases, increase in deaths by chronic disorders associated with aging   stage 4 — delayed degenerative diseases (low but increasing CDR)  death by cardiovascular diseases and cancer delayed because of modern medicine   (possible) stage 5  evolution: infectious disease microbes adapt around drugs, new strains form poverty: infectious diseases are more prevalent in poor areas due to unsanitary conditions and inability to afford medicine / treatment increased connections: advancements in transportation, e.g. air travel, increases contact as well as urbanization   death rates are high during first, the drop off til they level around stage 4 this is due to increase in education and healthcare, as well as contraceptives     Jobs  Economic Activities  Primary: Production of raw materials or natural resource extraction (e.g., agriculture, mining, energy, timber, fishing) Secondary: Processing or refining of natural resources (e.g., manufacturing finished goods, industry, building construction, assembly, factory work, value-added, blue collar) Tertiary: Provision of services (e.g., healthcare, technology, communications, financial, wholesale and retail trade, transportation, personal, professional, business services, white collar)   How these patterns change as courtiers develop       2.6 Malthusian Theory #   IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\n  Learning Objective: Explain theories of population growth and decline. Essential Knowledge:  Malthusian theory and its critiques are used to analyze population change and its consequences.  Thomas Malthus - proposed in his Essay on the Principle of Population 1798, that the population grows faster than the food supply. He claimed that while population expanded at a geometric or exponential rate, food supply increased arithmetically or linearly. However, the continued evolution of agriculture has continued to provide the world with an adequate amount of food. The problem now is distribution of food, not the actual production of it. Also, the birth rates declined sharply in the latter part of the 20th century, thus the world population expanded to only 6 billion compared to Malthus’s predicted 10.  Neo-Malthusians  claim that more LDC’s are in stage 2 of the demographic transition than ever before in history, thus putting a larger strain on the food supply. They also modified Malthus’s theory by stating that the population growth is out-stripping not just food production, but a wide variety of resources, such as oil, natural gas, etc.   Critics of Malthus  claim that population growth stimulates new technology and that as strain is put on any resource, the inventive human being will simply develop an alternative method once it is economically feasible.        2.7 Population Policies #   SPS-2 Changes in population have long- and short-term effects on a place’s economy, culture, and politics.\n  Learning Objective: Explain the intent and effects of various population and immigration policies on population size and composition. Essential Knowledge:  Types of population policies include those that promote or discourage population growth, such as pronatalist, antinatalist, and immigration policies.  countries fearing overpopulation may enact Antinatilist policies, e.g. China\u0026rsquo;s child limit countries fearing dipping below the replacement level, to assure the population continues to replace itself, may enact pronatilist policies, e.g. Scandinavian country\u0026rsquo;s proactive ads, or policy encourage immigration (migration in to the country)      2.8 Women and Demographic Change #   SPS-2 Changes in population have long- and short-term effects on a place’s economy, culture, and politics.\n  Learning Objective: Explain how the changing role of females has demographic consequences in different parts of the world. Essential Knowledge:  Changing social values and access to education, employment, health care, and contraception have reduced fertility rates in most parts of the world.  social:  women have a say in whether or not they want a child   economic:  women joining the workforce leaves less time for relationships   political roles:  women in government can enact laws that better represent what women may need   healthcare:  higher chance of mother and child surviving   contraception  less likely for \u0026lsquo;accidents\u0026rsquo;   Social status change    Changing social, economic, and political roles for females have influenced patterns of fertility, mortality, and migration, as illustrated by Ravenstein’s laws of migration.  Ravenstein\u0026rsquo;s Laws:  Most migrants move only a short distance. Migration proceeds step by step. There is a process of absorption, whereby people immediately surrounding a rapidly growing town move into it and the gaps they leave are filled by migrants from more distant areas, and so on until the attractive force is spent. Migrants going long distances generally go by preference to one of the great centres of commerce or industry. Each current of migration produces a compensating counter-current. Natives of towns are less migratory than those of rural areas Females are more migratory than males within the kingdom of their birth, but males more frequently venture beyond. Most migrants are adults: families rarely migrate out of their country of birth. Large towns grow more by migration than by natural increase. Migration increases in volume as industries and commerce develop and transport improves. The major direction of migration is from the agricultural areas to the centres of industry and commerce. The major causes of migration are economic.   Ravensteins laws aren\u0026rsquo;t scientific Are too specificied  E.g. short distance occurs in Africa where most migrations is due to wars, while most migration from China is to the US (long)        2.9 Aging Populations #   SPS-2 Changes in population have long- and short-term effects on a place’s economy, culture, and politics.\n  Learning Objective: Explain the causes and consequences of an aging population. Essential Knowledge:  Population aging is determined by birth and death rates and life expectancy. An aging population has political, social, and economic consequences, including the dependency ratio.  dependency ratio: ratio of citizens under 15 or 65 and older to those between age 15 and 65  Gives us an idea of how many workers are needed to support the dependent population   If the population is aging:  Government spending for adult daycare, nursing homes, and home care social services will increase Government spending for education, child welfare, and health services will decrease   Why population is aging  Reduced Fertility  Improved education of women, more women working, delays in starting families Children are an economic liability in MDCs, too expensive to have several, societal norms (1–2 children) Birth control: cost, availability, accessibility, acceptance, quality More urban societies: less need for children to work on farms Government and private pensions reduce “children as pension”   Increased Life Expectancy  Improved health care (e.g., medicine, facilities, research/knowledge, personnel, technologies, accessibility) Improved lifestyle (e.g., knowledge of health risks, improved diets, technology, nutrition and exercise) Improved food security/availability Less conflict (e.g., less crime, fewer wars) Improved work conditions (e.g., less physically demanding labor, better safety standards) Improved public health (e.g., sanitation, water supply, housing, standard of living) Improved financial security for elderly (e.g., pensions, care facilities) Improved safety standards (e.g., sports, transportation, building codes)   Out-migration of Youth  Out-migration of youth for better lifestyle (e.g., jobs, security)           2.1 Causes of Migration #   IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\n  Learning Objective: Explain how different causal factors encourage migration. Essential Knowledge:  Migration is commonly divided into push factors and pull factors.  push factors — bad stuff in current location  famine war no jobs disease violence hate crime overcrowding   pull factors — good stuff somewhere else  better jobs lower taxes better climate better schools/social services more room low crime     Push/pull factors and intervening opportunities/obstacles can be cultural, demographic, economic, environmental, or political.  Intervening obstacle — a feature that hinders migration cultural  similar culture to home   demographic  people tend to like to be around similar people (age, race)   economic  better jobs   environmental  distance  Distance Decay: Says that migrants try to minimize the friction of distance  migrants will be more inclined to move to locations closer to them; they will be less interested in moving longer distances  has been on the decline    Intervening Opportunity\u0026rsquo;s: Idea that migrants will choose a location closer rather than farther if all other factors are the same  related to other reasons (time and money go up farther you have to travel)     climate (push + pull) oceans/water rugged terrain (intervening obstacles)   political  social services no war less corruption   age       2.1 Forced and Voluntary Migration #   IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\n  Learning Objective: Describe types of forced and voluntary migration. Essential Knowledge:  Forced migrations include slavery and events that produce refugees, internally displaced persons, and asylum seekers  types of migration:  Immigrant:  person entering another country with intention of living there   Emigrant:  person who is leaving one country with the intention of living in a different country   refugee:  A person who flees, is displaced, or is forced to leave his or her home country, often due to religion, ethnicity, race, or political belief Reasons    IDP — Internally Displaced Person:  A person who is forced out of the home region due to war, political, or social unrest, environmental problems, etc. does not cross any international boarders       Types of voluntary migrations include transnational, transhumance, internal, chain, step, guest worker, and rural-to-urban.  transnational  migration across one or more nation   transhumance  movement between mountains and lowlands, typically practiced by farmers Cyclic Movement: movement that has a closed route repeated annually or seasonally   internal  permanent move w/in the same country. Interregional migration  move from one region to another within country. e.g. from Middleton to North WI boonies   Intraregional migration  move within one region within one country. e.g. moving apartments in downtown Madison     chain migration  migration of people to a certain location because family members (or other contacts), typically of the same nationality, previously migrated there Examples must clearly establish a link/transfer of knowledge between the first group of migrants and subsequent groups OR it should be clear that subsequent migrants are from areas of close proximity to the source area of the early migrants, and that they are migrating to the same destination area.   step  migration to a distant destination that occurs in stages hard to measure / verify e.g. from farm to nearby village to town to city   guest worker  legal immigrant who has work visa, usually short term typically take unskilled labor jobs risk of them overstaying typically citizens of poor countries who temporarily obtain dangerous low-paying jobs in MDC’s that the permanent citizens refuse to accept.   rural-to-urban  migration flow going frow rural to urban areas In LDC’s, the migration trend recently has been rural to urban. In MDC’s, the migration trend has been urban to suburban Counterurbanization — net migration from urban to rural areas.  This has been a trend in MDC’s, as improved technologies enable people to live farther from their places of employment and still enjoy all the amenities the city offers. However, in the U.S., counterurbanization has stopped because of poor economic conditions in the rural areas. Once again, the trend is from non-metropolitan to metropolitan areas, only now it is characterized by a move into the suburbs rather than the inner city.          2.1 Effects of Migration #   IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\n  Learning Objective: Explain historical and contemporary geographic effects of migration. Essential Knowledge:  Migration has political, economic, and cultural effects.  cultural  visually see change in landscape Chinatown, mosques, etc.    political  potentially controversial hate crimes   economic  typically beneficial fill unskilled labor jobs    Migration transition  identified by Wilbur Zelinsky consists of changes in a society comparable to the demographic transition. Stage 1 consists of little migration Stage 2 involves international migration Stages 3 and 4 are characterized by internal migration.   brain drain may occur due to human capital theory of migration (states that smart people are the ones to leave and seek better job opportunities)  smartest/most talented people leave a country, leaving only stupid people benefitial to both countries  in-country gets talented labor and capital out-country gets often gets remittances (payments sent from individuals)     Quotas — maximum limits on the number of people who could immigrate to the U.S. from a country in 1 year — may encourage illegal immigrants some countries rely on immigration from other countries to  stay above the replacement level of 2.1 to assure the population stays even support those who are dependent (under 15, over 65)       Normally shows the % of the total pop in 5-year age brackets with youngest at base of pyramid and oldest at the top. The length of the bar represents the % of total pop in that group.   ⚱️ Unit 3 - Cultural Patterns and Processes #  Developing Understanding\n The main focus of this unit is on cultural patterns and processes that create recognized cultural identities. Students consider the physical environment to determine the effects of geographical location and available resources on cultural practices. Visuals representing artifacts, mentifacts and sociofacts all shed light on cultural landscapes and how they change over time. Practice in analyzing images of different places at different times for evidence of their ethnicity, language, religion, gender roles and attitudes, and other cultural attributes builds students’ understanding of cultural patterns and processes. This unit also considers from a temporal and spatial perspective how culture spreads, through traditional forces such as colonialism and imperialism and through contemporary influences such as social media. Rather than emphasize the details of cultural practices associated with specific languages and religions, this unit instead focuses on the distribution of cultural practices and on the causes and effects of their diffusion. For example, students might study the distribution of Chinese versus English languages or the diffusion patterns of religions such as Hinduism and Islam, at local, national, or global scales. An understanding of the diffusion of cultural practices provides a foundation for the study of political patterns and processes in the next unit\n  BIG IDEA 1 Patterns and Spatial Organization (PSO)\n How does where people live and what resources they have access to impact their cultural practices? BIG IDEA 2 Impacts and Interactions (IMP) How does the interaction of people contribute to the spread of cultural practices? BIG IDEA 3 Spatial Processes and Societal Change (SPS) How and why do cultural ideas, practices, and innovations change or disappear over time?   3.1 Introduction to Culture #   PSO-3 Cultural practices vary across geographical locations because of physical geography and available resources.\n  Learning Objective: Define the characteristics, attitudes, and traits that influence geographers when they study culture. Essential Knowledge:  Culture comprises the shared practices, technologies, attitudes, and behaviors transmitted by a society.  shared practices  teaching style events holidays   technologies  what side of the road we drive on 120/240 volt outlet   attitudes  how we treat different genders   behaviors  how we greet one another   Social customs  originates at a hearth, a center of innovation. Folk customs tend to have anonymous sources, from unknown dates, through multiple hearths  Folk music tells stories or conveys information about daily activities. Isolation promotes cultural diversity as a group’s unique customs develop over several centuries.  Therefore, folk culture varies widely from place to place at one time. Since most folk culture deals in some way with the lives and habits of its people, the physical environment in which the people act has a tremendous impact on the culture.     pop culture generally has a known originator, normally from MDC’s, and results from more leisure time and more capital.  Pop music is written by specific individuals for the purpose of being sold to a large number of people.       Cultural traits include such things as food preferences, architecture, and land use.  Food:  the food we eat daily and the food we experience while traveling around the world all depends upon our location often passed throughout generations brings us together; sharable food in US reflects patterns of migration and what we\u0026rsquo;re capable of growing food also shows if there\u0026rsquo;s any (religious) taboos  Low meat consumption in Africa and S Asia due to large Hindu population, which don\u0026rsquo;t eat beef because they believe the cow to be sacred Muslim and Judaism prohibited from eating pork Somali clans restrict the consumption of fish      Land use:  location determines what foods are grown locally and readily available in a particular region of the world  certain states are known for certain foods; Jersey tomatoes, Florida oranges, Georgia peaches     Architectural trait  reflection of our built land scape can explain what was going on at a given time and what resources were available     Cultural relativism and ethnocentrism are different attitudes toward cultural difference.  relativism  looking at culture objectively / holistically believing nothing is right or wrong   ethnocentrism  viewing other cultures through your own believing that your culture is the norm / superior pride in heritage, devaluation of other groups        3.2 Cultural Landscapes #   PSO-3 Cultural practices vary across geographical locations because of physical geography and available resources.\n  Learning Objective: Describe the characteristics of cultural landscapes. Essential Knowledge:  Cultural landscapes are combinations physical features, agricultural and practices, religious and linguistic characteristics, evidence of sequent occupancy, and other expressions of culture including traditional and postmodern architecture and land-use patterns.  Toponyms  reflect leaders / people of power / religious figures / in immigrant\u0026rsquo;s native language    Religious impact  Religious architecture sacred spaces religious symbols   Architecture  traditional architecture built for elements that impact the area being built on built with materials (abundantly) available post-modern architecture is designed to descriptive / feats of design   Sequent Occupance  early societies leave their cultural imprint on a place old fashion architecture old-street\u0026rsquo;s names land surveys — how land was parceled / divided  square pattern system long-lot (french)   housing  reflects cultural identities of those who lived there and environmental constraints       \u0026ldquo;The cultural landscape is fashioned from a natural landscape by a cultural group. Culture is the agent, the natural area is the medium, the cultural landscape is the result.\u0026rdquo; - Carl Sauer\n  Gentrification  Positive Impacts  Negative Impacts  How govt can slow down + rpevent        Learning Objective: Explain how landscape features and land and resource use reflect cultural beliefs and identities Essential Knowledge:  Attitudes toward ethnicity and gender, including the role of women in the workforce; ethnic neighborhoods; and indigenous communities and lands help shape the use of space in a given society.   positive attitudes encourage chain migration can lead to subsections of area with high concentration of a particular ethnicity  China town little Mexico   generally, women are becoming more equal but there\u0026rsquo;s still progress to be made    3.3 Cultural Patterns #   PSO-3 Cultural practices vary across geographical locations because of physical geography and available resources.\n  Learning Objective: Cultural practices vary across geographical locations because of physical geography and available resources. Essential Knowledge:  Regional patterns of language, religion, and ethnicity contribute to a sense of place, enhance placemaking, and shape the global cultural landscape.  language  dialects phrases    ethnicity  immigrants shape neighborhoods  china town     sense of place   link   Bilingualism    Language, ethnicity, and religion are factors in creating centripetal and centrifugal forces.  countries need a stronger centripetal force than centrifugal force to stay intact forces and produce regionalism or dissimilarity between people in the same country centripetal exist in a place and don\u0026rsquo;t move — typically people don\u0026rsquo;t wanna or can\u0026rsquo;t leave while push/pull are actively working centripetal forces — together  Centripetal forces unify a state (provide stability, strengthen, bind together, create solidarity). culture regligious acceptance ethnic unity and tolerance social equity economic equity just and fair legal system nationalism  history — common heritage    centrifugal forces — apart (repel)  Centrifugal forces divide a state (lead to balkanization/devolution, disrupt internal order, destabilize, weaken). cultural diversity religious differences language ethnic conflict social injustice nationalism legal restrictions physical features economic stratification    “White flight” is the rapid fleeing of whites from the cities as black families emigrate out of the ghettos, or as the ghetto expands. It was encouraged by blockbusting.  blockbusting- the real estate practice of scaring whites into selling their homes at low prices by telling them that blacks would soon be moving in and causing property values to fall. The real estate agents then turned around and sold the homes at extremely high prices to blacks that were emigrating from the inner city. Apartheid-the physical separation of different races into different geographic areas, i.e. South Africa.  The apartheid laws were repealed in 1991 in South Africa, but many years will be needed to erase the legacy of such racist policies.          3.4 Types of Diffusion #   IMP**-3 The in**teraction of people contributes to the spread of cultural practices.\n  Learning Objective: Define the types of diffusion. Essential Knowledge:  Relocation and expansion — including contagious, hierarchical, and stimulus expansion — are types of diffusion   Relocation — hearth moves  act of people physically moving takes time, typically slow not everyone is going to absorb it term: person who uses a term moves to a new location and continues to use the term in the new location, OR a form of media, in which a term is used, is relocated to a new place and the term is used in the new location. Example: Spread of Christianity, when people moved and brought it with them    expansion — hearth stays same place  contagious  diseases rapid spread term: an individual uses, or individuals use, the new word and then acquaintances (or those in close proximity to them) begin to use the word as well Example: Hinduism spreading throughout the Indian subcontinent    hierarchical  intent is to spread selectively term: celebrities start to use the new word and then it spreads to others down the social hierarchy OR people in large cities start to use the word and then the word eventually gets to smaller places or media markets, OR Reverse Hierarchical: minority use of the term spreads up the social ladder to majority group(s). spread by choice, often wealth    stimulus  innovative idea diffuses from its hearth outward, but the original idea is changed by the new adopters Example: Different Menu items from McDonalds around the world.        3.5 Historical Causes of Diffusion #   SPS-3 Cultural ideas, practices, and innovations change or disappear over time.\n  Learning Objective: Explain how historical processes impact current cultural patterns. Essential Knowledge:  Interactions between and among cultural traits and larger global forces can lead to new forms of cultural expression; for example, creolization and lingua franca.  lingua franca  a language that is informally agreed upon as the language of business and trade  Reasons for US being lingua franca / dominant  Historical  Globalization      creolization  mix of languages that form its own language native to some group of people vocab from different language   pidgin  no ones native language usually result of trading between groups of people who don\u0026rsquo;t share the same language     Colonialism, imperialism, and trade helped to shape patterns and practices of culture.  Colonialism + imperialism  The widespread diffusion of English is thanks, in large part, to the colonial practices of the British   trade   link        3.6 Contemporary Causes of Diffusion #   SPS-3 Cultural ideas, practices, and innovations change or disappear over time.\n  Learning Objective: Explain how historical processes impact current cultural patterns. Essential Knowledge:  Cultural ideas and practices are socially constructed and change through both small-scale and large-scale processes such as urbanization and globalization. These processes come to bear on culture through media, technological change, politics, economics, and social relationships.  sense of place is the special perception we have of a certain place based on our feelings, emotion, and associations with that place.  also called distinctive culture    Placelessness is he loss of a place\u0026rsquo;s unique favor and identity because of standardizing influence of popular culture and globalization   Communication technologies, such as the internet and the time-space convergence, are reshaping and accelerating interactions among people; changing cultural practices, as in the increasing use of English and the loss of indigenous languages; and creating cultural convergence and divergence.  the internet has united us more  pros  easier to share + spread culture english is language of the internet, universal   cons  culture can be easily judged without full context english is prereq and reducing usage of other languages          3.7 Diffusion of Religion and Language #   IMP**-3 The** interaction of people contributes to the spread of cultural practices.\n  Learning Objective: Explain what factors lead to the diffusion of universalizing and ethnic religions. Essential Knowledge:  Language  Language families, languages, dialects, world religions, ethnic cultures, and gender roles diffuse from cultural hearths. Diffusion of language families, including Indo-European, and religious patterns and distributions can be visually represented on maps, in charts and toponyms, and in other representations.   Religion  Hinduism  Hearth: Pakistan in ~2300 BCE Because Hinduism is an ethnic religion it primarily diffused via relocation diffusion to India and Nepal   Judaism  Hearth: Isreal/Palestine in ~1800 BCE Due to persecution from many countries, Judaism has diffused across many countries but is most prominent in Isreal and the United States now.   Christianity  Hearth: Jerusalem on 1 AD Christianity largely spread due to conquest throughout much of the Roman Empire, and again later on through colonialism. Now it’s the most practiced religion and is most influential in Europe, the Americas, South Africa, and Australia   Islam  Hearth: Arabian Peninsula/Saudi Arabia in ~600 CE Spread via conquest and trade, concentrated primarily in the Middle East, North Africa, Southwest Asia, and some portions of Southeast Asia   Buddhism  Hearth: Nepal in ~500 BCE Missionaries and trade helped diffuse Buddhism, and it’s not found in Southeast and East Asia, India, Sri Lanka, and Tibet     Religion can identify, unit, or divide a group of people  RELIGION IS ARGUABLY THE MOST VOLITALE OF ALL HUMAN RELATIONS AND THE SOURCE OF MOST VIOLENCE THROUGHOUT HISTORY. EUnion forbid any religious symbols such as crucifixes, crosses, etc. on public school walls and calls them a violation of religious and educational freedom Religion is nearly always suppressed in communist countries. Leaders believe that religion has a tendency to upset stability and therefore ban it altogether, though often they just concrete the people’s religious adherence instead of destroying it.     Religions have distinct places of origin from which they diffused to other locations through different processes. Practices and belief systems impacted how widespread the religion diffused.  Romans came and pushed out Jews, forcing them to diffuse Many religions spread via trade routes  Christian countries tended to have many trade routes, so it spread to a range of areas Islamic countries didn\u0026rsquo;t trade very far outside Africa and Asia (a bit to Europe)   Buddhism barely diffused from Asia   Universalizing religions, including Christianity, Islam, Buddhism, and Sikhism, are spread through expansion and relocation diffusion.  Anyone can become a member of a universalizing religion universalizing religion stories often attempt to explain the mystical and there calendar\u0026rsquo;s main purpose in calendars is to commemorate events in the founder’s life, thus the seasons or weather are not central to the structure Christianity, Buddhism, and Islam are the three main  Buddhism and Islam are the universalizing religions that place the most emphasis on identifying shrines/holy places.  In universalizing religions, the holy places are generally locations at which memorable events happened in the founder’s life, such as Mecca is in Islam because it is Muhammad’s birthplace. Holy places in ethnic religions are often physical features that are closely tied to the religion (For example, in Hindu one of the most important rituals is the bathing of oneself in the Ganges River.)     Members actively proselytize, or seek new converts by sending missionaries through the world to spread their beliefs Excluding Hinduism, this shows diffusion of universalizing religions   Ethnic religions, including Hinduism and Judaism, are generally found near the hearth or spread through relocation diffusion.  Only really spread from generation to generation Ethnic religious creation stories tend to deal with the physical environment and natural events and typically organize their calendars around the seasons, other natural events, or the physical geography Ethnic religions rarely diffuse, and when they do, it is to a small extent  Judaism is an exception in that it has diffused widely throughout the years, mainly because its people have had to flee persecution from many areas in the world.   Traditional religions  subgroup of ethnic practiced by small groups, typically within a village or tribe          3.8 Effects of Diffusion #   SPS-3 The interaction of people contributes to the spread of cultural practices.\n  Learning Objective: Explain how the process of diffusion results in changes to the cultural landscape Essential Knowledge:  Acculturation, assimilation, syncretism, and multiculturalism are effects of the diffusion of culture.   Acculturation  process of adopting some of the values, customs, and behaviors of the host culture immigrants may adopt the language and a few other customs of the host group but will retain many distinctive customs   assimilation  Assimilation is the process whereby individuals or groups of differing ethnic heritage are totally absorbed into the dominant culture of a society. The process of assimilating involves taking on the traits of the dominant culture to such a degree that the assimilating group becomes socially indistinguishable from other members of the society. as we become more assimilated, languages become lost   syncretism  blending of cultures and ideas from different places   multiculturalism  grouping of various cultures in a certain area can lead to loss of cultural uniqueness, languages, and general \u0026ldquo;sameness\u0026rdquo; — link       🏛️Unit 4 - Political Patterns and Processes #  Developing Understanding\n This unit addresses the political organization of the world. Building on knowledge of populations and cultural patterns learned in previous units, students examine the contemporary political map and the impact of territoriality on political power and on issues of identity for peoples. Students also look at the different types of political boundaries, how they function, and their scale, as they consider both internal and international boundaries. The interplay of political and cultural influences may cause tensions over boundaries to arise, such as sovereign states making claims on what other states consider to be international waters. Students also examine forms of government and how forces such as devolution may alter the functioning of political units and cause changes to established political boundaries. Separatist and independence movements that challenge the sovereignty of political states may arise from economic and nationalistic forces, as seen in Scotland, Northern Ireland, and Spain. The influence of supranational organizations such as the United Nations or European Union and their role in global affairs presents another challenge to nationalist sovereignty. Student understanding of cultural patterns and processes helps inform their understanding of the consequences of centrifugal and centripetal forces.\n  BIG IDEA 1Patterns and Spatial Organization (PSO)\n How do historical and current events influence political structures around the world? BIG IDEA 2 Impacts and Interactions (IMP) How are balances of power reflected in political boundaries and government power structures? BIG IDEA 3Spatial Processes and Societal Change (SPS) How can political, economic, cultural, or technological changes challenge state sovereignty?   4.1 Introduction to Political Geography #   PSO-4 The political organization of space results from historical and current processes, events, and ideas.\n  Learning Objective: For world political maps: a. Define the different types of political entities. b. Identify a contemporary example of political entities. Essential Knowledge:  Independent states are the primary building blocks of the world political map. Types of political entities include nations, nation-states, stateless nations, multinational states, multistate nations, and autonomous and semiautonomous regions, such as American Indian reservations.  state:  a country and not a political subdivision within the united states, such as Nevada or Maine has sovereignty, boundaries, and a permanent population   nations:  unified group of people with a common culture Navajo, Roma   nation-states:  States in which over 90 percent of the population are the same specific culture or group of people A politically organized area in which nation and state occupy the same space. can act as a centripetal factor to those of the same ethnicity as majority Japan, Iceland, Armenia, Bangladesh, Lesotho   stateless nations  A nationality that is not represented by a state.   multinational states  states made up of a two or more ethnic groups United states, Canada, China, Russia, India, Brazil    multistate nations  country with two or more nationalities within its borders (a nation that exists in multiple states) Kurds, French, Basque   Buffer state  States that are allowed to exist by neighboring states (to help relieve tension between the neighboring states). Mongolia between China and Russia   autonomous  a group of people or territory are self-governing, thus not under the control of a higher level of government   semiautonomous regions  a group of people that have some level of automity, but are still controlled by another entity         4.2 Political Processes #   PSO-4 Explain the processes that have shaped contemporary political geography.\n  Learning Objective: Explain the processes that have shaped contemporary political geography. Essential Knowledge:  The concepts of sovereignty, nation-states, and self-determination shape the contemporary world  sovereignty  internationally recognized exercise of a country\u0026rsquo;s power over its people and territory   nation-states   URL   self-determination  the concept that ethnicities have the right to govern themselves can lead to irredentism     Colonialism, imperialism, independence movements, and devolution along national lines have influenced contemporary political boundaries.  Colonialism  when a group of people impose a set of formal controls by the mother country over its colonies or outside territories Colonizers colonize because of  Gold — seek monitary gains at (most of the time) any expense God — want to spread there own religion Glory — clout   Effects still present today  Social unrest typically speak langauge of colonizers  French in Northern Africa, English (British) in Southern Africa     boundaries expand that aren\u0026rsquo;t physically connected to mother country   imperialism  the use of military, cultural domination, and or economic sanctions to gain control of a country and its resources boundaries expand from mother country   independence movements  can result in section breaking off   devolution   Quizlet the transition of power from the central government to regional governments in a state is done by  Altering of a constitution Experiments on new governmental body Internal Division (Ethnocultural, Economic, or Spatial)   results in  Creation of an independent state Calls for Autonomy   can result in section breaking off          4.3 Political Power and Territoriality #   PSO-4 Explain the processes that have shaped contemporary political geography.\n  Learning Objective: Describe the concepts of political power and territoriality as used by geographers Essential Knowledge:  Political power is expressed geographically as control over people, land, and resources, as illustrated by neocolonialism, shatter belts, and choke points.  neocolonialism  Refers to the economic control that MDCs are sometimes believed to have over LDCs. Through organizations such as the IMF, the MDCs are able to dictate precisely what LDCs economic policies are, or are able to use their economic subsidies to put LDCs industries out of business.   shatter belts  an area of instability between regions with opposing political and cultural values   choke points  A geographical land feature such as a valley or water way narrowing causing a decrease in forces making their way through.     Territoriality is the connection of people, their culture, and their economic systems to the land.  boundaries are set to connect people with same/similar culture and that want to have an economic relation with one anther     Stages of Economic Growth and Core Periphery Model (Core-Periphery) Core Periphery  Stages of each Reasons for economic location Core-periphery leads to uneven spatial distribution of economic, political, or cultural power       4.4 Defining Political Boundaries #   IMP-4.Political boundaries and divisions of governance, between states and within them, reflect balances of power that have been negotiated or imposed.\n  Learning Objective: Define types of political boundaries used by geographers. Essential Knowledge:  Types of political boundaries (barriers)include relic, superimposed, subsequent, antecedent, geometric, and consequent boundaries.  relic  boundary that used to exist, but is no longer active / present You can often still see effects of relic boundary even if they aren\u0026rsquo;t there e.g. great wall of China, East and West Germany   superimposed  boundary imposed by an outside force may not reflect cultural landscape e.g. treaties, Africa during Colonial era    subsequent  corresponds to group that is there, often regardless of cultural divide boundary set after the settlements of different groups meet often correspond to ecumene wall impacts   consequent boundaries  A boundary line that coincides with some cultural divide, such as religion or language. E.g. India   antecedent  pre-existing; most commonly physical features such as rivers, bays, mountains, desserts can potentially be removed with technology  road build across dessert whole through mountain     geometric  straight lines US-Canada boarder because they aren\u0026rsquo;t visible, can lead to conflict   Shapes  compact  round easy defense and communication   prorupted or protruded  round with a large extension increases access to resources or water/ports   elongated  long, narrow difficult communication between areas   fragmented  two or more areas separated by another country or body of water difficult communication   perforated  totally surrounds another country can abuse country w trade taxes/tariffs   landlocked          4.5 The Function of Political Boundaries #   IMP-4. Political boundaries and divisions of governance, between states and within them, reflect balances of power that have been negotiated or imposed.\n  Learning Objective: Explain the nature and function of international and internal boundaries. Essential Knowledge:  Boundaries are defined, delimited, demarcated, and administered to establish limits of sovereignty, but they are often contested.  defined  Treaty or legal document   delimited  Drawn on map in agreement   demarcated  VISUALLY MARKED walls, posts, fence   administered  the enforcement \u0026amp; maintaining of a boundary by government who can cross? what goods can cross? demarcated?     Political boundaries often coincide with cultural, national, or economic divisions. However, some boundaries are created by demilitarized zones or policy, such as the Berlin Conference.  most of the time are made to not piss people / countries off if made by a supranational org   Land and maritime boundaries and international agreements can influence national or regional identity and encourage or discourage international or internal interactions and disputes over resources. The United Nations Convention on the Law of the Sea defines the rights and responsibilities of nations in the use of international waters, established territorial seas, and exclusive economic zones.  UN came up with these zones  EEZ is important because you can tax ships that travel and make money  Includes islands too which has put pressure / created conflict at some islands  South China Sea     UN came in because otherwise it was hard to figure out who owned what area and lead to conflicts       4.6 Internal Boundaries #   IMP-4.Political boundaries and divisions of governance, between states and within them, reflect balances of power that have been negotiated or imposed.\n  Learning Objective: Explain the nature and function of international and internal boundaries. Essential Knowledge:  Voting districts, redistricting, and gerrymandering affect election results at various scales.  Voting districts  subsections in states specifically for voting    redistricting  occurs once in every 10 years in US after census goal is to be drawn fairer and group like people often results in gerrymandering   gerrymandering  redistricting in such a way that it favors a political party         4.7 Forms of Governance #   IMP-4.Political boundaries and divisions of governance, between states and within them, reflect balances of power that have been negotiated or imposed.\n  Learning Objective: Define federal and unitary states. Essential Knowledge:  Forms of governance include unitary states and federal states  unitary states  most power lies in centralized govt areas far away from central power aren\u0026rsquo;t represented equally can pull a country together    federal states  most power lies in local govt  country is split into states / provinces, typically to group like-people   can better represent areas Green = Federal       Learning Objective: Explain how federal and unitary states affect spatial organization. Essential Knowledge:  Unitary states tend to have a more top-down, centralized form of governance, while federal states have more locally based, dispersed power centers.  unitary states  focus on central government or big city   federal states  multiple nodal points   stateless  compact around a center nodal point small boarders         4.8 Defining Devolutionary Factors #   SPS-4.Political, economic, cultural, or technological changes can challenge state sovereignty.\n  Learning Objective: Define factors that lead to the devolution of states Essential Knowledge:  Factors that can lead to the devolution of states include the division of groups by physical geography, ethnic separatism, ethnic cleansing, terrorism, economic and social problems, and irredentism.   physical geography  if state is physically separated by land, water, etc.   ethnic separatism  rise of ethnic groups in a state that want there own statehood   ethnic cleansing  not genocide  genocide = killing people   ethnic cleansing is moving certain people out   political justification  Heartland-rimland theory  justified eu colonization during 19th century by claiming EU was the heartland and the surrounding territories comprised of the rimland the heartland was well positioned to dominate the world because of the immense size of its mass. since Russia formed the major part of the heartland, Mackinder (creator of theory) influenced politicians of the day to try to limit Russia\u0026rsquo;s expansion by colonizing territories near Russia tl;dr — Politicians used some crappy justification that aligned with the biases to further there agenda   domino thoery  once a country became communist, the neighboring countries around it were likely to also become communist     terrorism  goal is to intimidate or coerce a govt to do the terrorists political or social objective serves to pull country apart   economic  richer areas can want to split off so that they don\u0026rsquo;t have to pay a majority in taxes to people they don\u0026rsquo;t know/relate to   social problems  due to differences between cultural groups   irredentism  the goal of a group of people to want to unit with another group of people who share cultural elements with, but are divided by national boundaries can result in civil wars       4.9 Challenges to Sovereignty #   SPS-4.Political, economic, cultural, or technological changes can challenge state sovereignty.\n  Learning Objective: Explain how political, economic, cultural, and technological changes challenge state sovereignty.  political  superimposed boarders can lead to people upset   economic  area wanting less taxes because they\u0026rsquo;re paying an unequal amount terrorist groups attacking transportation / pipes   cultural  e.g. one group wanting an official language and another group wanting a different official language     Essential Knowledge:  Devolution occurs when states fragment into autonomous regions; subnational political territorial units, such as those within Spain, Belgium, Canada, and Nigeria; or when states disintegrate, as happened in Sudan and the former Soviet Union.  autonomous regions; subnational political territorial units   Link E.g. Spain, Belgium, Canada, and Nigeria   disintegrate  E.g. Sudan and the former Soviet Union     Advances in communication technology have facilitated devolution, supranationalism, and democratization.  devolution — link supranationalism  easier to connect with similar people and want to join them Political, economic, and/or cultural cooperation among national states to promote shared objectives Tendency for states to give up political power to a higher authority in pursuit of common objectives (political, economic, military, environmental) Venture involving multiple national states (two or more, many, several) with a common goal   democratization  easier to see how much better it is outside your country with internet     Global efforts to address transnational and environmental challenges and to create economies of scale, trade agreements, and military alliances help to further supranationalism.  economies of scale trade agreements military alliances   Supranational organizations—including the United Nations (UN), North Atlantic Treaty Organization (NATO), European Union (EU), Association of Southeast Asian Nations (ASEAN), Arctic Council, and African Union— can challenge state sovereignty by limiting the economic or political actions of member states.  international group which the power and influence of member states transcend national boundaries or interest to share in decision making and vote on issues concerning the collective body member states give up some rights for common good of supranational organziation cooperation should resolve conflict sometimes used for collective defense can make economic stuff easier by opening boarders to member states set standards        4.1 Consequences of Centrifugal and Centripetal Forces #   SPS-4.Political, economic, cultural, or technological changes can challenge state sovereignty.\n  Learning Objective: Explain how the concepts of centrifugal and centripetal forces apply at the state scale. Essential Knowledge:  Centrifugal forces may lead to failed states, uneven development, stateless nations, and ethnic nationalist movements.  failed states  political body that has disintegrated to a point where basic conditions and responsibilities of a sovereign govt no longer function most LDCs   uneven development  tend to be poor with corrupt govt   stateless nations  can serve as a centrifugal factor to state they\u0026rsquo;re in united inside there own area typically grouped by ethnic groups   ethnic nationalist movements  lead to separation movements riots against govt if not adequately represented     Centripetal forces can lead to ethnonationalism, more equitable infrastructure development, and increased cultural cohesion.  ethnonationalism  nationalism of people with common background / language unites people   more equitable infrastructure development increased cultural cohesion       🚜Unit 5 — Agriculture and Rural Land-Use Patterns and Processes #  Developing Understanding\n This unit examines the origins of agriculture and its subsequent diffusion. Students learn about the ways agricultural practices have changed over time as a result of technological innovations, such as equipment mechanization and improvements in transportation that create global markets. In addition, they examine the consequences of agricultural practices such as the use of high-yield seeds and chemicals, revisiting the human–environmental relationships studied in Unit 1. Course emphasis on spatial patterns is evident in this unit as students consider the differences in what foods or resources are produced and where they are produced. These agricultural production regions are impacted by economic and technological forces that increase the size of agricultural operations and the carrying capacity of the land. This has in turn created a global system of agriculture and the interdependence of regions of agricultural consumption and production. Student understanding of this global system of agriculture based on government cooperation lays the foundation for a deeper understanding of economic development in the final unit of the course.\n  BIG IDEA 1Patterns and Spatial Organization (PSO)\n How do a people’s culture and the resources available to them influence how they grow food? BIG IDEA 2 Impacts and Interactions (IMP) How does what people produce and consume vary in different locations? BIG IDEA 3Spatial Processes and Societal Change (SPS) What kind of cultural changes and technological advances have impacted the way people grow and consume food?   5.1 Introduction to Agriculture #   PSO 5 Availability of resources and cultural practices influence agricultural practices and land-use patterns.\n  Learning Objective: Explain the connection between physical geography and agricultural practices. Essential Knowledge:  Agricultural practices are influenced by the physical environment and climatic conditions, such as the Mediterranean climate and tropical climates.  During the First Agricultural Revolution:  Sarted around 11,000 BC Unknown origins / how it happened (before recording of history) Humans radically changed their behavior: Went from hunting/gather life style to settling in to single areas and cultivating the land, planting crops, and raising animals   Agriculture is impacted by:  Land — cheap, near market + transportation, good quality soil Labor — cheap, skilled (enough), enough quantity Climate — have to meet requirements of crop, enough rain   Mediterranean Agriculture:  produces grapes and olives (cash crops), alongside citruses and figs — helps attract tourists, contributes to culture still produce cereals, especially wheat for pasta/bread requires warm year-round climate with lots of sunshine and boardering a sea horticulture: growing fruits, veggies, and flowers     Intensive farming practices include market gardening, plantation agriculture, and mixed crop/livestock systems.  Land: Small — land isn\u0026rsquo;t cheap so only small portions of high quality land is used High yield (food produced) to feed consumers Location: Closest to market Relies on lots of labor and tech (pesticides, fertilizer, etc.) (Oftentimes) variety of products produced — polyculture Examples:  market gardening  close to market small scale production of cash crops: fruits, vegetables, and flowers (apples, asparagus, cherries, lettuce, mushrooms, tomatoes) sold directly to local consumers. truck farming: truck means \u0026ldquo;barter\u0026rdquo; or \u0026ldquo;exchange\u0026rdquo;, not a physical truck   plantation agriculture (cash crop, cashcrop)  highly efficient tend to be established in or near the tropics produce a cash crop    mixed crop/livestock systems  Both animal and crops are farmed in the same area. Most common form of agriculture in US Crops, like maize and soybeans, are grown primarily to feed animals Utilizes crop rotation: cycles various crops and fields left to fallow (naturally grow over) to allow nutrient replenishing   China, India, and SE Asia rely on this type of agriculure to double-crop  Fit 2 years of harvest in 1 year       Extensive farming practices include shifting cultivation, nomadic herding, and ranching.  Land: Large Location: Farther from market — land isn\u0026rsquo;t cheap so it\u0026rsquo;s not that great and far away from market Examples:  Shifting cultivation  (slash-and-burn) vegetation is cut down and then ignited to make the ground more productive low yield / ineffective occurs in tropics  More notes   Nomadic herding  (animal husbandry) based on herding domesticated animals. can result in desertification low yield, but only needs to support tribe/family   Ranching  commercial grazing of livestock over an extensive area practiced is semi-arid or arid land, where vegetation is too sparse or the soil to too poor to support crops prominent in later 19th century in the American West; on the decline due to low profit margins — more intensive to go into mono farming           5.2 Settlement Patterns and Survey Methods #   PSO 5 Availability of resources and cultural practices influence agricultural practices and land-use patterns.\n  Learning Objective: Identify different rural settlement patterns and methods of surveying rural settlements. Essential Knowledge:  Specific agricultural practices shape different rural land-use patterns.  Rural defined as \u0026lt; 2500 residents, and between 1 and 999 person per square mile 3 factors that affect the pattern of rural setllement:  The kind of resource/feature that attracts people to the area (forests, farmlands, fields) The transportation method avaliable at the time of settlement (rivers, roads) Role of government policy, especially the land survey system (metes-and-bonds, long lot, rectangle, etc.)     Rural settlement patterns are classified as clustered, dispersed, or linear.  clustered  A clustered rural settlement typically includes homes, barns, tool sheds, and other farm structures, plus personal services, such as religious structures and schools.   dispersed  characterized by farmers living on individual farms isolated from neighbors rather than alongside other farmers in the area.   linear  Linear rural settlements feature buildings clustered along a road, river, or dike to facilitate communications.   nucleated  a number of families live in close proximity to each other, with fields surrounding the collection of houses and farm buildings (e.g., Asian longhouse)     Rural survey methods include metes and bounds, township and range, and long lot.  Rectangular survey system  Also called the Public Land Survey The system was used by the U.S. Land Office Survey to parcel land west of the Appalacian mountains. The system divides land into a series of rectangular parcels.   metes and bounds  A system of land surveying east of the Appalachian Mountains (EU) It is a system that relies on descriptions of land ownership and natural features such as streams or trees.    township and range  rectangular land division scheme designed by Thomas Jefferson grid system Intended to disperse settlers evenly across farmlands of the U.S. interior    long lot  Distinct regional approach to land surveying found in the Canadian Maritimes, parts of Quebec, Louisiana, and Texas designed to give everyone an equal type of land / soil (one person shouldnt get all poor land / land on a road or river / etc.) Land is divided into narrow parcels stretching back from rivers, roads, or canals.          5.3 Agricultural Origins and Diffusions #   SPS 5 Agriculture has changed over time because of cultural diffusion and advances in technology.\n  Learning Objective: Identify major centers of domestication of plant sand animals. Essential Knowledge:  Early hearths of domestication of plants and animals arose in the Fertile Crescent and several other regions of the world, including the Indus River Valley, Southeast Asia, and Central America.  Fertile Crescent (Mesopotamia) — 10,000 years ago  1200 years ago it became good for sedentary agriculture In the Middle East that includes most of Iraq (Known as Mesopotamia in the past), Syria, Lebanon, Israel, and the Nile River basin in Egypt.    Huang He (Yellow) Valley — 10,000 years ago  Flooding of rivers resulted in people settling near them and using them to farm Barley, wheat, lentils, and olives Diffused west to EU + Central Asia Experienced the Primary Revolution later than in the Fertile Crescent/Mesopotamia   Nile River Valley — 8,000 years ago  Used crop rotation with lagoons and cereals to reduce salt build up Settlements around Nile   Indus River Valley — 4,000 years ago  Extended from modern-day northeast Afghanistan to Pakistan and northwest India. Important innovations of this civilization include standardized weights and measures, seal carving, and metallurgy with copper, bronze, lead, and tin.    Central America.  Uncertain time period, but probably happened last Some scholars estimate 2000 BC, but may go up to the discovery of the Americas by the Europeans because some Native Tribes had not progressed to the First Agricultural Revolution by that time Beans, maize (corn), and cotton Diffused North and South   Sub-Saharan Africa  Sorghum, yams, milet, and rice 10,000 years ago Diffused south       Learning Objective: Explain how plants and animals diffused globally. Essential Knowledge:  Patterns of diffusion, such as the Columbian Exchange and the agricultural revolutions, resulted in the global spread of various plants and animals.      5.4 The Second Agricultural Revolution #   SPS 5 Agriculture has changed over time because of cultural diffusion and advances in technology.\n  Learning Objective: Explain the advances and impacts of the second agricultural revolution. Essential Knowledge:  New technology and increased food production in the second agricultural revolution led to better diets, longer life expectancies, and more people available for work in factories.  Page 105 in Barron\u0026rsquo;s Occurred in 1700\u0026rsquo;s through 1940\u0026rsquo;s (alongside industrial revolution) Advances:  Motors, specifically tractors, which further advanced stuff in the 1930\u0026rsquo;s People used crop rotation instead of letting land grow over   Where:  Happened in Europe and North America  Started with horse-drawn hoes in England     Outcomes:  Surplus of crops in England diffused through EU People ate healthier because more food was available at lower prices Allowed more people to move to cities which led to industrial revolution women needed less kids for farms Farming changed from family to commercial enterprise (agribusiness) that emphasized single crops and profits Vertical integration (contracts between farmer and purchaser) caused farm outputs to increase by 1990s         5.5 The Green Revolution #   SPS 5 Agriculture has changed over time because of cultural diffusion and advances in technology.\n  Learning Objective: Explain the consequences of the Green Revolution on food supply and the environment in the developing world. Essential Knowledge:  The Green Revolution was characterized in agriculture by the use of high-yield seeds, increased use of chemicals, and mechanized farming  Machines have replaced human labor New seeds, chemical pesticides, and fertilizers increased yield MDC often get newest tech first   The Green Revolution had positive and negative consequences for both human populations and the environment.  Started in mid-1970\u0026rsquo;s when scientists developed hybrid higher-yield seeds and new fertilizers to use alongside them. + New seeds and fertilizers diffused from core to periphery countries to help eradicate hunger + China, India, and SE Asia had rice harvests increase + Decrease land devoted to farms + Less expensive food + Reduce poverty + More consistent yield - Many poor farmers couldn\u0026rsquo;t afford new seeds - Africa couldn\u0026rsquo;t take advantage of seeds (there chief foods are millet, sorghum, yams, and cassavas - Increased irrigation, causing environmental damage - Focus on cash crops - Some soil has lost majority of nutrients due to over use - Biodiversity and native food crops have gone down, increased chance of blight       5.6 Agricultural Production Regions #   PSO Availability of resources and cultural practices influence agricultural practices and land-use patterns.\n  Learning Objective: Explain how economic forces influence agricultural practices Essential Knowledge:  Agricultural production regions are defined by the extent to which they reflect subsistence or commercial practices (monocropping or monoculture).  Subsistence vs Commercial:  Subsistence is :  Food grown for the farmer or farmer’s family/kin Food grown for local consumption for village/community market Food NOT grown for commercial purposes/sold for revenue     Monocropping or Monoculture — cultivation of a single crop Occurs in mostly commercial farms in MDCs — US in 1950\u0026rsquo;s minimizes risks — climate, cost of inputs like labor or fertilizer, market demand, etc. maximize profits — choice of crop best suited for growing, potential pricing, etc.  Supply and demands influences farmers to raise the crops that have high demands Governments disort market influence by subsidizing certain crops (rice in Japan, milk in US)     Intensive and extensive farming practices are determined in part by land costs (bid-rent theory).  bid-rent: geographical economic theory: refers to how the price and demand on real estate changes as the distance towards the Central Business District (CBD) increases. intensive agriculture: any kind of agriculture activity that involves effective and efficient use of labor on small plots of land to maximize crop yield extensive agriculture: an agricultural system characterized by low inputs of labor per unit land area        5.7 Spatial Organization of Agriculture #   PSO Availability of resources and cultural practices influence agricultural practices and land-use patterns.\n  Learning Objective: Explain how economic forces influence agricultural practices. Essential Knowledge:  Large-scale commercial agricultural operations are replacing small family farms.  Occured during 20th century due to larger profits  Further notes   Complex commodity chains link production and consumption of agricultural products.  Von Thunen   Technology has increased economies of scale in the agricultural sector and the carrying capacity of the land.  More food leads to people spending less time trying to figure out how to eat and shifting to figuring out how to grow / be smarter Technology has lead to intensive farming that has optimized how we use land       5.8 Von Thünen (Thunen) Model #   PSO Availability of resources and cultural practices influence agricultural practices and land-use patterns.\n  Learning Objective: Describe how the von Thünen model is used to explain patterns of agricultural production at various scales Essential Knowledge:  Von Thünen’s model helps to explain rural land use by emphasizing the importance of transportation costs associated with distance from the market; however, regions of specialty farming do not always conform to von Thünen’s concentric rings.  The closer the land is to the city, the more expensive it  Because perishable items, e.g. Milk, and difficult to transport items must be grown very closely to their market  Milkshed is ring around market where dairy farming occurs Weberian theory   Sort of not true with advances in transportation and that all land is able to support it\u0026rsquo;s designated task   Forest resources (needed for fuel) could be grown and harvested further out than fruits/veggies from the market  Market example with automobiles    Grain could be harvested even further out because it could be grown, harvested, and stored easily and cheaply until needed Limitations  Livestock then could be raised in the outer ring where cheap, larges pastures were pentiful        5.9 The Global System of Agriculture #   PSO Availability of resources and cultural practices influence agricultural practices and land-use patterns.\n  Learning Objective: Explain the interdependence among regions of agricultural production and consumption Essential Knowledge:  Food and other agricultural products are part of a global supply chain.  MDCs tend to have access to best tech and get far ahead compared to LDCs LDCs with land arable for certain foods may be funded by MDCs for a specific product that they (MDCs) can\u0026rsquo;t produce   Some countries have become highly dependent on one or more export commodities.  Country\u0026rsquo;s that have a monopoly on foods can exploit other countries that depend on them If there\u0026rsquo;s a pest+drought+other issue that stops production of producer country from making food, then all dependents are screwed too   The main elements of global food distribution networks are affected by political relationships, infrastructure, and patterns of world trade.  Tariffs can screw over trade agreements Country\u0026rsquo;s with more infrastructure are more likely to receive investment because its key to exporting goods Core-periphery model applies to agriculture       5.1 Consequences of Agricultural Practices #   IMP Agricultural production and consumption patterns vary in different locations, presenting different environmental, social, economic, and cultural opportunities and challenges.\n  Learning Objective: Explain how agricultural practices have environmental and societal consequences. Essential Knowledge:  Environmental effects of agricultural land use include pollution, land cover change, desertification, soil salinization, and conservation efforts.  pollution land cover change desertification  overgrazing leads to land being perminent damage to land via erosion of unprotected topsoils   soil salinization conservation efforts For rice farming For rice farming For mechanization / wheat farming   Agricultural practices—including slash and burn, terraces, irrigation, deforestation, draining wetlands, shifting cultivation, and pastoral nomadism—alter the landscape.  terraces  creating an embankment (a terrance) at a right angle to sloping land in order to allow water to soak into the soil rather than move down the slope, taking the soil with it   irrigation  more efficient, developed to keep up with population demand   deforestation plantation farming  mainly specialize in 1-2 crops mostly in tropics, Latin America, Africa, some Asia Mostly produce prodcuts for sale is MDCs   Intensive subsistence with wet rice dominant  High agricultural density — lots of farmers, little land must produce enough food for family or small village wet rice:  field prep: plow flooding: rain, river, or irrigation transplanting: rice seedling grow on dry land then moveod to flooded field to grow harvest: by hand   double cropping: finishing 2 harvests in 1 year   Intensive subsistence with wet rice NOT dominant  climate prevents growing of rice in some regions where summer preciiptation is too low and/or winters are too harsh wheat, barley, millet, oats, corn, and some cash crops (cotton, flax, hemp) grown small land worked fulley commonly use crop rotation   shifting cultivation  based on growing crops in different fields on a rotating basis, e.g.  Maya in the Yucatan grow maize by rotating fields (on a seven-year cycle)   crops include rice, maize, manioc, millet, sorghum, yams, surgercane, veggies fields are cut and burned each year to enrich the soil with nutrients  process called swidden or slash-and-burn   seeds are planted in time for rainy season cultivated fields are used for two or three years until all nutrients are used critics it should be replaced by a more efficient means defenders say it is the most environmentally sound approach occupies 25% of world\u0026rsquo;s land, but practiced by just 5% of people used to be tradiationally done by village, now mostly private companies being replaced by logging, ranching, and cashcrops (monofarming)    pastoral nomadism  animals are herded in a seasonal migratory pattern 200+ million pastoralists in the world often cattle, goats, sheet, camels, and reindeer often in arid, marginal alnds — N Africa, Central Asia, Middle east when herds are moved from land to land, it\u0026rsquo;s called transhumance declining in popularity because modern tech can make better use of pastures  mining, irrigation, petroleum       Societal effects of agricultural practices include changing diets, role of women in agricultural production, and economic purpose.  changing diets  food security plays a large role in LDCs  you can\u0026rsquo;t flourish if you\u0026rsquo;re physical and mental power is spent on getting food   maps   additional notes   role of women in agricultural production economic purpose       5.1 Challenges of Contemporary Agriculture #   IMP Agricultural production and consumption patterns vary in different locations, presenting different environmental, social, economic, and cultural opportunities and challenges.\n  Learning Objective: Explain challenges and debates related to the changing nature of contemporary agriculture and food-production practices. Essential Knowledge:  Agricultural innovations such as biotechnology, genetically modified organisms, and aquaculture have been accompanied by debates over sustainability, soil and water usage, reductions in biodiversity, and extensive fertilizer and pesticide use.  biotechnology, genetically modified organisms, and aquaculture  technological innovations have led to much higher yield   debates over sustainability, soil and water usage, reductions in biodiversity, and extensive fertilizer and pesticide use  pesticides kill off good bugs, possibly whipe out entire vital species by accident the majority of the latest tech is avaliable only the core countries, not periphery agricultural diversity has been on the decline, increased chance of blight  New, or very old, disease comes back and, because of lack of genetic diversity, most crops highly susciptible       Patterns of food production and consumption are influenced by movements relating to individual food choice, such as urban farming, community-supported agriculture (CSA), organic farming, value-added specialty crops, fair trade, local-food movements, and dietary shifts.  urban farming community-supported agriculture (CSA) organic farming  avoid using synthetic chemical fertilizers and GMOs aim to protect earth and produce safe, healthy food with \u0026ldquo;zero impact\u0026rdquo; on environment   value-added specialty crops fair trade local-food movements dietary shifts  Most typical citizen is an asian farmer who produces enough to get by MDCs people eat a lot more Cliamte affects what people eat  MDCs this is less of an impact due to better tech making shipping faster LDCs can only really eat what is avaliable locally   Cultural prefences still dictate diet  \u0026lsquo;Fast-food\u0026rsquo; diet   Meat consumption:  MDCs get 1/3 of protein from meat LDCs get 1/10 of protein from meat, rely more on grains        Challenges of feeding a global population include lack of food access, as in cases of food insecurity and food deserts; problems with distribution systems; adverse weather; and land use lost to suburbanization.  food access (food insecurity and food deserts problems with distribution systems adverse weather land use lost to suburbanization     The location of food-processing facilities and markets, economies of scale, distribution systems, and government policies all have economic effects on food-production practices.     5.1 Women in Agriculture #   IMP Agricultural production and consumption patterns vary in different locations, presenting different environmental, social, economic, and cultural opportunities and challenges.\n  Learning Objective: Explain geographic variations in female roles in food production and consumption. Essential Knowledge:  The role of females in food production, distribution, and consumption varies in many places depending on the type of production involved.  Historically, Men gathered the materials and women used these materials to manufacture household objects and maintained there house Obstacles to equality + empowerment      Impact of empowerment effects of this women empowerment / equality on population growth effects of this women empowerment / equality on economic development effects of this women empowerment / equality on gender roles in the developing world.    "},{"id":50,"href":"/ap/cmech/","title":"AP Physics C: Mechanics","section":"AP Notes","content":"This are very disjoint notes I took long ago. I would recommend using this for practice qs and perhaps equation review after you have a solid understanding of the chapters. My other notes are much more comprehensive, I swear! :)  1. Kinematics #  Four Primary Equations #   $$\\Delta x=\\frac{1}{2}(v_f-v_i)\\Delta t \\text{ \u0026ndash; no } a$$ $$v_f=v_i+a\\Delta t \\text{ \u0026ndash; no } x$$ $$\\Delta x=v_i \\Delta t+\\frac{1}{2}a \\Delta t^2 \\text{ \u0026ndash; no } v_f$$ $$\\Delta x=v_f \\Delta t-\\frac{1}{2}a \\Delta t^2 \\text{ \u0026ndash; no } v_i$$ $$v_f^2=v_i^2+2a \\Delta x \\text{ \u0026ndash; no } t$$   Used when .$a$cceration is constant  Slope and Area #    Top is .$x$, middle is .$v$, bottom is .$a$   Projectile Motion #   Half of parabolic flight time: $$t_\\text{top}=\\frac{v_i*\\sin\\theta}{g}$$ Peak in .$y$ direction: $$y_\\text{max}=\\frac{v_i*\\sin^2\\theta}{2g}$$ Distance traveled in .$x$ direction: $$x_\\text{max}=\\frac{v_i*\\sin2\\theta}{g}$$ Desmos tools   Projectile motion  Displacement, Velocity, and Acceleration    Practice #  FRQs to study  Graphs  Changing Acceleration / Velocity     Example Qs 1. 2. 3. 4. 5. 6. 7. 8.       2. Forces #   .$N = \\text{kg m/s}^2$ \u0026ndash; a force of 1N causes a 1kg mass to accelerate at 1ms.$^{-2}$ Normal doesn\u0026rsquo;t always equal mg!  Friction #   Kinetic friction only acts when the force breaks past the static friction threshold The friction force is always the lesser of .$\\mu \\cdot N$ or the force it\u0026rsquo;s resisting $$F_s \\le \\mu_s \\cdot F_N$$  Spring #  $$F_\\text{spring} = -kx$$  $$k=\\frac{\\Delta F}{\\Delta x}$$    Thus, the slope .$\\Delta y / \\Delta x$ of a force vs. distance is .$k$  Centripital #  $$F_\\text{centripetal} = \\frac{mv^2}{r}$$\nGravity #  $$mg\\sin(θ) = F_\\text{gx} \\text{ \u0026ndash; Acceleration down ramp w/no friction}$$ $$mg\\cos(θ) = F_\\text{gy} \\text{ \u0026ndash; Normal force when no other forces act in the y direction}$$\nPulleys + Atwoods #  $$\\text{Acceleration of a Pulley} = \\frac{Mg}{m+M} = \\frac{Mg-\\mu mg}{m+M}$$\nDrag Force #   Drag on x-axis:  Drag on y-axis:   Practice #  FRQs to study Drag Multiple Bodies (pulleys, carts)   Practice Qs                                 3. Energy #  Work #  $$W = \\int F\\ dx = \\vec F_\\parallel \\cdot x = +\\Delta KE = -\\Delta PE = \\int P dt$$\n Force parallel to distance traveled If force is opposing motion and acceleration changes, work stays the same  Potential #  $$F = -\\frac{dU}{dx}$$\n Potential Energy can only depend on position Negative relation with force indicates that the direction of the force is always towards lower PE Derivation   Conservation #  Consider the total work done by a force that acts on a particle as the particle moves around a closed path and returns to its starting point. If this total work is zero, we call the force a conservative force. If the total work for the round trip is not zero, we call the force a non-conservative force. Consider the work done by a force that acts on an object as the object moves from an initial position to a final position along any arbitrarily chosen path. If this work is the same for all such paths, we call the force a conservative force. If the work is not the same for all paths, we call the force a non-conservative force.  $$\\Delta K + \\Delta U + \\Delta E_\\text{int}= W_\\text{ext}$$\n Conservative — NO external forces  Mechanical Energy conserved; ME = ME' Gravity, Spring Force Always have a potential energy associated with it Conservative force\u0026rsquo;s magnitude and direction only depend on the object\u0026rsquo;s location, not on how the object is moving   Non-conservative — external force present  Mechanical Energy lost; ME \u0026gt; ME' Friction, Air resistance (drag)   Internal Energy   Power #  Rate at which work is done $$P=\\frac{dW}{dt}=\\frac{dKE}{dt}=\\frac{W}{t}=\\vec F \\cdot \\vec v$$\nSprings #  $$W_\\text{spring}=\\int F_\\text{spring} dx= \\int (-kx)dx = -\\frac{1}{2}kx^2 $$ $$U_\\text{spring} = -W_\\text{spring}=\\frac{1}{2}kx^2$$\n Springs are most compressed in collisions when velocity of both objects are equal  Therefore, we can treat the system as inelastic at that moment Steps     Equilibrium #   Neutral Equilibrium is where the Potential Energy of the object remains constant regardless of position. For example, a ball rolling on a level surface. Stable Equilibrium is where the Potential Energy of the object increases as the position of the object moves away from the equilibrium position and therefore the object naturally returns to the equilibrium position. For example, a water bottle being tipped to the side. Unstable Equilibrium is where the Potential Energy of the object decreases as the position of the object moves away from the equilibrium position and therefore the object naturally moves away from the equilibrium position. For example, a marker being tipped to the side.   Practice #  Practice Qs                                         4. Momentum #  Collisions #  Elastic — bounce off #   KE conserved Momentum conserved (while no unbalanced ext forces) If the final velocity of an object is less than half of the initial velocity of the object (v_i/2), then the object it\u0026rsquo;s colliding with has more mass $$v_1+v_1\u0026rsquo;=v_2+v_2\u0026rsquo;$$ $$v_1\u0026rsquo;=\\frac{m_1-m_2}{m_1+m_2}v_1$$ $$v_2\u0026rsquo;=\\frac{2m_1}{m_1+m_2}v_2$$  Inelastic — Stick #   KE lost Momentum conserved (while no unbalanced ext forces) Maximum speed when m \u0026laquo; M   Impulse — Force and Time #  $$\\vec J = \\int \\vec F dt = \\vec F_\\text{avg} \\Delta t= \\Delta \\vec p = m \\Delta \\vec v$$\nCenter of Mass #   When only gravity is acting on a object that is thrown, it will spin (pivot) around the center of mass If you split an object along the center of mass line, both sides aren\u0026rsquo;t equal in mass unless density / form is the same for both. $$x_\\text{cm}=\\frac{\\Sigma(m_ix_i)}{\\Sigma(m)}=\\frac{\\int x \\lambda \\cdot dx}{\\Sigma M}$$ $$v_\\text{cm}=\\frac{\\Sigma(m_iv_i)}{\\Sigma(m)}$$ $$\\Sigma p=mv_\\text{cm}$$ $$\\Sigma F=ma_\\text{cm}$$  Practice #  Practice Qs           a. Integrate 0m to 4m                     5. Rotation #  Rotational Kinematics #  Used when α is constant\n $$ \\Delta \\theta=\\frac{1}{2}(\\omega_f-\\omega_i)\\Delta t \\text{ \u0026ndash; no } \\alpha$$ $$ \\omega_f=\\omega_i+\\alpha\\Delta t \\text{ \u0026ndash; no } \\theta$$ $$\\ \\Delta \\theta=\\omega_i \\Delta t+\\frac{1}{2}\\alpha \\Delta t^2 \\text{ \u0026ndash; no } \\omega_f$$ $$\\ \\Delta \\theta=\\omega_f \\Delta t-\\frac{1}{2}\\alpha \\Delta t^2 \\text{ \u0026ndash; no } \\omega_i$$ $$\\omega_f^2=\\omega_i^2+2\\alpha \\Delta \\theta \\text{ \u0026ndash; no } t$$  Rotational Inertia #   Pulleys with finishing with none+blue same time, then green, then red   Rolling Down an Incline   Rolling Down an Incline + Slipping   Rolling Up an Incline   Rolling Up an Incline   Rolling Up an Incline + Slipping Should be Blue \u0026gt; Green \u0026gt; Red (0)   Practice Qs #  Practice Qs         where green has lower moment of inertia, and red has larger moment of inertia        Answer       9 10 11 12 13     "},{"id":51,"href":"/ap/stats/","title":"AP Statistics","section":"AP Notes","content":"The content of these notes are solid, but formatting is not since they\u0026rsquo;re exported from Notion.  Unit 1: Exploring One-Variable Data #  Types of Variables #   Categorical variables assigns labels that place each individual into a particular group, called a category.  Zip code. hair color   Quantitative variables takes number values that are quantities—counts or measurements.  Height, GPA   Explanatory  x on graph independent variable — what we\u0026rsquo;re changing measures an outcome of a study.   Response  y on graph (potentially) dependent variable — what we\u0026rsquo;re measuring may help predict or explain changes in a response variable   Confounding  Any factor that messes skews data Confounding occurs when two variables are associated in such a way that their effects on a response variable cannot be distinguished from each other. If you are asked to identify a possible confounding variable in a given setting, you are expected to explain how the variable you choose (1) is associated with the explanatory variable and (2) is associated with the response variable.    Frequencies #   A frequency table shows the number of individuals having each value.  A relative frequency table shows the proportion or percent of individuals having each value. A marginal relative frequency gives the percent or proportion of individuals that have a specific value for one Categorical variable.  What percent of people in the sample are environmental club members?  What proportion of people in the sample never used a snowmobile?    A joint relative frequency gives the percent or proportion of individuals that have a specific value for one Categorical variable and a specific value for another Categorical variable.  We can compute marginal relative frequencies for the row totals to give the distribution of snowmobile use for all the individuals in the sample:  We can compute marginal relative frequencies for the column totals to give the distribution of environmental club membership in the entire sample of 1526 park visitors    A conditional relative frequency gives the percent or proportion of individuals that have a specific value for one Categorical variable among individuals who share the same value of another Categorical variable (the condition).  What proportion of snowmobile renters in the sample are not environmental club members?  What percent of environmental club members in the sample are snowmobile owners?     Types of Graphs #   Pie Chart — Categorical  Need frequency value and corresponding label  Doesn\u0026rsquo;t show sample size     Bar Graph — Categorical  Needs bar labels, axis names, units, vertical axis scale should start at 0 A side-by-side bar graph displays the distribution of a Categorical variable for each value of another Categorical variable. The bars are grouped together based on the values of one of the Categorical variables and placed side by side. A segmented bar graph displays the distribution of a Categorical variable as segments of a rectangle, with the area of each segment proportional to the percent of individuals in the corresponding category.  Doesn\u0026rsquo;t show sample size, only proportions  This can be fixed by using a mosaic plot which scales the width corresponding to size       Dotplot — Quantitative  A dot plot shows each data value as a dot above its location on a number line. Needs title, axis label, unit of measurement How to find percentile  Percentile is the percent of people you\u0026rsquo;re better than, or percent of people that are worse than you Find how many points the decided point is ahead of, then divide by sample size The blue point is greater than 17 points, making it 17/20 —\u0026gt; in the 85% percentile     Stemplot — Quantitative  A stemplot shows each data value separated into two parts: a stem, which consists of all but the final digit, and a leaf, the final digit. The stems are ordered from lowest to highest and arranged in a vertical column. The leaves are arranged in increasing order out from the appropriate stems. Needs key and title  Key should give context   Key: 8|2 is a [context — student whose resting pulse rate] is 82 [beats per minute]\n    Histogram — Quantitative  A histogram shows each interval of values as a bar. The heights of the bars show the frequencies or relative frequencies of values in each interval. Needs title, axis label, unit of measurement   Boxplot — Quantitative  Describing Distributions (SOCS) + Context #   Always be sure to include context when you are asked to describe a distribution. This means using the variable name, not just the units the variable is measured in. When comparing distributions of Quantitative data, it’s not enough just to list values for the center and variability of each distribution. You have to explicitly compare these values, using words like “greater than,” “less than,” or “about the same as.”\n Shape (Skew) #    A distribution is skewed to the right if the right side of the graph is much longer than the left side. A distribution is skewed to the left if the left side of the graph is much longer than the right side.   The distribution of [context] is [skewed left/right/sym]\n Outlier #   Gaps too Low outliers \u0026lt; Q1 − 1.5 × IQR High outliers \u0026gt; Q3 + 1.5 × IQR Doesn\u0026rsquo;t follow trend, large residual   The [context — games played with 5 points / person with a height of 3\u0026rsquo;] appears to be an outlier\n Center #   Mean / average  The mean is sensitive to extreme values in a distribution.  These may be outliers, but a skewed distribution that has no outliers will also pull the mean toward its long tail.   We say that the mean is not a resistant measure of center — Shouldn\u0026rsquo;t be used with skew or outliers   Median  Resistant — should be used with outliers and skew    Spread / Variability #   Range  Not resistant — Shouldn\u0026rsquo;t be used with skew or outliers   The data vary from [min] to [max] [context — points scored / heights] meaning it had a range of [max - min]\n  Standard Deviation  Measure of the typical distance of the values in a distribution from the mean. It should be used only when the mean is chosen as the measure of center. sx is not a resistant measure of variability — Shouldn\u0026rsquo;t be used with skew or outliers Larger values of sx indicate greater variation sx is always greater than or equal to   The Interquartile Range (IQR)  What  The quartiles of a distribution divide the ordered data set into four groups having roughly the same number of values. To find the quartiles, arrange the data values from smallest to largest and find the median. The first quartile Q1 is the median of the data values that are to the left of the median in the ordered list. The third quartile Q3 is the median of the data values that are to the right of the median in the ordered list. IQR = Q3 - Q1   Resistant because they are not affected by a few extreme value — should be used with outliers    Why is it important? #   They might be inaccurate data values. Maybe someone recorded a value as 10.1 instead of 101. Perhaps a measuring device broke down. Or maybe someone gave a silly response, like the student in a class survey who claimed to study 30,000 minutes per night! Try to correct errors like these if possible. If you can’t, give summary statistics with and without the outlier. They can indicate a remarkable occurrence. For example, in a graph of net worth, Bill Gates is likely to be an outlier. They can heavily influence the values of some summary statistics, like the mean, range, and standard deviation. It can make it easier to see associations between variables  An association exists when there is a difference in outcome for different inputs We can only find definitive associations for the sample, and we have to use test to find out if we can extrapolate this data to a larger sample For example, there may be an association between AP Stats students and not having post-HS plans and overall being less likely to go to University when compared to AP Calc students    Five number summary (+ boxplot) #   Min Q1 Median Q3 Max  Standardized score (z-score) — the \u0026rsquo;test statistic' #    Tells us how many standard deviations from the mean the value falls, and in what direction.\n  Values larger than the mean have positive z-scores. Values smaller than the mean have negative z-scores.\n  Shape must be close to normal for z-scores to work\n  Never say that a distribution of Quantitative data is Normal. Real-world data always show at least slight departures from a Normal distribution. The most you can say is that the distribution is “approximately Normal.” 68–95–99.7  Approximately 68% of the observations fall within σ of the mean μ Approximately 95% of the observations fall within σ 2 of the mean μ Approximately 99.7% of the observations fall within σ 3 of the mean μ    Transforming Data #   Multiplying / dividing by a constant (Units converted)  Multiplies (divides) center and location (mean, five-number summary, percentiles) by b Multiplies (divides) measures of variability (range, IQR, standard deviation) by b Does not change the shape of the distribution   Adding/subtracting constant  Adds a to (subtracts a from) measures of center and location (mean, five-number summary, percentiles) Does not change measures of variability (range, IQR, standard deviation) Does not change the shape of the distribution    Percentile #   invNorm(.9, 0, 1) would find the z-score of 90%  Good video   Unit 2: Exploring Two-Variable Data #  How to Describe a Scatterplot #   Use CONTEXT Direction (association) Two variables have a positive association when above-average values of one variable tend to accompany above-average values of the other variable and when below-average values also tend to occur together.  More [x-unit], more [y-unit]   Two variables have a negative association when above-average values of one variable tend to accompany below-average values of the other variable.  More [x-unit], less [y-unit]   There is no association between two variables if knowing the value of one variable does not help us predict the value of the other variable.  Form: #   A scatterplot can show a linear form or a nonlinear form. The form is linear if the overall pattern follows a straight line. Otherwise, the form is nonlinear.  Strength (correlation): #   A scatterplot can show a weak, moderate, or strong association. An association is strong if the points don’t deviate much from the form identified. An association is weak if the points deviate quite a bit from the form identified. Correlation doesn’t imply causation.  In many cases, two variables might have a strong correlation, but changes in one variable are very unlikely to cause changes in the other variable   \u0026lsquo;r\u0026rsquo; — Correlation Coefficie  It is only appropriate to use the correlation to describe strength and direction for a linear relationship Has same sign (positive or negative) as the slope r measures the direction and strength of the association, and does not measure form The correlation r is always a number between −1 and 1 (−1 ≤ r ≤ 1) The correlation r indicates the direction of a linear relationship by its sign: r \u0026gt; 0 for a positive association and r \u0026lt; 0 for a negative association. The extreme values r = −1 and r = 1 occur only in the case of a perfect linear relationship, when the points lie exactly along a straight line. If the linear relationship is strong, the correlation r will be close to 1 or −1. If the linear relationship is weak, the correlation r will be close to 0.     Unusual features: #   outliers  that fall outside the overall pattern and distinct clusters of points — doesn\u0026rsquo;t follow trend large residual  definition link   influential point  if you remove the point, then there would be substantial changes on slope, y-int, or r    Interpreting #   There is a [strength — fairly strong/weak], [direction — positive / negative] [form — (non)linear] relationship between [x var] and [y-var] with [any outliers + outlier point].\n Residuals #   a = y-int, b = slope, s = s, R-sq = .$r^2$\nLeast-squares Regression Line (LSRL) #   A regression line is a line that describes how a response variable y changes as an explanatory variable x changes. Made to reduce the residual  Regression lines are expressed in the form where ŷ(pronounced “y-hat”) is the predicted value of y for a given value of x.  Extrapolation is the use of a regression line for prediction far outside the interval of x values used to obtain the line. Such predictions are often not accurate.  Don’t make predictions using values of x that are much larger or much smaller than those that actually appear in your data.   Interpretation — NEEDS CONTEXT  y-int y=b0+b1*x  b0   For a [context of x-var] with a [x-unit] of 0, the predicted [y-var] is [b0]\n  Slope  b1   For every increase of 1 in [x-unit], the predicted [y-unit] increases by [b1] [y-units]\n    Residual  Difference between actual and predicted value Interpretation:  The actual [y-var] for a [context] of [x-input \u0026amp; x-units] is [actual value (point we know) - predicted value] [lower/higher] than predicted by the LSRL.\n  Plug in respective values to LSRL to get the predicted value Residual Plot  a scatterplot that displays the residuals on the vertical axis and the explanatory variable on the horizontal axis. To determine whether the regression model is appropriate, look at the residual plot.  If there is no leftover curved pattern in the residual plot, the regression model is appropriate. LSRL is good Interpretation:  Because the residual plot does not show a clear pattern, the linear model is appropriate for the data\n  If there is a leftover curved pattern in the residual plot, consider using a regression model with a different form. LSRL is bad Interpretation:  Because the residual plot shows a clear patter, the linear model is not appropriate for the data\n         Standard deviation of residuals: .$s$ #   The standard deviation of the residuals s measures the size of a typical residual. That is, s measures the typical distance between the actual y values and the predicted y values. Interpretation:  The actual [y-var] [units] is typically around [s] away from the predicted by the least-squares regression line with x = [x-units]\n   The coefficient of determination: .$r^2$ #   The coefficient of determination .$r^2$ measures the percent reduction in the sum of squared residuals when using the least-squares regression line to make predictions, rather than the mean value of y. In other words, .$r^2$ measures the percent of the variability in the response variable that is accounted for by the least-squares regression line. Interpretation:  About [.$r^2$ in percent form]% of the variability for [y-var] is accounted for by the least-squares regression line with x = [x-var]\n    Unit 3: Collecting Data #  Chapter 4\nSampling #   The population in a statistical study is the entire group of individuals we want information about. A census collects data from every individual in the population. A sample is a subset of individuals in the population from which we collect data. A sample survey is a study that collects data from a sample that is chosen to represent a specific population.  Poor Sampling #   Convenience sampling selects individuals from the population who are easy to reach. Voluntary response sampling allows people to choose to be in the sample by responding to a general invitation Bias:  any difference between the sample result and the truth about the population that tends to occur in the same direction whenever you use the same sampling method The design of a statistical study shows bias if it is very likely to underestimate or very likely to overestimate the value you want to know. Bias is not just bad luck in one sample, it’s the result of a bad study design that will consistently miss the truth about the population in the same way If you’re asked to describe how the design of a sample survey leads to bias, you’re expected to do two things:  Describe how the members of the sample might respond differently from the rest of the population Explain how this difference would lead to an underestimate or overestimate.   Suppose you were asked to explain how using your statistics class as a sample to estimate the proportion of all high school students who own a graphing calculator could result in bias. You might respond, “This is a convenience sample . It would probably include a much higher proportion of students with a graphing calculator than in the population at large because a graphing calculator is required for the statistics class. So this method would probably lead to an overestimate of the actual population proportion.”   Undercoverage  occurs when some members of the population are less likely to be chosen or cannot be chosen in a sample. Most samples suffer from some degree of undercoverage. A sample survey of households, for example, will miss not only homeless people but also prison inmates and students in dormitories.   Nonresponse  Nonresponse occurs when an individual chosen for the sample can’t be contacted or refuses to participate Nonresponse leads to bias when the individuals who can’t be contacted or refuse to participate would respond differently from those who do participate. Consider a telephone survey that asks people how many hours of television they watch per day. People who are selected but are out of the house won’t be able to respond.   Response Bias  Response bias occurs when there is a systematic pattern of inaccurate answers to a survey question. The way questions are worded or the order in which they\u0026rsquo;re asked can lead to response bias    Good Sampling #   Simple random sample (SRS)  Involves using a chance process to determine which members of a population are included in the sample . Gives each possible sample an equal chance of being selected A simple random sample (SRS) of size n is chosen in such a way that every group of n individuals in the population has an equal chance to be selected as the sample. For example, to choose a random sample of 6 students from a class of 30, start by writing each of the 30 names on a separate slip of paper, making sure the slips are all the same size. Then put the slips in a hat, mix them well, and pull out slips one at a time until you have identified 6 different students.   Strata, Stratified random sample  Strata are groups of individuals in a population who share characteristics thought to be associated with the variables being measured in a study. good for when sample sizes between population groups (stratas) are different Stratified random sampling selects a sample by choosing an SRS from each stratum and combining the SRSs into one overall sample. For example, in a study of sleep habits on school nights, the population of students in a large high school might be divided into freshman, sophomore, junior, and senior strata. After all, it is reasonable to think that freshmen have different sleep habits than seniors. The following activity illustrates the benefit of choosing appropriate strata.   Clusters, Cluster sampling  A cluster is a group of individuals in the population that are physically located near each other. Cluster sampling selects a sample by randomly choosing clusters and including each member of the selected clusters in the sample . Cluster sampling is often used for practical reasons, like saving time and money. Imagine a large high school that assigns students to homerooms alphabetically by last name, in groups of 25. Administrators want to survey 200 randomly selected students about a proposed schedule change. It would be difficult to track down an SRS of 200 students, so the administration opts for a cluster sample of homerooms. The principal (who knows some statistics) selects an SRS of 8 homerooms and gives the survey to all 25 students in each homeroom.   Systematic Random Sampling  In systematic random sampling, the researcher first randomly picks the first item or subject from the population . Then, the researcher will select each n\u0026rsquo;th subject from the list. The procedure involved in systematic random sampling is very easy and can be done manually. The results are representative of the population unless certain characteristics of the population are repeated for every n\u0026rsquo;th individual, which is highly unlikely.    Experiments #   Goal is to  reduce bias and  allow replication with the hopes that we find statistically significant results that we can infer/extrapolate to the population Four conditions of Experimental Design  Comparison. Use a design that compares two or more treatments. Random assignment. Use chance to assign experimental units to treatments. Doing so helps create roughly equivalent groups of experimental units by balancing the effects of other variables among the treatment groups. Control. Keep other variables the same for all groups, especially variables that are likely to affect the response variable. Control helps avoid confounding and reduces variability in the response variable. Replication. (more than one experimental unit in each treatment group) — Use enough experimental units in each group so that any differences in the effects of the treatments can be distinguished from chance differences between the groups.   Study:  Observational Study: observes individuals and measures variables of interest but does not attempt to influence the responses. Observational Study vs experiment  experiment (randomly) assigns treatments in studies the researcher has no interaction/input whatsoever   data is observed and recorded naturally, scientists had no say  can reduce bias from scientists   no random assignment of subjects, but random sample can be taken  therefore, we can make inferences about the population from which the individuals were chose, but not about cause and effect ( link)     Vocab  Experiment: deliberately imposes some treatment on individuals to measure their responses  Response / Explanatory / Confounding Variables Placebo: A placebo is a treatment that has no active ingredient, but is otherwise like other treatments.  The placebo effect describes the fact that some subjects in an experiment will respond favorably to any treatment, even an inactive treatment.   Control: In an experiment, control means keeping other variables constant for all experimental units. Treatment: A specific condition applied to the individuals in an experiment Control group  In an experiment, a control group is used to provide a baseline for comparing the effects of other treatments. Depending on the purpose of the experiment, a control group may be given an inactive treatment (placebo), an active treatment, or no treatment at all.   Experimental unit: the object to which a treatment is randomly assigned Subjects: When the experimental units are human beings, they are often called subjects. Factor: In an experiment, a factor is a variable that is manipulated and may cause a change in the response variable.  Levels: In an experiment, a factor is a variable that is manipulated and may cause a change in the response variable. The different values of a factor are called levels.   Blinds  In a double-blind experiment, neither the subjects nor those who interact with them and measure the response variable know which treatment a subject received. In a single-blind experiment, either the subjects don’t know which treatment they are receiving or the people who interact with them and measure the response variable don’t know which subjects are receiving which treatment   Replication  In an experiment, replication means using enough experimental units to distinguish a difference in the effects of the treatments from chance variation due to the random assignment.   Sampling Variability  Refers to the fact that different random samples of the same size from the same population produce different estimates. Larger random samples tend to produce estimates that are closer to the true population value than smaller random samples. In other words, estimates from larger samples are more precise.   Statistically significant  When the observed results of a study are too unusual to be explained by chance alone, the results are called statistically significant.     Types of Experiments  Block, Randomized block design  A block is a group of experimental units that are known before the experiment to be similar in some way that is expected to affect the response to the treatments. In a randomized block design, the random assignment of experimental units to treatments is carried out separately within each block.    Matched Pairs  A matched pairs design is a common experimental design for comparing two treatments that uses blocks of size 2. In some matched pairs designs, two very similar experimental units are paired and the two treatments are randomly assigned within each pair. In others, each experimental unit receives both treatments in a random order.   Random Assignment: In an experiment, random assignment means that the treatment / placebo is randomly given out   Scope of Inference  Inference: The process of drawing conclusions about a population based on samples, since we infer information about the population from what we know about the samples. Random Selection — sample units are selected randomly  allows inference about the population from which the individuals were chosen groups may not be representative of population includes studies   Random Assignment — experimental units are assigned to treatments using a chance process.  allows inference about cause and effect. groups may differ between studies if not randomly assigned tend to average out all other uncontrollable factors so that they aren\u0026rsquo;t confounding with the treatment effects not studies   Additional Requirements:  The association is strong. The association is consistent. Larger values of the explanatory variable are associated w/ stronger responses. The alleged cause precedes the effect in time.     Criteria for Establishing Causation When an Experiment CANNOT Be Done ● The association is strong. ● The association is consistent. ● Larger values of the explanatory variable are associated w/ stronger responses. ● The alleged cause precedes the effect in time. ● The alleged cause is plausible. Ethics  All planned studies must be reviewed in advance by an institutional review board charged with protecting the safety and well-being of the subjects. All individuals who are subjects in a study must give their informed consent before data are collected. All individual data must be kept confidential. Only statistical summaries for groups of subjects may be made public.     Unit 4: Probability, Random Variables, and Probability Distributions #  Chapters 5 \u0026amp; 6\nProbability #   LAW OF LARGE NUMBERS  A law that states if we observe more and more repetitions of any chance process, the proportion of times a specific outcome occurs approaches its actual probability. We cannot accurately predict outcomes in the SHORT RUN; Order only emerges in the LONG RUN. No such thing as Law of Averages – Only Law of Large Numbers!!!!!   Probibility  The probability of any outcome of a chance process is a number between 0 and 1 that describes the proportion of times the outcome would occur in A VERY LONG SERIES OF REPETITIONS. Outcomes that will never ever occur Probability = 0 Outcomes that will always occur Probability = 1   Simulation  The imitation of chance behavior, based on a model that accurately reflects the situation. The Simulation Process  Describe how to use a chance device to imitate one trial (repetition) of the simulation. Tell what you will record at the end of each trial.  Remember that every label needs to be the same length. In the golden ticket lottery example, the labels should be 01 to 95 (all two digits), not 1 to 95. When sampling without replacement, be sure to mention that repeated numbers should be ignored.   Perform many trials of the simulation. Use the results of your simulation to answer the question of interest. Example      Probability Model: A description of some chance process that consists of 2 parts:  a list of all possible outcomes  SAMPLE SPACE: The list of all possible outcomes.   the probability for each outcome   EVENT Any collection of outcomes from some chance process — A subset of the entire sample space. MUTUALLY EXCLUSIVE Two events A \u0026amp; B are mutually exclusive if they have no outcomes in common and so can never occur together – that is, if P(A and B) = 0. General Rules $$0 ≤ P(A) ≤ 1 \\text{ for any event }A$$ $$P(S) = 1 \\text{ if }S\\text{ is the sample space in a probability model}$$ $$P(A)=\\frac{\\text{Number of outcomes in event } A}{\\text{Total number of outcomes in sample space}}\\text{ in the case of EQUALLY LIKELY outcomes,}$$ $$\\text{Complement Rule: } P(A^c)=1-P(A); \\text{where }A^c=\\text{the event that A does not occur}$$ $$\\text{Addition rule for mutually exclusive events: }P(A \\text{ or } B)=P(A \\cup B) = P(A) + P(B)$$ $$\\text{General addition rule: } P(A \\text{ or } B) =P(A \\cup B)= P(A) + P(B) − P(A \\text{ and } B) $$ $$\\text{Dependent events: } P(A \\text{ and } B) = P(A ∩ B) = P(A) ⋅ P(B | A)$$ $$\\text{Independent events: } P(A \\text{ and } B) = P(A ∩ B) = P(A) ⋅ P(B)$$ $$\\text{Probability of A given B: } P(A|B)=\\frac{P(A \\text{ and } B)}{P(B)} $$ Conditional  CONDITIONAL PROBABILITY  Example  The probability that one event happens given that another event is known to have happened. The conditional probability that event B happens GIVEN that event A has happened is denoted by P(B | A).     INDEPENDENT EVENTS  A and B are independent events if knowing whether or not one event has occurred does not change the probability that the other event will happen.  In other words, events A and B are independent if $$P(A ∣ B) = P(A ∣ B ^c ) = P(A)$$ Alternatively, events A and B are independent if $$P(B ∣ A) = P(B ∣ A^c) = P(B)$$    Random Variables #   DISCRETE RANDOM VARIABLE  A random variable that has a countable number of outcomes with gaps. Examples: ACT Scores; # of Free-Throws Made, etc.   CONTINUOUS RANDOM VARIABLE  A random variable that has an infinite number of outcomes with no gaps. Examples: Temperature; Race Times; Heart Rate, etc.   Mean  Variance  Standard Deviation  Transforming — only works for independent!  When MULTIPLYING (or DIVIDING) each value in a probability distribution by some number b, the ● mean is MULTIPLIED (or DIVIDED) by b ● variance is MULTIPLIED (or DIVIDED) by b^2 ● standard deviation is MULTIPLIED (or DIVIDED) by b When ADDING (or SUBTRACTING) the number a to each value in a probability distribution, the ● mean INCREASES (or DECREASES) by a ● variance STAYS THE SAME ● standard deviation STAYS THE SAME   Combining — only works for independent! Suppose we add two normal distributions (X + Y) or we subtract two normal distributions (X – Y). The shape of the resulting distribution will be NORMAL and the mean and standard deviation can be calculated using the RULES. where \\row (no ^2) is standard deviation Difference between the binomial setting and the geometric setting  Binomial  Binomial Setting:  Binary? Each observation falls into 1 of 2 categories: SUCCESS or FAILURE Independent? The n observations are all INDEPENDENT. (knowing one outcome of a trial has no effect on the other trials)  Note: if sampling w/o replacement, you need to check the 10% condition   Number? There is a fixed number n of TRIALS/OBSERVATIONS. Success? The probability of success, p, is SAME for each trial.   BINOMIAL DISTRIBUTION  If large counts is verified, then the binomial distribution\u0026rsquo;s shape is approximately normal The distribution of the count X of successes in the binomial setting with parameters n and p. n = # of Trials/Observations p = Probability of Success (per Trial) Possible Values for X = whole #s 0 to n Abbreviation = B (n, p)   BINOMIAL COEFFICIENT  The number of ways to arrange k successes among n trials; “Combinations”    Binomial Probability Formula  binomialPdf / Cdf also works      Geometric:  The Geometric Setting  Binary? Each observation falls into 1 of 2 categories: SUCCESS or FAILURE Independent? The n observations are all INDEPENDENT. (knowing one outcome of a trial has no effect on the other trials). Trials? The goal is to count the number of trials until the FIRST SUCCESS Success? The probability of success, p, is SAME for each trial.   Shape  skewed right    GEOMETRIC PROBABILITY FORMULA  geometCdf / Pdf also works        Unit 5: Sampling Distributions #  Chapter 7 + 10\nSampling Distribution: #   The sampling distribution of a statistic is the distribution of values taken by the statistic in all possible samples of the same size from the same population. Always say “the distribution of [blank],” being careful to distinguish the distribution of the population, the distribution of sample data, and the sampling distribution of a statistic. Sampling distribution of the sample proportion  The sampling distribution of the sample proportion p hat describes the distribution of values taken by the sample proportion p hat in all possible samples of the same size from the same population.  Conditions  Random: The data must come from a well-designed RANDOM sample or a RANDOMIZED experiment. Normal: The sampling distribution is approximately NORMAL, meaning we can use a z-test statistic.  Large Counts: (np ≥ 10) \u0026amp; (n (1 − p) ≥ 10 )   Independent:  If 2 samples, both samples must be independent 10% Condition: When sampling w/o replacement to verify the use of our standard deviation ( 10n \u0026lt; N )       Sampling distribution of the sample mean  The sampling distribution of the sample mean x describes the distribution of values taken by the sample mean x in all possible samples of the same size from the same population.  Conditions  Random: The data must come from a well-designed RANDOM sample or a RANDOMIZED experiment. Normal: The sampling distribution is approximately NORMAL, meaning we can use a z-test/t-test statistic.  Either (or both) condition(s) must be met: CLT  n ≥ 30 — n_diff ≥ 30 for paired data The central limit theorem (CLT) says that when n is larger than 30, the sampling distribution of the sample mean x is approximately Normal.   Distribution shouldn\u0026rsquo;t be skewed  values above the median are much more variable than the values below the median      Independent:  If 2 samples, both samples must be independent 10% Condition: When sampling w/o replacement to verify the use of our standard deviation ( 10n \u0026lt; N ) — 10*n_diff \u0026lt; N_diff for paired data       Sampling Variability: Sampling variability refers to the fact that different random samples of the same size from the same population produce different values for a statistic.  Parameter: A number computed from a population Statistic  A number computed from a SAMPLE What makes a statistic a good estimator of a parameter?  LOW BIAS (Randomization) High bias is usually because of a poor sampling design (lack of randomness). LOW VARIABILITY (Sample Size) Reduce the variability of a statistic is to INCREASING SAMPLE SIZE.     Difference between proportions  Difference between means Many students use “accurate” when they really mean “precise.” For example, a response that says “increasing the sample size will make an estimate more accurate” is incorrect   Paired Data #   Paired data result from recording two values of the same Quantitative variable for each individual or for each pair of similar individuals. 2 sets of data that are not independent from each other, then they\u0026rsquo;re paired Analyzing Paired Data: To analyze paired data, start by computing the difference for each pair. Then make a graph of the differences. Use the mean difference x and the standard deviation of the differences as summary statistic.   Confidence Intervals #   Point estimator:  a statistic that provides an estimate of a population parameter. The value of that statistic from a sample is called a point estimate.  Ideally our “best guess” at the value of an unknown parameter. Because the sample mean ¯x is an unbiased estimator of the population mean μ, we use the statistic ¯x as a point estimator ****of the parameter μ. The best guess for the value of μ is ¯x   Unbiased Estimator: A statistic used to estimate a parameter is an unbiased estimator if the mean of its sampling distribution is equal to the value of the parameter being estimated.   Confidence Level α  The confidence level C% gives the overall success rate of the method used to calculate the confidence interval. Interpretation  If we were to select many random samples from a population and construct a C% confidence interval using each sample, about C% of the intervals would capture the [parameter in context].\n    Confidence interval  When interpreting a confidence interval, make sure that you are describing the parameter and not the statistic. Interpretation  “We are C% confident that the interval from [min] to [max] captures the true value of the [parameter in context].”\n    Margin of error  describes how far, at most, we expect the estimate to vary from the true population value. In a C% confidence interval, the distance between the point estimate and the true parameter value will be less than the margin of error in C% of all samples. How to decrease MOE  The confidence level decreases. To obtain a smaller margin of error from the same data, you must be willing to accept less confidence. The sample size n increases. In general, increasing the sample size n reduces the margin of error for any fixed confidence level.   Margin of error accounts for only the variability we expect from random sampling. It does not account for practical difficulties, such as undercoverage and nonresponse in a sample survey   Critical Value  The critical value is a multiplier that makes the interval wide enough to have the stated capture rate. Z-score when we know stdiv t-score when we don\u0026rsquo;t know stdiv   Standard Error (SE)   Proportions #   Four-step process:  State  What parameter do you want to estimate and at what confidence level? 1 proportion  \u0026ldquo;We wish to estimate the true proportion of all [parameter], with [C%] confidence.\u0026rdquo;\n  2 proportions  \u0026ldquo;We wish to estimate the true difference of the proportion of all [parameter 1] and all [parameter 2] for [context], with [C%] confidence.\u0026rdquo;\n    Plan  Identify the appropriate inference method  \u0026ldquo;We\u0026rsquo;ll carry out a [ONE/TWO]-SAMPLE Z INTERVAL FOR A POPULATION PROPORTION (because we\u0026rsquo;re estimating a proportion and we know the standard deviation.)\u0026rdquo;\n  Check conditions   Do  Perform the calculations.   \u0026ldquo;Because the conditions are true, we can do our calculations:\u0026rdquo;   1 proportion  2 proportions  where z* is the critical value for the standard Normal curve with C% of its area between −z* and z*.   Conclude  Interpret your interval in the context of the problem.  We are [C%] confident that the interval of [min] to [max] [units] captures the true proportion of all [context]\n  2 sample difference  If 0 is within confidence interval range:  Because 0 is contained in the [C%] confidence interval it is plausible there is no difference between [parameter 1] and [parameter 2]. We do not have convincing evidence of a difference of proportions of [context]\n  If 0 is NOT within confidence interval range:  Because 0 is not contained in the [C%] confidence interval it is plausible there is a difference between [parameter 1] and [parameter 2]. We have convincing evidence of a difference of proportions of [context]\n         Means #   Four-step process  State  What parameter do you want to estimate and at what confidence level? 1 proportion  We wish to estimate the true mean of all [parameter], with [C%] confidence.\n  2 proportions  We wish to estimate the true difference of the mean of all [parameter 1] and all [parameter 2] for [context], with [C%] confidence.\n    Plan  Identify the appropriate inference method  If we know stdiv  We\u0026rsquo;ll carry out a [ONE/TWO]-SAMPLE Z INTERVAL FOR A POPULATION MEAN(because we know the standard deviation.)\n  If we don\u0026rsquo;t know stdiv  We\u0026rsquo;ll carry out a [ONE/TWO]-SAMPLE Z INTERVAL FOR A POPULATION MEAN(because and we don\u0026rsquo;t know the standard deviation.)\n    Check conditions   Do  Perform the calculations. z-score  Because we know conditions are true, can do our calculations   1 mean  2 means with z* score and \\row   t-score  Because we know conditions are true, we can say that the t-distribution\u0026rsquo;s degree of freedom (df) is df = n - 1 and we\u0026rsquo;ll carry out a [one/two]-sample t interval for a population mean   1 mean  2 means  Difference      Conclude  Interpret your interval in the context of the problem.  We are [C%] confident that the interval of [min] to [max] [units] captures the true mean of all [context]\n  2 sample difference  If 0 is within confidence interval range:  Because 0 is contained in the [C%] confidence interval it is plausible there is no difference between [parameter 1] and [parameter 2]. We do not have convincing evidence of a difference between means of [context]\n  If 0 is NOT within confidence interval range:  Because 0 is not contained in the [C%] confidence interval it is plausible there is a difference between [parameter 1] and [parameter 2]. We have convincing evidence of a difference between means of [context]\n        t-scores  A t-distribution is specified by its degrees of freedom (df) calculated df = n - 1 The spread of the t-distribution is MORE than that of a standard Normal distribution. The t-distribution has MORE probability in the tails than the standard Normal distribution, since substituting the estimate sx for the parameter σ introduces MORE variation into the statistic. As degrees of freedom increases, the t-distribution becomes CLOSER to the standard Normal distribution, since sx estimates MORE accurately when the sample size is large.    Choosing sample size #   Sometimes, we want to choose our sample size (n) so that we may estimate a proportion within a particular margin of error. We must choose our sample size before we start sampling.  Conservative Approach: Use p .5 , because it maximizes the margin of error. Better Approach if Possible: Make a guess about the value of p based on prior knowledge, common knowledge, previous studies, etc. $$Z^*\\sqrt{\\frac{p(1-p)}{n}} \\leq ME, \\text{and solve for n}$$   Sample Size for a Desired Margin of Error when Estimating μ  To determine the sample size n that will yield a C% confidence interval for a population mean with a specified margin of error ME:  Get a reasonable value for the population standard deviation σ from an earlier or pilot study. Find the critical value z* from a standard Normal curve for confidence level C%. Set the expression for the margin of error to be less than or equal to ME and solve for n:       Tests #  Shared Vocab #   Significance Test  A formal procedure for comparing OBSERVED DATA with a CLAIM whose truth we want to assess.   Null hypothesis — H0  A test is designed to assess the strength of the evidence AGAINST this. This hypothesis is often the statement of “no difference.”   Alternative hypothesis — Ha  The claim about the population we are trying to find evidence FOR. This hypothesis should always be created BEFORE seeing the data. One sided  less than or greater than   Two sided  not equal     Both Null \u0026amp; Alternative Hypotheses refer to a POPULATION and use PARAMETERS (μ \u0026amp; p) p-value  Assuming H0 is true, the probability the statistic (such as p^hat or x^bar) would take a value as extreme or more extreme than the one actually observed. The smaller the p-value, the STRONGER the evidence is AGAINST the H0 Interpretation  \u0026ldquo;Assuming H0 is true, there is a [P-val] probability of getting the [sample val] [or even smaller/larger] by random chance with a sample size of [n]\u0026rdquo;\n    significance level  The level at which that, when our p-value falls below it, we consider it to be SIGNIFICANT We consider that our sample is so unlikely to happen IF H0 is true, that it likely did NOT happen by chance   error + power  Type 1:  When H0 is true, but we REJECT H0 P(Type I) = confidence level α   Type 2:  When Ha is true, but we FAIL TO REJECT H0 P(Type II) = 1 - Power   Power  The ability of a test to correctly detect the alternative when it\u0026rsquo;s true.  When Ha is true, and we CORRECTLY REJECT H0   Interpretation  \u0026ldquo;Given Ha is true (in context), there is a (power) probability we correctly rejecting H0 (finding convincing evidence for Ha)\n  Power = 1 – P(Type II Error) How to increase  INCREASE the sample size (n), INCREASE the Confidence Level (α), or Make Ha further away from H0     STANDARDIZED TEST STATISTIC  A standardized test statistic measures how far a sample statistic is from what we would expect if the null hypothesis H0 were true, in standard deviation units.       Proportions #   Four-step process  State  State your Hypotheses: H[relation] = [p/µ] interpret values — 1 proportion  where p is the true proportion of [context] and Significance Level (alpha)\n  interpret values — 2 proportion  where p is the true difference between the proportions of [parameter 1] and [parameter 2] of [context] and Significance Level (alpha)\n    Plan  Identify the appropriate testing method  We\u0026rsquo;ll carry out a [ONE/TWO]-SAMPLE Z TEST FOR A POPULATION PROPORTION (because we\u0026rsquo;re estimating a proportion and we know the standard deviation)\n  Check conditions   Do  Perform the calculations.  Because we know conditions are true, can do our calculations   1 sample  2 sample Proportion Difference find p-value   Conclude  Interpret your p-value in the context of the problem.  P-value less than  Assuming the [H0] is true, there is a [p-value] probability of getting [statistic found] or [more [and/neither] less — more for H0 \u0026lt; Ha; less for Ha \u0026lt; H0; both for H0 ≠ Ha] in a sample of [sample size] purely by chance. Because [p-value] is less than [alpha] of [confidence level], we have evidence to reject the null hypothesis, and have some evidence that the null hypothesis may be true, meaning [context]\n  P-value greater than  Assuming the [H0] is true, there is a [p-value] probability of getting [statistic found] or [more [and/neither] less — more for H0 \u0026lt; Ha; less for Ha \u0026lt; H0; both for H0 ≠ Ha] in a sample of [sample size] purely by chance. Because [p-value] is greater than [alpha] of [confidence level], we do not have enough evidence to reject the null hypothesis, meaning [context]          Means #   Four-step process  State  State your Hypotheses: H[relation] = [p/µ] interpret values — 1 proportion  where p is the true mean of [context] and Significance Level (α)\n  interpret values — 2 proportion  where p is the true difference between the means of [parameter 1] and [parameter 2] of [context] and Significance Level (α)\n    Plan  Identify the appropriate testing method  We\u0026rsquo;ll carry out a [[ONE/TWO]-SAMPLE]/MATCHED PAIRS] T TEST FOR A POPULATION MEAN\n  Check conditions   Do  Perform the calculations.  Because we know conditions are true, can do our calculations with (n-1) degrees of freedom   1 sample  2 sample Mean Difference Paired Paired find P-value   Conclude  Interpret your p-value in the context of the problem.  P-value less than  Assuming the parameter is true, there is a [p-value] probability of getting [statistic found] or more/less in a sample of [sample size] purely by chance. Because [p-value] is less than [alpha] of [confidence level], we have evidence to reject the null hypothesis, and have some evidence that the null hypothesis may be true, meaning [context]\n  P-value greater than  Assuming the parameter is true, there is a [p-value] probability of getting [statistic found] or more/less in a sample of [sample size] purely by chance. Because [p-value] is greater than [alpha] of [confidence level], we do not have enough evidence to reject the null hypothesis, meaning [context]\n         "}]