[{"id":0,"href":"/cogsci-c100/intro/","title":"Introduction","section":"CogSci C100","content":"Overview and Fields #   Cognitive Science: Study of the mind and cognition that integrates a number of different academic disciplines:  Neuroscientists study the mind’s biological machinery Psychologists directly study mental processes, such as perception, learning/memory, judgement and decision-making Computer scientists explore how those processes can be simulated and modeled in computers Philosophers ask critical questions about the nature of the mind \u0026ndash; what is mind? how does it interface with body? is is purely the brain? Evolutionary biologists and anthropologists speculate about how the mind evolved       The job of cognitive science is to provide a framework for bringing all those perspectives on the mind together Each of the various academic disciplines that comprise cognitive science use different methods, examples:  Philosophers look at where the unity of their discipline comes from  A commitment to rigorous argument and analysis Particularly in the so-called analytic tradition\u0026ndash; the tradition most relevant to cognitive science Certain problems that are standardly accepted as philosophical   In contrast, the unity of psychology comes from a shared set of experimental techniques and paradigms (Different branches of) Neuroscience employ different tools appropriate to the level of organization at which they are studying the brain; These tools and techniques generally vary in\u0026hellip;  Spatial resolution (y-axis): the scale on which they give precise measurement (varying scale: single neurons, e.x. light microscopy; to looking at parts of the brain in general \u0026ndash; which lobe/area is there activity?) Temporal resolution (x-axis): time intervals to which they are sensitive (the frequency at which you make observations: EEG is very high, to where fMRI/PETS where the effects are measured over a longer scale)     Cognitive Science includes the study of anthropology and cultural differences  Conclusions derived from Western psychology experiments may not be very representative of humanity as a whole Typical research participants tend to be WEIRD: Western, Educated, Industrialized, Rich, and Democratic       Summary #   Ideally, Cognitive Science would involve integration of these disparate methods:\n  Philosophers \u0026ndash; Deductive reasoning Psychologists \u0026ndash; Scientific method Cognitive psychologists \u0026ndash; Modeling AI researchers \u0026ndash; Computer models Neuroscientists \u0026ndash; Case studies, lesion methods, brain imaging Roboticists \u0026ndash; Build and test machines  History of Cognitive Psychology/Cognitive Science #   Cognition is mental activity – the acquisition, storage, transformation, and use of knowledge\n Early History #   Attempts to understand mind go back at least to the ancient Greeks  Discovered laws of learning and memory, e.g., method of loci \u0026ndash; using imagery to enhance your memory capacity Described human thinking in terms of mechanical \u0026lsquo;manipulation of symbols\u0026rsquo;   Study of mind remained province of philosophy until 19th century In 1879, Wundt established first psychology laboratory  One of few important dates (this is the birth date of psychology!) Studied mental processes systematically using technique of introspection  Not what we would consider rigorous now adays e.x. scientist would play a note on an instrument, then ask \u0026ldquo;how does this make you feel?\u0026rdquo;     Within decades, however, experimental psychology became dominated by behaviorism\u0026ndash; a view that virtually denied the existence of the mind  Believe that psychology should study relation between observable stimuli and observable behavioral responses Mind was banished from respectable scientific discussion \u0026ndash; you can\u0026rsquo;t tell what\u0026rsquo;s in that black box, so ignore it!   However, in 1950’s, people started to become disenchanted with behaviorism (e.x. Little Albert) + more experimental research was being done, so cognitive psychology began to emerge  Result of growth of interest in memory and developmental psychology, linguistics and computer science   The Magical Number Seven, Plus or Minus Two \u0026ndash; proved you could study the mind experimentally. Discovered that people universally learned things at similar ages   View that mental processes can best be understood by comparison with a computer  A particular cognitive process can be represented by information flowing through a series of stages      Development of Computational Model of Mind #   Alan Turing  In article published in 1936-37, conceived of information processing as an algorithmic or rule-based calculation process (Turing machine)  A Turing machine has a set of instructions (machine table) that determines what the machine will do when it encounters a particular symbol in a particular cell, depending upon which internal state it is in\n  Together with advances that were made in designing and building digital computers during and after World War II, this led to development of view that cognition involves an algorithmic process of information processing   Parallel distributed processing (PDP) and connectionist models/neural networks became popular in 1990’s  That is, processing can happen parallel, simultaneously \u0026ndash; contrast with serial processing approach Hold that cognitive processes operate in a parallel fashion  e.x: face recognition \u0026ndash; cognitive processes can be completed even when supplied information is incomplete or faulty; your friend dyes their hair, but you still recognize them next time you see them.     Research in AI and Machine Learning boomed in early 21st century due to growth in computing power and availability of large data sets  We knew how to do this way before, but didn\u0026rsquo;t have the data sets nor computational power til now   Classifications:  Artificial Intelligence (AI): tries to design computer models that accomplish the same cognitive tasks that humans do Machine Learning: a subset of AI that allows computers to \u0026ldquo;learn\u0026rdquo; (i.e. progressively improve performance on a specific task) by creating new algorithms to produce a desired output based on structured (or unstructured) data that is provided  Relies on labeled data set and human input to differentiate classifications (e.x telling the computer cats have pink noses while dogs have black, etc.)       Deep Learning: a subset of Machine Learning involving numerous layers of algorithms  Machine does not need to be provided with structured data \u0026ndash; doesn\u0026rsquo;t required labeled data set, harder to do       Neural Networks: Networks of algorithms that are similar to the neural networks present in the human brain    The Turn to the Brain in Cognitive Science #   Early models of cognitive functions, such as visual perception, focused on top-down analysis and included relatively little discussion of neural implementation \u0026ndash; not based on scientific method  Neuroimaging techniques that emerged in the 1980s and 1990s, such as PET and fMRI, allowed neuroscientists to begin establishing large-scale correlations between types of cognitive functioning and specific brain areas  Other techniques, such as single-cell recordings, have made it possible to study brain activity in nonhuman animals at the level of the single neuron      The Cerebral Cortex #  This will be on the exam!     Frontal lobes: involved in speaking \u0026amp; muscle movements and in making plans \u0026amp; judgments \u0026ndash; directly proportional to social network Parietal lobes: include the sensory cortex, important in spatial navigation Occipital lobes: include the visual areas, which receive visual information from the opposite visual field     Temporal lobes: include the auditory areas and mystical (out of body) experiences Motor cortex: area at the rear of the frontal lobes that controls voluntary movements Sensory cortex: area at the front of the parietal lobes that registers \u0026amp; processes body sensations  Limbic System #   Limbic cortex: phylogenetically older part of cortex Amygdala: Two almond-shaped neural clusters that are components of the limbic system and are linked to emotion, particularly fear and aggression Hippocampus: Donut-shaped structure that is important in memory      Are our behaviors determined by brain function? #   Or, is brain function determined by our behaviors? (Which came first\u0026ndash; the chicken or the egg?)\n  Physiological correlates can almost always be found for psychological states  If we haven\u0026rsquo;t figured it out yet, we probably will very soon   Penfield found that stimulating various parts of the brain with electrodes give rise to specific thoughts, emotions, images, or motor movements  Done on epilepsy patients in preparation for surgery (so they didn\u0026rsquo;t remove any parts that were crucial) Abnormal EEG patterns seen in those with schizophrenia, depression, obsessive-compulsive disorder (OCD), and attention deficit-hyperactivity disorder (ADHD) However, this does not necessarily mean that brain states cause mental states!  e.x. psychotherapy and drug therapy produce similar types of brain changes (e.g., in studies of treatment of depression, OCD, and ADHD) Recalling sad memories makes your brain temporarily look like the brain of someone with depression Psychotherapy (talk therapy) produces the same brain state that meditation does      Controversies in CogSci #   Do the benefits of cognitive neuroscience justify the costs?\n  Neuroimaging studies can be quite outrageously expensive, and many of these studies do not provide direct practical benefits  To run an hour PET on someone, it costs $20-30k per subject and you need many subjects for research   Some researchers claim that cognitive neuroscience has not really helped to develop psychological theories \u0026ndash; people are just wowed by pictures of brains  Limitations of the experimental method #   Artificiality of experiments (lack of ecological validity \u0026ndash; doesn\u0026rsquo;t apply to real-world scenarios): the more you control the environment, the less like real life it becomes Argument that the best things in life (e.g., love, beauty, truth, joy) cannot be quantified    There was an awful rainbow once in heaven:\nWe know her woof, her texture; she is given\nIn the dull catalogue of common things.\nPhilosophy will clip an Angel’s wings.\n \u0026ndash; John Keats\n   Belief as a confounding variable: Magellan’s diary  When Magellan interacted with native people, they could not see (perceive) his large ships The idea is that the ships were so alien to their experience that \u0026ldquo;\u0026hellip; their highly filtered perceptions couldn\u0026rsquo;t register what was happening, and they literally failed to \u0026lsquo;see\u0026rsquo; the ships.\u0026rdquo; (JZ Knight, What the Bleep Do We Know?) Certain things have to be believed until they can be seen    SQ3R technique #   Steps:  Survey: Scan material; Read headings, figures, summaries Question: Pose questions to yourself Read: Look for answers to questions as you read; Read actively, not word-by-word (key to speed-reading!) Recite: Practice rehearsal (tell someone about the material) Review: Go over answers to questions; Review material again a day or several days later   Fallacies:  You have to read every word. The slower you read, the higher your comprehension. It’s a \u0026lsquo;sin\u0026rsquo; to skip around when you are reading.    "},{"id":1,"href":"/cogsci-c100/perception/","title":"Perception","section":"CogSci C100","content":"Definition of sensation and perception #   As humans, we are cognitive beings who\u0026hellip;  Acquire information about the world around us Integrate that information with prior knowledge from our stored memory Store that knowledge in our memory so we can use it later to help us achieve our goals   First step in this process of acquiring knowledge about the world involves sensation and perception  Sensation: process by which our sensory receptors and nervous system receive stimulus energies from the environment and transduce them into neural impulses. The inherent stimuli. Objective Perception: process of interpreting and organizing sensory information through use of previous knowledge. What gives stimuli meaning. Subjective.    Early models of object perception #  Template matching model #   Template matching model: object perception involves a comparison of the stimulus with set of templates or specific patterns stored in memory Problem: cannot account for complexity and flexibility of object recognition  e.g. individual differences in handwriting     Feature analysis model #   Feature-analysis model: discrimination of objects is based on small number of characteristics of stimuli  Are these two the same letter?: G R P M  People are faster at deciding whether G and M are different than P and R   Supported by neurological evidence – some neurons respond only to horizontal lines, others to diagonals, etc.   Problem: Cannot explain recognition of complex objects with features that move and distort (e.g., horse or kangaroo)   Recognition-by-components model #    Recognition-by-components model: view that an object is represented as an arrangement of simple 3-D shapes called geons  Cup/pail composed of cylinder and curved tube geons in a particular arrangement         David Marr’s Model of Visual Processing #   The image is then transformed into a 3-D sketch in which the the axes of symmetry and elongation link the object parts  Symmetry axis: line that divides an object into mirror image halves Elongation axis: line defining direction along which main bulk or mass of a shape is distributed   The 3-D sketch is object-centered – the object’s parts are described relative to one another and are linked on the basis of shared properties and axes  This solves the object constancy problem, allowing recognition of an object presented in different orientations and under different conditions, e.g., lighting changes     Prototype model #   Prototype model: object perception involves a comparison of the stimulus with ideal, abstract example  People are faster at identifying sparrow as a bird than penguin   One of the most famous models in all of cognitive psychology It has been hypothesized that our sensory systems act primarily as a selective filtering mechanism  This filter sorts things according to a limited number of variables (e.g., warm, unpleasant, green) out of which we construct our world But prototype theory suggests that our minds can also perceive objects in a very different way\u0026hellip;   That which is essential is invisible to the eye. – de Saint-Exupery\n   Alternative modes of perception #   Alternative modes of perception: Mindfulness is largely about seeing the “suchness” of things, that is, seeing things directly without conceptual filters What assumptions might you make about this woman if you were told she is from New England? from California?  Our preconceived notions prevent us from seeing the real person in front of us         If the doors of perception were cleansed, everything would appear to man as it is, infinite.\nTo see a World in a Grain of Sand, And a Heaven in a Wildflower, Hold Infinity in the palm of your hand, And Eternity in an hour. \u0026ndash; Blake\n Neural Networks #   Artificial Neural Networks in Pattern Recognition    Human neurons Many different neurons connect to the dendrites of each neuron  Some produce excitatory effect; others produce inhibitory effect There are also different levels of intensity of these effects   If the activation of the neuron reaches a certain minimum threshold, the neuron will fire       16A Notes ↕   Because circuit analysis translates to a wide range of fields, we can model many physical systems as electrical circuits, often gaining insight about the system. You may have heard of neural networks, an important machine learning tool that can be used to “learn” tasks such as image and voice recognition from examples instead of explicit programming. Neural networks are modeled after biological neural networks, which are fundamentally circuits operating on electrical signals within a brain: In a general sense, studying circuits provides you with the conceptual and mathematical tools needed to analyze such networks. More broadly, circuit concepts are relevant to understanding network analysis and signal flows in systems, which can be applied to areas ranging from transportation analysis to social network analysis. (from EECS16A Note0)\n     Artificial neural networks (ANN)  The nodes or neurons are organized into layers in much the same way that human neural networks are The weights attached to the connections between pairs of units in adjacent layers determine the overall behavior of the network  This is similar to the way in which excitatory and inhibitory neurons of various strengths connect to a particular neuron in human neural networks   The bias term indicates what the weighted sum needs to be before the node/neuron will activate  This is similar to the threshold necessary for activation of a neuron in human neural networks         An artificial neural network is an interconnected group of nodes, inspired by a simplification of neurons in a brain. Here, each circular node represents an artificial neuron and an arrow represents a connection from the output of one artificial neuron to the input of another.\n     Ex: How might a computer recognize a “9” using neural networks? #   There is huge variety of ways in which people write 9’s To simplify things, we can represent the “9” using a grid of 28 x 28 pixels of varying shades of gray   Steps ↕   First (input) layer of network  Starts with bunch of neurons or nodes corresponding to an array of 28 x 28 pixels in the image Each node holds a number that represents the grayscale value of the corresponding pixel, ranging from 0 for black to 1 for white This is the neuron’s activation level Activations in one layer bring about activations in the next layer, which in turn bring about activations in the next layer\u0026hellip;  This is loosely analogous to how, in biological networks of neuron, some groups of neurons cause other neurons to fire     Second layer (or first “hidden layer”)  Each neuron in the second layer might pick up on whether there is an edgein one particular region You assign a weight to each one of the connections between a particular neuron in the second layer and the neurons in the first layer Then you take all the activations from the first layer and compute their weighted sum according to the weights  Could make the weights associated with almost all of the pixels 0 except for some positive weights in target region To really pick up on whether there is an edge here, could also have some negative weights associated with the surrounding pixels  Sum is largest when those middle pixels are bright but surrounding pixels are darker     But maybe you don’t want the neuron to light up anytime the sum is bigger than zero \u0026ndash; maybe you only want it to be active when the sum is bigger than say 10 So you add in some other number (the bias), like -10, to the weighted sum  The bias tells you how high the weighted sum needs to be before the neuron starts getting meaningfully active     Third layer (or second “hidden layer”)  When we recognize digits, we piece together various components  e.x: A “9” has a loop near the top and a line on the right whereas an “8” has a loop on the top and one below   Each neuron in the third layer corresponds to one of these subcomponents  e.x: A particular neuron in the third layer might be activated by any generally loopy pattern toward the top   These subcomponents are made up of the various edges from the second layer   Last (output) layer  Has 10 neurons, each representing one of the digits The activation in these neurons – some number between 0 and 1 – represents how much the system thinks a given image corresponds with a given digit Learning is about getting the computer to find a setting for all of the different weights and biases so that it will actually solve the problem at hand  This is done through backpropagation      \u0026lt;/div\u0026gt;     Learning in Neural Nets: Backpropagation #   ANNs can compute any function that can be computed by a digital computer  However, it was not until the emergence of backpropagation learning algorithm that it became possible to train multilayer neural networks   The strength or weight of the connections between neurons in adjacent layers varies: neural networks learn by modifying these weights  Learning algorithms that are programmed into the ANN change the weights of the connections between pairs of neurons in adjacent layers in order to reduce the “mistakes” that the network makes The basic idea is that each hidden unit connected to an output unit bears a degree of “responsibility” for the error of that output unit If the activation level of an output unit is too low, then the weight between the output unit and each hidden unit connected to it is increased to decrease the error The network then assigns error levels to the next layer of hidden units, so the error is propagated back down through the network until the input layer is reached    Other Neural Networks Q\u0026amp;A #  Q: How many neurons should there be in each hidden layer?\nA: There are a number of empirically-derived rules-of-thumb. Of these, the most commonly relied on is “the optimal size of the hidden layer is usually between the size of the input and size of the output layers”  Q: How many hidden layers are needed? Are more layers better?\nA: No. Situations in which performance improves with additional hidden layers are very few. One hidden layer is sufficient most of the time.  Q: Why are more hidden layers not necessarily better?\nA: Increasing the number of hidden layers much more than the sufficient number will cause the network to overfit the training set. It will learn the training data, but it won’t be able to generalize to new unseen data    Top-down processing in object recognition #   Limitations of models of object perception discussed above: assumes that perception is always objective and accurate, but in real life, that is often not the case\u0026hellip;  What we perceive, the way we perceive, is not always what would be predicted by these models Our concepts, expectations, and beliefs play a much bigger role in perception than we usually realize   Perception engages both top-down and bottom-up processing  Bottom-up processing: analysis of information coming from stimuli through sensory receptors  Object perception as combination of stimulus information from sensory receptors Emphasizes the importance of information coming from the outside world   Top-down processing: information processing guided by higher-level processes, such as our beliefs, expectations, and memories  Our knowledge, beliefs about the world inform our perceptions Emphasizes the importance of information coming from our minds     “Objective reality” is often not as objective as we think\u0026hellip;  A fool sees not the same tree that a wise man sees. \u0026mdash; William Blake\n  Reversible figures (e.g., Necker cube; vase/profiles); ambiguous figures (e.g., old woman/young woman)      Effect of expectations on perception  Perceptual set brain teasers: SOAK FOLK CROAK Context effects (e.g., Presidential illusion)        Effects of expectations, experience, emotional patterns, and beliefs on perception #   Effects of Prior Experience on Perception  Children who have been physically abused are significantly more likely to misperceive a fearful face as angry (Pollak)   Cultural effects on perception  What is above the woman’s head? Is this an indoor or outdoor scene? (Gregory and Gombrich, 1973)   Rorscharch and Thematic Apperception Test (TAT) When angry, people more often perceive neutral objects as guns (Baumann \u0026amp; DeSteno, 2010) Effect of beliefs/preconceived notions on perception  Rosenhan study on effects of psychological labeling    Self-fulfilling prophecies #   Self-fulfilling prophecies: People generally think that it is our experiences and perceptions that create our beliefs, but often, it is actually our beliefs that create our experiences and perceptions    Our beliefs and expectations influence others’ behavior  The Pygmalion effect: study found that students who were (randomly) labeled intellectual “spurters” showed significantly greater gains in IQ and academic performance after 8 months than controls  Follow-up: If teacher believed that girls learn to read faster than boys, they did   Children who were told they were neat and tidy became more neat and tidy than those who were told they should be neat and tidy  Follow-up: children who are told that they are good at math showed greater improvements in math scores than those who were told that they should try to become good at math   Those who over-idealize romantic partners as having many virtues and few faults tend to have happier and longer-lasting relationships (Miller, Niehuis, \u0026amp; Huston, 2006) Moreover, the partners who are over-idealized tended to develop those traits over time! (Sandra Murray)   Our beliefs and expectations influence our own behavior  Study by Mark Snyder found that when a man was led to believe that a woman found him attractive, she was more likely to act as if she did  Assume a virtue if you have it not. – Shakespeare\n     Perceptual Constancies #   Perceptual constancy: perceiving objects as unchanging (having consistent lightness, color, shape, and size) even as illumination and retinal images change  Many visual illusions result from the overuse of strategies employed to achieve perceptual constancy   Is Tile A or Tile B darker or are they the same color?\n Illusion results from visual system’s attempt to maintain lightness constancy: we perceive an object as having a constant color, even if changing illumination alters the wavelengths reflected by the object      Shape constancy: we perceive the form of familiar objects as constant even while our retinal images of them change  A door casts an increasingly trapezoidal image on our retinas as it opens, yet we still perceive it as rectangular     Müller-Lyer illusion:  Is line AB or line BC longer? Size-distance constancy: Our brains are used to perceiving angles as corners that are near or far away and sees the inward-facing corners as more distant and therefore smaller      Are the two parallelograms the same size and shape?     Ponzo illusion:  Which line is longer?        Moon illusion: Does the moon appear larger near the horizon or when it is high in the sky?    When the moon is near the horizon we perceive it to be farther away from us than when it is high in the sky, but since the moon is actually the same size, our minds make it look bigger when it is near the horizon to compensate for the increased distance    The Magical Kingdom of Salt     In the Salar de Uyuni of Bolivia, the world’s largest salt flat, with no other objects in sights, the human eye loses its ability to establish a proper field of depth. The result is some bizarre pictures.       Effects of color in marketing #   Assume that you are considering buying condoms  You enter a store and notice that the store doesn’t carry all the brands you may be familiar with, so you’re going to have to make your choice based on the product package alone You are really interested in finding a brand that is considered  Durable, strong, and well built (“rugged” condition) OR Classy, attractive, and refined (“sophisticated” condition)  Which would you choose? ↕      Match ↕     Sincerity: white, yellow.$^1$ Excitement: red, orange.$^1$ Competence: blue Sophistication: black, pink, purple Ruggedness: brown .$^1$Marginally significant             Neurological disorders of visual perception #  Face perception and prosopagnosia #   Face recognition is “special”  Single-cell recordings of monkeys show activation of particular cells in lower temporal only when full-face photos of other monkeys are presented   Recognition accuracy for faces and houses: parts vs. whole  Study (Tanaka and Farah, 1993) in which participants were shown series of faces with person’s name and series of houses with owner’s name Later on recognition test, they showed greater recall of  Parts of houses but Whole faces         Do people tend to perceive men or women more in “parts”? Women (Gervais, Vescio , Forster et al., 2012)   Prosopagnosia: failure to recognize particular people by the sight of their faces  After stroke, sheep rancher could not recognize people but could recognize sheep Note: the eyes also play a special role in perception    70-90% of famous portrait paintings sampled from the last five centuries have an eye at or within 5% of the painting’s exact centerline (Christopher W. Tyler)\nEvery man indicates in his eye the exact indication of his rank. – Emerson       Modular processing #   Visual illusions suggest that the mind is at least in part modular (Jerry Fodor)  That is, it is not solely organized in terms of faculties, such as memory and attention, that can process any type of information Rather, there are specialized information-processing modules that  Respond automatically Cannot be “switched off”            Modular processes are usually characterized by\u0026hellip;\n Fixed neural architecture  It is sometimes possible to identify determinate regions of the brain that are associated with particular types of modular processing  e.x: fusiform face area for face recognition     Specific breakdown patterns  Modules can fail in highly determinate ways, which provide clues on the form and structure of processing  e.x: prosopagnosia        Other Neurological Disorders Related to Visual Perception #   Visual agnosia: inability to recognize/identify visual objects despite relatively good visual perception  Usually due to damage in occipital or temporal lobes  “Mr. P” in Oliver Sacks’ Man Who Mistook His Wife for a Hat Man with agnosia puzzling over a picture of a cow suddenly found himself making alternating up-and-down movements with fists. He looked down at his hands and said, “Oh, a cow!”     Visual neglect syndrome or unilateral spatial neglect:  Tendency to ignore – or to be unaware of – information on one half of visual field, usually the left side Typically occurs after damage (e.g., stroke) to right hemisphere, particularly damage to the parietal and frontal lobes Relatively common      Patients are asked to bisect each line. Their markings are typically skewed to the right, as if they do not see the leftmost segment\n    Patients are asked to draw from memory or to copy an illustration (Driver \u0026amp; Vuilleumier, 2001)\n    House ↕        Experimenter: Are the two houses the same or different?\nPatient: The same.\nExperimenter: Which house would you prefer to live in?\nPatient: The left house.\n     Capgras syndrome: characterized by belief that family and/or friends are imposters  Damage to pathway between visual cortex and amygdala, which regulates emotions Emotional “glow” that we normally feel around people we are close to is missing Ramachandran argues that this emotional “glow” is, to a large extent, what gives us a sense of continuity in our relationships   Functional blindness (conversion disorder): unexplained vision loss with no organic basis  Cambodian women who had witnessed horrible war atrocities became either partially or wholly blind     Blindsight: vision without awareness  Blindness resulting from damage to visual cortex When presented with various shapes like circles and square, or photos of faces of men and women, patient could not tell (or guess) what his eyes were gazing at However, when shown pictures of people with angry or happy faces, he was able to guess the emotions expressed, at a rate far better than chance Patients are also able to correctly “guess” the identity or location of particular objects Patients report that they get a “gut” feeling that allows them to perform these tasks A second pathway of visual perception may account for this phenomenon       Blindsight patient was able to meander around all the clutter in a hallway that he was told was empty (Weiskrantz)\n   Two pathways of visual perception #     Study looked at speed with which people were able to find a specific hidden object among a group of similar objects Participants were instructed to  Passively allow the target to just “pop” into their minds OR Actively direct their attention to the target   Participants in Group 1 outperformed those in Group 2 (Smilek, Enns, Eastwood et al., 2006)     Targets ↕   Look for the circle with just one gap, and say whether the gap is on the left or the right Use “relax” strategy, then try active search strategy      Proposed explanation:  Participants who were basically told to relax and go with their gut instinct used a secondary pathway of visual perception that  Does not go through the visual cortex Instead simply makes a very short loop through the limbic system: the emotional, instinctual center of the brain          Research evidence for existence of two pathways:  Auditory cortex of rats was destroyed, then rats were exposed to tone paired with an electric shock Rats quickly learned to fear tone, though they could not “hear” it! Explanation: the sound took the direct route from ear to thalamus to amygdala, bypassing all higher avenues (Joseph Ledoux)      Development of perception #    Adults who were born blind and later gained vision through newly-developed surgical interventions (e.g., cataract surgery) usually have some difficulty recognizing objects  At age 3, Mike May lost his vision in an explosion. Decades later, a new cornea restored vision to his right eye. Unfortunately, although signals were now reaching his visual cortex, it lacked the experience to interpret them  May could not recognize expression, or faces, apart from features such as hair Yet he can see an object in motion        There is a critical period for normal sensory and perceptual development Kittens reared in a cylinder with only vertical black and white stripes later had difficulty perceiving horizontal bars  Kitten would play with rod only when it was held upright        "},{"id":2,"href":"/e-29/0/","title":"Week 0","section":"Engineering 29","content":"1-18: Course introduction #  Overview #  This class focuses on three main components \u0026ndash; manufacturing processes, dimensional tolerances, and design communication \u0026ndash; and how they interact with one another.\n The class is made up of 9 modules:\n Fundamentals Subtractive manufacturing processes Additive manufacturing processes Forming processes Joining processes Graphical visualization techniques Metrology: measuring manufactured objects Geometric dimensioning and tolerancing The future of manufacturing  Why manufacturing? #   In 2018, U.S. manufacturing accounted for 11.6% of the U.S. economy, 18.2% of global manufacturing output, and 8.2% of the U.S. workforce \u0026ndash; source Manufacturing output is growing, and is returning to the U.S.; output increased \u0026gt;30% between end of 2008 and 2014 67% of U.S. R\u0026amp;D is funded by industry Even when production is offshore, design is often done here anyway Automation is increasing, yet there is a shortage of skilled (human) talent Even if you don\u0026rsquo;t want to go into manufacturing industry, research and academia still require manufacturing knowledge Even if the process if outsourced, design is still done in the US. To design well, you have to have a base-level understanding of manufacturing    Manufacturing output and employment are rising\n    Many companies have regionalized their supply chains since the pandemic\n   Processes #  In this class we will consider multiple families of processes:  This is a rapidly moving field that is always adapting This class should give you a top level overview so you can evaluate novel methods  Materials #  In this class we will consider multiple families of materials:  Materials choices influence performance  For example, consider the progress of the plane: In 1903 the right brothers low-density wood with steel wire and silk In 1935 the Douglas DC3 used aluminum alloy (since it became feasible to produce and manipulate) Now the 2010 Boeing 787 Dreamliner is made up of 50 wt% composites 20 wt% aluminum 15 wt% titanium 20% lower fuel consumption per passenger mile  Composite materials are two(+) materials combined together to get best of both worlds, in aviation typically stiff/strong carbon fibers embed in tough/fatigue-resistant polymers.     Materials choices influence market size  There isn\u0026rsquo;t always a best material; different materials fit different markets/needs Opposite side of the coin: There may be multiple valid material choices for a particular function    Tolerance #   Tolerancing is a formal way of specifying limits on the amount of dimensional variability allowable in manufactured parts  We need a range because measurements will never be 100% precise; we need to define an acceptable range Some sources of variation  Human operator changes and/or errors Tool wear Environmental changes (temperature, humidity leads to tiny expansions / contractions) Input material variability Measurement error     Affordable mass-production relies on interchangeability of parts  When mating parts of given designs, it should not matter which specific parts   Therefore part dimensions must be consistent  But no manufacturing process is perfectly consistent   If you don\u0026rsquo;t understand the process of manufacturing and the capabilities of tools, then you will won\u0026rsquo;t know how to create manufacturable designs    Tighter tolerances (closer tolerance limits) are generally more expensive to achieve The solid green line shows an ideal process The dotted green line shows the impact of an error shifting the distribution, shifting the tails to approach the tolerance upper / lower bound The red line shows a unsuitable process (even if it\u0026rsquo;s calibrated accurately, the poor precision causes high variance that it\u0026rsquo;s not really feasible; however, if outside of the limits an additive (or less common subtractive) could be used to )   How E29 integrates manufacturing and tolerancing #   Tighter tolerances are more expensive The physics of a process determine how tight a tolerance is achievable and how much it costs Therefore we need to understand how manufacturing processes work in order to:  Select a suitable process for the application Specify reasonable tolerances Geometric Dimensioning and Tolerancing: a graphical language for specifying tolerances robustly    Design Communication #   Important to effectively describe your ideas and designs graphically  Persuade \u0026ndash; we need to be able to show are perspective Instruct \u0026ndash; we need an agreed an unambiguous way to communicate Document \u0026ndash; we need to convey how to construct our final design Seek feedback \u0026ndash; we need to ensure everyone is on the same page   Drawings can be 2D or 3D representations  Interpreting 2D drawings made by others Creating 2D “working drawings” with unambiguous instructions   Design communication is not only graphical  Oral, written Manufacturing relies on teams Teaming activities    1-20: Tolerancing principles #   See why we study tolerancing from yesterday\u0026rsquo;s notes  Basic tolerance formats #   Unilateral  e.g. Inches: .$.500^{+0.005}_{-0.000}$, Metric: .$35^{+0.05}_0$ (notice sigfig notation)   Bilateral  Most common; start with nominal then you have some tolerance bounds above and below Equal or unequal deviations from nominal dimension Same number of decimal places for upper and lower limits e.g. Inches: .$.500 \\pm .005$ or .$.500^{+0.005}_{-.010}$, Metric: .$35 \\pm 0.05$ or .$35^{+0.05} _{-0.10}$   Limit  Given only bounds, not the nominal value e.g. Inches: .$.250, .248$, Metric: .$35.05, 35.00$    Tolerance buildup #   In the real world we have error, so the way we define dimensions have an impact Best dimensions to label depend on function  That is, dimensioning should be done intentionally such that critical distances result in minimal error, e.g.suppose distance between .$X$ and .$Y$ is critical      Chain is bad since the potential (and often times real world) maximum error is large  The errors compound since dimensions are in reference to other dimensions that may will contain error. The more dimensions chained, the greater the possible error   Baseline is better \u0026ndash; every feature references a single base.  However the worst case is still significant .$X$ may be off by .$\\pm .05$ and .$Y$ may be off .$\\mp 05$, compounding to .$\\pm 0.10$!   Direct is ideal  Depends on which dimensions are critical (that is, .$X, Y$)     Normal cumulative distribution function #   Tighter tolerances (closer tolerance limits) are generally more expensive to achieve The physics of the process used determines the curve\u0026rsquo;s characteristics  .$\\sigma$ is the stdiv (width) of this density   .$\\mu = x_0$ is the target (average) value we give This probability density characterizes how this function is distributed and the chance a given range of values occur  The area under the curve in a given range is the probability the value falls within that range Single values, i.e .$x_0$, have a 0% probability. We can only calculate ranges because this is a density function.       Probability density, e.g. given by Gaussian/Normal probability density function: $$p(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-\\frac{(x-x_0)^2}{2\\sigma^2}}$$\n    Why do we care about statistics?  We want to look at a process, look at tolerances, and figure out whether it\u0026rsquo;s worth to manufacture using this process If you know the distribution of a process, you can work out the probability a given part satisfies spec limits.   There is no easy, exact analytical way to integrate the normal probability density function.  The probability that a randomly chosen member of a normally distributed population has a value .$\\leq x$ is $$\\int_{-\\infty}^x p(x)\\ dx = P(x) = Z\\bigg(\\frac{x-\\mu}{\\sigma}\\bigg) = \\frac{1}{2}\\bigg[1 + \\text{erf}\\bigg(\\frac{x-\\mu}{\\sigma\\sqrt{2}}\\bigg)\\bigg]$$  .$\\text{erf()}$ is the error function .$Z$ is the normal cumulative distribution function; values of .$Z$ are tabulated in a Z table       Example probability of part lying between within spec limits ↕     Process capability and tolerancing #   Sigma, .$\\sigma$, is the standard deviation of dimensions actually produced by a process  Six sigma processes  Six Sigma (6σ) is a set of techniques and tools for process improvement. [\u0026hellip;] A six sigma process is one in which 99.99966% of all opportunities to produce some feature of a part are statistically expected to be free of defects.\n  Specification limits are .$12\\sigma$ apart. Here, 2 parts per billion lie outside specification limits if process is \u0026lsquo;in control\u0026rsquo; (i.e. if mean output of process is centered between specification limits) Arose because the cost of manufacturing, specifically the process that creates an error, has a cost. This cost can grow very large, very quickly, when mass-manufacturing.  You\u0026rsquo;re best off spending money improving the process so the distribution gets tighter The alternative is either (1) accepting errors (resulting in faulty products) or (2) testing all components to ensure they are \u0026lsquo;good\u0026rsquo; and tossing out the bad ones   Process capability: .$C_p = \\frac{\\text{USL - LSL}}{6\\sigma}$    Classes of Fit #   Tolerances should be\u0026hellip;  Not too tight: tight tolerances are expensive Not too loose: otherwise function is compromised      Clearance fit: designed with space left between two components  e.g. a shaft with a bearing need to have some give / free space   Interference (push) fit: designed to be touching  You may want interference because you want the friction between the components; you want the two pieces to not move/rotate/etc How? Elastic or even plastic deformation e.g. two pieces may need to fit tightly with friction as to prevent vibrations Expansion fit:  If there are large forces/torques acting on these two components so you want them very tight e.g. you may temporarily expand one component (e.x. with heat) to fit on/around the other, then it will shrink down   Shrink fit:  Same as expansion, but using some cooling process (e.x. liquid nitrogen) Why do this over heat?  It\u0026rsquo;s typically more expensive to cool down The material may deform / weaken \u0026ndash; e.g. steel will be degraded if heated up       Transition fit: complete interchangeability is compromised to allow looser tolerance on individual components.  If fit type is not critical. But even then, why not choose one or the other? Because you don\u0026rsquo;t want a large gap and the materials/parts cannot withstand the force needed to assemble them with an interference fit. The pieces are just for alignment \u0026ndash; think Ikea assembly pegs; they\u0026rsquo;re just to align components. It\u0026rsquo;s easier to manufacture these parts     Snap fits #    Involves temporary elastic deflection which enables parts to interlock, e.g. involving bending of one component Done often with molded parts Tends to involve Cantilever (e.g. casings), Annular (e.g. pen lids, take-out soup container lids) Designed to be assembled once, and typically not disassembled (multiple times) \u0026ndash; irreversible. Relatively simple: you don\u0026rsquo;t need screws/glues/etc. \u0026ndash; useful for rapid prototyping since you don\u0026rsquo;t have to consider fasteners Takes advantage of the fact that the material has some elasticity  You need to stay within the elasticity limits of the material Most 3D plastics have \u0026lsquo;enough\u0026rsquo; give You (generally) want to design such that the stress is from bending, not stretching    More, additional, extra, readings   Terminology Definitions #   Don\u0026rsquo;t stress about memorizing these !\n   Maximum material condition (MMC): The greatest allowable amount of material left on the part (max size for a shaft; min size for a hole) Minimum/least material condition (LMC): The least allowable amount of material left on the part (min size for a shaft; max size for a hole)  Important with MMC since they tell us how much they\u0026rsquo;re able to \u0026lsquo;slosh around\u0026rsquo;   Basic size: Exact theoretical size from which limits are derived  Different form nominal since basic refers to the standard table which gives respective upper and lower bounds (MMC and LMCs) Hole basis: Basic size is minimum size of hole Shaft basis: Basic size is maximum size of shaft \u0026ndash; used when many components need to fit on to one shaft. Basic size could be chosen to be in-between hole and shaft basis   Tolerance: Allowable variation of one particular dimension Fundamental deviation: Difference between basic size and the closer of the MMC and LMC Allowance: Difference between maximum material conditions of the two components   Types of fit #   These types are created by ANSI: American National Standards Institute Exact values are tabulated in many source    RC: Running and sliding clearance fits  Nine categories:  RC1: Close sliding: assemble without perceptible “play” (e.g. watches)  Less than a 1/1000\u0026quot;. Basically impossible for air, let alone liquids, through.   RC2: Sliding fits: seize with small temperature changes (e.g. ) RC3: Precision running: not suitable for appreciable temperature differences RC4: Close running: moderate surface speeds and pressures RC5/6: Medium running: higher speed/pressure RC7: Free running: where accuracy not essential and/or temperature variations large RC8/9: Loose running   Go for lower if you want minimal vibration/gaps \u0026ndash; no perceivable play. Has drawbacks:  The less clearance, the easier it is to seize up \u0026ndash; especially if two components are touching and made up of different materials (different expansion/contraction rates). Susceptible to dust, you would have to seal the machine or use it in clean conditions.   If you go less precise, you don\u0026rsquo;t need to go slow, cheaper operator costs, cheaper tooling   RC Chart ↕        RC Table ↕        LC: Locational clearance fits  Normally stationary, but freely assembled/disassembled Used when you need clearance to dis able and clean   LC Chart ↕          LT: Location transition fits  Accuracy of location important Small amount of clearance or interference OK e.g. ikea furniture pegs   LN: Locational interference  When you need friction Accuracy of location is critical         FN: Force fits  When you need to hold a load (typically uses temporary heating) Designed to transmit frictional loads from one part to another     Example: Which type of fit? ↕     Processes, tolerances, and surface quality #   How do we relate physical processes and tools to these values?    From MF Ashby, Materials Selection in Mechanical Design\n Roughness #   How do we define roughness? You may use tool that uses a tiny needle to \u0026lsquo;scan\u0026rsquo; the surface, measuring deflections as you go    From MF Ashby, Materials Selection in Mechanical Design\n  RMS roughness: root mean square of deviations over the measured surface length  i.e.: .$R^2 = L^{-1} \\int_0^L y^2\\ dx$ Usually, tolerance, .$T$, lies between 5R and 1000R   Generally, if you go high rotation speed and slow translational speed you get less rough surfaces  RMS Roughness Example ↕        "},{"id":3,"href":"/eecs-16a/0/","title":"Week 0","section":"EECS 16A","content":"1-18: Course Introduction #    Slides Notes 0, 1A   All logistics, no notes!\n1-20: Introduction to Imaging, Tomography, and Linear Equations #    Slides Notes 1A, 1B   System Design #   We use devices, such as imagers, that provide information, such as a visual representation of a system  Often, these devices don’t work alone \u0026ndash; they are part of a larger system that uses a combination of both physical sensors and signal processing techniques.   When we take projections of images, we tend to need to take multiple measuring (pictures) from differing angles  Otherwise we have issues with overlap and ambiguity To generate 3D models, we need these multiple perspectives   We ideally want to design a system that gives us a set of linear equations  Some times we can only approximate these linear equations Lots of physical processes (i.e xrays!) are exponential so we just slap a log on it  .$\\hat y = p \\cdot (e^{x_1} + \\dots + e^{x_n})$ .$y = -\\log_e (\\hat y \\cdot p^{-1}) = x_1 + \\dots + x_n$ .$\\hat y$ is our measured energy value .$x_n$ is the .$n$th \u0026lsquo;pixel\u0026rsquo; .$p$ is the power of the energy source  Tomography Example ↕        To solve, we need enough independent equations that do not contain redundant information, otherwise there will be multiple ambiguous solutions Different models are made up of different configurations (of the energy source and measuring sensor) and result in different system of equations  We can obtain equations by moving both the energy source and measuring sensor (think document scanner) to get each individual pixel We can also move the energy source alone instead \u0026ndash; think camera pointed at image with a projector used to light up certain (group of) pixel(s)  Different patterns have pros/cons \u0026ndash; speed, resolution, accuracy, number of measurements, energy use        Linear Algebra #   The study of linear functions and linear equations, typically using vectors and matrices Linearity is not always applicable, but can be a good first-order approximation There exist good fast algorithms to solve these problems (and lots of fun properties!) Consider .$f(x_1, \\dots, x_n) : \\mathbb{R}^n \\to \\mathbb{R}$; .$f$ is linear if the following hold\u0026hellip;  Homogeneity: .$f (\\alpha x_1, \\dots, \\alpha x_n) = \\alpha f(x_1, \\dots, x_n)$  If I scale the input by a scalar (i.e. by a factor of 2) then the output should also scale by the same factor   Super position (distributivity): if .$x_i = y_i + z_i$ then .$f(y_1 + z_1, \\dots, y_n + z_n) = f(y_1, \\dots y_n) + f(z_1, \\dots z_n)$  2 possible inputs:  Pass the first input through the system to get a value. Pass another input through the system, and get another value. Add those two values to get a result.   1 possible input:  Pass the summation of value 1 and value 2 through the system to get a result.   If the result of both approaches are equal, then distributivity holds. Otherwise, distributivity does not hold.     Linear functions can always be expressed as .$f(x_1, \\dots, x_n) = c_1 x_1 + \\dots + c_n x_n$  For .$\\mathbb{R}^2$, that is, .$f(x_1, x_2) = c_1 x_1 + c_2 x_2$ We know this system is linear so it follows these two rules above. So we should set up an equation where we can apply these properties.  $$ x_1 = 1 \\cdot x_1 + 0 \\cdot x_2;\\ x_2 = 0 \\cdot x_1 + 1 \\cdot x_2$$ $$\\text{Let } y_1 = 1, z_1 = 0; y_2 = 0, z_2 = 1$$ $$ \\Longrightarrow x_1 = x_1 y_1 + x_1 z_1;\\ x_2 = x_2 y_2 + x_2 z_2$$ $$ \\Longrightarrow x_1 = x_1 (y_1 + z_1);\\ x_2 = x_2 (y_2 + z_2)$$ $$\\text{Therefore, } f(x_1, x_2) = f(x_1 y_1 + x_2 z_1, x_1 y_2 + x_2 z_2)$$ $$= x_1f(y_1, y_2) + x_2f(z_1, z_2)$$ $$= x_1f(1, 0) + x_2f(0, 1)$$ $$= c_1 x_1 + c_2 x_2\\ \\blacksquare$$\n    Linear Set of Equations Consider the set of .$M$ linear equations with .$N$ variables: $$\\begin{matrix}a_{11} x_1 + a_{12} x_2 + \\dots + a_{1N} x_{N} = b_1\\\\ a_{21} x_1 + a_{22} x_2 + \\dots + a_{2N} x_{N} = b_2\\\\ \\text{} \\vdots\\\\ a_{M1} x_1 + a_{M2} x_2 + \\dots + a_{MN} x_{N} = b_M\\end{matrix}$$  \u0026hellip;it can be written compactly using augmented matrix: $$\\begin{bmatrix}a_{11} \u0026amp; a_{12} \u0026amp; \u0026hellip; \u0026amp; a_{1N} \u0026amp; \\text{|} \u0026amp; b_1\\\\ a_{21} \u0026amp; a_{22} \u0026amp; \u0026hellip; \u0026amp; a_{2N} \u0026amp; \\text{|} \u0026amp; b_2\\\\ \\vdots \u0026amp; \\text{} \u0026amp; \\vdots \u0026amp; \\text{ } \u0026amp; \\text{|} \u0026amp; \\vdots\\\\ a_{M1} \u0026amp; a_{M2} \u0026amp; \u0026hellip; \u0026amp; a_{MN} \u0026amp; \\text{|} \u0026amp; b_M\\end{bmatrix}$$    An interesting thing to notice about this representation is that the symbols corresponding to our unknowns have vanished entirely!   Algorithm for solving linear equations  Three basic operations that don\u0026rsquo;t change a solution:  Multiply an equation with nonzero scalar  .$2x+3y=4$ is same as .$4x+6y=8$ In other words, no solution exists that satisfies the second equation, but not the first. Consequently, the second equation is not only implied by, but also implies the first equation. When each of two equations imply the other, we say that they are equivalent.   Adding a scalar constant multiple of one equation to another  Example ↕  If we have the equations.. $$(1)\\ 5a+6b=7$$ $$(2)\\ 8a+9b=10$$  \u0026hellip;we can multiply .$(2)$ by the scalar 3 and add it to .$(1)$, to obtain the new system $$(3)\\ 29a+33b=37$$ $$(2)\\ 8a+9b=10$$   Clearly, observe that any solution to the first system will also be a solution to the second, since the first system of equations implies the second. But is the reverse true? Well, observe that equation .$(1)$ can be recovered by taking equation .$(3)$ and subtracting our scalar (in this case, 3) multiplied by equation .$(2)$. In other words, our second system is, not only implied by, but also implies the first system, so it does not introduce any new solutions. Thus, replacing the first system with the second does not change the solution set of our linear system, so this operation is valid.\n    Swapping equations (changing arbitrary labels, trivial)      Note 1A Extra #   Affine function: a function that can be written as a sum of a linear function and a scalar constant, so though .$\\beta (x)=2x+1$ is not linear, it is still _affine  Notice that the definition of affine functions includes all linear functions (by setting the scalar constant to 0), so every linear function is also affine, though not vice-versa. These definitions mean that while all functions describing a line can be shown to be affine, not all of them are linear. This has the unfortunate consequence that, in informal conversation, affine functions may be called linear, since both describe a line. This usage, though common, is wrong!, as seen with .$\\beta (x)$ above     Linear Equation: Formally, a linear equation with the unknown scalars .$x_1, x_2, \\dots x_n$ is an equation where each side is a sum of scalar-valued linear functions of each of the unknowns plus a scalar constant.  Expressed algebraically, we obtain the most general form of a linear equation, where the .$f_i$ and .$g_i$ are each linear functions with a single scalar input and output, and .$b_f$ and .$b_g$ are two scalar constants: $$f_1(x_1) + f_2(x_2) + \\dots + f_n(x_n) + b_f = g_1(x_1) + g_2(x_2) + \\dots + g_n (x_n) + b_g$$ Now, recall that linear functions with a single scalar input and output can be expressed in a very particular form \u0026ndash; we know that we can write .$f_i(x) = a_i \\cdot x$ and .$g_i(x) = a_i ' \\cdot x$, where all the .$a_i$ and .$a_i \u0026lsquo;$ are scalar constants. Substituting, we find that the general form of a linear equation can be rewritten as $$a_1x_1 + a_2 x_2 + \\dots = a_n x_n + b_f = a_1\u0026rsquo; x_1 + a_2 ' x_2 + \\dots + a_n ' x_n + b_g$$ Notice that this expression can be thought of as a “weighted sum” of the .$x_i$, where the weights are the scalar constants .$a_i$. When the weights do not depend on any of the terms (such as when the weights are constants), we call the weighted sum a linear combination of said terms. So the above expression is typically referred to as a linear combination of the .$x_i$. That is,  A linear equation is one that equates two linear combinations of the unknowns plus a constant term.\n   Practice questions    "},{"id":4,"href":"/e-29/1/","title":"Week 1","section":"Engineering 29","content":"1-25: Fundamentals of graphical communication #  Evolution of graphical visualization #   Hand drawing Instrument drawing (using mechanical things to measure distances) 2D CAD (initially only able to draw side views) 3D CAD (solid modeling)  Automatic generation of 2D working drawings Enable easy communication of measurements between designer and manufacturer Created with the assumption that manufactured objects are made up of elementary objects, geons? Now we have the ability to run algos to analyze models, removing unnecessary bits We\u0026rsquo;re moving towards computer-generated geometry that\u0026rsquo;s contained by human input     #     Increasingly complex geometries   Topological optimization Internal lattices The way we interface with drawings has to keep up with this   New interfaces  Virtual and augmented reality for visualizing designs    Why bother sketching by hand? #     Why not go straight to CAD? Some possible reasons:  There is a connection between drawing and your own creativity; a feedback loop of sorts CAD bottlenecks you to designing a certain way Find one’s own distinctive style Avoid making detailed decisions too early Keep geometries more freeform Ideas may come to mind anywhere, anytime Potentially quicker       Sketch Examples ↕   Leonardo da Vinci: “helicopter” (c. 1489)  Charles and Ray Eames: chair  Renzo Piano + Richard Rogers: Pompidou Center    Philippe Starck: lemon squeezer  Aside: how is it made? \n    #     Jonathan Ive/Apple design team: iPhone  Burj Khalifa: Adrian Smith  Tesla Model 3: Franz Holzhausen  Concept drawing for Berkeley Engineering      Essentials of 2D sketching #   Line types matters  Solid: edges Dashed: hidden detail Chain: centerline.  - . - .  \u0026hellip;   Faint: construction  Align, but don\u0026rsquo;t touch, features   Dimension lines:  Fainter than edges, and not connected. Long, thin arrows. Lots of differing standards, just be consistent          3D pictorial approaches #  Isometric drawing #   \u0026lsquo;iso\u0026rsquo; = same, \u0026lsquo;metric\u0026rsquo; = measure  Any lines parallel .$x,y,z$ on the lines are equal length   Orthogonal edges of a 3D object map to:  Vertical lines Lines at .$\\pm 30^\\circ$ to horizontal   Dimensions in these orthogonal directions are preserved on page Dimensions in other directions are not preserved on page       Circles in isometric  Use construction lines for bounding box Mark midpoints Draw longer quadrants first Through holes: use construction lines for obscured circle; darken later What if circle is not on an orthogonal face?        Coded plans for practicing isometric sketching #   Principle: number in cell gives height of column to be drawn Codes could be given on isometric or square grid ( plan view) Square grid: viewpoint explicitly specified       Different views / perspectives may obscure different features. Chose the one that minimizes information loss / ambiguity You can shade certain surface to convey shadow (and thus depth, 3D information)  Axonometric drawing #   Orthogonal edges are represented by:  Vertical lines Lines at .$\\pm 45^\\circ$ to horizontal   Advantage:  Floorplans are not skewed/distorted   Disadvantage:  Areas of equal orthogonal faces are not equal on drawing Can look more \u0026ldquo;distorted\u0026rdquo;    #     Example of axonometric drawing\n Sometimes called “planometric” Popular in architecture to preserve floorplans     Oblique drawings #   Front view is undistorted Conveys lots of information of a single face Angles are arbitrary (here they\u0026rsquo;re ~45) Receding lines drawn at a constant angle Judgement needed to select scale for receding direction      Perspective drawing #   Simulates how the eye sees 3D objects: further away objects/details are smaller Much more challenging than other methods  Receding lines not parallel But CAD software can generate   Horizon line Vanishing point(s)  One point: dimensions referenced from closest surface Two points: dimensions referenced from closest edge        Introduction to sketching tools #  Digital sketching tools #   Autodesk Sketchbook  Import isometric grid on Layer 2 Draw on Layer 1   Google Jamboard OneNote Adobe Photoshop, Illustrator Software resource page in bCourses   Analog sketching tools #   Set square/drawing triangle Pencils:  Various hardness/softness Mechanical vs traditional   Pens  Ballpoint Felt tip Technical      Possible ways of enhancing 3D sketches #   Shading  Simulate the effect of light falling on object   Visual clarity  Edges bolder: example of how it clears confusion   Suggesting motion, sound, texture…  "},{"id":5,"href":"/eecs-16a/1/","title":"Week 1","section":"EECS 16A","content":"1-25: Gaussian Elimination, Vectors #    Slides Notes 2A, 2B   Upper Triangular Systems #   Consider the following equation $$x-y+2z=1$$ $$y-z=2$$ $$z=1$$   \u0026hellip;which can be represent as $$\\begin{bmatrix} 1 \u0026amp; -1 \u0026amp; 2 \u0026amp; \\text{|} \u0026amp; 1\\\\ 0 \u0026amp; 1 \u0026amp; -1 \u0026amp; \\text{|} \u0026amp; 2\\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; \\text{|} \u0026amp; 1 \\end{bmatrix}$$    These are called upper triangle matrices \u0026ndash; they are nice in that they\u0026rsquo;re easy to solve!  The solution is reached when the diagonal is all one, the remaining is zero (excluding the rightmost \u0026lsquo;answer\u0026rsquo; colum)   More precisely, a matrix is in row echelon form when the following criteria are met:  All nonzero rows are above all zero rows. The leading coefficient of a non-zero row is always to the right of the leading coefficient of the row above it.   $$\\begin{bmatrix} 1 \u0026amp; * \u0026amp; * \u0026amp; * \u0026amp; \\text{|} \u0026amp; *\\\\ 0 \u0026amp; 1 \u0026amp; * \u0026amp; * \u0026amp; \\text{|} \u0026amp; *\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; \\text{|} \u0026amp; *\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\text{|} \u0026amp; 0\\\\ \\end{bmatrix}$$    The leading coefficient of every non-zero row (which we call the pivot, and say is in the pivot position) is 1.  Some textbooks will require this third property, others don\u0026rsquo;t     In addition to row echelon form, there is also reduced row echelon form.  This requires that: In addition, after the upwards propagation of variables in step (3), we will obtain a matrix with the following properties, in addition to the two mentioned above:  The matrix is in row echelon form. The leading coefficient of every non-zero row (which we call the pivot, and say is in the pivot position) is 1. Each column with an element that is in the pivot position of some row has 0s everywhere else.   $$\\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; * \u0026amp; 0 \u0026amp; \\text{|} \u0026amp; *\\\\ 0 \u0026amp; 1 \u0026amp; * \u0026amp; 0 \u0026amp; \\text{|} \u0026amp; *\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; \\text{|} \u0026amp; *\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\text{|} \u0026amp; 0\\\\ \\end{bmatrix}$$    Sometimes abbreviated (especially in programming) as rref. By construction, the Gaussian elimination algorithm always results in a matrix that is in reduced row echelon form.  Once an augmented matrix is reduced to reduced row echelon form, variables corresponding to columns containing leading entries are called basic variables, and the remaining variables are called free variables   As will be discussed shortly, the distinction between basic and free variables allows us to characterize all solutions to the system of linear equations (if any exist!).     Example ↕  We start with the following system: $$x-y+2z=1$$ $$2x+y+z=8$$ $$-4x+5y = 7$$  \u0026hellip;which we can write as a matrix $$\\begin{bmatrix} 1 \u0026amp; -1 \u0026amp; 2 \u0026amp; \\text{|} \u0026amp; 1\\\\ 2 \u0026amp; 1 \u0026amp; 1 \u0026amp; \\text{|} \u0026amp; 8\\\\ -4 \u0026amp; 5 \u0026amp; 0 \u0026amp; \\text{|} \u0026amp; 7 \\end{bmatrix}$$   \u0026hellip;and we can row-reduce to upper triangle (Row echelon)\n \u0026hellip;which we can use back substitution to solve\n     Tomograph Example ↕         In real systems, we will always have noise (error) that makes our systems slightly skewed  So what if we repeat the example above, but have a measurement of .$+0.1$\u0026hellip; are there any solutions?  Error Example ↕         We can represent our solution as a set of linear equations, meaning we can represent them graphically   "},{"id":6,"href":"/math-53/10/","title":"10: Parametric Equations and Polar Coordinates","section":"Math 53","content":"10.1 Curves Defined by Parametric Equations #   Parametric equations are written as .$(f(t), g(t))$ They define curves (not functions!) Time  .$t \\in [t_i, t_f]$ Initial point: .$\\big(f(t_i), g(t_i)\\big)$ Terminal point: .$\\big(f(t_f), g(t_f)\\big)$   For parametric equation in form .$\\big(h + r \\cdot \\sin(t), k + r \\cdot \\cos(t)\\big)$ on .$t \\in [0, 2\\pi]$ , the resulting curve is a circle clockwise centered around the point .$(h,k)$  Likewise, .$(r \\cdot \\cos(t), r \\cdot \\sin(t))$ is counter clockwise    Useful Desmos calculator If we need to graph an equation in form .$x = g(y)$ , we can use parametric equations .$x = g(t)$ and .$y = t$  10.2 Calculus with Parametric Curves #  Tangents #   Given .$x = f(t)$ and .$y = g(t)$ where both .$f$ and .$g$ are differentiable, we can get the tangent line to the curve by finding .$\\frac{dy}{dx}$ We can find .$\\frac{dy}{dt}$ using the chain rule: $$\\frac{dy}{dx} \\cdot \\frac{dx}{dt}$$ If .$\\frac{dx}{dt} \\neq 0$ , then we can solve .$\\frac{dy}{dt}$ : $$\\frac{dy}{dx} = \\frac{\\frac{dy}{dt}}{\\frac{dx}{dt}}$$ Horizontal tangents exist when .$\\frac{dy}{dt}= 0$ (assuming .$\\frac{dx}{dt} \\neq 0$ ) Vertical tangents exist when .$\\frac{dx}{dt}= 0$ (assuming .$\\frac{dy}{dt} \\neq 0$ )  Double Derivative #  $$\\frac{d^2y}{dx^2} = \\frac{d}{dx}\\Big(\\frac{dy}{dx}\\Big) = \\frac{d}{dt}\\cdot\\frac{dt}{dx}\\Big(\\frac{dy}{dx}\\Big) = \\frac{\\frac{d}{dt}\\Big(\\frac{dy}{dx}\\Big)}{\\frac{dx}{dt}}$$\nAreas #  Given .$x = f(t)$ and .$y = g(t)$ over .$t \\in (\\alpha, \\beta)$ , we can calculate the area between .$C$ and the .$x$ -axis with the following equation $$A = \\int_\\alpha^\\beta f'(t) \\cdot g(t)\\ dt $$ Likewise, between .$C$ and the .$y$-axis we derive the parametric equation for .$y$ : $$A = \\int_\\alpha^\\beta f(t) \\cdot g'(t)\\ dt $$\nArc Length #  To find length .$L$ of curve .$C$ given in form .$x = f(t)$ and .$y = g(t)$ on .$t \\in [\\alpha, \\beta]$ where .$\\frac{dx}{dt} = f'(t) \u0026gt; 0$ (meaning that .$C$ is traversed once from left to right as .$t$ increases from .$\\alpha$ to .$\\beta$ ) and where .$f'$ and .$g'$ are continuous on .$[\\alpha, \\beta]$ : $$L = \\int_\\alpha^\\beta \\sqrt{\\Big(\\frac{dx}{dt}\\Big)^2 + \\Big(\\frac{dy}{dt}\\Big)^2}\\ dt$$ Note that trig functions (.$\\sin, \\cos, \\text{etc.})$ ) loop every .$\\frac{\\pi}{2}$ because of the formula finds the absolute value.\nSurface Area #  Suppose the curve .$C$ given the equations .$x = f(t)$ and .$y = g(t)$ on .$\\ t \\in [\\alpha, \\beta]$ where .$f'$ and .$g'$ are continuous, and .$g(t) \u0026gt; 0$ , is rotated about the .$x$ -axis. If .$C$ is traversed exactly once, then the area of the resulting surface is given by $$S = 2\\pi \\int_\\alpha^\\beta y(t) \\sqrt{\\Big(\\frac{dx}{dt}\\Big)^2 + \\Big(\\frac{dy}{dt}\\Big)^2}\\ dt$$ Similarly, if instead .$C$ is rotated about the .$y$ -axis instead we use the following: $$S = 2\\pi \\int_\\alpha^\\beta x(t) \\sqrt{\\Big(\\frac{dx}{dt}\\Big)^2 + \\Big(\\frac{dy}{dt}\\Big)^2}\\ dt$$\n10.3 Polar Coordinates #   Pole = origin; labeled .$O$ Polar axis = line through .$O$ Polar coordinates = .$r, \\theta$ .$r$ is distance from point .$P$ and .$O$ .$\\theta$ is the angle between the polar axis and the line .$OP$ .$(r, \\theta) = (-r, \\theta + \\pi)$  Converting between Cartesian #   .$x = r\\cdot \\cos\\theta$ .$y = r\\cdot \\sin\\theta$ .$r^2 = x^2 + y^2$ .$\\tan\\theta = \\frac{y}{x}$  Symmetry #   If polar equation is the same when .$\\theta = -\\theta$ , the curve is symmetric about the polar axis If polar equation is the same when .$r = -r$ or when .$\\theta = \\theta + \\pi$ , the curve is symmetric about the pole If polar equation is the same when .$\\theta = \\pi-\\theta$ , then the curve is symmetric about the vertical line .$\\theta = \\pi/2$  Polar Tangents #  Knowing that $$x = r \\cdot \\cos\\theta = f(\\theta)\\cdot\\cos\\theta$$ $$y = r \\cdot \\sin\\theta = g(\\theta)\\cdot\\sin\\theta$$ We can use the product rule to find the tangent equation $$\\frac{dy}{dx} = \\frac{\\frac{dy}{d\\theta}}{\\frac{dx}{d\\theta}} = \\frac{\\frac{dr}{d\\theta} \\sin\\theta + r\\cos\\theta}{\\frac{dr}{d\\theta}\\cos\\theta - r \\sin\\theta} $$\n Horizontal Tangent: .$\\frac{dy}{d\\theta} = 0$ (when .$\\frac{dx}{d\\theta} \\neq 0$ ) Vertical Tangent: .$\\frac{dx}{d\\theta} = 0$ (when .$\\frac{dy}{d\\theta} \\neq 0$ ) Notice that for .$r = 0$ , then .$\\frac{dy}{dx} = \\tan\\theta$ if .$\\frac{dr}{d\\theta} \\neq 0$ We can then write the full formula: $$y-y_0 = \\frac{dy}{dx}\\Big(\\theta\\Big)(x-x_0)$$  10.4 Area and Lengths in Polar Coordinates #  Area of Polar Region #  Knowing that the area of a \u0026ldquo;slice\u0026rdquo; can be written as .$A = \\frac{1}{2}r^2\\theta$ , we can expand this to the case where the curve is a function .$r = f(\\theta)$ : $$A = \\int_a^b \\frac{1}{2} r^2\\ d\\theta$$\nArc Length of Polar Curve #  Given a polar curve .$r = f(\\theta), a \\leq \\theta \\leq b$ , we can re-write our base equations as $$x = r\\cos\\theta = f(\\theta)\\cos\\theta$$ $$y = r\\sin\\theta = f(\\theta)\\sin\\theta$$ Thus we can use the product rule when differentiating to get $$\\frac{dx}{d\\theta} = \\frac{dr}{d\\theta}\\cos\\theta - r\\sin\\theta$$ $$\\frac{dy}{d\\theta} = \\frac{dr}{d\\theta}\\sin\\theta + r\\cos\\theta$$ and using .$\\cos^2\\theta + \\sin^2\\theta = 1$ , we have $$\\Big(\\frac{dx}{d\\theta}\\Big)^2 + \\Big(\\frac{dy}{d\\theta}\\Big)^2 = [\\text{ugly stuff, see page 711}] = \\Big(\\frac{dr}{d\\theta}\\Big)^2 + r^2$$ so when .$f'$ is continuous, we can write the arc length equation as $$L = \\int_a^b \\sqrt{\\Big(\\frac{dx}{d\\theta}\\Big)^2 + \\Big(\\frac{dy}{d\\theta}\\Big)^2} d\\theta = \\int_a^b \\sqrt{r^2 + \\Big(\\frac{dr}{d\\theta}\\Big)^2}d\\theta$$\nCommon shapes #  Rose #   $$a\\cdot[\\sin \\text{or} \\cos](k\\cdot\\theta)$$\n .$r$ = .$a$ .$\\sin$ = Symmetry over .$\\theta = 0$ .$\\cos$ = Symmetry over .$\\theta = \\pi/2$ If .$k$ is even, rose will have .$2k$ petals. If .$k$ is odd, rose will have .$k$ petals. .$T = 2\\pi/k$ is range of a petal\u0026rsquo;s cycle .$2\\pi/T = k$ cycles displayed in graph .$A_{\\text{petal}} = \\frac{\\pi a^2}{4k}$  Cardioid #   $$r(\\theta) = a(1-\\cos\\theta)$$ $$A = \\frac{3}{2}\\pi a^2$$ $$L = 8a$$\nLimaçon #   $$r = b+a\\cos\\theta$$ Other equations I\u0026rsquo;m too lazy to type out\n"},{"id":7,"href":"/docs/math-53/","title":"Math 53","section":"Docs","content":"Chapters #   10: Parametric Equations and Polar Coordinates 12: Vectors \u0026amp; Geometry of Space 13: Vector Functions 14: Partial Derivatives 15: Multiple Integrals 16: Vector Calculus  "},{"id":8,"href":"/docs/physics-7b/","title":"Physics 7B","section":"Docs","content":"Chapters #   17: Temperature, Thermal Expansion, \u0026amp; Ideal Gas Law 18: Kinetic Theory of Gases 19: Heat \u0026amp; First Law of Thermo 20: Second Law of Thermo 21: Electric Charges \u0026amp; Fields 22: Flux \u0026amp; Gauss\u0026#39;s Law 23: Electric Potential 24: Capacitance, Dielectrics, Electric Energy Storage 25: Electric Current and Resistance 26: DC Circuits 27: Magnetism 28: Sources of Magnetic Field 29: Electromagnetic Induction \u0026amp; Faraday\u0026#39;s Law 30: Inductance, Electromagnetic Oscillations, \u0026amp; AC Circuits  "},{"id":9,"href":"/anthro-c12ac/","title":"Anthro C12AC","section":"Docs","content":"Anthropocene #   The time when human activity began to have an influence on (global) landscape due to our use of fire Large subject used in a range of fields \u0026ndash; no single definition Defining feature: combustion of carbon and greenhouse gases Ice core measurement technique  As ice forms, methane and CO2 get trapped along with ash/dust/pollen which scientists can measure by coring Ice can be dated so we can compare these variables so we can see change in greenhouse gases over time   Beginning is disputed  Industrial revolution (1780s)  Most popular among scholars   Atomic Testing (1940s)  The isotopic by-products of bomb testing provide a distinctive marker horizon in ice cores, ocean and lake sediments, and soils   Stages idea:  Includes vital events such as forest cutting and grassland conversion: the two largest spatial transformations of Earth\u0026rsquo;s surface in human history   1.8 million years ago: When fire was discovered 6000-4000s years ago: With neolithic agriculture 1780s: Industrial revolution     Identifying fire requirements:  Evidence of temporal or spatial changes in fire activity and vegetation Demonstration that these changes are not predicted by climate parameters alone Temporal/spatial coincidence between fire regime changes and changes in the human record    Pyrogeography #   History of the variation of fire activity over space and time at the landscape scale in different regions of the world Pyrogeography started in Silurian period when plant life began Fire requirements: 13% Oxygen in a normal environment and 30% Oxygen in damp vegetation. Fires are a selection force in the evolution of plants  Four phases for Pyrogeography #  1. Natural Biospheric Fire \u0026ndash; Natural Fire Regime #   (Potential) start date for pyrogeography During Silurian and Devonian Periods (440-400 HYA) Natural fire regime started during this period because it was the first time that the fire triangle came together Fire triangle:  Ignition Source: (Since beginning) Natural ignition from lightening (most common), volcanoes, (rarely) falling rock sparks  These natural sources tend to only begin fires in the dry season Lightening is most common in mountain regions (over a costal region)   Oxygen Source: (Cambrian period) Atmospheric Oxygen (from photosynthetic plants) leads to appearance of photosynthetic organisms Fuel Source: (Silurian and Devonian Periods) Enough terrestrial plants in ecosystems to acts as fuel   During this time, natural fire regimes evolved  As coal became more common (Carboniferous period), fires did too   Started long time ago, before humans and dinosaurs  2. Wildland Anthropogenic Fire \u0026ndash; Hunter/Gatherer Fire Regime #   When people began acting as the ignition source Primarily used fire for domestic cases  Heating, cooking, warmth, etc.   When people move to a new land  Major changes in fauna, vegetation, and fires (charcoal) People seem to bring fire with them as they migrate   Start dates  40 ka for Australia  90% of fauna went extinct Lots of evidence of fire   45 ka for Highland New Guinea 50 ka for lowland Borneo 20 ka for the Americas  Extinctions of many animals and vegetation  Debate: are these because of natural process like climate change (ice age -\u0026gt; post ice age?) or do people play a large role   Native Perspective \u0026ndash; Indigenous people have been here since time began      When did humans actually discover fire? #   Defining the bridge between phase one and two is difficult Definition problems  Do we ask when did (modern humans / hominin ancestors) develop the ability to control and utilize fire? We also need to distinguish between (1) controlling / utilizing fire and (2) being able to start a fire on a whim   Archeological problems  Fire exists naturally, so we can\u0026rsquo;t assume all fire evidence is from human action Other natural processes can look like fire (e.g. staining by minerals in soil, oxidation causing reddish patches) Combustion of natural objects (e.g. bushes) can leave charcoal which looks like a human hearth  Additionally, evidence of a hearth doesn\u0026rsquo;t mean that humans started/controlled fire   Provides a single snapshot, has little temporal depth   Archaeological Record Analysis  In the field:  Observation and collection of materials Study the geology of the site   In the lab:  Microscopic analysis to see if there was burning If so, could the location of the sample been transported after combustion? Further, how does the history of the burned object associate with cultural items      How long has fire been controlled? #   Europe: Strong evidence of 400,000 - 300,000 years ago Western Asia: One established case from 780,000 years ago. Other sites are similar to Europe Africa: Claims have been made for a cave site that shows fire around 1.5-1.6 million years ago Note that opportunistic use of fire could have happened much earlier  Eg. lighting a torch from a natural-starting forest fire    3. Agriculture Anthropogenic Fire \u0026ndash; Agricultural Fire Regime #   Required fire to alter the natural vegetation from perennial-dominated to annual-dominated landscapes. People preferred to live in fire-prone places because the burning provides advantages for hunting, foraging, cultivating, and livestock herding  4. Industrial and Domestic Anthropogenic Fire \u0026ndash; Industrial Fire Regime #   Low-severity surface fire regimes are being replaced with low-frequency, high-intensity crown fires that are outside the historical range of variability for these ecosystems Western US: forests have also experienced an increase in hazardous fuels due to highly effective fire suppression policy that excluded fires for much of the 20th century Eastern US: Fire suppression has shifted oak and pine woodlands to mesophytic hardwoods consequently reducing flammability and fire activity Globally: urban areas have steadily expanded into wildland areas  Producing more ignition sources (arson and accidental) Exposing more people to wildfire    Key Factors in Fire Regimes (Discussion 8-30) #   Frequency  The interval of fire occurrences E.x. every four years   Area  Size, distribution, location Ground fires (primarily dead plants) vs crown (burning upper canopy of living trees)  Crown fires areas are more difficult to manage because controlled burns still damage natural resources     Severity  How destructive a fire is (high mortality = high severity) Change in dominant species / change in ecosystem Quantifiable by how much soil on the ground is visible   Seasonality  How the season affects fires May or may not be annual May arise due to weather conditions Ex. Annual to decadal cycles of drying conditions   Interactions  General activity on the landscape leading to different fire outcomes Droughts leading to stress on fuels Beatles eating bark, making trees more vulnerable Fire suppression leading to less severe fires Climate change making fires more severe    Biodiversity and Fire as a Selective Variable in Evolution #   C4 grass  Spread during seasonal climate in the tertiary period (when fires became more common) Fires lead to woodlands and created environments favorable to C4 grasslands Since C4 is high flammability, it would have produced a feedback process that further increased fire activity,  Thus maintaining the grassland-dominated landscape This process is similar to the one currently maintaining many of our savannas     Plant attributes  Heat shock  Certain species have seeds that will open with heat Not exclusive to fire; correlated with soil heat too   Smoke  Highly selective and specific to fire Smoke is a mixture of specific chemicals unique to itself   Note that plants become resistant to certain fire regimes, not necessarily all  Changes in fire regime can kill off fire resistant plants     Even small differences in the deployment of fire outside of natural lightning strikes can alter patterns of forest succession, fuel availability, and seasonality of ignitions  Fires Relating to Evolution #   Beneficial Attributes  Cooking hypothesis  Key claim: Fire + cooking started with the Homo erectus. As such, humans have evolved around a cooked diet that they can\u0026rsquo;t live without Led to fitness advantage More energy + nutrient from food, enabling body and brain size increase Detoxing effect Increase digestibility of all food Cooking takes time, leading to social development  Distribution of tasks among group: (collection, preparation, even stealing)   Cooking accounts for reduction in jaw, tooth size (due to softer food), stomach, and digestive system size There is no evidence of modern human societies existing without cooked food Counterpoints:  It\u0026rsquo;s still unclear that Homo erectus controlled fire There are some sites that show no example of cooking: e.g. Neanderthal sites in cold climates Energetic effects aren\u0026rsquo;t well quantified Digestive evolution may not have been linear; other adaptations related to fire occurred after Homo erectus     Protection benefits at night (especially versus the alternative: sleeping in trees) Allowed much better vision in caves  Enables cave art   Evidence that some hominids could use fire to morph certain woods into tools (e.g. digging sticks, hafted spears) Allowed humans to colonize colder environments Increase prey abundances, maintain mosaic landscapes, and increase pyrodiversity and succession stage heterogeneity   Social bonding  Led to camp fires Allows people to stay up later Fire could be used as a story telling enhancer, means to pass on history, culture, etc. Provides a sense of intimacy and openness Opportunity for music    Fire-stick farming  clearing ground for human habitats facilitating travel killing vermin, hunting regenerating plant food sources for both humans and livestock warfare among tribes   Woody, closed-canopy shrublands were opened up or entirely displaced  Led to spread of fast-growing annual species that provided greater seed resources, travel, and hunting and planting opportunities Ex. CA land was only used for agriculture after burnings, which led to many other alien plants spreading too Reductions in arboreal cover and woody understory have the most potential to enhance erosion Reshaping of landscapes has posed problems for ecologists trying to understand contemporary landscape patterns    Overview of Fires in California #   Conflagrating California\n ~54% of CA ecosystems depend on fire The remaining ecosystems that aren\u0026rsquo;t too extreme for fires (so not deserts, stony summits, wetlands, etc.) are fire adapted  \u0026ldquo;Fire season is 13 months\u0026rdquo;\n  CA has a diverse ecosystem; each site is similar to another one elsewhere though What sets CA apart is the scale and intensity of it\u0026rsquo;s fires    CA\u0026rsquo;s fires are unique in that they lead national discourse Texas views the US as France views the EUnion \u0026ndash; a canvas to project it\u0026rsquo;s ideals Alaska view the US as a source of subsidies. It\u0026rsquo;s isolated and treated almost as a commonwealth. California shares sizes, political isolation, and sense of selfhood with the aforementioned.  Unlike AL, it has a strong and wide economy Unlike TX, it has been independent but not secessionist and, while CA and TX both have strong cultures, CA doesn\u0026rsquo;t project its   Importance - 1/9 Americans live in CA - 8th largest economy - Social uses 1/2 the national fire budget - Source (and testing ground) of new firefighting technology  \u0026ldquo;CA is like the rest of the US, just more so\u0026rdquo;\n     Two CA  North and south Sierra and Seacoast Rich and poor Scrubland, megalopolis, \u0026amp; wilderness Lowest and highest elevation in nation (Mount Whitney @ 14,500 ft and Death Valley @ -280 ft)   Sierra Nevada is analogous to NoCal  Big tilt Highest in SE and slants lower to N + W Mostly timber More frequent fires   Transverse Range is analogous to SoCal  Big Kink Highest in E, bends sharp W then trails to pacific and N Mostly bush More intense fires 56% of ppl live on 8% of land      CA is a national innovator  Created geological survey in 1860 Created Board of Forestry in 1885 Set standard for fire control   Light-burning controversy  Pro-burn:  Frontier practices (the Indian way of forest management) Advocated for regular burning montane woods and lowlands NoCal   Pro-protection  Use govt to prevent\\fight fires SoCal   National issue debated in CA 1923: Light-burning anathematized      Leopold report, Wilderness Act, and Tall Timbers fire ecology conferences  Began in 1962 Aimed to transform fire control into fire management Good for conservation + private land owners who wanted traditional working landscapes Loggers and ranchers started moving out at this time Didn\u0026rsquo;t target urban areas   Urban Areas  Used fire suppression  CA to spawn as AK to wilderness\n  Fires in SoCal rained embers onto cities SoCal retaliated w larger firefighting force   New Practices  Operation Firestop: Transform tech into operational programs 1956: Aerial tankers used to drop retardant on firelines 1961: Specialty fire crews expanded nationally 1963: Forest Service opened Western Fire Lab to coordinate fire suppression w air attacks 1970: Organized SoCal fire agencies towards common practices   Area Specialty  Florida: Prescribed fire N Rockies: Management over back countries (So)Cal: Fire suppression  Land management in Cali was synonymous to fire management, thus fire suppression        As CA grew, the motivation for fire suppression was primarily economical This lead to divisive debates of suppression vs let-burn  When there were flames, it was fight or flight   Many fire ideas spread from CA  Often transformed and simplified      Fires are especially susceptible due to Scioecological Systems (SES)  History of fires suppression Climate change More extreme fire weather Expanding development Droughts   Difficult to predict future fire regimes well Changes in human behavior can amplify, but tend to cancel out climatic effects on fire regimes  For example, humans alter through changing land use, ignitions, fuel conditions, or fire suppression Fire activity is influenced by climate variability  More (less) fire occurred in dry (wet) and warm (cool) years, and high-fire years were preceded by moist and sometimes cool conditions 1\u0026ndash;4 y earlier.   (Sierra Nevada) fire-regime shifts correlate to SES changes, not shifts in climate.   Are best bet is to look at history and see how fire regimes changed from past changes in socioeconomic variables  Climate increased fire activity on a large-scale after Native American depopulation reduced the buffering effect of due to their burnings  Sierra Nevada tribes were hunter-gatherers who used sophisticated burning practices to manage resources The fire index nearly doubled after depopulation   Later Euro-American settlement and fire suppression buffered fire activity from temperature increases  Logging, fire suppression, livestock increase (grazing effects)     The overall sensitivity of fire regimes to low-frequency temperature variation is related to temperature-driven vegetation changes that alter fuel structure and fuel type  Peopling of North America #   Traditional Perspective \u0026ndash; Clovis First Model  13,000 ka, there was an ice-free corridor that opened up and let people come to north America  People from Asia follow herds of megafauna across Bering Strait ( Beringia)   We have found kill sites across America  Butchered mammoth, horses, bison, ground sloths, etc.     New Thoughts about Peopling of Americas: Multiple Migrations of People 20,000-40,000 years ago Coastal Migration Model:  Use Boats to Come to Americas from Asia Some travels may not have been successful which is why there is less evidence for this theory Based on:  Evidence sophisticated cultures  Art, pottery, (primitive) technology, etc.   Evidence of maritime seafaring at early date (Australia, New Guinea, Japan) People follow the Kelp Highway Maritime  Kelp forests very productive (food source) Kelp Highway went along Pacific Rim        Peopling of California #    Earliest well dated sites in CA (13,000-10,000 BP) [Based on radio carbon dates]\n Sites located in SoCal: Channel Islands, South Coast These Islands have always been separated by water so we know people had boats relatively early    Find Evidence of Shell Middens\n Contain shell, fish, other maritime foods Have evidence of tools for kelp + technology Big Game Kill Sites rare in California Dietary Differences (Midwest/Plains vs California)  Perhaps because of dietary differences Suggests different groups of people, so potentially different groups of migrants      Major Changes observed on Channel Islands\n Changes in Fauna (Pygmy Mammoths) Changes in Flora Evidence of Fires!    Debate about what caused these changes\n Due to\u0026hellip;  Climate Change  Climate change at end of Ice Age  Mega herbivores died after ice age, increasing fuel sources (vegetation) which we can see with charcoal signatures   Causes warming + drying (leading to fire) Changes in vegetation and animals because they couldn\u0026rsquo;t adapt   Comet  Newest theory Estimated that 5km comet hit earth somewhere We\u0026rsquo;ve found comet-diamonds and various sites that have chemical signatures potentially from a comet Cloud from comet would have affected photo-synthetic processes, killing plants + animals   People  People may have over-hunted animals May have brought fire with them     Potentially due to multiple reasons Kent thinks it\u0026rsquo;s likely climate change + people    Concluding Points\n Clearly people knew about fire from earliest times Very Sophisticated Maritime Peoples (Kent\u0026rsquo;s opinion) Early for early anthropogenic Influenced fire regimes from earliest times Implications: the Holocene Epoch in CA (last 10,000 years); you cannot assume That only Natural Fire Regimes existed Must consider the influence of people    Historical Fire Records in California #  Methods #   Key Question: What methods can we use to get historical information on fires?  1. Coring Lakes #    Annual layers are laid down in some lakes  Realistically you can date to around fifty years of accuracy This samples have deeper temporal depth vs other methods We can also radiocarbon date these samples to determine the time period   What to sample  Charcoal present is indicates fire  Larger particle tend to travel small distances Smaller particles can travel much longer distances Some plants may be easier/harder to identify than others   Pollen analysis can give you knowledge on what (wind pollinated) plants were common at the time in that area  Provides broad perspective of vegetation over time Pollen can travel far, so resolution isn\u0026rsquo;t great   Phytoliths  Tiny particles formed in many plants They don\u0026rsquo;t break down \u0026ndash; can stay in soil for hundreds to thousands of years! Can be used to identify plant species Cons: Not all plants produce them; overrepresented in grasses      2. Coring Trees #    You basically jab a metal straw into a tree and get a sample of the tree  Doesn\u0026rsquo;t harm tree, tree naturally patches the hole itself   These sample contain rings Give us age and growth rate of the tree  Growth increase in rings can allude to neighboring trees being killed Dead neighboring trees means less canopy blocking sunshine and less trees competing for nutrients   Multiple samples can give us an overview of a landscape  Do we see a multi-age forest? Do we see synchrony in growth rate?   Crossdating: To identify events, we compare the sample\u0026rsquo;s tree rings to those of other \u0026ldquo;regular\u0026rdquo; trees in different areas at the same time    Note that the example above is a rare occurrence  3. Fire Scars #    Fire scars occur when fire kills part of the cambium below bark, leaving a wound  The scar itself takes ~10 years to show up   Multiple dated wounds allude to multiple fire occurrences You can also get the seasonality too  Spring trees have warmer water so the scars are lighter in color Fall/winter trees have slower cell movement, so the scars are darker (this is called \u0026ldquo;latewood\u0026rdquo;) Therefore, how deep the scar is in the wood corresponds to the season the fire occurred   Use crossdating for high accuracy and precision Pines, White oaks, Sequoia, Redwood, Incense, and Cedars are all good trees to take samples from Wedges:  You can take wedges from the tree to get access to the ring view Both living and dead wood samples can be dated Pines, redwood, cedar, giant sequoia are all rot resistant thus good species to sample You ideally want to cut a thin wedge that has a large surface area and includes center of tree   Downsides  Trees heal covering up scars or scars are in an exposed cavity that can be seen Problem when fire interval \u0026lt; 10 years (such as cultural burnings)  Most of the time fires aren\u0026rsquo;t severe enough to scare deeply enough and if they do scar, it\u0026rsquo;s feint Only 5% of trees sampled scarred in Sierra Nevada   Fire scars have a finite lifespan (tree lifespan) Paints picture only of a certain plant in the landscape    Fire History Study Sierra Nevada #   Two large sampling areas, one north and south Sierra Nevada Systematic fire history sample in mixed conifer forests Important confluence of at least 3 Tribes: Sierra Miwok, Yokut, and Western Mono.  Burned extensively for multiple objectives This periodic burning limited severity of fires   Fire area did not exceed 1500 ha in any year.  Approximately 50% of area This is tiny compared to the scale of other fires in California!    Area burned in California #   Before 1800  Lightning fire Indian burning  Burned most of grasslands, wetlands, oak woodlands, some forests   4.5 million acres/yr. burned    Costal California Today #   Large area: scotia to Morro bay Very diverse vegetation type  From mixed conifer to costal prairie Fire regimes depend on vegetation, thus they\u0026rsquo;re diverse Likewise, some regions don\u0026rsquo;t consider burning at all and only do suppression whereas others use burnings frequently   General ignition sources  At higher mountains, lighting ignition occurs (still rare, however) At lower elevations / costal areas, human ignition is the main sources  Looking at history, we see that Indian fires dominated for thousands of years     Sudden oak death (SOD) in Tanoak Forest  Invasive pathogen in Marin Country Dead trees increase the severity of fires   Prescribed fire periods  Done in fall if not drying to damage trees  Trees are in dormant phase, less damaging   Done in spring if trying to control/limit  Wet spring conditions are easier to manage      Location Types #   Costal Prairie  Interval: Short  Frequent fires critical to killing shrubs/trees Therefore, due to human intervention douglas-fir and shrublands have began to take over prairies   Source: Indian Type: high \u0026ndash; removes overstory of grass Size: Small to moderate   Coast Redwood  Severity: low  Have thick, adapted bark   Interval: Short up to 1880\u0026rsquo;s Size: Small to moderate Source: Indian burnings Can re-sprout after fires Redwoods are very fire and rot resistant so many contain information about fires Difficult to date because the asynchronous ring structure   California Annual Grasslands  Interval: Short  Interval needs to be short so that shrubs don\u0026rsquo;t come in Practicing fire suppression/exclusion results in quick spreading, non-fire resistant plants like douglas-firs taking over   Severity: high \u0026ndash; removes overstory of grass Size: Moderate to Large Non-native plants dominate today, very different  Human intervention lead to overgrazing and drought which enhanced ability for mediterranean plants to prosper It\u0026rsquo;s hard to go back and restore to native ecosystem state     Coastal Scrub \u0026ndash; Coyote Bush (Oakland hills)  Interval: Moderate Severity: High Size: Moderate Source: Indian burnings for diverse objectives   Oak Woodlands, Mixed Oak Woodland  Severity: Low  Have thick, adapted bark   Frequency: High Size: Small Naturally dense  Very dense nowadays due to lack of Indian burnings Dense locations are less productive than managed and open areas   Mosaic of vegetation patches created that limit fire spread   Chaparral  Interval: Low-Moderate  Frequent burnings can lead to (invasive) grassland conversion (especially in SoCal) Many other \u0026ldquo;fire follower\u0026rdquo; species begin growing after fires too   Severity: High  Very volatile even in spring (non-dry conditions)   Size: Moderate to high Stand replacing regime  30-75 yr. interval Crown fire adapted High intensity burns Climate driven  Droughts Low fuel moistures Foehn winds \u0026ndash; Winds from east that are generally dry and warm     Fire scars \u0026ndash; not common   Knobcone Pine  Severity: High - High severity required to activate seeds Interval: Moderate to long Size: Moderate to large Overstory tends to burn completely   Douglas-fir in North Coast  Severity: Moderate  Not adapted for fire (have thin bark)   Interval: Low to moderate Size: Moderate Changed from fire exclusion, harvesting, and fire suppression    Native Californians #   Long-History of Human Occupation in CA  Archaeological Evidence: 13,000 years or more Evidence for multiple immigrations from both sea and land to California Diverse composition of people   Native communities are still in California  110+ recognized tribes today in CA We can learn from them now about how they treated fire over history 80-100 languages spoken between all tribes  Evidence for multiple immigration waves   The concentration of native communities is most dense North of Mexico   Packed Landscapes:  Many Tribes (Tribelets) or Small Nations 100-1000 people make up polities Mostly small Tribal territories Crowded Landscapes   Complex Societies  Village Communities have Elaborate Ritual and Political Organizations  Different people would specialize in different areas   Food Storage (Granaries) Sophisticated Material Culture: Baskets, Shell Beads, etc.   Non-Agrarian People  No formal agriculture practices outside SE CA Sustainer primarily by hunting/gathering (use of wild plants and gatherers) Adjacent Areas \u0026ndash; neighboring people would grow corn, beans, squash but Indians chose not to practice agriculture Perception about Non-Agrarian people Changed over time  (Falsely) Seen initially as passive foragers that minimal impact to environment      Indigenous Stewards of Land and Sea #   Better way of describing CA Indians (compared to hunter gatherers) Indians worked/work as Active Agents to Augment Environmental Productivity and Diversity Seascape Stewardship: Various ways Native people enhanced the productivity and sustainability of shellfish populations and fisheries Landscape Stewardship: Anthropological Rethinking back to 1940s, picks up steam in 1970s, 1980s that culminates with Anderson 2005 publication Various Methods Employed in Landscape Management Practices:  Transplanting Water Diversion Pruning/Coppicing Weeding/Tillage Sowing/Broadcasting Seeds All for the purpose of enhancing productivity of natural plants/animals   Most Important: Anthropogenic or Cultural Burning was the key method of stewardship  Long History in California (Channel Islands)? Mediterranean Climate is Fire Enabler  Wet cool winters lead to high plant production Dry and drought-ful summers provide a dry, extensive fuel base   Native Californians realized that fire was a natural occurrence and learned to live with fire Reasoning for Cultural Burnings (Landscape scale)  Fires Control Insects/Pests Remove Detritus, clean-up landscape  Allows light through which leads to healthy growth   Open Pathways Use Fire to Hunt Game (driving animals into traps/valleys) and Insects Produce Straight Stems for cordage, baskets Augment Growth/Diversity of Plants and Animals in Territory  Grasslands and other plants may have deeper roots which make them more difficult to kill   Increases productivity of nutrient rich plants that animals eat  Deer heard sizes are correlated with burnings   Stimulate Growth of broad spectrum of economic resources  Through burning in Patchy Mosaics     How Areas Were Burned  Instigate fire regimes with frequent, small, low-intensity surface burns  Seasonality of burning very important to minimize risk of catastrophic fires Additionally, risk reduced by reduce fuel loads + creating fuel breaks   Burn to increase productivity and stimulate growth of broad spectrum of economic resources  Notably shrubs with berries, oak woodlands, coniferous   Intentionally create Patchy Mosaics  Increase quantity, diversity and sustainability of key plants and animals Different environments benefit from different style burnings resulting in checkerboard-esque patterns Used for foods, medicines, and raw materials Minimize risk of catastrophic fires due to reduced fuel loads and fire breaks   Burn areas contained by natural rivers/hills/ridges/basalt flows   Implications of Cultural Burning  Not Pristine Wilderness, but Managed Anthropogenic Landscape \u0026ndash; you have to take into account Indians when looking at CA\u0026rsquo;s landscape You can\u0026rsquo;t do restoration without bringing in people  Now, because of a lack of recent cultural burnings, some habitats are struggling        Controversy regarding cultural burnings #   Some argue that cultural fires were small in size, near villages, and had little impact on the larger ecosystem Rather, natural fires best explain these fires Evidence Types tend to be soft;  Tribal Oral Traditions have a Short Temporal Depth for cultural burnings  Observations limited primarily to last 250 years   Limitations arise when primarily referring to Ethnohistoric Sources  Ethnohistoric Studies are from (typically Spaniard around 1600-1700) explorers and not trained as anthropologists Accounts tend to be spotty, geographically biased, and not very detailed Sources don\u0026rsquo;t include key fire regime aspects (freq, seasonality, severity, area, synergy) Susceptible to biases, uncertainty, and anecdotes   Ethnographic Studies  Information is word of mouth history from within the tribe that\u0026rsquo;s passed from one generation to another Recorded by anthropologists Information is very brief/general and lacking in our definition of fire regime now Old archeologists may have viewed Indians as hunter/gatherers (which is wrong!) Colonizers prevented cultural fires (fire exclusion)  Fire exclusion is when fire is indirectly removed from the environment  E.x. adding livestock removes fuels, reducing/removing fire E.x. Colonizers removing Natives (for reasons other than their cultural burnings) removed fires, changing fire regime   Whereas fire suppression is mindful + target specifically at stopping fires  E.x. Using firetrucks, airplanes, etc. to stop a fire from spreading E.x laws preventing you from creating fires during the dry season     Thus, when we started Ethnographic studies in 1901(ish), we didn\u0026rsquo;t see the history before because current tribes weren\u0026rsquo;t allowed to perform cultural burnings     Instead, critics would like to see hard ecological data (fire scars, pollen analysis, charcoal accumulation, phytoliths) Two main reasons to address these criticisms  Differential impacts due to colonialism in different spaces and at different times  Some areas colonized much earlier than others in the state  Central and Souther coast colonized 2.5 centuries ago by Spaniards Others only were colonized during the gold rush)   Some tribes subjected to Fire Exclusion/Suppression policies  Lacking specific information about when these policies were enacted Tribes colonized during gold rush tend to have more information than those colonized earlier in time   Consequently, some tribes have not been able to practice Cultural burning for generations   Political Implications  Some scholars argue that there is no real evidence that Native people were good stewards of the land  Point to times when animals/plants went extinct   Consequently, they should not play a special role in decision making Ecological restoration projects today  Nor play much of a role in the management of our public Lands today        Eco-archaeological Research #   Eco-archaeological Research: When we bridge ecological studies with anthropological / archeological studies and native Oral traditions Tries to tackle Major Challenge of Eco-Archaeological Research: Differentiating Natural Fire Regimes from Anthropogenic Fire Regimes  Compare Expected Fire Regime from Lightning Strikes with Observed Fire Regime Based on multiple lines of evidence         Long-Term Diachronic Approach that Employ Multiple Lines of Evidence:  Native Oral Histories/Traditions Ethnohistorical Accounts Ethnographic Studies Ecological Studies of Fire Archaeological Research  Other methods   Involves Researching with Tribes  Two Case Studies #  1. Sierra Nevada Mountains #   Difficult to carry out research because of high ignition rate due to lightening being common  Hard to differentiate between natural and anthropogenic fires   Research done by Linn Gassaway  Specifically looks at Yosemite Valley which Home of Southern Sierra Miwok people Utilized Ethnohistory, Ethnography, Archaeology, Dendroecology (Fires Scars)   Lightning Fires less Frequent in Valley Floor, more common on mountain peaks  Natural Fire Regime in the valley has a Long Interval Between Lightning Ignited Fires   Three Basic Findings By Gassaway:  Fires more Frequent for prehistoric, protohistoric historic times than expected for Natural Fires Alone  Evidence for potential Cultural Burning   Still evidence of fire activity in 1800s (When Native peoples were removed)  Miwok people still maintaining traditional fire practices?   1890s: Fire frequency reduced when Military takes over administration of Yosemite Valley \u0026ndash; Evidence for Fire Suppression    2. Eco-Archaeological Study of Central Coast of CA #   Research done by John Keeley  Central Coast great place to do study of Cultural Burning Hypothesis Presented for Strong Likelihood of Cultural Burning Here Low Frequency of Lightning on Coast  Natural Fire Return Interval around 50 to 100 Years Greater Bay Area: About 2-5 lightning ignitions per hundred kilometers squared per century   Conditions of high frequency (around 5 years) fire interval (cultural burnings)  Forests dominated by Douglas fir would be suppressed Redwood (fire adapted) forests would remain dominant, but have a more open understory with less fuel Shrublands would be suppressed and costal parries would take over   Conditions of low frequency fire interval (natural)  Shrublands and forests would be common      Central California Coast Project  Amah Mutsun Tribal Band  Issues of Food Security and Food Sovereignty  Limited Access to Native Foods Do not own much property   Tribe has Commitment to Ecological Restoration  Want to return indigenous plants and animals to the land     Established the Amah Mutsun Land Trust (AMLT)  Purpose is to restore natural resources Purpose it to steward lands and waters Return to path of traditional ecological knowledge   AMLT working with resource agencies who own much of the land (CA State Parks, BLM, etc.)  AMLT also working to purchase land for the tribe   Established Native Stewardship Corps  Boots on the ground for ecological restoration   Amah Mutsun Tribe interested in Collaborative Work  Legacy of Colonialism Tribe working with collaborative team to bring Knowledge of indigenous stewardship practices out of dormancy Opportunity to integrate Indigenous Science With Western Science   Amah Mutsun work with Team of Scholars from UCB, UCSC, and California State Parks Three components of project  Synthesize Previous Work:  Ethnohistory, Ethnographic Observations, Tribal Oral, Traditions, Historical Fire Ecology Cuthrell: Early Spanish explorers demonstrate extensive grasslands that must have been maintained through prescribed cultural burnings, as well as established Indigenous burning systems   Undertake Field/Lab work—Fire Ecology Studies:  Take samples of Fire Scars (Redwoods), Pollen/Charcoal, Phytoliths, Lake Cores Cuthrell: Phytolith Data from soil cores in Quiroste Valley indicate a long term history of grassland vegetation over the last ~1500 years   Archaeology  Archaeology provides understanding of past cultural practices (e.g., tools, settlements) Emphasis on recovering floral and faunal remains; evidence of kinds of resources harvested; Intersection of Archaeology with Fire Ecology; When we see changes in fire regimes, vegetation \u0026ndash; Do we see changes in kinds of resources harvested As outcome of landscape stewardship? Study number of sites:  Middle Holocene (6500-3000 BP) Late Holocene (3000-500 BP) Historical (after 500 BP)   Collaborative Field Schools  Involves UCB students, faculty State Park Archaeologists, ecologists Amah Mutsun Tribal Band, AMLT Native Stewardship Corps   Employ Low Impact Methodology  Geophysical survey work (ground penetrating radar)   Examples of Sites  CA-SCR-7 (6500-4000 BP) CA-SCR-10 (1300-1200 BP) Bolcoff Adobe (1830s-1840s)   Recovery of Plant and Animal Remains  Excavate Soil Flotation of Soil to Recover Remains Laboratory Analysis   Cuthrell:  Food remains indicate costal prairie seed foods (which came from prairies) were prominent parts of people\u0026rsquo;s diets during the last 1000+ years. Charcoal from hearth fires indicates fire-compatible trees such as redwood were the primary fuel sources, while fire-vulnerable trees like Douglas firs were not as common       Our Findings:  Observed fire frequency greater than Expected from Lightning Ignitions Alone  Strong evidence of Cultural Burning   Extensive Cultural Burning:  Begins about 1769-1770 CE Pattern of frequent, low intensity burns for the past 9-10 Centuries; up to Portola Expedition Create Coastal Prairie Environments,  Evidence of grasses, clovers, tarweeds, hazelnuts, etc. Also evidence of plant foods being harvested that required frequent fires to maintain     Patchwork of fires—burning areas every 1 to 5 years or so \u0026ndash; maintain coastal grassland Work in other areas corroborating our Findings  Other Study Areas Coastal Prairies \u0026ndash; extend from California to British Columbia   Conclusion  Key Point for Rest of Class: How can these Lessons from the Past derived from studies Indigenous Landscape Stewardship Practices be employed today?        Colonization of California #  Introduction #   Maritime Exploration  The first real instance of Colonization Happened from 1542-1603 then a long break   Spanish Missions, Presidios (forts), Pueblos (civilian settlements)  Happened from 1769-1823 Primary goal was to Christianize and Civilize Created large farm areas Recruited thousands of Natives as labourers Select locations where existing towns had reduction policies  Reduction policies moved natives into a single village after their land was taken     Mexican Missions, Ranchos  When Mexico took over CA Happened from 1822-1846 Established huge, private ranches (Ranchos)  Ran by natives Generated lots of money     Colony Ross  Russian Colonization from 1812-1841 Carried out by Russian American Company  Hunted sea otters Sold pelts to China   Recruit Native Alaskans who served as primary hunters    Impact #   Native population declines  Many deaths due to diseases (some of which hit instantly, some which took time) Violence and warfare between natives and soldiers (Sexual) Abuse of young women   Unleashing of Foreign Weeds, Pests (Crosby 2004)  Raised range of new foods on large ranches Thousands of cattle changed landscape too by overgrazing Weeds spread aggressively at expense of indigenous plants Land remains changed even today (90% of biomass in grasslands today isn\u0026rsquo;t native) Archaeological Evidence of Spread of Weeds Mission excavations and adobe (mud) bricks   Grazing Economy (Dart-Newton, Erlandson 2006)  Free-Range Grazing (no fences) In addition to cattle, brought Sheep, Goats, Horses, and Pigs  Wild pigs are still an issue today   Major impacts to local environments and Native Foods  Overgrazing trample indigenous Ecological habitats Help spread weeds     Commercial Hunting of Mammals  Terrestrial Fur Trade  Primarily hunted beaver  Pelt used to make hats in Europe   Exterminate beavers from Western North America, Northern California Major Impacts for wetland habitats   Maritime Fur Trade (Colony Ross)  Use Native Alaskan Hunters Very Efficient Harvest primarily Sea Otters  Nearly eliminated, otter population still low population today   Major Changes to Kelp Forests which impacted Fisheries of California     Fire Exclusion (Timbrook)  Began in 1793 when the Governor prohibited burning from Natives Explicit Policies Enacted to Stop Native Peoples from Cultural Burning Affected both Native Neophytes and so Called Gentile Indians (not part of missions)    Implications #   Loss of Traditional Ecological Knowledge (TEK)  Amah Mutsun Tribal Band (Lopez 2013)  Could not conduct ceremonies, prayer songs Could not Steward the land Unable to pass information to next generation (loss of TEK) Willing to work with archaeologists, fire ecologists \u0026ndash; bring knowledge out of dormancy  Working to Restore Landscape Today     Chumash People (Timbrook et al 1993)  Located around Santa Barbara Ethnohistoric accounts of Native Burning, but largely faded from tribal memory when ethnographic research conducted in 1920-1930s     Significant Impact to Local Coastal Environments  Increase of Foreign Plants and Animals Decline in Diversity and Quantity of Indigenous Flora and Fauna Decreases Loss of Food Security, Food Sovereignty, Native Medicine, Raw Material, etc. for Natives   Many Coastal Tribes Displaced  Colonial Invaders take away Native land Especially costal land   Major Transformation in California Fire Regimes  Cultural Burning on Coast Stopped  Coastal Prairies get overrun by woody vegetation quickly Even if grazing kept off shrubs, new grasses would begin growing   Some Disturbance keep areas open: Grazing, Colonial Burning? Altered Fire Regimes due to new plant types    Timber Owners and Early Use of Fire (10/4) #   1880: Advocates for ‘light burning' in California appear \u0026ndash; some thought fire was needed to manage forests  Whereas cultural burnings are done for main  div  article  ul:nth-child(68)  li:nth-child(7)  ul  li:nth-child(4)  ol\").scrollIntoView()'specific intentional reasons, light burning is done for other reasons such as reducing fuel, increasing food for livestock, and other economic reasons That is, cultural burning is a form of light burning   1900: Debate start regarding fire management near Lake Almanor in CA  Private forest land owners practiced ‘light burning' following early Indian and sheep herder traditions Most foresters dismissed this proposal as mere ‘Paiute Forestry' (derogatory term based on an Indian tribe)   1902:  H.J. Ostrander attacked ‘protectionist' policy of fire control as worse than effective because it allowed fuel to accumulate US National Academy of Science committee on forest reserves urged fire control policy   1908:  Gene Tolly: Sierra National Forest Ranger from 1905-1912 and cowboy assigned to range management for USFS Gifford Pinchot: 1st Chief of the USFS Tolly took Gifford on a back country trip through the Sierra National Forest to try and convince him to allow Indian Burning to keep meadows and forests from getting overgrown but Gifford didn\u0026rsquo;t buy it   1910:  Sunset magazine was an outlet used for forestry discussion at the time  G.L. Hoxie wrote in the magazine to advocated light burning claimed it should not be merely acceptable but made mandatory Made economic, not ecological argument   Unfortunately at same time, Great Idaho Fire occurred  Burned 3 million acres and killed 85 people. Happened due to drought period with ignitions from lightning, locomotives, and logging Resulted in national debate:  Senator Weldon Heyburn (R-Idaho) led effort to disband the USFS so that private land owners could manage their own land Others argued that the newly found US Forest Service (1905) should be expanded so that it could prevent future fires (happened, turns out govt tends to only grow bigger)       1930s: Two experiments were occurring in northeast CA around this time  Full Control  McCloud River Lumber Company Use trains, hand crews, etc   Light Burning  Thomas Barlow (T.B.) Walker was raised from Minnesota and ran the Red River Lumber Co. near Lake Almanor Clinton Walker (T.B\u0026rsquo;s son) wrote a letter to the Red River Lumber Company in 1938 (years after he had left the Company) saying:  The general condition of the forests when the white man first came into CA was very excellent Then came the foresters from Yale University and put the tourniquet on the forests Would prefer to remove the tourniquet in our timber matters [which] is the lack of fire I requested permission [to burn] from the State Forester and the USFS DuBois. Both refused We proceeded to burn anyway, and Chief Forester Graves came out from Washington and DuBois and many others with cameras and notebooks to get damaging evidence They stayed several days and followed the burning, with comment by Graves that the work was excellent DuBois apologized to me for panning me in the newspapers previously   Graves suggested that T.B underwrite a chair of fire protection at Yale University  Walker agreed, contributing $100,000 (a huge amount of funding 1900\u0026rsquo;s). Harvey Chapman hired who was huge force in longleaf pine is southeast US       Over the next decade trials done across the US, especially in pine belts of the West and South Stuart Show (from Stanford btw) looked for light burning area around Mt. Hough, Claremont, Meadow Valley Country  Found a suitable area near Snake Lake Commit data/scientific fraud by adding more fuel:  \u0026ldquo;Ed and I did 250 acres alone and, except for the long hitch of work, didn\u0026rsquo;t have any trouble. The only dishonest thing we did was to pile some pine limbwood in big fire scars of a few large pines, with the gratifying result that they burned down and became damage statistics\u0026rdquo;\n  Dave Rogers already had made up his mind regarding light burnings  \u0026ldquo;Went over nonchalantly to reburn Snake Lake (in 1920). It would have been O.K. except that Plumas Supervisor Dave Rogers came out the night of the burn, grabbed a brush burning torch and ended up stringing fire outside the line on two opposite ends. Then he left.\u0026rdquo; \u0026ldquo;You can understand our deep affection for Dave and the Plumas\u0026rdquo;\n  The use of fire in forest management was not given an objective evaluation anywhere in the Western US including Indigenous burning     1940s: Harold Biswell was a professor in the Berkeley Forestry Department from 1947 - 1972  Biswell conducted prescribed fire research in the forests of Georgia from 1942 to 1947 when he was a researcher for the US Forest Service Southern Research Station Began prescribed fire work in Ponderosa pine forests in 1951 (Boggs Mountain near Middletown as well as Teaford Ranch in the Southern Sierra near Bass Lake)  Both of these locations were private land because no government agency would let him burn in public land   Said in his 1958 paper:  \u0026ldquo;At the time the idea of burning was fairly new to me and I looked upon fire as the arch enemy of forests and forestry\u0026rdquo;\n  His 1958 paper showed it was possible to use fire in CA forest management and warned about future problems if fuels were not reduced  His conclusions were very controversial at the time His PhD students recall  \u0026ldquo;There was little opposition to him burning in grasslands and shrublands, but when he began burning experiments in ponderosa pine forests, active and open criticism of him and his work exploded. He was referred to as \u0026ldquo;Harry the Torch,\u0026rdquo; \u0026ldquo;Burn-Em-Up Biswell,\u0026rdquo; and other derisive names, and not always behind his back\u0026rdquo;\n  No forestry faculty would work with Biswell.  UCB Forestry faculty voted to forbid him or his graduate students to work at Blodgett Forest (Scott\u0026rsquo;s Opinion:) At the very least, some UC Berkeley forestry faculty should have worked cooperatively with Biswell to further explore this topic     In 1973, he was given the Berkeley Citation, awarded for his contribution to the University of California that \u0026ldquo;go beyond the call of duty and whose achievements exceed the standards of excellence in their fields.\u0026rdquo;  He was the first UCB forestry professor to get this award      Early Foresters and Fire (10/6) #   Some debate, but suppression wins in 1910s  However, one exception: Southern US continues to use fire   Pre WWII:  1933: Civilian Conservation Corps labor (CCC) used to fight fires  Hired many people due to great depression   1935: 10 AM (National) Policy: All fires should be out by 10AM the day after they\u0026rsquo;re detected before conditions that would make fire more severe arise   During WWII  Firefighting resources (people, machines) tied up with the war  Consensus objectors put into fire fighting crews Many were ridiculed but they fought the fire with little technology and overhead   Japanese sub fires shell near Santa Barbara  Fear of Los Padres NF and others being burned   Japanese also launch fire balloons  Hundreds hit the US, but they\u0026rsquo;re kept hidden from public   Public urged to be careful and fire is connected to the war USFS organizes Cooperative Forest Fire Protection Campaign  Fire protection was framed as National Security through public campaigns Huge push to save resource during the war  \u0026ldquo;Careless matches aid the Axis\u0026rdquo; \u0026ldquo;Our carelessness, their secret weapon\u0026rdquo;   Bambi brought (in 1944)  Movie showed terrible fires started by hunters Only on loan from Disney for 1 year   Smokey Bear named in 1945  Named after asst. Chief of NYC Fire Dept. 1919-1930 \u0026ndash; \u0026ldquo;Smokey\u0026rdquo; Joe Martin       Post WWII  Smokey Bear (cont.)  \u0026ldquo;Only YOU can prevent forest fires!\u0026rdquo; created in 1947 Canada steals him in 1956. Focus broadened to appeal to children   1950: The \u0026ldquo;Real\u0026rdquo; Deal  Las Tablas fire breaks out and a bear cub found almost dead Cub is treated and heals, eventually ends up in D.C. Zoo   Still endearing  One of most recognized figures in U.S. behind Santa and Mickey Mouse Stamps made (1984) Own zip code (20252) \u0026ndash; you can write him a letter and get a reply Office, Web page, Twitter, Facebook, Instagram, YouTube, etc.   Has Smokey\u0026rsquo;s message been TOO successful?  Original message was very black and white      Colonialism (10/8) #  Settler Colonialism In The American #  Earlier Colonial Enterprises (1769-1846) #   main  div  article  ul:nth-child(83)  li:nth-child(2)\").scrollIntoView()'Missionary Colonies: Franciscan Missions \u0026ndash; interested in converting main  div  article  ul:nth-child(83)  li:nth-child(4)\").scrollIntoView()'Mercantile Colony: Colony Ross (Fort Ross) \u0026ndash; interested in pelts and profit Common Features to both:  Predate Settler Colonialism Involved Few Euro-Americans \u0026ndash; workforce was almost all Native people Self-Contained Agrarian Systems Native people integral to their success   Major Outcomes ( 9/27/21 Lecture)  Loss of Traditional Ecological Knowledge Significant Environmental Impacts to Coastal CA Many Coastal Tribes Displaced Transformations in Fire Regimes    Settler Colonies #   Immigration of European/foreign settlers  British employed Settler Colonialism in Eastern USA Establish Permanent Residences   Predicated on Removal of Indigenous People Employed \u0026ldquo;Logic of Elimination\u0026rdquo; \u0026ndash; Moral Ground for Taking Land Away After American Revolution \u0026ndash; USA Adopts Settler Colony Practices; Manifest Destiny; Millions of people moved westward Key Dates for California:  1840s: Movement of settlers along California, Oregon, Mormon Trails 1846: Mexican-American War, Annexation of CA 1848: Treaty of Guadalupe Hidalgo Gold Rush 1850: California became the 31st State 1869: Transcontinental Railroad Completed 1850s-1870s:Settler Colonialism really takes off    Implications Of Settler Colonialism #  1. Genocide (Madley 2016 Reading) #   1846-1870s \u0026ndash; Dark Ages for Native People Extermination of Indians supported by Governors and other Politicians:  First Governor Peter Burnett proclaimed \u0026ldquo;War of Extermination\u0026rdquo; Senator John Weller (Governor in 1858) \u0026ndash; \u0026ldquo;White Man Demands Extinction\u0026rdquo; California Legislature passed anti-Indian laws:  Legal slavery of Indian Children Bounty Hunters paid by the scalp No rights in Court (couldn\u0026rsquo;t testify against a white person) Vagrancy Laws, etc. California and Federal Government Supported militias \u0026ndash; volunteer companies (Essentially Death Squads) that removed Indians from their lands California and Federal Governments \u0026ndash; allocated over $2 million dollars for this     Also diseases, starvation, etc. took a terrible toll on Indians Outcome of Extermination Policies: Native people Decimated, while Colonists Explode in Numbers:  Indian Population:  1769 = 310,000 1846 = 150,000 1900 = 15,000      Settler Colonist Population:  1850 = 92,597 1900 = 1,485,053         2. Reservations #   Unlike other Western States, most California Tribes did not have treaties with the Federal Government (as such, tribes cannot practice cultural burnings!) Abysmal Treaty Record in California  1851-1852: 18 Treaties Negotiated with Tribes of California; Proposed Reservation Land of 11,700 sq miles (Anderson 2005 Reading) None of the 18 Treaties Ratified by US Senate even though some Natives already moved  Politicians didn\u0026rsquo;t want to give up good agricultural land   Subsequent attempts to create Reservation Land \u0026ndash; Not very Successful;   1850s-1870s: Military Reservations 1870s-1900:  Federal Funding for Small Land Grants Influence of Helen Hunt Jackson, Her Book, Ramona, very important in Humanitarian movement  Fictional book told a love story of an Indian chief which became a best seller and brought attention to the situation     1906-1930: Another period of federal funding for small Land Grants for California Indians but it was all tiny sections of land (called Rancheria lands)  3. Federal Recognition #   Discuss Importance of Federal Recognition: Housing, legal assistance, Indian Health, food distribution, child welfare, Indian arts and culture development, fund tribal cultural heritage programs, tribal historic preservation officers, NAGPRA, Indian Gaming Three-Tiered System in California:  Gaming Tribes (Fed Recognized) Non-Gaming Tribes (Fed Recognized) Unacknowledged Tribes   In California Many Tribes Not Federally Recognized (Unacknowledged Status with Federal Government \u0026ndash; no land or status with feds!) \u0026ndash; Why is this the case?  1851-52: treaties not ratified 1870s-1900s:  Award Federal Recognition to tribes with strong continuities with Past; Those that maintained Indian cultural practices over time This was influenced by early anthropologists (i.e. UC Berkeley)  Program of \u0026ldquo;Ethnographic Salvage\u0026rdquo; Tended not to work with Tribes who had undergone major transformations, acculturation   Discuss Spatial Distribution of Fed Recognized Tribes; Many Unacknowledged Tribes in Former Mission Lands E.x. Ohlone Indians in post-mission times did not disappear  1840s: In East Bay 1860s: Lived at Alisal Rancheria well into 1900s  Active Indian community \u0026ndash; inter-marry with other tribes, Hispanics Some Anthropologists claim they were \u0026ldquo;culturally extinct\u0026rdquo; role that early Anthropology Played in Tribes obtaining Federal Recognition, and those that did not (Lightfoot 2005 Reading)          4. Environmental Degradation (Anderson 2005 Reading) #   Commodification of Environment Gold Mining, Hydraulic Mining  Impacted rivers and lakes   Commercial Agriculture and Ranching  Drained wetlands Monocropping   Commercial Hunting of Game, Birds, Fishing Massive Timber Harvests  Clear cut total forests Exploitive \u0026ndash; not forestry Specifically Redwoods, Sierra Nevada   Dam Rivers Unleash Plethora of Foreign Plants/Animals  Four Outcomes Of Settler Colonialism On Indigenous Landscape Management Practices In California #  1. Fire Prohibition Policies #   Initially Directed Against Native People; Racism \u0026ndash; Early Fire Bans Did Not Apply to All Settler Colonists  Settlers, Ranchers, and timber companies still burned land   Why Natives Signaled out for Ban?  Fire Suppression - - Component of Settler Colonialism Strategy to Facilitate the Removal of Natives from their Lands?    2. Minimal Reservation Land Implications for Indigenous Stewardship Practices; #   Fewer Restrictions on Indian Trust/Reservation Lands However, Lack of Tribal Lands in California  Curtailed ability of tribes to Revitalize Landscape Practices, such as Cultural Burning   Compare California with Trust Lands in American Southwest!!  3. Native People Lost Access To Resources From Their Tribal Lands #   Major problem for tribes—they were not granted trust land (reservations) AND they had minimal access to resources on Public Lands (California State Parks, BLM, National Park Service, US Forest Service) Until Recently - Tribes not allowed to undertake Stewardship practices on Public Lands  no cultural burning no harvesting of foods, medicines, raw materials    4. Conservation Practices: Exclusion Of Native People (Anderson 2005, Johnson 2014 Readings) #   Influence of John Muir on Conservation Movement in USA in early 1900s  Early debate about conservation practices involving light burning, indigenous stewardship Believed land was cathedral of nature and should be untouched (so no Indian burning!)   John Muir:  Argued for creations of pristine, natural preserves untouched by people Did not Advocate for Native Stewardship Practices, such as Cultural Burning Conservation Model - - Put Fence Around Property and keep people out Fire Suppression Policies of Settler colonialism  One component of broader package of developments that have kept tribes from revitalizing cultural burning until recently     Policies of extermination, genocide; poverty, diseases, food shortages; limited sized reservations; many California tribes unacknowledged; massive environmental destruction of tribal lands Upshot of Discussion, up until the 1960s-1970s, Native Californians had little or no land to call their own, minimal tribal land, little access to resources on Public Lands in California for harvesting foods, medicines, raw materials for baskets, etc. Greatly curtailed ability to undertake Indigenous Landscape Stewardship Practices, such as Cultural Burning  Outline Fire Suppression Policies of US/CA Governments #   Nathanial Kenny wrote an article on the US Fire Service  Published in 1956 in National Geographic Argued that at the end of the day, science would be the most crucial role in controlling fires   \u0026ldquo;I don\u0026rsquo;t believe that equipment and development alone will show us how to keep having the relatively few big fires… Researchers must let their imaginations soar for answers that today would seem fantastic\u0026rdquo;\n  Fire Suppression:  Begins around 1905 Approximately 80,000 fires/year today 98-99% of all wildland fires out at less than 5 acres in size 95% of area burned today is from 1-2% of the fires that escape initial attack  Often occurs in terrible conditions   4.5 million acres once burned in CA  Over half Tribal burning \u0026ndash; 10-35% of this area burns today in most years but 2020 will burn this amount for 1st time (Stephens et al. 2007) Size is only one aspect \u0026ndash; what is the fire mortality? what is the distribution? etc.   Not just area burned, burn patterns inside   Historical data yields insight into controls on forest structure in pine-mixed conifer forests  In 1911 photograph and datasets we can see much more sunny forests This is due to more frequent, natural/cultural burnings vs today\u0026rsquo;s fire suppression Kern National Forest Structure and Composition (Stephens et al. 2015)   Southern California and Baja Forests (Stephens et al 2003)  Drought from 1999-2002 in southern California and northwestern Mexico  Only 5 inches of rain one year, driest on record in So Cal mountains another year   Fire suppression and past forest harvesting have increased forest density in So Cal (Minnich et al 1995)  Native bark beetle population increased because of weaker trees   Sierra San Pedro Martir / Northern Baja California  Mediterranean climate Annual precipitation averages 24 in Area has been grazed by livestock Similar to southern California and eastern Sierra Nevada Fire suppression begins in 1970, no harvesting SSPM Mission in 1794 severely impacted populations Within the California floristic province Forested area of around 40,000 acres Fire suppression and past forest harvesting have increased forest density (Minnich et al. 1995) Elevation upper plateau 8800 ft  3 large plateaus, Peninsular Mountains   Jeffrey pine-mixed conifer forests  Similar to souther CA and eastern Sierra Nevada Fire suppression begins in 1970s, no harvesting   3 indigenous cultures used portions of the SSPM outside the winter: Paipai Kiliwa, Nakipa  SSPM Mission in 1794 severely impacted populations Mission lasted 8 years due to extreme climate     SSPM wildfire July 4, 2003  Started in chaparral below forest Fire burned approximately 600 acres  More shrubland than forest burned   Largest fire in 20 years  Occurred at end of sever drought, 1999-2002 Same drought as in SoCal  SoCal drought killed millions of trees w/o fire     Only 20% of trees killed  Jeffrey pine more dominate after fire, trees and seedlings (less white fir, incense-cedar)   Fire was very patchy  Directly linked to heterogeneity of forest structure and fuels pre-fire Mortality very low even after 4 year drought and wildfire (Stephens et al. 2008)   Incredible forest resilience!!  Gives us hope in California To answer Nathanial Kenny \u0026ndash; Fire back, restoration thinning, and stewardship are also key        Implications for Local Ecosystems #   Changes to Grasslands  Encroachment of woody species  Pinyon pine-Juniper in Southwest   Tallgrass prairie Mountain meadows Coastal Prairies   Fire taken out of system  Fire return intervals increased Whole ecosystems change Examples from Montana and Arizona   Rim Wildfire  Largest fire in Sierra Nevada  Fifth largest fire in history of CA   Ignited August 17, 2013 Total area burned: 270,000 acres (102,000 ha ) Fire effects  Very large high severity patches   Cost of suppression : $127.2 million   Management Response  Forest fuel reduction treatments implemented to reduce fire hazards and fire effects  Reduction of surface and ladder fuels critical (Agee and Skinner 2005)   Example of fuel reduction treatments  Research has determined that treatments are effective in reducing potential fire behavior and effects (Fulé et al. 2012)     Permanent Backlog: Sierra Nevada  2.9 million acres (60% of FS acreage) will always remain fuel loaded 2/3\u0026rsquo;s of this acreage is pine-dominated and mixed-conifer forest types This is a disaster! Only gets worse with climate change   Summary  Tree density increased 2-3 times in mixed conifer forests since 1911 Forest change has decreased resiliency Climate change will make this situation worse Need increased fuel reduction treatments and wildfire for resource benefit frequent fire forests - critical California legislation $200 Million/yr. through 2028 Fuel treatments on 1 million acres/yr. by 2025 US Forest Service management plans being revised  Best chance in decades to change trajectory   Next 1-2 decades absolutely critical Leave options available for future managers We are running out of time!!    Leopold and Forest Restoration #  Leopold et al. 1963 #   Asked to carry out report by US govt Carried out in Yellowstone Took view of the whole ecosystem, not just a single issue Animal populations \u0026lsquo;protected\u0026rsquo; from hunting and habitats \u0026lsquo;protected\u0026rsquo; from wildfire  Wolfs (predators) were hunted before so that elk could thrive Elk thrived too much; Elk became hunted because their population grew so high   Habitat is not stable that can be set aside and preserved behind a fence Goal of Park Management in the United States  Each park be maintained, or where necessary recreated, in the condition when first visited by the white man  Wilderness isn\u0026rsquo;t devoid of people; need to consider native stewards   A primitive America could be recreated, using skill, judgment, and ecologic sensitivity The forty-niners poured over the Sierra Nevada and found big trees in gigantic magnificence  Ground was grass parkland, in springtime carpeted with wildflowers (No mention of indigenous management) Today dog-hair thicket of young trees and mature brush—a direct function of protection from natural fires   Is it possible that the primitive open forest could be restored? And if so, how? (Big question even for today)   Policies of Park Management  Research, not intuition, should form the basis for all management Agency best to study park management is the National Park Service Management without knowledge would be a dangerous policy indeed   Methods of Habitat Management  Of the methods of manipulating vegetation, controlled use of fire is the most \u0026ldquo;natural\u0026rdquo; and the cheapest and easiest to apply (easy?? Maybe in the 1960\u0026rsquo;s) Forest and chaparral areas protected from fire may require careful advance treatment (Harold Biswell influence?) Trees and mature brush may have to be cut, piled, and burned before ground fire (Harold Biswell did this with his early burning) Once fuel is reduced, periodic burning can be conducted safely and at low expense (Biswell)  Against wind and down hill results in slowest and least severe fire conditions   \u0026ldquo;We are calling for a set of ecologic skills unknown in this country today\u0026rdquo; (Indigenous?) \u0026ldquo;It will not be done by passive protection alone\u0026rdquo; (Big statement at the time, Still important today)   Very powerful ideas included, changes NPS course of action (no Indigenous people though)  Sneeuwjagt et al. 2013 #   Rick was the head of bushfire and prescribed fire in Western Australia which also has a Mediterranean climate Opportunities for improved fire use and management in California: lessons from Western Australia (WA) Treatment size - Prescribed burn units much larger than those implemented in the US - make ours bigger  Burns averaging in excess of 5000 ac, with some as large as 25,000 acres in Western Australia   Department of Environment and Conservation (DEC) fire managers take advantage of relatively few burn windows to burn large areas  Managers use weekends and nights, if conditions are favorable Have multiple burn plans in place in each region in order react quickly to conditions DEC begins training new seasonal crews on prescribed fires in the spring burning season DEC has responsibility for fire management across all public lands in the state of Western Australia (integrated versus USA system) Impossible to combine the many county, state, and federal agencies of CA under one agency but we need to do better   Similar to California, prescribed fire in Western Australia is a contentious issue, particularly some urban residents who not aware of benefits of prescribed fire Indigenous burning not integrated with DEC burning \u0026ndash; rare across Australia at least in 2013 DEC uses a focused outreach effort to the public and politicians \u0026ndash; otherwise, fire program could get cut  Fire program severely tested from an escaped prescribed burn in November 2011 that destroyed 32 houses  Part of Reason Rick retired   The first instance of home loss from a DEC burn in 50 years More stringent risk management assessment of the program occurred Despite community anxiety, support for continuation of extensive prescribed burn program remains high (similar to Florida from home losses 5 years ago)   These are mature programs, California is in the beginning and we will need patience and the support from the public and politicians We will have problems: Indigenous fire use could help us move forward Hopefully can learn from them and build a program  MT2 Review #   Construction of railroad occurred after statehood of CA Colonization from San Fran do San Diego was unique in that it was primarily to set up missions Paiute Forestry was an offensive term that was directed at light burning, calling it \u0026lsquo;primitive\u0026rsquo; because tribes practiced it Stuart Show manipulated data to make burnings look more dangerous Canopy fires  Higher severity \u0026ndash; upper trees aren\u0026rsquo;t fire adapted like the base of trees Used to be rare pre-1800s, now more common due to build up of surface fuels Latter fuels allow fire to travel up fuel, up to canopies   Clinton Walker was an advocate of light burning There is little short-term economic gain to do fuel treatment CA\u0026rsquo;s first governor (Peter Burnett) supported the Native American protection act and endorsed the war of extermination At least 4.5 million acres were burned annually pre-colonization (1800s) Ron Good claimed that cultural burning was primarily for cultural reasons + increase value of raw materials and increase visibility Harold Biswell was a UCB professor and was an advocate of prescribed burning when it was taboo  Was ostracized at the time, but is now recognized   Early EU explorer period was different from the Spanish missionary period in that the EUs didn\u0026rsquo;t settle down and instead explored/traded while the Spanish established settlements Gifford Pinchot was very against any kind of burnings 1910 fire occurred in Idaho and led to many advocating for fire suppression Population reversal of CA Indians occurred due to the finishing of the rail road (letting more people in to CA, i.e during the Gold Rush) Essay Question:  Settler colonialism differed from earlier Missionary trips in that\u0026hellip;  Settler missions went inwards + cared primarily about making money During Missionary trips, Natives were a large part of the workforce and the main purpose to convert them to Christianity   Two sides of light burning controversy:  Natives encouraged to burn so that there wasn\u0026rsquo;t fuel build up, etc. Foresters who opposed ranchers employing any form of burning, called it Paiute Forestry   Settler colonialism impacts  Intersection of many invasive plants/animals that radically altered ecosystem (e.x. cattle) Draining of lakes/dams to flood areas (altering ecosystem) and other forms of land modification for the purpose of agriculture Hydrolic mining leading to soil erosion Logging + clear cutting of forests   Anderson 2005, settler period  Forceful removal \u0026ndash; through raids, violence, giving false land titles, destroying food/water source Extermination (killing) \u0026ndash; Genocide (Benjamin Madley) Assimilation \u0026ndash; Native Children went to school to be whitewashed (re-educated)      How to plan for prescribed burning, comparison with Florida #   Prescribed fire definition: A wildland fire burning under pre-defined conditions that will accomplish certain planned objectives. Fire is ignited by people by drip torch or helicopter  Whereas cultural burnings exist only for cultural reasons   Prescribed burner must integrate:  Weather (present day and forecast)  Weather has strongest correlation with severity of the fire + it can change rapidly   Topography Fuels (load, moisture content)  Spotting (embers flying across lines) occurs when fuel is very dry   Ignition patterns (how fair is put on the ground)  Art side \u0026ndash; factor you can control E.x. head fires, backing fires, strip-head fires   Crew size and experience, where to assign people Safety (highest priority of all fires) Risk (all fires have risk, goal is to minimize it and have a plan in place to execute if something goes wrong)   Prescribed fire is both art and science  You can use science, but it ultimately depends on land/weather   Biswell did not take measurements  His graduate student Jan van Wagtendonk developed prescriptions for his PhD at UCB    Southeast USA #   Forests, savannas, and grasslands of the southern US, well-established history of fire, whether from lightning, Indigenous ignitions, or Anglo-Europeans Florida, Georgia, Alabama, Carolinas, all have great prescribed burning programs  Carried down from tradition  Burning used to increase productivity of sap for turpentine, decrease hardwoods in timber lots, enhance grazing forage Became a family tradition   Plant adaptations diverse: closed cones, large terminal buds, sprouting, bark thickness  Longleaf pine  Low intensity, frequent surface fire to reduce competition Thick, corky insulating bark Self-pruning at maturity Large terminal bud Chapman studied \u0026ndash; Yale     USFS tried to eliminate but not successful   Kobziar et al. (2015) conducted survey of eastern US burners from in 2011 - 2012  Most respondents (75%) were employed by State or Federal forest or wildlife agencies, with the remainder landowners or contractors Fuels reduction primary goal of prescribed burning overall Program continues to be successful Florida burned \u0026gt; 1.2 million acres of forest last year  Longleaf pine in \u0026lt;5 year, low intensity, understory, summer, brown rot Big shrub (sand pine) 25-100 year, high intensity, crown, spring or summer, large areas Bald Cypress / tupelo swamp, \u0026gt; 200 years, small area, mixed severity, only during drought   Georgia said it surpassed Florida in terms of acres this year Prescribed fire in California - Low - maybe 50,000 acres   Brown Administration Bill passed to provide $200 million/yr. for fuels management projects - Apply for grants Continues under Newson Administration and funded through 2028  Goal to increase prescribed fire in CA to 1,000,000 acres/yr by 2025: 500k acres State and Private and 500k acres Federal   What is our baseline? Cultural burning combined with Rx fire? Task forces created in State to increase pace and scale of restoration and prescribed fire Public lands managers - limited budget and staffing are impediments, also planning issues We don\u0026rsquo;t have the experience, crews, or political or institutional support in place today for a large program We need to be patient - will take time  Managed Wildfire Effects on Water and Forest Health #   Fire and Hydrology in Western US Watersheds - Project Starts 2002  Managed Lighting Fire, Increase Forest Resilience   Illilouette Creek Basin, Yosemite National Park  Fires in occur naturally through lightening here every 9 years 50 years of fire use, 40,000 ac watershed   Reburn fires Interactions between adjacent fires Historically open, patchy stands with large trees not everywhere  Evidence of small proportions of stand-replacing fire (5-15%)   Show and Kotok (1924):  \u0026ldquo;…no large fires occur without a certain amount of heat-killing\u0026rdquo; \u0026ldquo;This loss, it should be noted, represents the complete or nearly complete wiping out of small patches of the stand rather than a uniformly distributed loss over the entire area\u0026rdquo;   Vegetation Change from Photos:  Fires Reduced Forest Area by 22% Wet meadows increased by 200% Dry meadows increased by 200% Shrublands increased by 30%   In Yosemite amount of stream water leaving watershed has increased or remained stable since 1974 - modeling study increased by 60 mm Three other control watersheds significantly decreased  Flood risk unchanged Soil water increased Lower tree mortality in drought   Since fire suppression ended…  Runoff ratio increased or stable Duration of spring snowmelt longer Soil water storage increased, less mortality drought Stream discharge up 3-6%, deep storage up Use of lightening ignited wildfires in Yosemite has provided several benefits to forest and water Indigenous fire could complement lightning fire   California is water scarce and is experiencing an increasing number of severe wildfires  Despite warming climate, managed wildfires in Illilouette promote a healthy watershed Increased streamflow from wildfires will persist in a warming climate Water agencies supportive of bond funding to manage watersheds but not their base budgets - should change   2020 North Complex Fire burned the largest watershed that feeds the largest lake in the State Water Project (Oroville Lake) Next 1-2 decades absolutely critical in California frequent fire forests Optimistic but we must move decisively  Case Studies of Cultural Burning #  Background On Tribal Revitalization #   Timeline  1960s - Watershed time in California 1963 - Leopold Report \u0026ldquo;Wildlife Management in National Parks\u0026rdquo;  bring fire back to National Park Service Managed Lightning Fires Prescribed Burning   1960s - Also Time of Native Activism in CA   Historical Perspective:  By the 1960s tribes facing some real structural challenges:   Recovering from Genocide Little land to call their own Consequence of 1851-52 treaties not being ratified Many California tribes not federally recognized Tribes denied access to federal/state lands to harvest plants and animals Fire Prohibition Policies  Fire Exclusion - Spanish, Mexican and Russian Colonists Fire Suppression - American period  1890s - Sequoia and Yosemite 1900s - Elsewhere in California       Upshot for Tribes:  A. Not allowed to implement Indigenous landscape Stewardship practices B. Poor Health of CA Environments  Fire Suppression Policies:  Major Impacts to indigenous plants and animals fuel loads increase less ecological diversity loss of patchy mosaic Some Native species disappeared fire adverse species take over hydrology affected some ecosystems - become endangered (e.g., coastal prairies)        Native Activism #   1960s - Native Activism, part of broader Civil Rights Movement in USA  Protest series of issues: discrimination, poverty, unemployment, religious freedom, fair housing, broken treaties, lack of resources Natives not given right to vote until 1924 Snyder Act Some states did not allow Indians to vote until 1950s, 1960s   1968 - Civil Rights Act signed by President Johnson  Guaranteed rights to not only African-American, but American Indians   1968 - when American Indian Movement Founded (AIM)  Advocate for rights on Native people   1968-1971 - Occupation of Alcatraz Island by tribes Post-1968 - series of protests, demonstrations, marches for American Indian causes  Tribal Revitalization In California #   Last few decades - major renaissance with Tribes Keep in mind that Tribes still facing many issues  Poverty Unemployment - not much of a land base, FAR from urban jobs Addiction issues - alcohol, drugs Health issues, such as diabetes, obesity Gang issues with younger tribal members Still explicit discrimination   But despite these lingering problems from colonization  Major transformations taking place in many tribal groups Restoration of local habitats \u0026ndash; Crucial part of this process But need to look as this within broader context Tribal revitalization - involves various facets of Native Life TODAY     Native Languages  Estimated that 80-100 languages spoken in California \u0026ndash; but many languages endangered     Legacy of Colonialism  Indian Boarding Schools (late 1800s-mid 1900s) Assimilation Policy of US Government Carlisle Boarding School, Pennsylvania Sherman Institute, Riverside, CA \u0026ldquo;Civilize\u0026rdquo; Indian Children away from negative influences of parents, tribes  Children forcibly removed from home and sent to Boarding Schools Taught Western ways Speaking Native Languages Forbidden!   By mid-1900s - Many Tribes Facing Crisis with Their Languages  Only half of Native languages in CA still spoken   Leanne Hinton - UC Berkeley  90% of Native Languages in CA may disappear   Major Push Today: language training for California tribes  The Advocates for Indigenous California Language Survival \u0026ldquo;Breath Of Life\u0026rdquo; workshop Program on Berkeley campus provides training to Indians studying/learning endangered languages historic linguistic tapes and information in Linguistics Dept, Bancroft Library, Hearst Museum of Anthropology Tribal scholars relearn how to speak dormant languages (Mutsun, Chochenyo Languages)      Revitalization Of Native Ceremonies, Dances  Many groups involved in reviving spiritual practices  Healers, Indian doctors, spiritual specialists Create active dance groups, e.x. Su Su Shinal Kashia Pomo   Close Relationship of California Indian religions with Environment   Resurgence Of Native Craftspeople  Resurgence of Native Crafts  Ron Goode - soapstone artifacts woodcarving - Northwest Coast Acorn spoons, boxes,   Basket Weaving  Premier basket makers in world Baskets served many purposes in Indian households Challenges for Indian Basket Making  by 1980s - only a few active weavers Led to Establishment of California Indian Basket Weaver Association host gatherings, workshops more than 650 weavers today! Major Advocate for Indigenous Landscape Stewardship Practices!       Great Interest In Native Foodways  Traditional menus, traditional foods  acorn mush, salmon \u0026ndash; but also seaweed, tar weed, hazel nuts   Pow Wows Tribal food security, food sovereignty Café Ohlone - Bancroft Way - bring to Cal campus   All Of These Developments - tied into Native Landscapes and Environments  Most tribes interested in ecological restoration of their lands Implementing some form of indigenous landscape management practices  Bring Fire Back To Landscape \u0026ndash; Tending The Wild and gaining access to various resources on Public Lands Obtain indigenous foods, medicines, dance regalia, raw materials for crafts      Ecological Revitalization #  Five Case Studies Of Indigenous Stewardship Practices In California\n1. Fowler et al #   Fowler, Catherine S., P. Esteves, G. Goad, B. Helmer and K. Watterson 2003 Caring for the Trees: Restoring Timbisha Shoshone Land Management Practices in Death Valley National Park. Ecological Restoration 21(4):302-306.\n  Federally Recognized Tribe working with National Park Service  Death Valley National Park   Timbisha Shoshone tribe in Southern Deserts  Granted federal recognition in 2000  Obtained Trust Lands \u0026ndash; Federal Recognition     Right to enter traditional management agreements with Federal Agencies (NPS, BLM) Work out co-management agreement with NPS in Death Valley National Park Co-manage Two Key Resources  Honey Mesquite, Single Leaf Pinyon Both used as food, raw materials, etc.   Timbisha Shoshone  Begin to tend the Mesquite and pine groves in Death Valley Had not been tended in years \u0026ndash; in terrible shape!   How Undertake Ecological Revitalization  While Tribe used Fire to Tend the Land in the Past Current work - using Fire Surrogate Methods \u0026ndash; hope to use fire in future   Define Study Plots - Leave half of plot as control Other Half of Plot - Tended by Tribe  Trim lower branches of trees Clear ground of underbrush Open trees to sunlight   Challenges  Insect infestations Changes in Hydrology    2. Codero-Lamb et al #   Codero-Lamb, Julie, Jared Dahl Aldern and Teresa Romero 2018 Bring Back the Good Fires. News from Native California 31 (Spring):14-17.\n  Non-Fed Recognized Tribe  Work on private property Ecological restoration   Southern California  Chumash - Santa Barbara Area \u0026ndash; only one of tribes federally recognized Santa Ynez Band of Chumash Mission Indians article about non-federally recognized CHUMASH  Aftermath of Thomas Fire in Dec 2017     Strong Commitment To Bring Back Indigenous Landscape Practices  Bring back good fires recognize issues of working in Chapparal Environments   Paper outline difficulties of doing this when not federally recognized, no tribal land  No current agreements with government agencies to burn   instead - burn on small patches of private land  tiny patches tended by Chumash   Burn Protocols  based on elders, songs, and Scientific Studies   Discuss Frequency Or Timing Of Burns  Springs - Annually grasses and shrubs for baskets - every 3 years 10-15 years in chaparral   Recognize that they must adjust seasonal timing of burns with CLIMATE CHANGE Strong Advocates for Cultural Burning Important Points:  For federal and state to restore environment after years of Fire Suppression  Need to incorporate local communities (Tribes)   Get Tribes Involved In All Aspects of Projects Must Recognize Tek is Valid Strategic Placement of Tended Lands \u0026ndash; can serve as fuel breaks    3. Karuk and Yurok tribes of Northwest California #   Lake, Frank K., and Amy C. Christianson 2019 Indigenous Fire Stewardship. In Encyclopedia of Wildfires and Wildland-Urban Interface (WUI) Fires, edited by Samuel L. Manzello. Springer, Cham. https://doi.org/10.1007/978-3-319-51727-8_225-1. Lake, Frank K., Vita Wright, Penelope Morgan, Mary McFadzen, Dave McWethy and Camille Stevens-Rumann 2017 Returning Fire to the Land: Celebrating Traditional Knowledge and Fire. Journal of Forestry 115(5):343-353. Terence, Malcolm 2016 Unleashing the TREX: Why Officials Think Controlled Burns Can Save California from Wildfire. North Coast Journal ( http://www.northcoastjournal.com/humboldt/unleashing-the-trex/content?oid=4132514.\n  Federally Recognized Tribe \u0026ndash; work with Federal Agency (USFS) Frank Lake \u0026ndash; key player in bringing Cultural Burning to California  Karuk tribal member and works for USFS well positioned for making a difference publishing widely on cultural burning strong proponent for government agencies, conservation groups  to develop collaborative partnerships with Tribes     Makes this point in Lake and Christianson 2019 Reading  How cultural burning can reduce or mediate impacts of wildfires Important information about burning and stewardship passed down through generations Significance of Traditional Ecological Knowledge (TEK)  TEK looks at what works, what doesn\u0026rsquo;t, and how things change over time Important for us to use/employ today in how we can learn to live with fire in California     Frank helping to bring cultural burning back to Northwest California  burns taking place on\u0026hellip;.  Private land (fewer restrictions) Tribal lands \u0026ndash; Yurok have some land USFS lands \u0026ndash; control most of traditional tribal lands in the area      Five Points to emphasize in burning in Yurok and Karuk lands #   Karuk and Yurok Tribes  Different process of colonization than Central/Southern California Later in time - post Gold Rush (1848) which is unique  Compared to SoCal, where practices were banned early on, Karuk and Yurok have more recent information E.x. Bill Crook learned from his grandma who practiced burns pre-gold rush   Considerable Indigenous Knowledge about Cultural Longer continuation of burning   USFS  Until fairly recently, have not been receptive to Cultural Burning Until fairly recently Now have Native Californian employees high up in management  Can\u0026rsquo;t be about certain people, should be about policy Otherwise, if these key people retire then we\u0026rsquo;re screwed!   Signed agreements \u0026ndash; MOUs (Memorandum of Understanding) \u0026ndash; between USFS and Karuk Tribe Government To Government Relations  Frank Lake et al. 2017 Reading Importance of developing person-to-person relationships and trust workshops, meetings, importance of communication with tribal leaders     Integration of TEK and WS (Western Science)  Two Different Ways of Knowing  WS: Prescribed Burning  More utilitarian approach \u0026ndash; can be tailored to smaller area to achieve specific outcome Emphasize Fuel Reduction Residential Areas (W/U Interface)   TEK: Cultural Burning requires a more nuanced, patch-like approach  Need to consider specific resources in a generally large area E.x. burn early for short basket shoots and later for longer shoots     Frank Lake argues that \u0026hellip;  Advocate for integrating TEK with scientific disciplines Use multiple lines of evidence to understand past fire regimes and cultural burning     Federal Agencies - need to respect TEK  Work collaboratively with tribes \u0026ndash; all phases of projects   Need to Provide Sufficient Funding!  To maintain partnerships, Cultural Burning Programs Need to follow through and show commitment to tribes    4. North Fork Mono Tribe #   Ortiz, Beverly R. 2018 Ron Goode: A Life Lived in Service to Community and Environment. News from Native California 31(3 (Spring):18-26. Goode, Ron W. 2015 Tribal-Traditional Ecological Knowledge. News from Native California Spring 2015:23-28. Long, Jonathan W., Frank K. Lake, Ron W. Goode, and Benrita Mae Burnette 2020 How Traditional Tribal Perspectives Influence Ecosystem Restoration. Ecopsychology 12(2):71-82\n  Case Study: Non-federally recognized tribe work on private lands + also develop agreement with USFS North Fork Mono: Major advocates of Cultural Burning   Ron\u0026rsquo;s knowledge about Cultural Burning comes from his (grand)parents who continued cultural burnings during fire-suppression years  Also works with scientists to teach/learn from them Involves other tribes with work to get range of perspectives   Cultural Burning \u0026ndash; tied To Spiritual Practices  Tribe\u0026rsquo;s Spiritual Philosophy involves prayers and songs Mother Earth And Creator   Began burning on private property his family owns 2003 - began working with USFS in partnership  Meadow restoration project in tribal territory  Restore meadow and spring Enhance deer grass (for baskets)   Long et al 2017 Reading discusses\u0026hellip;.  Importance of cultural resources (i.e. plants which can be used as medicine) Archaeology Culturally important plants, etc. Differing opinions with USFS  E.x. USFS wants to remove all invasive plants whereas Ron argued to leave a few that the tribe would look over         2017-2021 Has been practicing Cultural Burning on private ranch  Near Mariposa (Yosemite National Park)  Location is associated with major archeological sites Burn for targeted results, as listed below     Specific Reasons for Burning  Burn for positive result to affect outcomes of targeted cultural resources  More than just fuel reduction (which is a trait of prescribed burning)   Ron views Prescribed Burning as Industrial Scale burning Cultural Burning: more NUANCED kind of burning \u0026ndash; burn treatment depends on cultural resources being enhanced Sourberry \u0026ndash; important plant for food and basketry material Pretreatment before burns  Prune vegetation Create burn piles Burn small plots   Post-Burn \u0026ndash; mix burned soils with water to create a nutritious soil bed     Summary thus far\u0026hellip; #   Tribes \u0026ndash; need to be treated respectfully  Need to establish partnerships in CA  Resource agencies, tribes, and researchers     Tribes should be involved in decision making concerning fire management strategies  For their traditional lands Bring in at the outset of revitalization plans   Many tribes working with researchers  Recognition of importance of TEK and WS Not mutually exclusive! Brought together   Too many regulations in bringing cultural fire back  Need to ease up on RED TAPE (based scott) Especially at the Federal level, CA is actually pretty good as far as enabling burning   Dealing with Intrusive species  Areas overgrown from Fire Suppression  E.x Chapparal     Need Funding for Proactive Work to Manage Environments  Funding for pro-active management Funding for environmental revitalization Funding for eco-system corps Maintain programs over time   Possibility of Incorporating  Prescribed Burning and Cultural Burning?    5. Amah Mutsun Tribal Band #   Hannibal, Mary Ellen 2016 Rekindling the Old Ways: The Amah Mutsun and the Recovery of Traditional Ecological Knowledge Bay Nature April-June 2016:28-35. Lightfoot, Kent G., Rob Q. Cuthrell, Cristie M. Boone, Roger Byrne, Andrea B. Chavez, Laurel Collins, Alicia Cowart, and R. Evett, Fine V.A. Paul, Diane Gifford-Gonzalez, Mark G. Hylkema, Valentin Lopez, Tracy M. Misiewicz and Rachel E. B. Reid 2013 Anthropogenic Burning on the Central California Coast in Late Holocene and Early Historical Times: Findings, Implications, and Future Directions. California Archaeology 5(2):371-390.\n  Valentin Lopez \u0026ndash; Tribal Chair In Week 5 \u0026ndash; discussed eco-archaeological work that UCB and UCSC  Partnering with Amah Mutsun + California State Parks   Outlined findings employing different lines of evidence  Fire scar analysis Pollen/charcoal (wetland coring) Phytoliths \u0026ndash; tells us the extent of grasslands Archaeology Ethnography, ethnohistory, tribal history   Our Findings:  Strong evidence of Cultural Burning Observed fire frequency greater than Expected from Lightning Ignitions Alone   Extensive Cultural Burning:  Begins about 1300-1200 BP Pattern of frequent, low intensity burns for 9-10 Centuries up to Portola Expedition in CE (Common Era) 1769-1770 Create Coastal Prairie Environments,   Evidence of grasses, clovers, tarweeds, hazelnuts, etc.  Rob Cuthrell talked about this   Fire Tenders created a productive, patchy landscape mosaic  Burning some patches one to 5 years or so cycle maintain coastal grassland! along with neighboring woodlands, wetlands, and forests with fire-adapted species such as hazelnut, California lilac, and redwood    What Are We Doing With These Findings? #   Ultimate Goal Of Research Program  How lessons from the past can be applicable to contemporary CA? How these finding may be incorporated into ecological revitalization programs  That are rooted in the deep history of tribal practices   The Amah Mutsun working with California State Parks  Co-managing some lands \u0026ndash; Quiroste Valley Cultural Preserve MOUs (Frank Lake) Committed to ecological revitalization  Understand limitations of fire suppression Bringing back Native plants and animals that once flourished       Based on findings from our eco-archaeological findings  Tribe \u0026ndash; interested in bringing back patchy landscape mosaics  That includes extensive patches of coastal prairies which have become rare with fire suppression  Encroached on by conifer forests and shrublands       Val Lopez and Tribe  Created Amah Mutsun Land Trust Purpose is to restore lands in their territory Undertake research  Support Native Stewardship Corps Boots on the Ground for work      How we are doing this: #   Select Patches Where we Open up Landscape Involves Removing Problematic Invasives  Poison hemlock, milk and Italian thistle, jubata (Pampas Grass)   Fuel Reduction  Use clippers / chainsaws remove brush and small trees  Can be used to make burn piles, biswell-style   Few places mechanized removal of overgrowth   Where Possible  Implement Cultural Burns Begin Process Of Bringing Fire Back   Work To Bring Back Culturally Important Plants in Patches  Plants used for food, medicines and raw materials Based on Eco-Archaeological Work  We have good information about plants recovered   Two Ways:  Patches selected for revitalization  Undertake Integrated Cultural Survey  Reason: Ama Mutsun have a spiritual obligation from Creator to use fire to take care of ancestral land Goals: (1) To document, protect, and steward cultural and natural resources, (2) locate areas that may be suitable for landscape revitalization + seed collection Landscape components: (1) Non-biological = archeological sites, natural springs, viewsheds, salmon spawning habitat (2) biological = vegetation type and ethnobotany Stratified survey approach: focus on broad areas of flat land near water   Include survey to detect ancestral archaeological sites  High density of ethnobotanical and culturally-important vegetation (seed and nut foods, basketry and crafting taxa, hazelnut patches) Grasslands being converted to shrublands   Also locate other important cultural resources  Food plants, medicinal plants     AMLT \u0026ndash; Implemented a Native Nursery and Plant Propagation Program  Nursery used to raise thousands of plants identified in eco-arch work  Tarweeds, California Brome Grass, California Canary Grass, Red maids, yarrow, etc.   After propagated in the greenhouse, they plants are moved outside to field beds where they\u0026rsquo;re then \u0026ldquo;harvested\u0026rdquo; for their seeds Enables us to keep rare plants alive     Raise seedlings in nursery  Some then planted in fields these provide seeds for restoration   We will use these seedlings and seeds in our revitalization efforts In Undertaking This Work Hope To Create Fuel Breaks  Open Areas \u0026ndash; where we can slow down fire, may not stop major fire but provide where calfire can better manage major fire! Hope to Construct Patchy Landscape Mosaic across tribal territory         And if strategically designed and placed, can address three crucial concerns today:  Enhance Quantity And Diversity of Indigenous Plants And Animals Provide Better Food Security For Tribal Members  Provide Places for tribal harvesting of native foods, medicines, Dance regalia, raw materials for making baskets, other crafts   Create Extensive Fuel Breaks  In critical areas on public lands Help minimize risk of major fires      Eco-System Stewardship Work in CA #   Need to Create New Framework for Caring for our Open Spaces - Active Ecosystem Management - Ecological Revitalization - Need a Separate Stewardship Corps  dedicated to this mission - Need to get Tribes and Local Communities Involved! - Marks-Block et al 2021 Reading Discusses why we cannot rely on Fire Suppression people to do ecosystem management   Requires Locally Situated Practices  No one size or one way to manage landscape of California;   Employ Various Treatment Plans  Depends on Objectives and Options Anderson and Barbour 2003 Reading  Managed Wildfires  Simulated Wilderness Management Model   Broadscale Prescribed Burning Indigenous Landscape Stewardship Practices  Cultural Burning Co-Management of Area Simulated Indigenous Management Model       Integration of Industrial-Scale Prescribed Burning with Indigenous Stewardship Practices (Cultural Burning)? Is it possible?  Prior to Treatment \u0026ndash; Eco-Archaeological Surveys Integrated Approach outlined by Alec  Identify Locations of Archaeological Sites; Identify patches of important Ecological Resources: Plants important to tribes for food, medicines, materials, etc.   If enough time, may be possible to do refined Eco-Archaeological study  Soil samples, flotation, recover plant/animal remains and associated tools from archaeological contexts Obtain physical remains of plants and animals that tribes harvested   Areas with Important Arch/Ecological Resources:  May call for additional or different treatments from rest of prescribed burn area   Similar to Cultural Resources Management work in Urban Context Some Cases \u0026ndash; Prescribed Burning OK  But require additional follow-up treatment   Other Cases \u0026ndash; need pre-treatment before  Prescribed Burn: treat differently from rest of prescribed burn area   Ron Goode \u0026ndash; pruning, vegetation removal around site or patch reduce fuel loads Scott \u0026ndash; San Vicente Redwoods  Treat oaks differently than redwoods (different burn treatment)   Marks-Block et al 2019  California Hazelnut Experimentation   Must Deal with Intrusive Species Need to initiate long-term maintenance commitment to the Landscape Costs!      Wildland Urban Interface (WUI) and Camp Fire (11-22) #   Kramer et al. 2019\n  Two types of WUI \u0026ndash; Wildland Urban Interface  Interface WUI - \u0026ldquo;where houses meet\u0026rdquo;: 🏠🏠🏠🌲🌲🌲 Intermix WUI - \u0026ldquo;where houses mingle\u0026rdquo; (with vegetation): 🏠🌲🏠🌲🏠🌲     U.S. WUI was large in 2010:  WUI Houses: 43.4 million = 33% of total  Around 10% of US population Probably has grown in last 10 years   WUI Area: 770,000 km2 = 9.5% of U.S.  Concentrated in West     U.S. WUI grew rapidly from 1990 to 2010:  WUI Houses: 30.8 to 43.4 million \u0026ndash; 41% growth         WUI Area: 581,000 to 770,000 km2 \u0026ndash; 33% growth  Due primarily due to housing growth (wrt change in vegetation, or both)   Destruction in WUI skewed and highly variable  Destruction rates ranged between 0% and 100% (averaged 25% for fires with burned buildings) 70% of all destroyed buildings were in the top 20 most destructive fires    Firewise communities  Communities that have principles for fire Have evacuation / build material standards Are well located, but many are reactive only after wildfires Tends to be run by volunteers \u0026ndash; should aim to try and get more professions / advisors involved         CA is a risky place; it\u0026rsquo;s contained\u0026hellip;  12 of the 20 most destructive fires in US 46% of buildings threatened by fire in US    60% of buildings destroyed by fire in US Fire insurance being cancelled     Not all buildings are rebuilt  In the US, 23% are rebuilt within 5 years In CA, 35% are rebuilt within 5 years In CA, 72% are rebuilt within 20 years (ranging from 13% to 100%)   Big differences between affluent and non-affluent communities \u0026ndash; fire insurance Strong growth within all fire perimeters:  1981 Atlas Creek Fire - 65 homes burned 2017 Atlas Fire - 781 homes burned Extreme growth within Tubbs perimeter: For every home present in 1940, there were 26 homes in 2010 (2600% growth)   Lessons from Tubbs Fire:  Occurred due to eastern winds that traveled from high to low pressure, coastal areas  Going downhill means faster winds thus hotter fires Additionally, winds can speed up as they move through canyons and mountain spaces  Leads to reoccurring burned areas     People likely won\u0026rsquo;t change behavior if incentives are not established Tubbs was highly destructive, and not the norm, but it also was not an anomaly: 6 of the 10 most destructive fires in CA have occurred since 2000 People are continuing to build in areas where fire risk is high and suppression is difficult   Camp Fire \u0026ndash; Butte County  Electrical power line started fire which the wind then carried Two ignitions related to power lines 85 people died, \u0026gt;18,000 homes lost over 149,000 acres Most expensive natural disaster in world in 2018 in terms of insured losses Mixture of ponderosa pine forests, woodlands, shrublands  2008 BTU Lighting Complex burned before   Worst loss of life in a California wildfire  Paradise had practiced evacuating Thought was one of most prepared cities Position of Paradise very hazardous with one road in and out Needs: Better community preparation and forest/woodland management, electrical infrastructure improvements     Recommendations:  Don\u0026rsquo;t reduce regulations to speed rebuilding Mandate good building codes Provide resources to people beyond a few years \u0026ndash; only 2/3 have rebuilt by 5 years Despite regulations on new building, the best incentive could be from insurance More engagement of public to prepare   Australia a Leader in WUI: They have done a much better job of engaging people who live in the WUI    Stephens et al. 2009, Gill and Stephens 2009\n  In U.S. mostly done by volunteer groups, better with UC extension employees Prepare, stay, defend, or leave early \u0026ndash; Australia  Catastrophic fire danger level with climate change   Updated Australia policy after 2009 Black Saturday Fires \u0026ndash; 174 people killed Updated Australia Policy  PREPARE your family, home or business \u0026ndash; know your risk from bushfire and have a survival plan ACT on the fire danger ratings - put your preparations into action, do not wait to get message on your phone or tablet SURVIVE by monitoring conditions if a fire starts Know bushfire warning alert levels and what you will do if you are caught in a fire    Summary #   Exposure of human communities to fire in California is huge Communities need to prepare better for fire \u0026ndash; UC Cooperative Extension program Forest and woodland management could improve conditions \u0026ndash; TEK can assist Chaparral less options Electrical infrastructure needs improvement CA can learn from Australian experience Governor Newson\u0026rsquo;s and California\u0026rsquo;s next move?  Class Summary #   As an AC class, a major objective of this course is to examine diverse populations relationship to fire in California  Today, while most of us fear wildland fires, that has not always been the case;   Defining fire regimes for local regions of CA:  fire frequency, fire season, fire area, fire severity, interaction with other factors; Scott’s Discussions of fire regimes for different CA ecosystems anthropogenic and natural fire regimes;   Long-Term use of fire by Human populations:  Important component of human evolution Constructive use of fire over hundreds of thousands of years for cooking, warmth, ceremonial use, etc. people bring fire with them when they colonized new landscapes and places across the globe, including California probably 13,000-15,000 years ago;   Historical Fire Ecology:  How we study the history of past fire regimes: Coring lakes to obtain charcoal, pollen, phytoliths Coring trees Wedges from trees for fire scar analysis Other lines of evidence employed: ethnohistorical accounts, ethnography, Native histories (oral traditions) Eco-archaeology (flotation to recover plant animal remains from archaeological sites)   Cultural Burning in California  California Indians have lived here more than 13,000 years Traditionally referred to as “Hunter-Gatherers” in anthropology literature,” but best to Refer to Them as “Resource Managers or Landscape Stewards”; Reasons for anthropogenic fires (control pests, remove detritus, open pathways, hunting, habitat revitalization to facilitate growth of tribal foods, medicines, dance regalia, raw materials) Regular, small-scale burning to enhance productivity, diversity, and sustainability of habitats – produce patchy mosaics Holocene times – California characterized byanthropogenic landscape, not “Pristine Wilderness” Controversy about scale and timing of anthropogenic/cultural burning: Central California – evidence for creation of coastal prairies by people 800-1400 CE (Rob Cuthrell, Valentin Lopez – eco-arch Research);   Transformations with Colonialism:  Significant impacts of Spanish, Russian, Mexican, and American (settler) colonization: altered fire regimes environmental degradation genocide of Native peoples Loss of land few reservations granted – mostly very small in size many tribes not federally recognized detrimental impacts of fire exclusion and later fire suppression Termination of Indigenous landscape stewardship practices on any major scale, but timing varied across state depending on history of colonization Some loss of Traditional Ecological Knowledge TEK (Val Lopez);   The Advent of Fire Suppression:   Debate about “Light Burning” in 1880s-early 1900s  use of fire by sheep herders and by timber companies establishment of Forest Reserves, USFS (1905) influence of Gifford Pinchot (trained in Europe as discussed by Jameson Karns) Light Burning loses out to total fire suppression influence of 1910 Great Idaho Fire and other factors discussed by Scott fire suppression really develops in WWII and Post-war years Smokey the Bear, etc.    Impact of Fire Suppression on local Ecosystems:  Fire suppression methods very effective: 98-99% of fires out at less than 5 acres in size Major implications for taking fire out of ecosystem: increase fuel loads (ladder, surface, crown fuels), increase density of vegetation, fewer open areas, vegetation that is more homogeneous, encroachment of shrubs and trees, loss of grasslands, meadows, spring (Scott, Brandon Collins)    Post-Suppression Times:  Importance of Leopold Report in 1963 for National Parks and otherfederal and state agencies USFS, NPS and others experiment with prescribed burning, managed fires, and various fire proxy methods, including manual thinning, mechanized removal of vegetation, etc. (Jim Agee, Jan van Wagtendonk) In regard to prescribed burning, California nowhere near what Florida does. Much more needs to be done here!   Tribal Revitalization in California - important concern of Tribes: Health of Environment, work to bring back Indigenous Stewardship Practices - ecological restoration of Tribal Lands - push to bring Cultural Burningand other stewardship practices back to the land: Five Case studies discussed: Timbisha Shoshone (Death Valley) - Chumash (Santa Barbara) - North Fork Mono Tribe (southern Sierra Nevada Mts.) - Karuk And Yurok Tribes (Northwest California) - Amah Mutsun Tribal Band (Central Coast of California); The Future: Rethinking how we manage open spaces, public lands, wildland/urban Interface in California:  Use of Managed Fires where possible (Yosemite Case Study) Need much more prescribed burning to reduce fuel loads, develop fuel breaks, forest restoration, etc. Also employ manual thinning and mechanized vegetation removal when burning not a viable option; Need to bring back Indigenous landscape management practices, including strategic use of Cultural Burning (more nuanced treatment of specific resources)  Create partnerships with Tribes and Federal and State Agencies Can we combine prescribed burning and cultural Burning in some areas of California? We think so and are working on it\u0026hellip;   Proposal: Establish a Stewardship Corps for California that is dedicated to active ecosystem management  Implement programs for training and certifying prescribed burn managers (like Florida) Fund stewardship corps work throughout year (prescribed/cultural burns in winter, spring, late fall) Create local/regional stewardship districts where corps undertakes regular maintenance of the land (like painting the Golden Gate Bridge) \u0026ndash; tailored to specific local ecosystems Composition of stewardship corps would include people from local tribes and members of local communities – create career Opportunities;   New policies and regulations: fire insurance, zoning issues (try to decrease further development in Wildland/Urban Interface?)  Mandate good building codes to fire-proof homes and surroundings – especially after major fires improve electrical infrastructure of California advocate for more community participation to prepare for fires increase funding for UC Extension to work with communities to better prepare for fires;      "},{"id":10,"href":"/asamst-20a/","title":"ASAMST 20A","section":"Docs","content":"Week 1 (January 18 \u0026amp; 20): Introduction to the course. History, Memory, and Racialization #  Reading: Tataki, Strangers from a Different Shore, Preface and Ch. 1: “From a Different Shore.”\nWhat is Asian American Studies?\n Panethnicity  \u0026ldquo;pan\u0026rdquo; - a conglomeration \u0026ldquo;ethnicity\u0026rdquo; - belonging to a social group Panethnic identity example: Asian American   Panethnicity Cultural Literacy  One\u0026rsquo;s competency about their implicit biases    Reading:\n Angel Island versus Ellis Island  Angel Island was the west coast immigration entry point for people coming from the west (mainly Asian migration) Ellis Island was the entry point for many immigrrants from the east (mainly European)   \u0026ldquo;Multiculuralism was a find of fear and optimism around how we are a very mixed country and what binds us together is this appreciation of different ethnic backgrounds, but we also assimilate under some cultural practice/viewpoint\u0026rdquo; - Michael Chang\n   Ron Tataki on Multiculturalism (side note - \u0026ldquo;Reasonable minds may differ\u0026rdquo;)\n What is \u0026ldquo;epistemology\u0026rdquo;: Theory of knowledge. Asks the question:  \u0026ldquo;How do you know what you know?\u0026rdquo;\n   Race is socially constructed\n Through history socio-econmic, labor, and capital conflicts Any type of social norm is dependent upon contestation between people in the majority and minority. The power is asymmetric: Majority \u0026gt; Minority.  Cultual Literacy\n In studying Asian American history we are learning to understand how we have come to understand American history.  What are the source we have been taught? What are the viewpoints presented in the curriculum we have been taught as history? How do we believe in cultural literacy, in that we are literate in a diverse range of viewpoints representing the true multicultural background of the United States?    Arthur Schlesinger\u0026rsquo;s The Disuniting of America: Reflections on a Multicultural Country\n A very different view of multiculturalism:  The concern of a \u0026ldquo;breaking apart\u0026rdquo; or \u0026lsquo;Balkanization\u0026rsquo; due to conflicts Association with multiculturalism with ethnic conflict Reassertion of national unity around assimilation paradigm The concern of the \u0026ldquo;race problem.\u0026rdquo; The \u0026ldquo;American Creed\u0026rdquo; Schlesinger on \u0026ldquo;disuniting\u0026rdquo;    Two different viewpoints: Ron Tataki and Arthur Schlesinger\nDiscussion Questions:\n Takaki’s formulation of multiculturalism aligns with the concept of diversity, equity and inclusion of the 2000’s.  How is Diversity related to multiculturalism? What does the term \u0026ldquo;American Exceptionalism\u0026rdquo; mean to you?  Schlesinger was a proponent of “American Exceptionalism” the idea that America has provided safe harbor to many different groups of people. And that here in America, class, and lineage are not important.   How do Asian Americans fit into these models of diversity, multiculturalism and \u0026ldquo;American Exceptionalism\u0026rdquo;    Asian Americans fastest-growing electorate\n A naturalized citizen = someone who immigrated to the U.S. and gained citizenship   “More than 11 million will be able to vote this year, making up nearly 5% of the nation’s eligible voters (for this analysis, U.S. citizens ages 18 and older). They are also the only major racial or ethnic group in which naturalized citizens – rather than the U.S. born – make up a majority of eligible voters, according to a Pew Research Center analysis of Census Bureau data.”\n  Many Asian Americans have limited English proficiency  image    Aliens Ineligible for Citizenship and the 14th Amendment\n 1790 Immigrration and Nationality Act (INA): Asian Americans were restricted from naturalized citizenship from 1790 into the 1940s and until the 1950\u0026rsquo;s depending on Asian ethnic groups. At the same time the 14th Amendment was passed in 1867 as an important legal tool against discrimination by state and local governments.  Included an important clause stating that states cannot treat people differently on the basis of race (now it includes gender)  \u0026ldquo;Simply stated, all persons must be treated equally without regard to their race, color, or national origin.\u0026rdquo;\n    Legislation in 1965: Effectively ended the immigration restrictions and quotas against many Asian immigrants  As you move through the readings\u0026hellip;\n Consider what \u0026ldquo;power\u0026rdquo;, \u0026ldquo;agency\u0026rdquo; and \u0026ldquo;contestation\u0026rdquo; mean in the context of the history that you reading. Those who are constructed in history as \u0026ldquo;minority\u0026rdquo; also have agency while those with majority power must contend with the contestationo of majority control. How did the process occur in the U.S.? What are the legal and socio-cultural institutions and practices that result in a given standard of a moment in time, and in change?  Racial Formation\n Michael Omi \u0026amp; Howard Winant, Introduction, Racial Formation in the United States. 2014. HO  Dynamic-constantly in flux Reproduction of political interests  Aligns with the notion that within a diverse society, there will be multiple stakeholders (different groups and persons bringing forth different interests). The social construction around access to property and citizenship.   Race is socially constructed: came out from social contestation, geopolitics, etc.   Racial formation theory explains the fluidity of racial categories and the interest and forces that shape them. These pieces provide historical examples of how “white” identity came to be legally constructed through court cases and through the socio-economic forces supporting these legal outcomes.  Do the courts drive the outcome? Legal institions? 1690: the brewing slave trade 1790: contestation around what “white” meant. Before the slave trade was active, the primary source of labor was young Irish women. Came as indentured servants (a form of labor in which a person is contracted to work without salary for a specific number of years). Example of instability around what being “white” meant.   Sociologists Omi and Winant describe the fluidity of racial constructions over time dependent on political interests and socio-economic (incomplete) What is Omi and Winant\u0026rsquo;s concept of \u0026ldquo;common sense\u0026rdquo;?  “Common sense” derives from Italian philosopher and political economist Antonio Gramsci’s theories on asymmetry in political power and the interest conflicts that may emerge as a result.  I.e. today’s “Common sense” surrounding gender is that gender is a social construct as opposed to one’s sex. Gramsci wrote about hegemony as in “how does power operate when there is one party that maintains much of the mechanisms of culture and state?”  You have agency. A consensus that results from an agreement (not so much voluntary, but through negotiation)        What is a \u0026ldquo;Race\u0026rdquo; versus an \u0026ldquo;Ethnicity\u0026rdquo;? Consider the challenge of formally categorizing groups:\n The U.S. Census Bureau uses the term \u0026ldquo;Hispanis\u0026rdquo;  Who are \u0026ldquo;Hispanics\u0026rdquo;? Who ae \u0026ldquo;Latinos\u0026rdquo;? (incomplete)    Taki referred to the popular perception of Asian Americans as:\n Model Minority: A trope that gained traction in the 1960s that stresses the prototypical Asian’s high achievement in socioeconomic status and focuses on their culture to explain their “success”; denies racism and other hardships that are experienced by Asian Americans; comparison between one minority group and another Perpetual Foreigner: stereotype in which naturalized and even native-born citizens are perceived by some members of the majority as foreign because they belong to a minority ethnic or racial group.  Twin pillars of how Asian Americans are constructed\n How do these sterotypes and categories affect cultural and legal outcomes for Asian Americans?\n The Social Construction of Race\n The idea that race is socially constructed emerged as a response to the view that race is based on biology  What does it mean to say that race is not based on biology? Does it mean that there are no biological or genetic bases to difference? What is the difference between (incomplete) and race? Blood quantum: the idea that if you have any drop of African American ancestry, in that jurisdiction/state, you are legally classified as black  For whites to maintain racial purity, property, power, and perpetuated the classification/segregation of people on the basis of race      Class Question: How has federal jurisdiction driven civil rights protections from the time of early Asian immigrants to the U.S. to the 2020s?\n For example, the Interstate Commerce Act addressed the problem of railroad monopolies by setting guidelines for how the railroads could do business.  Insiders and Outsiders\n As cited in footnote 4 of the U.S. Supreme Court\u0026rsquo;s Carolene Products the Tainted Milk, case:   “prejudice directed against discrete and insular minorities may call for “more searching judicial inquiry.”\n  Ensured that former slave-holding states would abide by this 14th amendment that said that African Americans had to have citizenship rights Created a legal authority when the former slave-holding states tried to reinstitute some form of slavery  Racial formation construction? (incomplete)  Sojourners vs. Immigrants\n Labor and capital interests drove demand for cheap labor during U.S. industrialization  Push and Pull\n Geopolitical political economic factors  Alienation of Migration Guangdong Chinese Women sang\n Dear husband, ever since you sojourned.\nIn a foreign land.\nI\u0026rsquo;ve lost interest in all matters.\nAll day long, I stay inside the bedroom,\nMy brows knitted; ten thousand\nThoughts bring me endless remorse, in\nGrief, in silence.\nI cannot fall asleep on my lonely pillow.\n 1882 Chinese Exclusion Act\n Racialized labor conflict and competition The main landmark that stems from aliens ineligible for citizenship  Agency, Resistance and Contestation\n Yick Wo v. Hopkins, USC 1996  Provides the basis for the important legal evidence standard of \u0026ldquo;disparate impact\u0026rdquo; Supreme Court said that San Francisco zoning law is in violation of the 14th Amendment    120,000 Americans of Japanese descent on the Western U.S. seaboard were sent to internment camps. 75% of internees were American citizens by birth.\n"},{"id":11,"href":"/math-53/12/","title":"12: Vectors \u0026 Geometry of Space","section":"Math 53","content":"12.1 3D Coordinate Systems #   Right hand rule: Index point to .$x$, thumb to .$z$, and write through .$y$ If you have point .$P(a,b,c)$ and drop a perpendicular dot on the .$xy$-plane at .$a,b,0$, you now have a projection of .$P$ onto the .$xy$-plane The distance .$|P_1 P_2|$ between two points .$P_1(x_1, y_1, z_1)$ and .$P_2(x_2, y_2, z_2)$ is $$|P_1 P_2| = \\sqrt{(x_2-x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2}$$ We can define the equation for a sphere with a center at .$C(h,k,l)$ and radius .$r$ as $$(x-h)^2 + (y-k)^2 + (z-l)^2 = r^2$$  12.2 Vectors #   Written as .$\\overrightarrow{AB}$ Has initial point .$A$ at the tail and the a terminal point .$B$ at the tip  If the initial point .$A$ is at .$(x_1, y_1, z_1)$ and terminal point .$B$ is at .$(x_2, y_2, z_2)$, then we can write .$\\overrightarrow{AB} = \\langle x_2 - x_1, y_2 - y_1, z_2 - z_1\\rangle$   Vectors with the same length/magnitude are called equivalent or equal, despite not necessarily having the same initial/termination points Vector addition (order doesn\u0026rsquo;t matter) $$ \\overrightarrow{AC} = \\overrightarrow{AB} + \\overrightarrow{BC} = \\overrightarrow{BC} + \\overrightarrow{AB}$$ $$ \\vec u - \\vec v = \\vec u + (- \\vec v)$$ $$ \\vec a + (\\vec b + \\vec c) = (\\vec a + \\vec b) + \\vec c$$ Vector multiplication  Given scalar .$c$ and vector .$\\vec v$, .$c\\cdot\\vec v$ is like .$\\vec v$ but with length changed by a factor of .$\\Vert c\\Vert$ If .$c\u0026lt;0$, then the vector is flipped around $$c\\cdot\\vec v = \\langle cv_x, cv_y, cv_z\\rangle$$   Magnitude for .$\\vec a = \\langle a_x, a_y, a_z \\rangle$:  $$ \\Vert \\vec a \\Vert = \\sqrt{a_x^2 + a_y^2 + a_z^3}$$   Unit vector  Has length of one If .$\\vec a \\neq 0$ then the unit vector .$\\vec u$ in the same direction as .$\\vec a$ is:  $$\\vec u = \\frac{\\vec a}{\\Vert \\vec a \\Vert} = \\frac{1}{\\Vert \\vec a \\Vert} \\vec a$$ Notice that .$\\frac{1}{\\Vert \\vec a \\Vert}$ is a scalar      12.3 Dot Product #   The dot product measures the extent which two vectors are parallel to one another  Two vectors are perpendicular/orthogonal .$\\perp$ (.$90^\\circ$ from one another) iff the dot product is 0   .$\\vec a \\cdot \\vec b$ is the length of .$\\vec a$ times the scalar projection of .$\\vec b$ onto .$\\vec a$ Notice that the dot product gives a scalar $$\\langle a_1, a_2, a_3 \\rangle \\cdot \\langle b_1, b_2, b_3 \\rangle = a_1b_1 + a_2b_2 + a_3b_3$$ $$\\vec a \\cdot (\\vec b + \\vec c) = \\vec a \\cdot \\vec b + \\vec a\\cdot \\vec c$$ $$ \\vec a \\cdot \\vec a = \\Vert \\vec a \\Vert ^2$$ $$ \\vec a \\cdot \\vec b = \\vec b \\cdot \\vec a $$ $$ (c \\vec a) \\cdot \\vec b = c (\\vec a \\cdot \\vec b) = \\vec a \\cdot (c \\vec b)$$  $$\\vec a \\cdot \\vec b = \\Vert\\vec a\\Vert\\ \\Vert\\vec b\\Vert \\cos \\theta$$ $$\\Vert\\vec a - \\vec b \\Vert^2 = \\Vert\\vec a\\Vert^2+\\Vert\\vec b\\Vert^2 - 2\\Vert\\vec a\\Vert \\Vert\\vec b\\Vert \\cos\\theta\\ $$ $$\u0026hellip; = \\Vert\\vec a\\Vert\\ \\Vert\\vec b\\Vert \\cos \\theta$$ $$\\cos\\theta = \\frac{\\vec a \\cdot \\vec b}{\\Vert\\vec a\\Vert\\ \\Vert\\vec b\\Vert}$$   $$\\cos \\theta = \\frac{\\vec a}{\\Vert \\vec a \\Vert} \\cdot \\frac{\\vec b}{\\Vert \\vec b \\Vert} \\Longrightarrow \\cos^{-1}\\bigg(\\frac{\\vec a}{\\Vert \\vec a \\Vert} \\cdot \\frac{\\vec b}{\\Vert \\vec b \\Vert} \\bigg) = \\theta $$   Direction Vectors #   The direction angles of a nonzero vector .$\\vec a$ are the .$\\alpha, \\beta, \\gamma$ that a makes with the positive .$x,y,z$-axes respectively $$\\cos\\alpha = \\frac{\\vec a \\cdot \\vec i}{\\Vert \\vec a \\Vert \\Vert \\vec i \\Vert} = \\frac{a_1}{\\Vert \\vec a \\Vert}$$ $$\\vec a = \\Vert \\vec a \\Vert \\langle \\cos \\alpha, \\cos \\beta, \\cos \\gamma \\rangle$$  Projections #   Scalar projection of .$\\vec b$ onto .$\\vec a$: $$\\text{comp}_\\vec a\\vec b = \\frac{\\vec a\\cdot\\vec b}{\\Vert\\vec a\\Vert}$$ Vector projection of .$\\vec b$ onto .$\\vec a$: $$\\text{proj}_\\vec a\\vec b = \\bigg(\\frac{\\vec a\\cdot\\vec b}{\\Vert\\vec a\\Vert}\\bigg)\\frac{\\vec a}{\\Vert\\vec a\\Vert} = \\frac{\\vec a\\cdot\\vec b}{\\Vert\\vec a\\Vert^2}\\vec a$$   12.4 Cross Product #   The cross product measures how orthogonal two vectors are  Therefore, .$(\\vec a \\times \\vec b) \\cdot \\vec b = 0$ because measures how similar (close to .$0^\\circ$) two vectors are and cross product outputs a vector orthogonal (.$90^\\circ$ to both .$\\vec a, \\vec b$) Two nonzero vectors are only parallel iff their cross product is zero The magnitude is also the area of a parallelogram formed by the two vectors  We can find the volume of the 3D parallelogram formed by three vectors with the following equation: $$\\vec a \\cdot (\\vec b \\times \\vec c) = (\\vec a \\times \\vec b) \\cdot \\vec c$$  Realize that if the resulting area is .$0$, then all of the points exist on the same plane     Notice that the cross product gives a vector that is orthogonal to both original vectors  Direction is determined with the right-hand rule   We can also calculate the determinant with the unit vectors .$\\langle \\hat i, \\hat j, \\hat k \\rangle$to find the cross product $$\\langle a_1, a_2, a_3 \\rangle \\times \\langle b_1, b_2, b_3 \\rangle = \\langle a_2b_3 - a_3 b_2, -(a1_b3 - a_3 b_1), a_1b_2 - a_2 b_1 \\rangle$$ $$\\vec a \\times \\vec b = \\Vert \\vec a \\Vert \\Vert \\vec b \\Vert \\sin\\theta$$ $$(\\vec a \\times \\vec b) \\times \\vec c \\neq \\vec a \\times (\\vec b \\times \\vec c) \\Longrightarrow \\vec a \\times (\\vec b \\times \\vec c) = (\\vec a \\cdot \\vec c) \\vec b - (\\vec a \\cdot \\vec b ) \\vec c$$ $$\\vec a \\times \\vec b \\neq \\vec b \\times \\vec b \\Longrightarrow \\vec a \\times \\vec b = - \\vec b \\times \\vec a$$ $$(c \\vec a) \\times \\vec b = c(\\vec a \\times \\vec b) = \\vec a \\times (c \\vec b)$$  $$\\vec a \\times (\\vec b + \\vec c) = \\vec a \\times \\vec b + \\vec a \\times \\vec c$$ $$(\\vec a + \\vec b) \\times \\vec c = \\vec a \\times \\vec c + \\vec b \\times \\vec c$$   $$\\Vert \\vec a \\times \\vec b \\Vert ^2 = \\Vert \\vec a \\Vert^2 \\Vert \\vec b \\Vert^2 - (\\vec a \\cdot \\vec b)^2 = \\Vert \\vec a \\Vert^2 \\Vert \\vec b \\Vert^2 \\sin^2 \\theta$$ $$\u0026hellip; \\Longrightarrow \\Vert \\vec a \\times \\vec b \\Vert \\Vert \\vec a \\Vert \\Vert \\vec b \\Vert \\sin \\theta$$  12.5 Equation of Lines and Planes #  Line #   If given a point .$P_0 (x_0, y_0, z_0)$ and a vector .$\\vec v = \\langle a,b,c \\rangle$ that passes through said point (parallel), we can write a line equation as: $$\\langle x, y, z \\rangle = P_0 + t \\vec v = \\langle x_0 + ta, y_0 +tb, z_0 + tc \\rangle;\\ \\ t \\in \\mathbb{R}$$ We can then isolate .$t$ to find the symmetric equation of the line $$ t = \\frac{x-x_0}{a} = \\frac{y-y_0}{b} = \\frac{z-z_0}{c} $$ And we can extrapolate this to write an equation we can use to verify if two points are on a line: $$ t = \\frac{x-x_0}{x_1-x_0} = \\frac{y-y_0}{y_1-y_0} = \\frac{z-z_0}{z_1-z_0} $$  Note: If we have no change in an axis (such as .$x$), then .$x_1-x_0$ is zero. Therefore, we can write .$x = x_0$ (because we know it never changes) and the other relations for .$y$ and .$z$ still work   We can also write our original equation in vector form as $$\\vec r(t) = \\vec r_0 + t\\vec v$$ Which we can use to write a specific line between point .$A$ and .$B$ from .$t \\in [0,1]$ as $$\\overrightarrow{AB} = \\langle x_1 - x_0, y_1 - y_0, z_1 - z_0 \\rangle$$ $$r(t) = \\vec A(1-t) + \\vec B(t)$$ Two vectors are equal iff corresponding components are equal 3D Lines can be parallel (same direction vector), intersect at one point (.$r_1 = r_2\\ @\\ t_1, t_2$), or skew (not intersecting nor parallel \u0026ndash; not possible in 2D)  Planes #   Planes need a point and direction  Point .$P_0 (x_0, y_0, z_0)$ is trivial; a plane is a set of various points Direction is described by the normal vector .$\\vec n = \\langle a,b,c \\rangle$; only one normal unit vector per plane  Given three points .$P_1, P_2, P_3$ on the plane, we can write two vectors .$\\vec a = \\overrightarrow{P_1 P_2}, \\vec b = \\overrightarrow{P_1, P_3}$ as we can find the normal vector as .$\\vec n = \\vec a \\times \\vec b$     Knowing this, we can write a vector equation: $$ \\vec n \\cdot \\overrightarrow{P_0 P} = 0$$ $$ \\vec n \\cdot (\\vec r - \\vec r_0) = 0$$ This can also be parameterized as both the scalar and linear equation respectively: $$a(x-x_0) + b(y-y_0) + c(z-z_0) = 0$$ $$ax + yz + cz + d = 0$$ Planes are parallel if their normal vectors are parallel Otherwise, they intersect and form a straight line  Common Questions #   Intersection point(s) of plane and parametric curve  Given parametric curve .$C = \\langle \\alpha + a\\cdot t, \\beta + b\\cdot t, \\gamma + c \\cdot t \\rangle$ and plane equation .$P = x + y + z + d = 0$ \u0026hellip;   Plug in each component of .$C$ as .$x,y,z$ in the .$P$ equation Solve for .$t$(s), then plug (it/them) into the prior equation to get intersection point(s)   Angle between planes  Given two planes with .$\\vec n_1, \\vec n_2$ respectively   Use .$\\theta = \\cos^{-1}\\Big(\\frac{\\vec n_1 \\cdot \\vec n_2}{\\Vert \\vec n_1 \\Vert \\Vert \\vec n_2 \\Vert}\\Big)$ to find .$\\theta$   Angle between parametric lines that intercept at point .$P_3$  Given parametric equations .$L_1 = P_1 + t\\vec v_1$ and .$L_2 = P_2 + s\\vec v_2$   Find the .$t_3$ and .$s_3$ for when .$L_1 = P_3$ and .$L_2 = P_3$ (point of intersection) Use .$\\theta = \\cos^{-1}\\Big(\\frac{\\vec v_1'(t_3) \\cdot \\vec v_2'(s_3)}{\\Vert \\vec v_1'(t_3) \\Vert \\Vert \\vec v_2'(s_3) \\Vert}\\Big)$ to find .$\\theta$   Intersection of two lines:  .$L_1: \\langle x_1, y_1, z_1 \\rangle + t \\cdot \\langle a_1, b_1, c_1\\rangle; L_2: \\langle x_2, y_2, z_2 \\rangle + s \\cdot \\langle a_2, b_2, c_2 \\rangle;$ First, check if they are parallel by checking if the directions of the two lines are scalar multiples of one another. Second, check if they intersect by setting the two parametric equations equal to one another:  .$x_1 + t a_1 = x_2 + s a_2; y_1 + t b_1 = y_2 + s b_2; z_1 + t c_1 = z_2 + s c_2$ If an equation exists (that is, there is a valid .$t$ and .$s$) then they intersect at .$L_1(t)$ or .$L_2(s)$     Intersection line .$L$ of two planes  Set one of the 3D variables to zero (e.x. .$z = 0$) to find where the two planes intersect the remaining plane (in this case the .$z$ plane) We find the intersection point .$P (\\alpha, \\beta, 0)$ by solving when our plane equations in the prior equation are equal Since the line .$L$ is orthogonal to both planes' normal vectors, our direction vector is .$\\vec v = n_1 \\times n_2 = \\langle a,b,c \\rangle$ We can then plug in everything into the symmetric equation: .$\\frac{x-\\alpha}{a} = \\frac{y-\\beta}{b} = \\frac{z-0}{c}$   Distance from point to plane  Given point .$P_1(x_1, y_1, z_1)$ and plane .$ax+by+cz+d = 0$ $$D = \\Vert \\text{comp}_{\\vec n}{\\vec b} \\Vert = \\frac{\\vert ax_1 + by_1 + cz_1 +d\\vert}{\\sqrt{a^2 + b^2 + c^2}}$$   Distance from skew line to skew line  Given .$L_1 = \\langle x_1, y_1, z_1 \\rangle + t \\vec v_1$ and .$L_2 = \u0026hellip;$   Find the plane containing .$L_2$ that is parallel to .$L_1$. .$P_3 = \\langle x- x_2, y - y_2, z - z_2 \\rangle \\cdot (v_1 \\times v_2)$ Find the .$D$istance from .$x_1, y_1, z_1$ on .$L_1$ to the plane .$P_3$ above $$D = \\frac{\\vert a_3 x_1 + b_3 y_1 + c_3 z_1 +d\\vert}{\\sqrt{a_3^2 + b_3^2 + c_3^2}}$$   Distance from point to line  Given line .$L = \\langle x_0, y_0, z_0 \\rangle + \\langle a, b, c \\rangle$ and point .$P = \\langle P_x, P_y, P_z \\rangle$   Write a distance equation as .$D^2 = ((x_0 + ta) - P_x)^2 + ((y_0 + tb) - P_y)^2 + ((z_0 + tc) - P_z)^2$ Find the minimum value of .$t$ and plug in into the equation above and find .$D$ (but not .$D^2$!)    12.6 Cylinders and Quadratic Surfaces #  Traces #    Cross sections of a surface found by taking a three-variable equation and setting one of the equations variables equal to a constant. Help us visualize 3D curves by thinking about them from different axis $$z = \\frac{x^2}{4} + \\frac{y^2}{9} \\Longrightarrow k = \\frac{x^2}{4} + \\frac{y^2}{9}$$  $$\u0026hellip; \\Longrightarrow z = \\frac{x^2}{4} + \\frac{k^2}{9}$$    In the left example, for every .$z$ value we have a ellipse In the right example, we have a parabola for every .$y$ value    Cylinder #   A cylinder is a surface that consists of all rulings that at parallel to a given line that passes through a given plane curve Two variable equation in 3D space  E.x. .$y =\\sin x, z = x^2$    Quadratic Surfaces #   A quadric surface is the graph of a second-degree equation with three variables Two standard forms (when centered about origin): $$Ax^2 + By^2 + Cz^2 + J = 0$$ $$Ax^2 + By^2 + Iz = 0$$   "},{"id":12,"href":"/math-53/13/","title":"13: Vector Functions","section":"Math 53","content":"13.1 Vector Functions and Space Curves #  Vector Functions #   We can write a vector function as $$\\vec r(t) = \\langle f(t), g(t), h(t) \\rangle = f(t) \\hat i + g(t) \\hat j + h(t) \\hat k$$ The domain of .$\\vec r$ consists of all values of .$t$ for which each of the terms are defined The limit of a vector function is $$\\lim_{t\\to a} \\vec r(t) = \\big\\langle \\lim_{t\\to a} f(t), \\lim_{t\\to a} g(t), \\lim_{t\\to a} h(t) \\big\\rangle$$ .$\\vec r$ is continuous at time .$a$ if .$\\lim_{t\\to a} \\vec r(t) = \\vec r(a)$  Space Curve #   The set .$C$ of all points defined by a vector function .$\\vec r$ over interval .$I$ is called a space curve. Think of .$C$ as being traced out by a moving particle whose position follows .$\\vec r$ Space curves are parametrized by a vector function but isn\u0026rsquo;t necessarily that vector function!  E.x. .$\\vec r(t) \\langle \\cos t, \\sin t, t \\rangle \\neq \\vec q(t) = \\langle \\cos 3t, \\sin 3t, 3t \\rangle$ Space curves exist on the same point, but don\u0026rsquo;t grow at the same rate    13.2 Derivatives and Integrals of Vector Functions #  Derivatives #  $$\\frac{d\\vec r}{dt} = \\vec r'(t) = \\lim_{h \\to 0} \\frac{\\vec r(t+h) - r(t)}{h}$$ $$\u0026hellip; = \\big\\langle f'(t), g'(t), h'(t) \\big\\rangle$$\n Note that the last equation only works if each component is differentiable The direction is the tangent line and the magnitude is the rate at which the particle is moving at that point If we just want the tangent line, we can write the unit tangent vector: $$\\vec T(t) = \\frac{\\vec r'(t)}{\\Vert \\vec r ' (t) \\Vert}$$ Differentiation rules (notice .$f(t)$ is a scalar function) $$ \\frac{d}{dt} \\big[f(t) \\vec u(t) \\big] = f'(t) \\vec u(t) + f(t) \\vec u'(t)$$ $$ \\frac{d}{dt}\\big[\\vec u(t) \\cdot \\vec v(t)\\big] = \\vec u'(t) \\cdot \\vec v(t) + \\vec u(t) \\cdot \\vec v'(t) $$ $$ \\frac{d}{dt} \\big[\\vec u(t) \\times \\vec v(t)\\big] = \\vec u' (t) \\times \\vec v(t) + \\vec u(t) + \\vec v'(t)$$ $$ \\frac{d}{dt} \\big[ \\vec u(f(t)) \\big] = f'(t) \\vec u' (f(t))$$  Integrals #   Let .$\\vec r (t) = \\langle f(t), g(t), h(t) \\rangle$, then $$\\int_a^b \\vec r(t)\\ dt = \\bigg\\langle \\int_a^b f(t)\\ dt, \\int_a^b g(t) \\ dt, \\int_a^b h(t)\\ dt \\bigg\\rangle$$ Fundamental theorem: If .$\\vec R(t)$ is an anti-derivative of .$\\vec r(t)$, (i.e. .$\\vec R'(t) = \\vec r(t)$), then $$ \\int_a^b \\vec r(t) \\ dt = \\Big[\\vec R(t)\\Big]_a^b = \\vec R(b) - \\vec R(a)$$  "},{"id":13,"href":"/math-53/14/","title":"14: Partial Derivatives","section":"Math 53","content":"14.1 Functions of Several Variables #   In the real world, most things don\u0026rsquo;t depend on a single variable  Temperature may depend on the .$(x,y)$ (latitude/longitude) position Volume of a cylinder depends on radius .$r$ and height .$h$: .$V =\\pi r^2 h$   Formal Definition: A function .$f$ of two variables is a rule that assigns to each ordered pair of real numbers .$(x,y)$ in a set .$D$ a unique real number denoted by .$f(x,y)$. The set .$D$ is the domain of .$f$ and its range is the set of values that .$f$ takes on, that is, .$\\{f(x,y)\\ |\\ (x,y) \\in D \\}$.  E.x. for .$f(x,y) = \\frac{\\sqrt{x+y+1}}{x-1}$, the domain is .$D = \\{(x,y)\\ |\\ x + y + 1 \\geq 0, x \\neq 1\\}$ which can be graphed with a solid line following .$y =-x-1$ with a dotted line at .$x = 1$ E.x. for .$f(x,y) = x\\ln(y^2-x)$, the domain is .$D =\\{(x,y)\\ |\\ x\u0026lt;y^2\\}$. This can be graphed with a dotted line following the curve .$x = y^2$   For the equation .$z = f(x,y)$, .$x,y$ are the independent variables and .$z$ is the dependent variable \u0026ndash; similar to single variable equations We can visualize functions of two variables (i.e .$f(x,y)$) by graphing them in 3D as .$(x,y,f(x,y))$  We can then write level curves for the function by setting .$f(x,y) = k$ for some .$k$onstant in the range of .$f$. This will result in a graph similar to a Topographic map Level Curve: The level curves of a function .$f$ of two variables are the curves with equations .$f(x,y) = k$, where .$k$ is a constant (in the range of .$f$).      14.2 Limits and Continuity #  Limits #   Vector Limit: Let .$f$ be a function of two variables whose domain .$D$ includes points arbitrarily close to .$(a, b)$. Then we say that the limit of .$f(x, y)$ as .$(x, y)$ approaches .$a, b.$ is .$L$ and we write $$\\lim_{(x,y)\\to(a,b)} f(x,y) = L$$ if for every number .$\\varepsilon \u0026lt; 0$ there is a corresponding number .$\\delta \u0026lt; 0$ such that if .$(x, y) \\in D$ and .$0 \u0026lt; \\sqrt{(x-a)^2 + (y-b)^2} \u0026lt; \\delta$ then .$\\vert f(x,y) - L \\vert \u0026lt; \\varepsilon$   Notice that .$\\vert f(x,y) - L \\vert$ is the distance between the numbers .$f(x, y)$ and .$L$, and .$\\sqrt{(x-a)^2 + (y-b)^2}$ is the distance between the point .$(x, y)$ and the point .$(a, b)$. If .$f(x,y) \\to L_1$ as .$(x,y) \\to (a,b)$ along a path .$C_1$ and .$f(x,y) \\to L_2$ as .$(x,y) \\to (a,b)$ along a path .$C_2$, where .$L_1 \\neq L_2$, then .$\\lim_{(x,y)\\to(a,b)} f(x,y)$, does not exist.  We can test this by setting .$x$ and .$y$ to various different values (e.x. .$x = 0, y = 0, x = y, \u0026hellip;,$ etc)    Continuity #  A function .$f$ of two variables is called continuous at .$(a,b)$ if $$\\lim_{(x,y)\\to (a,b)} f(x,y) = f(a,b)$$ We say .$f$ is continuous on .$D$ if .$f$ is continuous at every point .$(a,b)$ in .$D$.   That is, we need the limit to exist ands for .$f(a,b)$ to be defined Continuous functions: .$x,y, c, \\text{ trig (on domain)}$ Arithmetic, composition, exponent all preserve continuity (on domain!) Dividing doesn\u0026rsquo;t necessarily preserve continuity  14.3 Partial Derivatives #  If .$f$ is a function of two variables, its partial derivatives are the functions .$f_x$ and .$f_y$ defined by $$f_x(x,y) = \\frac{\\delta f}{\\delta x} = \\lim_{h\\to0} \\frac{f(x+h,y)-f(x,y)}{h}$$ $$f_y(x,y) = \\frac{\\delta f}{\\delta y} = \\lim_{h\\to0} \\frac{f(x,y+h)-f(x,y)}{h}$$   Notice we use .$\\delta$ instead of .$d$ for partial derivatives These can be written at a single point .$(a,b)$ with respect to .$x$ and .$y$ by treating the remaining variables as a constant $$f_x(a,b) = g'(a); \\ \\ \\ g(x) = f(x,b)$$ $$f_y(a,b) = h'(b); \\ \\ \\ h(y) = f(a,y)$$ Which can be extrapolated for 3 (or more) variables: $$f_z(a,b,c) = k'(c); \\ \\ \\ k(z) = f(a,b,z)$$  Higher Derivatives #   Just like regular derivatives, we can do many partial derivatives For example, the following are second partial derivatives of .$z = f(x,y)$: $$(f_x)_x = f_{xx} = \\frac{\\delta }{\\delta x}\\bigg(\\frac{\\delta f}{\\delta x}\\bigg) = \\frac{\\delta^2f}{\\delta x^2}$$ $$(f_x)_y = f_{xy} = \\frac{\\delta }{\\delta y}\\bigg(\\frac{\\delta f}{\\delta x}\\bigg) = \\frac{\\delta^2f}{\\delta y \\delta x}$$ $$(f_y)_x = f_{yx} = \\frac{\\delta }{\\delta x}\\bigg(\\frac{\\delta f}{\\delta y}\\bigg) = \\frac{\\delta^2f}{\\delta x \\delta y}$$ $$(f_y)_y = f_{yy} = \\frac{\\delta }{\\delta y}\\bigg(\\frac{\\delta f}{\\delta y}\\bigg) = \\frac{\\delta^2f}{\\delta y^2}$$  Clairaut\u0026rsquo;s Theorem Suppose .$f$ is defined on a disk .$D$ that contains the point .$(a,b)$. If the functions .$f_{xy}$ and .$f_{yx}$ are both continuous on .$D$, then $$f_{xy}(a,b) = f_{yx}(a,b)$$  Partial Differential Equations #   In the sciences, we typically want to find how a system changes with respect to multiple variables Partial derivatives occur in partial differential equations, e.x Laplace\u0026rsquo;s Equation: $$ \\frac{\\delta^2 u}{\\delta x^2} + \\frac{\\delta^2 u}{\\delta y^2} = 0$$  Solutions to Laplace\u0026rsquo;s are always harmonic functions, such as .$u = e^x \\sin(y)$    14.4 Tangent Planes and Linear Approximations #  Tangent Planes #   Tangent planes are to surfaces as tangent lines are to curves  Tangent planes contain both the partial derivative lines w.r.t .$x$ and .$y$   All we need to know to write a tangent plane is a point .$(a,b)$ and direction of the two partial derivatives .$\\langle 1,0, f_x(a,b)\\rangle, \\langle 0,1, f_y(a,b)\\rangle$  Direction vector can be found with .$\\langle 1,0, f_x(a,b)\\rangle \\times \\langle 0,1, f_y(a,b)\\rangle = \\langle -f_x, -f_y, 1 \\rangle$ which we can dot with .$\\langle x-x_0, y-y_0, z-f(x_0,y_0) \\rangle$ Suppose .$f$ has continuous partial derivatives. An equation of the tangent plane to the surface .$z = f(x, y)$ at the point .$P(x_0,y_0,z_0)$ is $$z-f(x_0, y_0) = f_x(x_0,y_0)(x-x_0) + f_y(x_0, y_0)(y-y_0)$$      Linear Approximations #   As we get very close to the surface, then the tangent plane (at point .$(a,b)$) looks more and more like the surface  Thus, we can use it to for making approximations when we are near near .$(a,b)$ If .$z = f(x,y)$, then .$f$ is differentiable at .$(a,b)$ if .$\\Delta z$ can be expressed in the form $$\\Delta z = f_x(a,b)\\Delta x + f_y(a,b)\\Delta y + \\varepsilon_1 \\Delta x + \\varepsilon_2 \\Delta y$$ where the error terms, .$\\varepsilon_1$ and .$\\varepsilon_2 \\to 0$ as .$(\\Delta x, \\Delta y) \\to (0,0)$ and the other terms are the linearization of the function.     Rewriting this, we can use the given .$f(x,y)$ to write the linear approximation which is an estimate for point/state at .$f(a,b)$ $$f(x,y) \\approx f(a,b) + f_x(a,b) (x-a) + f_y(a,b)(y-b)$$ We can similarly define the 3D linear approximation, increment of .$w$, and differential .$dw$ as: $$f(x,y,z) \\approx f(a,b,c) + f_x(a,b,c) (x-a) + f_y(a,b,c)(y-b) + f_z(a,b,c) (z-c)$$ $$\\Delta w = f(x+\\Delta x, y + \\Delta y, z + \\Delta z) - f(x,y,z)$$ $$dw = \\frac{\\delta w}{\\delta x}dx + \\frac{\\delta w}{\\delta y}dy + \\frac{\\delta w}{\\delta z}dz$$  Differentials #   With one variable functions, i.e. .$y = f(x)$, we defined the differential .$dx$ to be independent so we had to write .$dy$ as .$dy = f'(x)\\ dx$ Given a differentiable function of two variables, i.e. .$z = f(x,y)$, we know both .$dx$ and .$dy$ are independent so we write: $$dz = f_x(x,y)\\ dx + f_y(x,y)\\ dy = \\frac{\\delta z}{\\delta x}dx + \\frac{\\delta z}{\\delta y}dy$$ If the partial derivatives .$f_x$ and .$f_y$ exist near .$(a,b)$ and are continuous at .$(a,b)$, then .$f$ is differentiable at .$(a,b)$.  14.5 Chain Rule #  Chain Rule #  Suppose that .$z = f(g_1 (x_1,_{\\dots}, x_m), g_2 (x_1,_{\\dots}, x_m), g_n (x_1,_{\\dots}, x_m))$ is a differentiable function of the .$n$ variables .$g_1,_{\\dots}, g_n$ and is .$g_j$ is a differentiable function of the .$m$ variables .$x_1,_{\\dots}, x_m$. Then .$z$ is a function of .$x_1,_{\\dots}, x_m$ and $$ \\frac{\\delta f}{\\delta x_i} = \\frac{\\delta f}{\\delta g_1} \\frac{\\delta g_1}{\\delta x_i} + \\frac{\\delta f}{\\delta g_2} \\frac{\\delta g_2}{\\delta x_i} + \\dots + \\frac{\\delta f}{\\delta g_m} \\frac{\\delta g_m}{\\delta x_i}$$ for each .$i = 1,2,\\dots,m$  Implicit Differentiation #    If .$F(x,y) = 0$ defines .$y$ implicitly as a function of .$x$ (that is, .$y = f(x)$, where .$F(x,f(x))= 0$ for all .$x$ in the domain of .$f$), then $$ \\frac{dy}{dx} = - \\frac{\\frac{\\delta F}{\\delta x}}{ \\frac{\\delta F}{\\delta y}} = - \\frac{F_x}{F_y}$$\n  If .$F(x,y,z) = 0$ defines .$z$ implicitly as a function of .$x,y$, then\n  $$ \\frac{dz}{dx} = - \\frac{\\frac{\\delta F}{\\delta x}}{ \\frac{\\delta F}{\\delta z}} = - \\frac{F_x}{F_z};\\ \\ \\frac{dz}{dy} = - \\frac{\\frac{\\delta F}{\\delta y}}{ \\frac{\\delta F}{\\delta z}} = - \\frac{F_y}{F_z}$$\n14.6 Directional Derivatives and the Gradient Vector #  Directional Derivatives #  Direction Derivative For function .$f$ at .$(x_0, y_0)$ in the direction of unit vector .$\\hat u = \\langle a, b \\rangle$ is $$D_{\\hat u} f(x_0, y_0) = \\lim_{h\\to 0} \\frac{f(x_0 + ha, y_0 + hb) - f(x_0, y_0)}{h} = $$ $$\\dots = \\nabla f \\cdot \\hat u = f_x (x,y) a + f_y (x,y) b$$ if the limit exists (for the former) and if .$f$ is a differentiable function of .$x$ and .$y$ (for the latter)   That is, .$\\hat u = \\hat i = \\langle 1, 0 \\rangle$ for .$D_\\hat{i} = f_x$ and .$\\hat u = \\hat j = \\langle 0, 1 \\rangle$ for .$D_\\hat{j} = f_y$ Differentiability is important because it means that as you approach the surface very closely, it looks more and more like the tangent plane. Directional derivatives can be thought of as the slope of the tangent line at a given point This definition can be extrapolated to (three variables/higher dimensions) trivially, shown below with gradient vectors  Gradient Vector #  Gradient: If .$f$ is a function of variable .$x,y,z$, then the gradient of .$f$ is the vector function .$\\nabla f$ defined by $$\\nabla f(x,y,z) = \\big\\langle f_x(x,y,z), f_y (x,y,z), f_z (x,y,z) \\big\\rangle = \\frac{\\delta f}{\\delta x}\\hat i + \\frac{\\delta f}{\\delta y}\\hat j + \\frac{\\delta f}{\\delta z}\\hat k$$   We can now use the gradient to re-write our directional derivative equation as $$D_{\\hat u} f(x,y,z,\\dots) = \\nabla f(x,y,z,\\dots) \\cdot \\hat u$$ We can re-write this using the definition of the dot product as $$D_{\\hat u} f(x,y,z,\\dots) = \\Vert \\nabla f \\Vert \\Vert \\hat u \\Vert \\cos\\theta =\\Vert \\nabla f \\Vert \\cos\\theta $$  Maximizing the Directional Derivative #  Suppose .$f$ is a differentiable function of two or three variables. The maximum value of the directional derivatives .$D_\\hat{u} f(\\vec x)$ is .$\\Vert \\nabla f(\\vec x ) \\Vert$ and it occurs when .$\\hat u$ has the same direction as the gradient vector .$\\nabla f(\\vec x)$   We can see from the definition above that since the max of .$\\cos\\theta$ is .$1$ when .$\\theta = 0$, therefore the max of the directional derivative occurs at the same angle (when .$\\hat u$ has the same direction of .$\\nabla f$ ) TL;DR: .$D_\\hat{u} f(\\vec x)$ is maximized if .$\\vec u = \\frac{\\nabla f}{\\Vert \\nabla f \\Vert}\\bigg\\vert_\\vec{p}$ at point .$\\vec p$  Tangent Planes to Level Surfaces #   If .$f(x,y) = k$ is a curve, then .$F(x,y,z) = k$ is a surface Let .$\\vec r(t)$ be a space curve on the surface .$F(x,y,z) = k$  Let .$\\vec r(t_0) = \\langle x_0, y_0, z_0 \\rangle$ for some .$t_0$ (at some time, the space curve passes through some point which is on the surface) We know .$F(\\vec r(t)) = k$, thus, using the chain rule: $$0 = \\frac{\\delta F}{\\delta x} \\frac{\\delta x}{\\delta t} + \\frac{\\delta F}{\\delta y} \\frac{\\delta y}{\\delta t} + \\frac{\\delta F}{\\delta z} \\frac{\\delta z}{\\delta t} = \\nabla F(x_0, y_0, z_0) \\cdot (\\vec r(t_0))'$$   The gradient vector at .$P$, .$F(x_0, y_0, z_0)$, is perpendicular to the tangent vector .$\\vec r'(t)$ to any curve .$C$ on .$S$ that passes through .$P$  In English: The direction of the gradient is always perpendicular to the level surface at every point   We can then define the tangent plane to the level surface .$F(x,y,z) = k$ at .$P(x_0, y_0, z_0)$ as the plane that passes through .$P$ and has normal vector .$\\nabla F(x_0, y_0, z_0)$: $$\\nabla F\\big\\vert_{(x_0, y_0, z_0)} \\cdot \\langle x-x_0, y-y_0, z-z_0 \\rangle = 0$$ We can also write this in the symmetric equation form: $$\\frac{x-x_0}{F_x(x_0, y_0, z_0)} = \\frac{y-y_0}{F_y(x_0, y_0, z_0)} = \\frac{z-z_0}{F_z(x_0, y_0, z_0)}$$  14.7 Maximum and Minimum Values #  Critical Points #  A function of two variables has a local maximum at .$(a,b)$ if .$f(x,y) \\leq f(a,b)$ when .$(x,y)$ is near .$(a,b)$ [This means that for .$f(x,y) \\leq f(a,b)$ for all points .$(x,y)$ in some disk with center .$(a,b)$.] The number .$f(a,b)$ is called a local maximum value. If .$f(x,y) \\geq f(a,b)$ when .$(x,y)$ is near .$(a,b)$, then .$f$ has a local minimum at .$(a,b)$ and .$(x,y)$ is a local minimum value.   If the inequalities above hold for all points .$(x,y)$ in the domain of .$f$, then .$f$ has an absolute maximum (or absolute minimum) at .$(a,b)$ If .$f$ has a local maximum or minimum at .$(a,b)$ and the first-order partial derivatives of .$f$ exist there, then .$f_x(a,b) = 0$ and .$f_y(a,b) = 0$.  If the graph of .$f$ has a tangent plane at a local maximum or minimum, then the tangent plane must be horizontal   .$(a,b)$ is a Critical Point of .$f$ if .$f_x(a,b) = 0$ and .$f_y(a,b) = 0$, or if one of these partial derivatives does not exist  Thus, if .$f$ has a local maximum or minimum at .$(a,b)$, then .$(a,b)$ is a critical point of .$f$ In other words, at a critical point, a function could have a local maximum or a local minimum or neither (saddle point).    Second Derivatives Test: Suppose the second partial derivatives of .$f$ are continuous on a disk with center .$(a, b)$, and suppose that .$f_x(a, b) = 0$ and .$f_y(a, b) = 0$ (that is, .$(a, b)$ is a critical point of .$f$ ). Let $$D = D(a, b) = \\begin{vmatrix}f_{xx} \u0026amp; f_{xy}\\\\ f_{yx} \u0026amp; f_{yy}\\end{vmatrix} = f_{xx}(a, b) f_{yy}(a, b) - (f_{xy}(a, b))^2$$\n If .$D \u0026gt; 0$ and .$f_{xx}(a, b) \u0026gt; 0$ (or .$f_{yy}(a, b) \u0026gt; 0$), then .$f(a, b)$ is a local minimum. If .$D \u0026gt; 0$ and .$f_{xx}(a, b) \u0026lt; 0$ (or .$f_{yy}(a, b) \u0026lt; 0$), then .$f(a, b)$ is a local maximum. If .$D \u0026lt; 0$, then .$f(a, b)$ is a saddle point If .$D = 0$, the test gives no information: .$f$ could be any of the above    Note that in the first two tests, it\u0026rsquo;s implied that .$f_{xx}$ and .$f_{yy}$ have the same sign The determinant is a Hessian matrix  Extreme Points #   Just as a closed interval contains its endpoints, a closed set in .$\\mathbb{R}^2$ is one that contains all its boundary points.  For instance, the disk .$D = \\{(x,y) \\vert x^2 + y^2 \\leq 1 \\}$ is a closed set because it contains all of its boundary points (which are the points on the circle .$r = 1$) But if even one point on the boundary curve were omitted, the set would not be closed   A bounded set in .$\\mathbb{R}^2$ is one that is contained within some disk \u0026ndash; it is finite in extent     Extreme Value Theorem for Functions of Two Variables: If .$f$ is continuous on a closed, bounded set .$D$ in .$\\mathbb{R}^2$, then .$f$ attains an absolute maximum value .$f(x_1, y_1)$ and an absolute minimum value .$f(x_2, y_2)$ at some points .$(x_1, y_1)$ and .$(x_2, y_2)$ in .$D$.   If .$f$ has an extreme value at .$(x_1, y_1)$, then .$(x_1, y_1)$ is either a critical point of .$f$ or a boundary point of .$d$. To find the absolute maximum and minimum values of a continuous function .$f$ on a closed, bounded set .$D$:  Find the values of .$f$ at the critical points of .$f$ in .$D$. Find the extreme values of .$f$ on the boundary of .$D$. The largest of the values from steps 1 and 2 is the absolute maximum value; the smallest of these values is the absolute minimum value.    14.8 Lagrange Multipliers #   We use Lagrange Multipliers to find critical points of a surface .$f$ given some constraining surface .$g$ Method of Lagrange Multipliers To find the maximum and minimum values of .$f(x,y,z)$ subject to the constraint .$g(x,y,z) = k$ [assuming that these extreme values exist and .$\\nabla \\neq 0$ on the surface .$g(x,y,z) = k$]:\n Find all values of .$x, y, z$, and .$\\lambda$ such that $$\\nabla f(x,y,z) = \\lambda \\nabla g(x,y,z)$$ $$g(x,y,z) = k$$ Evaluate .$f$ at all the points .$(x, y, z)$ that result from the first step. The largest of these values is the maximum value of .$f$; the smallest is the minimum value of .$f$.    We can decompose the first equation and use the second equation to get $$f_x = \\lambda g_x;\\ \\ f_y = \\lambda g_y;\\ \\ f_z = \\lambda g_z;\\ \\ g(x,y,z) = k$$ Notice we don\u0026rsquo;t care what .$\\lambda$ is, only that it exists  Two Constraints #   We can use Lagrange multipliers for two constraints .$f$ and .$g$ too: $$\\nabla f(x_0, y_0, z_0) = \\lambda \\nabla g(x_0, y_0, z_0) + \\mu \\nabla h(x_0, y_0, z_0)$$ Likewise, we can decompose the equation above to get the following five equations:  $$f_x = \\lambda g_x + \\mu h_x$$ $$f_y = \\lambda g_y + \\mu h_y$$ $$f_z = \\lambda g_z + \\mu h_z$$ $$g(x,y,z) = k$$ $$h(x,y,z) = c$$       "},{"id":14,"href":"/math-53/15/","title":"15: Multiple Integrals","section":"Math 53","content":"15.1 Double Integrals over Rectangles #   We describe closed rectangles in the form .$R = [a,b] \\times [c,b] = \\{(x,y) \\in \\mathbb{R}^2 \\vert a \\leq x \\leq b, c \\leq y \\leq d\\}$ Then we can write the solid .$S$ that lies above .$R$ as .$S = \\{(x,y,z) \\in \\mathbb{R}^3 \\vert 0 \\leq z \\leq f(x,y), (x,y) \\in R\\}$ To find the volume of this surface, we take a double integral $$V = \\iint_R f(x,y)\\ dA$$  Fubini\u0026rsquo;s Theorem: If .$f$ is continuous on the rectangle .$R = \\{(x,y) \\vert a \\leq x \\leq b, c \\leq y \\leq d\\}$, then $$\\iint_R f(x,y)\\ dA = \\int_a^b \\int_c^d f(x,y)\\ dy\\ dx = \\int_c^d \\int_a^b f(x,y)\\ dx\\ dy$$ More generally, this is true if we assume that .$f$ is bounded on .$R$, .$f$ is discontinuous only on a finite number of smooth curves, and the iterated integrals exist.  Average Value #   In the 2D case we could write the average as $$f_\\text{avg} = \\frac{1}{b-a} \\int_a^b f(x) dx$$ For 3D, instead of dividing by the change in just .$y$ (which was .$b-a$), we divide over the total area: $$f_\\text{avg} = \\frac{1}{A(R)}\\iint_R f(x,y)\\ dA$$  15.2 Double Integrals over General Regions #  Type I #  If .$f$ is continuous on a type I region .$D$ such that $$D = \\{(x,y)\\ \\vert\\ a \\leq x \\leq b,\\ g_1(x) \\leq y \\leq g_2(x)\\ \\}$$ then $$\\int_D f(x,y)\\ dA = \\int_a^b \\int_{g_1(x)}^{g_2(x)} f(x,y)\\ dy\\ dx$$   Type II #  If .$f$ is continuous on a type II region .$D$ such that $$D = \\{(x,y)\\ \\vert\\ c \\leq y \\leq d,\\ h_1(y) \\leq x \\leq h_2(y)\\ \\}$$ then $$\\int_D f(x,y)\\ dA = \\int_c^d \\int_{h_1(y)}^{h_2(y)} f(x,y)\\ dx\\ dy$$  Properties of Double Integrals #   $$\\iint_D \\Big[ f(x,y) + g(x,y)\\Big]\\ dA = \\iint_{D} f(x,y)\\ dA + \\iint_{D} g(x,y)\\ dA$$ $$\\iint_D c\\cdot f(x,y)\\ dA = c \\iint_D f(x,y)\\ dA\\ \\text{ where $c$ is a constant}$$ $$\\iint_D f(x,y)\\ dA \\geq \\iint_D g(x,y)\\ dA \\ \\text{ if $f(x,y) \\geq g(x,y)$ for all $(x,y) \\in D$}$$ $$\\iint_D f(x,y)\\ dA = \\iint_{D_1} f(x,y)\\ dA + \\iint_{D_2} f(x,y)\\ dA\\ \\text{ for $D = D_1 \\cup D_2$}$$ $$mA(D) \\leq \\iint_D f(x,y)\\ dA \\leq MA(D)$$  If .$m \\leq f(x,y) \\leq M$ for all .$(x,y) \\in D$    15.3 Double Integrals in Polar Coordinates #   Recall that we can convert cartesian to polar with the following equations: $$r^2 = x^2 +y^2$$  $$x = r\\cos\\theta$$  $$y = r\\sin\\theta$$      We multiply .$r$ because an \u0026ldquo;infinitesimal\u0026rdquo; polar rectangle as an ordinary rectangle with dimensions .$r\\ d\\theta$ and .$dr$ and therefore has area .$dA = r\\ dr\\ d\\theta$ That is, the further out the polar rectangle is (the larger the .$r$), the larger the area of that rectangle is (this scale is .$\\propto r$)     If .$f$ is continuous on a polar region of the form $$D = \\{(r,\\theta)\\ \\vert\\ \\alpha \\leq \\theta \\leq \\beta, h_1(\\theta) \\leq r \\leq h_2(\\theta) \\}$$ then $$\\iint_D f(x,y)\\ dA = \\int_\\alpha^\\beta \\int_{h_1(\\theta}^{h_2(\\theta)} r \\cdot f(r\\cos\\theta, r\\sin\\theta)\\ dr\\ d\\theta$$  15.5 Surface Area #  The area of the surface with equation .$z = f(x,y), (x,y) \\in D$, where .$f_x$ and .$f_y$ are continuous, is $$A(S) = \\iint_D \\sqrt{\\big[f_x(x,y)\\big]^2 + \\big[f_y(x,y)\\big]^2 + 1}\\ dA$$   Notice the similarities between the SA function and the line integral function, .$L = \\int_a^b \\sqrt{1 + \\big( \\frac{dy}{dx} \\big)^2}\\ dx$  15.6 Triple Integrals #  Fubini\u0026rsquo;s Theorem for Triple Integrals If f is continuous on the rectangular box B − fa, bg 3 fc, dg 3 fr, sg, then $$\\iiint_B f(x,y,z)\\ dV = \\int_r^s\\int_c^d\\int_a^b f(x,y,z)\\ dx\\ dy\\ dz$$   The iterated integral on the right side of Fubini\u0026rsquo;s Theorem means that we integrate first with respect to .$x$ (keeping .$y$ and .$z$ fixed), then we integrate with respect to .$y$ (keeping .$z$ fixed), and finally we integrate with respect to .$z$. Note that if .$f$ is separable this just becomes the product of three single-dimensional integrals, or one two-dimensional integral and two one-dimensional integrals. Fubini\u0026rsquo;s theorem still applies.  Type 1 #  $$\\iiint_E f(x,y,z)\\ dV$ = \\iint_D \\bigg[\\int_{u_1(x,y)}^{u_2(x,y)}f(x,y,z)\\ dz\\bigg]\\ dA$$\nType I #   $$\\dots = \\int_a^b \\int_{g_1(x)}^{g_2(x)} \\int_{u_1(x,y)}^{u_2(x,y)}f(x,y,z)\\ dz\\ dx\\ dy$$  Type II #   $$\\dots = \\int_c^d \\int_{h_1(y)}^{h_2(y)} \\int_{u_1(x,y)}^{u_2(x,y)}f(x,y,z)\\ dz\\ dy\\ dx$$   Type 2 #  $$\\iiint_E f(x,y,z)\\ dV$ = \\iint_D \\bigg[\\int_{u_1(y,z)}^{u_2(y,z)}f(x,y,z)\\ dx\\bigg]\\ dA$$\nType 3 #  $$\\iiint_E f(x,y,z)\\ dV$ = \\iint_D \\bigg[\\int_{u_1(x,z)}^{u_2(x,z)}f(x,y,z)\\ dy\\bigg]\\ dA$$\n15.7 Triple Integrals in Cylindrical Coordinates #  Cylindrical to Cartesian #   $$x = r\\cos\\theta$$ $$y = r\\sin\\theta$$ $$z = z$$  Cartesian to Cylindrical #   $$r^2 = x^2 + y^2$$ $$\\tan\\theta = \\frac{y}{x}$$ $$z = z$$    Now we deal with integration in cylindrical coordinates.  We have .$dV = dx\\ dy\\ dz$ Since .$z$ is the same, .$dz$ is the same. However, we can convert .$dx, dy$ to .$r\\ dr, dθ.$ since it is the same transformation as in polar coordinates. Thus the volume element in cylindrical coordinates is .$dV = r\\ dr\\ dθ\\ dz$.       $$\\iiint_D f(x,y,z) dx\\ dy\\ dz = \\iiint_D f(r\\cos\\theta, r\\sin\\theta, z)\\cdot r\\ dr\\ d\\theta\\ dz$$ $$\\dots = \\int_\\alpha^\\beta \\int_{h_1(\\theta)}^{h_2(\\theta)} \\int_{u_1(r\\cos\\theta, r\\sin\\theta)}^{u_2(r\\cos\\theta, r\\sin\\theta)} f(r\\cos\\theta, r\\sin\\theta, z)\\cdot r\\ dz\\ dr\\ d\\theta$$  15.8 Triple Integrals in Spherical Coordinates #   Spherical Coordinates map .$(x,y,z) \\Longrightarrow (\\rho, \\theta, \\phi)$  .$\\rho$ is the distance between the origin and point; .$\\rho \\geq 0$ .$\\theta$ is the angle on the .$xy$ plane; .$\\theta \\in [0, 2\\pi]$ .$\\phi$ is the angle between the .$z$ axis and the .$xy$ plane; .$\\phi \\in [0, \\pi]$  We only need to consider half the sphere; the other half is already counted by the varying .$\\theta$.         Spherical to Cartesian #   $$x =\\rho \\sin \\phi \\cos \\theta$$ $$y =\\rho \\sin \\phi \\sin \\theta$$ $$z =\\rho \\cos \\phi$$  Cylindrical to Spherical #   $$x =\\rho \\sin \\phi$$ $$\\theta = \\theta$$ $$z =\\rho \\cos \\phi$$  Cartesian to Spherical #   $$\\rho = \\sqrt{x^2 + y^2 + z^2}$$ $$\\tan \\theta = \\frac{y}{x}$$ $$\\tan \\phi = \\frac{z}{\\sqrt{x^2 + y^2}}$$   $$\\iiint_E f(x,y,z)\\ dV = \\dots$$ $$\\dots = \\int_c^d \\int_\\alpha^\\beta \\int_a^b f(\\rho\\sin\\phi\\cos\\theta, \\rho\\sin\\phi\\sin\\theta, \\rho\\cos\\phi) \\cdot \\rho^2 \\sin\\phi\\ d\\rho\\ d\\theta\\ d\\phi$$   We have the volume element .$dV = dx\\ dy\\ dz$. By converting to cylindrical coordinates and doing some algebraic conversions we have .$dV = \\rho^2 \\sin\\phi d\\rho\\ d\\theta\\ d\\phi$:     15.9 Change of Variable in Multiple Integrals #   We\u0026rsquo;ve done .$u$-sub before in single variable, as well as cartesian .$\\iff$ polar .$\\iff$ spherical in multivariable More generally, we can consider a change of variables that is given by a transformation .$T$ from the .$uv$-plane to the .$xy$-plane:  .$T(u,v) = (x,y)$ where .$x = g(u,v), y = h(u,v)$  .$x,y$ must be differentiable in .$S$   We usually assume that .$T$ is a .$C^1$ transformation: .$g$ and .$h$ have continuous first-order partial derivatives  A transformation .$T$ is really just a function whose domain and range are both subsets of .$\\mathbb{R}^2$ If .$T(u_1, v_1 = (x_1, y_1)$, then the point .$(x_1,y_1)$ is called the image of the point .$(u_1, v_1)$  That is, .$T$ transforms .$S$ into a region .$R$ in the .$xy$-plane called the image of .$S$, consisting of the images of all points in .$S$   If no two points have the same image, .$T$ is called one-to-one ( wiki)  If .$T$ is a one-to-one transformation, then it has an inverse transformation .$T^{-1}$ from the .$xy$-plane to the .$uv$-plane + it may be possible to solve for .$u$ and .$v$ in terms of .$x$ and .$y$: .$u = G(x,y), v = H(x,y)$ If not one-to-one, then the transformation would \u0026ldquo;fold\u0026rdquo; over itself \u0026ndash; we would double-count some amount of area          This change in variable affects the size of the region (the area/integral)  The vector .$\\vec r (u, v) = g(u, v) \\hat i + h(u, v) \\hat j$ is the position vector of the image of the point .$(u, v)$.  The tangent vector at .$(x_0, y_0)$ to the image curve of the lower side (.$v = v_0$) of .$S$: $$\\vec r_v = \\frac{\\delta x}{\\delta v} \\hat i + \\frac{\\delta y}{\\delta v} \\hat j$$    Similarly, the tangent vector at .$(x_0, y_0)$ to the image curve of the left side (.$u = u_0$) of .$S$: $$\\vec r_u = \\frac{\\delta x}{\\delta u} \\hat i + \\frac{\\delta y}{\\delta u} \\hat j$$         We can then find the area by calculating the cross product: $$\\vec r_u \\times \\vec r_v = \\begin{vmatrix} \\frac{\\delta x}{\\delta u} \u0026amp; \\frac{\\delta x}{\\delta v} \\\\ \\frac{\\delta y}{\\delta u} \u0026amp; \\frac{\\delta y}{\\delta v} \\end{vmatrix}$$ $$\\dots = \\frac{\\delta (x,y)}{\\delta (u,v)} = \\frac{\\delta x}{\\delta u} \\frac{\\delta y}{\\delta v} - \\frac{\\delta x}{\\delta v}\\frac{\\delta y}{\\delta u}$$ This is the Jacobian of the transformation .$T$ given by .$x = g(u,v)$ and .$y = h(u,v)$     Formally, Suppose that .$T$ is a .$C^1$ transformation whose Jacobian is nonzero and that .$T$ maps a region .$S$ in the .$uv$-plane onto a region .$R$ in the .$xy$-plane. Suppose that .$f$ is continuous on .$R$ and that .$R$ and .$S$ are type I or type II plane regions. Suppose also that .$T$ is one-to-one, except perhaps on the boundary of .$S$. Then, $$\\iint_R f(x,y) dA = \\iint_S f(x(u,v), y(u,v)) \\Bigg\\vert \\frac{\\delta (x,y)}{\\delta (u,v)} \\Bigg\\vert\\ du\\ dv$$   That is, .$dA = \\Bigg\\vert \\frac{\\delta (x,y)}{\\delta (u,v)} \\Bigg\\vert\\ du\\ dv$  General Solving Steps #   Write down transformations (.$x$ and .$y$ in terms of .$u$ and .$v$) Find the Jacobian Rewrite the equations with .$u$ and .$v$ Sketch the new region + find new bounds Integrate on the new field with Jacobian   Triple Integrals #   We can also let .$T$ be a transformation that maps a region .$S$ in .$uvw$-space onto a region .$R$ in .$xyz$-space by means of the equations: $$x = g(u,v,w)$$  $$y = h(u,v,w)$$  $$z = k(u,v,w)$$    Then, the Jacobian is a .$3 \\times 3$ determinant: $$ \\frac{\\delta (x,y,z)}{\\delta (u,v,w)} = \\begin{vmatrix} \\frac{\\delta x}{\\delta u} \u0026amp; \\frac{\\delta x}{\\delta v} \u0026amp; \\frac{\\delta x}{\\delta w} \\\\ \\frac{\\delta y}{\\delta u} \u0026amp; \\frac{\\delta y}{\\delta v} \u0026amp; \\frac{\\delta y}{\\delta w} \\\\ \\frac{\\delta z}{\\delta u} \u0026amp; \\frac{\\delta z}{\\delta v} \u0026amp; \\frac{\\delta z}{\\delta w} \\end{vmatrix} = dA$$  "},{"id":15,"href":"/math-53/16/","title":"16: Vector Calculus","section":"Math 53","content":"16.1 Vector Fields #   A vector field in .$\\mathbb{R}^3$ is a function .$\\vec F$ on region .$E \\in \\mathbb{R}^3$ that assigns each point .$(x,y,z)$ a vector .$F(x,y,z)$ .$\\vec F$ is made up of component function: .$\\vec F(x,y,z) = \\langle P(x,y,z)\\hat i, Q(x,y,z) \\hat j, R(x,y,z) \\hat k\\rangle$  .$\\vec F$ is continuos iff its component vectors are continuos   .$\\vec F$ is  conservative (path taken doesn\u0026rsquo;t change work) iff potential function .$f(x,y,z)$ is a partial of .$\\vec F$ $$\\vec F = \\nabla f$$  Notice that the gradient lines are always perpendicular to the level sets  If the function .$f$ is differentiable, .$\\nabla f$ at a point is either zero or perpendicular to the level set of .$f$ at that point.   That is, that the gradient of a function is called a gradient field which is always conservative (the fundamental theorem of calculus for line integrals)  Conversely, a (continuous) conservative vector field is always the gradient of a function      16.2 Line Integrals #   We know that the distance (length) normally is .$L = \\int_a^b \\sqrt{(dx/dt)^2 + (dy/dt)^2}\\ dt$ Over a vector field, we can think of the function being the density of the line (or height of particle). Therefore, we say .$ds = \\int_a^b \\sqrt{(dx/dt)^2 + (dy/dt)^2}\\ dt$ and can write $$\\int_C f(x,y) ds = \\int_a^bf(x(t), y(t)) \\cdot \\sqrt{\\bigg(\\frac{dx}{dt}\\bigg)^2 + \\bigg(\\frac{dy}{dt}\\bigg)^2} dt$$ and for 3D in a slightly different form: $$\\int_a^b f (\\vec r (t) ) \\vert \\vec r'(t) \\vert \\Longrightarrow \\int_a^b f(x(t), y(t), z(t)) \\cdot \\sqrt{x'(t)^2 + y'(t)^2 + z'(t)^2} dt$$  We can write .$\\vec a \\to \\vec b$ as .$(1-t)\\vec a + t\\vec b$ with .$t\\in[0,1]$ Just like usual, we can break up un-integrable smooth curves, i.e $$\\int_a^z f (x,y) = \\int_a^b f_1(x,y) + \\int_b^c f_2(x,y) + \\dots \\int_{\\dots}^z f_n(x,y)$$  wrt variable #  Opposed to the line integrals on .$f$ along .$C$ with respect to .$x$ both and .$y$, we can write line integral with respect to arc length as follows:\n$$\\int_C f(x,y) dx = \\int_a^b f(x(t), y(t)) \\cdot y'(t) dt$$ $$\\int_C f(x,y) dy = \\int_a^b f(x(t), y(t)) \\cdot x'(t) dt$$\nIt frequently happens that line integrals with respect to .$x$ and .$y$ occur together which we abbr as\n$$\\int_C P(x,y)\\ dx + \\int_C Q(x,y)\\ dy = \\int_C P(x,y)\\ dx + Q(x,y)\\ dy$$\nOrientation #   When we parameterize a curve, we give it a direction  Positive: Enclosed region .$D$ is always on the left as we traverse curve .$C$ (counter-clockwise) Negative: Enclosed region .$D$ is always on the right as we traverse curve .$C$ (clockwise)   The orientation represents the direction of the line  The positive direction corresponding to increasing values of the parameter .$t$ Doesn\u0026rsquo;t matter for regular line integrals: .$\\int_C f(x,y) ds = \\int_C f(x,y) ds$  Deals with distance, .$ds$, which doesn\u0026rsquo;t depend on direction   Does matter for field line integrals: .$\\int_C f(x,y) dx \\neq \\int_C f(x,y) dy$  Deals with displacement, .$dx/dy$, which depends on direction      Let .$\\vec F$ be a continuous vector field defined on a smooth curve .$C$ given by a vector function .$\\vec r(t), t\\in[a,b]$. Then the line integral of .$\\vec F$ along .$C$ is $$W = \\int_C \\vec F \\cdot d\\vec r = \\int_a^b \\vec F ( \\vec r (t) ) \\cdot (\\vec r (t))'\\ dt = \\int_C \\vec F \\cdot \\vec T\\ ds$$\n .$\\vec T(x,y,z)$ is the unit tangent vector at the point .$(x,y,z)$ on .$C$ .$\\vec F \\cdot \\vec T = \\vec F(x,y,z) \\cdot \\vec T(x,y,z)$    This equation says that work is the line integral with respect to arc length of the tangential component of the force. Then, for a non-conservative force i.e .$F = \\langle P(x,y,z), Q(x,y,z), R(x,y,z) \\rangle$ $$W = \\int_a^b P(\\vec r(t)) \\cdot x'(t) + Q(\\vec r(t)) \\cdot y'(t) + R(\\vec r(t)) \\cdot z'(t)$$ $$ \\Longrightarrow \\int_C P\\ dx + Q\\ dy + R\\ dz$$ If we flip the curve\u0026hellip;  \u0026hellip;and integrate with respect to just .$x$ or .$y$ then the value flips: $$\\int_{-C}f(x,y)\\ dx = - \\int_C f(x,y)\\ dx$$ Since .$\\Delta x$ and .$\\Delta y$ change sign when we reverse the orientation of .$C$.    \u0026hellip;and integrate with respect to arc length, the value of the line integral does not change when we reverse the orientation of the curve: $$\\int_{-C}f(x,y)\\ ds = \\int_C f(x,y)\\ ds$$ This is because .$\\Delta s$ is always positive.      16.3 Fundamental Thm for Line Integrals #  Let .$C$ be a smooth curve given by the vector function .$\\vec r (t), t\\in[a,b]$. Let .$f$ be a differentiable function of two or three variables whose gradient vector .$\\nabla f$ is continuous on .$C$. Then $$\\int_C \\nabla f \\cdot d\\vec r =\\int_C \\vec F \\cdot d\\vec r = f(\\vec r(b) ) f(\\vec r(a))$$  Independence of Path #   Suppose .$C_1$ and .$C_2$ are two piecewise-smooth curves (which are called paths) that have the same initial point .$A$ and terminal point .$B$.  Therefore, .$\\int_{C_1} \\nabla f \\cdot d\\vec r = \\int_{C_2} \\nabla f \\cdot d\\vec r$ whenever .$\\nabla f$ is continuous In other words, line integrals of conservative vector fields are independent of path (they only depend on the start and end points)    Plane Curves #  .$\\int_C \\vec F \\cdot d\\vec r$ is independent of path in .$D$ iff .$\\int_C \\vec F \\cdot d\\vec r = 0$ for every closed path .$C$ in .$D$   Closed: A curve with the same end and start points: .$\\vec r(b) = \\vec r(a)$ That is, only vector fields that are independent of path are conservative.     Space Curves #  Suppose .$\\vec F$ is a vector field that is continuous on an open connected region .$D$. If .$\\int_C \\vec F \\cdot d\\vec r$ is independent of path in .$D$, then .$\\vec F$ is a conservative vector field on .$D$; that is, there exists a function .$f$ such that .$\\nabla f = \\vec F$.   Open: For every point .$P$ in .$D$ there is a disk with center .$P$ that lies entirely in .$D$. (So .$D$ doesn\u0026rsquo;t contain any of its boundary points.) Connected: Any two points in .$D$ can be joined by a path that lies in .$D$.   $$$$     If .$\\vec F (x,y) = P(x,y) \\hat i + Q(x,y) \\hat j$ is a conservative vector field, where .$P$ and .$Q$ have continuous first-order partial derivatives on a domain .$D$, then throughout .$D$ we have $$ \\frac{\\delta P}{\\delta y} = \\frac{\\delta Q}{\\delta x}$$ The converse of the theorem above is true on only simple curves: curves that don\u0026rsquo;t intersect itself anywhere between its endpoints A simply-connected region in the plane is a connected region .$D$ such that every simple closed curve in .$D$ encloses only points that are in .$D$  Intuitively speaking, a simply-connected region contains no hole and can\u0026rsquo;t consist of two separate pieces.    .$\\vec F = \\langle P, Q \\rangle$ is a conservative vector field on an open simply-connected region .$D$ iff both .$P$ and .$Q$ have continuous first-order partial derivatives and $$ \\frac{\\delta P}{\\delta y} = \\frac{\\delta Q}{\\delta x} \\text{ throughout } D$$    16.4 Green\u0026rsquo;s Theorem #  Green\u0026rsquo;s Theorem: Let .$C$ be a positively oriented, piecewise-smooth, simple closed curve in the plane and let .$D$ be the region bounded by .$C$. If .$P$ and .$Q$ have continuous partial derivatives on an open region that contains .$D$, then $$\\int_C \\vec F \\cdot d\\vec r = \\oint_C P\\ dx + Q\\ dy = \\iint_D \\bigg(\\frac{\\delta Q}{\\delta x} - \\frac{\\delta P}{\\delta y}\\bigg) dA$$\n .$dA = dx\\ dy = r \\cdot dr\\ d\\theta = \\dots$ .$\\vec F(x,y) = \\langle P(x,y), Q(x,y)\\rangle$ .$\\oint$ implies an integral over a closed curve    The proof (for Green\u0026rsquo;s thm + remaining sections) is (are) too much for me to write out here, the book does a good job  One important takeaway is the the shape doesn\u0026rsquo;t have to be \u0026ldquo;nice\u0026rdquo; \u0026ndash; we can break up any shape into parts that are either Type I or II. Even though we will have overlapping lines, they cancel one another out (leaving only the boundaries) because of orientation   Green\u0026rsquo;s Theorem should be regarded as the counterpart of the Fundamental Theorem of Calculus for double integrals  Recall the Fundamental Theorem of Calculus is .$\\int_a^b F'(x)\\ dx = F(b) - F(a)$ In both cases there is an integral involving derivatives (.$F', \\delta Q/\\delta x, \\delta P/\\delta y$) on the left side of the equation. And in both cases the right side involves the values of the original functions (.$F, Q, P$) only on the boundary of the domain.  (In the one-dimensional case, the domain is an interval .$[a,b]$ whose boundary consists of just two points, .$a$ and .$b$.)      Application: Finding Area #   Since the area of .$D$ is .$\\iint_D 1 dA$, we wish to choose .$P$ and .$Q$ so that $$ \\frac{\\delta Q}{\\delta x} - \\frac{\\delta P}{\\delta y} = 1$$ Some examples of .$P/Q$ combos are $$P(x,y)= 0$$ $$Q(x,y)= x$$ $$A = \\oint_C x\\ dy$$  $$P(x,y)=-y$$ $$Q(x,y)= 0$$ $$A = -\\oint_C y\\ dx$$  $$P(x,y)=-y/2$$ $$Q(x,y)= x/2$$ $$A = \\frac{1}{2} \\oint_C x\\ dy - y\\ dx$$     Planimeters (a measuring instrument used to determine the area of an arbitrary two-dimensional shape) is an example of an application of Green Theorem We can also use Green\u0026rsquo;s to prove main  div  article  div:nth-child(22)  div:nth-child(2)  blockquote\").scrollIntoView()'our last equation found in 16.3: $$\\oint_C \\vec F \\cdot d \\vec r = \\oint_C P\\ dx + Q\\ dy = \\iint_R \\bigg( \\frac{\\delta Q}{\\delta x} - \\frac{\\delta P}{\\delta y}\\bigg)\\ dA = \\iint_R 0\\ dA = 0$$  A curve that is not simple crosses itself at one or more points and can be broken up into a number of simple curves. We have shown that the line integrals of .$\\vec F$ around these simple curves are all .$0$ and, adding these integrals, we see that .$\\int_C \\vec F \\cdot d\\vec r = 0$ for any closed curve .$C$. Therefore .$\\int_C \\vec F \\cdot d\\vec r$ is independent of path in .$D$. It follows that .$F$ is a conservative vector field.\n   16.5 Curl and Divergence #   Recall that .$\\nabla = \\langle \\frac{\\delta}{\\delta x} \\frac{\\delta}{\\delta y} \\frac{\\delta}{\\delta z} \\rangle$  3b1b video going over this section  Curl #   Vector of the rotation caused by the field at a given point $$\\nabla \\times \\vec F(x,y,z) = \\begin{bmatrix}\\hat i \u0026amp; \\hat j \u0026amp; \\hat k\\\\ \\frac{\\delta}{\\delta x} \u0026amp; \\frac{\\delta}{\\delta y} \u0026amp; \\frac{\\delta}{\\delta z}\\\\ P \u0026amp; Q \u0026amp; R\\end{bmatrix} = \\dots $$ If .$\\vec F$ is conservative then .$\\text{curl($\\vec F$) = 0}$  We know if .$\\vec F$ is conservative then .$\\vec F = \\nabla f$ for some .$f(x,y,z)$ Crossing .$\\nabla F$ with .$\\nabla$ we get .$\\langle \\frac{\\delta^2 f}{\\delta y \\delta z} - \\frac{\\delta^2 f}{\\delta z \\delta y}, \\dots \\rangle = \\langle 0, 0,0 \\rangle$    Divergence #   If .$\\vec F (x,y,z)$ is the velocity of a fluid (or gas), then .$\\text{div}(\\vec F (x,y,z))$ represents the net rate of change (wrt time) of the mass of fluid (or gas) flowing from the point .$(x,y,z)$ per unit volume.  In other words, .$\\text{div}(\\vec F (x,y,z))$ measures the tendency of the fluid to diverge from the point .$(x,y,z)$. If .$\\text{div}(\\vec F (x,y,z)) = 0$, then .$F$ is said to be incompressible.   Scalar of the amount of \u0026ldquo;flow\u0026rdquo; at a given point \u0026ndash; how much does the field expand/contract at a given point? $$\\nabla \\cdot \\vec F(x,y,z) = \\langle \\frac{\\delta}{\\delta x} \\frac{\\delta}{\\delta y} \\frac{\\delta}{\\delta z} \\rangle \\cdot \\langle P, Q, R \\rangle$$    Fun fact: .$\\text{(div(curl($\\vec F$)))} = \\nabla \\cdot (\\nabla \\times \\vec F)= 0$  We can use this fact to find if there exists a vector field .$\\vec G$ such that .$\\text{curl($\\vec G$)} = \\vec H$ because .$\\text{div(curl($\\vec G$))} = \\text{div($\\vec H$)} = 0$    Vector Form of Green\u0026rsquo;s #  $$\\oint_C \\vec F \\cdot d \\vec r = \\iint_D \\text{(curl ($\\vec F$))} \\cdot \\hat k\\ dA = \\bigg( \\frac{\\delta Q}{\\delta x} - \\frac{\\delta P}{\\delta y} \\bigg) \\hat k$$\n This equation expresses the line integral of the tangential component of .$\\vec F$ along .$C$ as the double integral of the vertical component of .$\\text{curl($\\vec F$)}$ over the region .$D$ enclosed by .$C$.      We can write this using the normal component of .$\\vec F$ too:  With .$\\vec r(t) = \\langle x(t), y(t) \\rangle; t \\in [a,b]$ Recall the unit tangent vector: .$\\vec T(t) = \\frac{1}{\\vert \\vec r ' (t) \\vert} \\langle x'(t), y'(t) \\rangle$ The outward unit normal vector to .$C$ is given by .$\\vec n (t) = \\frac{1}{\\vert \\vec r ' (t) \\vert} \\langle y'(t), -x'(t) \\rangle$ We can then evaluate $$\\oint_C \\vec F \\cdot \\vec n\\ ds = \\int_a^b (\\vec F \\cdot \\vec n)(t) \\vert \\vec r'(t) \\vert\\ dt = \\iint_D \\bigg( \\frac{\\delta P}{\\delta x} - \\frac{\\delta Q}{\\delta y} \\bigg)\\ dA = \\iint_D \\text{div $\\vec F (x,y)$}\\ dA$$ This says that the line integral of the normal component of .$\\vec F$ along .$C$ is equal to the double integral of the divergence of .$\\vec F$ over the region .$D$ enclosed by .$C$.    16.6 Parametric Surfaces and Their Area #  Parametric Surfaces #    Just like how we can describe curves with single parameter (variable) function .$\\vec r(t)$, we can describe surfaces with a vector function .$\\vec r(u,v) = \\langle x(u,v), y(u,v), z(u,v) \\rangle$  .$\\vec r(u,v)$ is called a vector-valued function defined on a region .$D$ in the .$uv$-plane .$x,y,z$ are the component functions of .$\\vec r$, each of which have domain .$D$   In general, a surface given as the graph of a function of .$x$ and .$y$, that is, with an equation of the form .$z = f(x,y)$, can always be regarded as a parametric surface by taking .$x$ and .$y$ as parameters and writing the parametric equations as .$x = x; y = y; z = f(x,y)$  E.x. the plane with point .$(x_0, y_0, z_0)$ and vectors .$\\langle a,b,c \\rangle$ .$\\langle \\alpha,\\beta,\\gamma \\rangle$ is .$\\vec r(u,v) = \\langle x_0, y_0, z_0 \\rangle + u\\langle a,b,c \\rangle + v\\langle \\alpha,\\beta,\\gamma \\rangle$ or .$0 = (\\langle x - x_0, y - y_0, z - z_0 \\rangle) \\cdot (\\langle a,b,c \\rangle \\times \\langle \\alpha,\\beta,\\gamma \\rangle)$    Surfaces of Revolution #    We can write surfaces of revolution as parametric equations too Consider surface .$S$ obtained by rotating the curve .$y = f(x)$ about the .$x$-axis (with .$f(x) \\geq 0$) Therefore, we get the following parameterization:  $$x = x$$  $$y = f(x)\\cos\\theta$$  $$z = f(x)\\sin\\theta$$     Tangent Planes #   Employing the same method as before, we can find the tangent plane to a param surface .$S$ by finding the initial point and the normal vector Given some parameterization .$\\vec r(u,v) = \\langle x(u,v), y(u,v), x(u,v) \\rangle$ and initial point .$P_0 = (x_0, y_0)$\u0026hellip;  Find point .$P_0$ by setting .$x(u,v) = x_0, y(u,v) = y_0, \\dots$ and solving for .$u_0,v_0$ Find normal vector .$\\vec n$ by deriving to get, then cross, the parameterization: .$\\vec n = \\vec r_u \\times \\vec r_v$  If the normal vector isn\u0026rsquo;t zero, the tangent plane is at .$\\vec n (u_0, v_0)$ If it is, then the surface .$S$ isn\u0026rsquo;t smooth (it is at a \u0026ldquo;corner\u0026rdquo;)   The tangent plane can then be expressed as $$(\\vec r_u \\times \\vec r_v)_{(u_0, v_0)} \\cdot (\\langle x,y,z \\rangle - \\langle x_0, y_0, z_0 \\rangle)$$    Surface Area #    The image of the subrectangle .$R_{ij}$ is the patch .$S_{ij}$.\n  Recall that the magnitude of the cross product is the area of a parallelogram formed by two vectors We can think of this as the jacobian of the transformation  If a smooth parametric surface .$S$ is given by the equation $$\\vec r(u,v) = \\langle x(u,v), y(u,v), z(u,v) \\rangle; (u,v) \\in D$$ and .$S$ is covered just once as .$(u,v)$ ranges throughout the parameter domain .$D$, then the surface area of .$S$ is $$A(S) = \\iint_D \\vert \\vec r_u \\times \\vec r_v \\vert\\ dA$$ where $$\\vec r_u = \\langle \\frac{\\delta x}{\\delta u}, \\frac{\\delta y}{\\delta u}, \\frac{\\delta z}{\\delta u} \\rangle; \\vec r_v = \\langle \\frac{\\delta x}{\\delta v}, \\frac{\\delta y}{\\delta v}, \\frac{\\delta z}{\\delta v} \\rangle$$  Surface Area of the Graph of a Function #   For the special case of a surface .$S$ with equation .$z = f(x,y)$, where .$(x,y)$ lies in .$D$ and .$f$ has continuous partial derivatives, we take .$x$ and .$y$ as parameters.  That is, the parametric equations are .$x = x; y = y; z = f(x,y)$ Therefore .$\\vec r_x = \\langle 1, 0, \\frac{\\delta f}{\\delta x} \\rangle; \\vec r_y = \\langle 0, 1, \\frac{\\delta f}{\\delta y};$ and .$\\vec n = \\sqrt{1 + \\frac{\\delta f}{\\delta x}^2 + \\frac{\\delta f}{\\delta y}^2}$ Thus, the surface area becomes $$A(S) = \\iint_D \\sqrt{1 + \\frac{\\delta f}{\\delta x}^2 + \\frac{\\delta f}{\\delta y}^2}\\ dA$$   Notice the similarity between the surface area formula above and the arc length formula  16.7 Surface Integral #  Surface Integral #   The relationship between surface integrals and surface area is much the same as the relationship between line integrals and arc length.  The arc length is a line integral where the density (or weight) function .$f(x,y,z) = 1$  That is, .$\\int_C f(x,y,z)\\ ds = \\int_a^b f(\\vec r(t)) \\vert \\vec r'(t) \\vert$   Similarly, the surface area is found taking the surface integral with density function .$f(x,y,z) = 1$  That is, .$\\iint_S 1\\ dS = \\iint_D \\vert \\vec r_u \\times \\vec r_v \\vert\\ dA = A(S)$     If we define .$\\vec r(u,v) = \\langle x(u,v), y(u,v), z(u,v) \\rangle; (u,v) \\in D$ $$\\iint_S f(x,y,z)\\ dS = \\iint_D f(\\vec r(u,v)) \\vert \\vec r_u \\times \\vec r_v \\vert\\ dA$$  Graphs of Functions #   Any surface .$S$ with equation .$z = g(x,y)$ can be regarded as a parametric surface with parametric equations $$x = x$$  $$y = y$$  $$z = g(x,y)$$    Thus, $$\\vec r_x = \\bigg\\langle 1, 0, \\frac{\\delta g}{\\delta x}\\bigg\\rangle$$  $$\\vec r_y = \\bigg\\langle 0, 1, \\frac{\\delta g}{\\delta y}\\bigg\\rangle$$   $$\\vec r_x \\times \\vec r_y = \\bigg\\langle -\\frac{\\delta g}{\\delta x}, -\\frac{\\delta g}{\\delta y}, 1\\bigg\\rangle$$  $$\\vec n = \\sqrt{\\bigg(\\frac{\\delta z}{\\delta x}\\bigg)^2 + \\bigg(\\frac{\\delta z}{\\delta y}\\bigg)^2 + 1}$$    Therefore, $$\\iint_S f(x,y,z)\\ dS = \\iint_D f(x,y,g(x,y)) \\sqrt{\\bigg(\\frac{\\delta z}{\\delta x}\\bigg)^2 + \\bigg(\\frac{\\delta z}{\\delta y}\\bigg)^2 + 1}\\ dA$$  Similar formulas apply when it is more convenient to project .$S$ onto the .$yz$-plane or .$xz$-plane.    Oriented Surfaces #    With the exception of the Möbius strip, most surfaces are two-sided, meaning they\u0026rsquo;re Orientable surfaces  We start with a surface .$S$ that has a tangent plane at every point .$(x,y,z)$ on .$S$ (except at any boundary point). There are two unit normal vectors .$\\hat n_1$ and .$\\hat n_2 = -\\vec n_1$ at .$(x,y,z)$ If it is possible to choose a unit normal vector .$\\hat n$ at every such point .$(x,y,z)$ so that .$\\hat n$ varies continuously over .$S$, then .$S$ is called an oriented surface  The choice of .$\\hat n$ provides .$S$ with an orientation. There are two possible orientations for any orientable surface For a closed surface, the positive orientation has the normal vectors pointing outward and vis-versa         If .$S$ is a smooth orientable surface given in parametric form by a vector function .$\\vec r (u,v)$ then it is automatically supplied with the orientation of the unit normal vector $$\\hat n = \\frac{\\vec r_u \\times \\vec r_v}{\\vert \\vec r_u \\times \\vec r_v \\vert}$$ E.x., going back to a surface .$z = g(x,y)$ given as the graph of .$g$, the normal unit vector is $$\\hat n = \\frac{\\big\\langle -\\frac{\\delta g}{\\delta x}, -\\frac{\\delta g}{\\delta y}, 1\\big\\rangle}{\\sqrt{\\big(\\frac{\\delta z}{\\delta x}\\big)^2 + \\big(\\frac{\\delta z}{\\delta y}\\big)^2 + 1}}$$  Since the .$\\hat k$-component is positive, this gives the upward orientation of the surface.    Surface Integrals of Vector Fields (Flux) #  If .$\\vec F$ is a continuous vector field defined on an oriented surface .$S$ with unit normal vector .$\\hat n$, then the surface integral of .$\\vec F$ over .$S$ is $$\\iint_S \\vec F \\cdot d\\vec S = \\iint_S \\vec F \\cdot \\hat n \\ dS = \\iint_D \\vec F \\cdot (\\vec r_u \\times \\vec r_v)\\ dA$$ This integral is also called the flux of .$\\vec F$ across .$S$.   In words, the surface integral of a vector field .$\\vec F$ over .$S$ is equal to the surface integral of its normal component over .$S$ (as previously defined). We can apply this to fluids:  Imagine a fluid with density .$\\rho (x,y,z)$ and velocity field .$\\vec v (x,y,z)$ flowing through .$S$. Think of .$S$ as an imaginary surface that doesn\u0026rsquo;t impede the fluid flow, like a fishing net across a stream. Then the rate of flow (mass per unit time) per unit area is .$\\vec F = \\vec v \\rho$ The flux can be interpreted physically as the rate of flow through .$S$.    16.8 Stokes' Theorem #   Just as Green\u0026rsquo;s Theorem relates a double integral over a plane region .$D$ to a line integral around its plane boundary curve, Stokes' Theorem relates a surface integral over surface .$S$ to a line integral around the boundary curve of .$S$ (which is a space curve) Stokes' Theorem: Let .$S$ be an oriented piecewise-smooth surface that is bounded by a simple, closed, piecewise-smooth boundary curve .$C$ with positive orientation. Let .$\\vec F$ be a vector field whose components have continuous partial derivatives on an open region in .$\\mathbb{R}^3$ that contains .$S$. Then $$\\int_C \\vec F \\cdot d \\vec r = \\iint_S \\text{curl } \\vec F \\cdot d\\vec S$$   In words, Stokes' Theorem says that the line integral around the boundary curve of .$S$ (some curve.$C$) of the tangential component of .$\\vec F$ is equal to the surface integral over .$S$ of the normal component of the curl of .$F$ This is since $$\\int_C \\vec F \\cdot d \\vec r = \\int_C \\vec F \\cdot \\vec T\\ ds \\ \\ \\ \\text{ and }\\ \\ \\iint_S \\text{curl } \\vec F \\cdot d\\vec S = \\iint_S \\text{curl } \\vec F \\cdot \\hat n\\ dS$$  16.9 Divergence Theorem #  Divergence Theorem: Let .$E$ be a simple solid region and .$S$ be the boundary surface of .$E$, given with positive (outward) orientation. Let .$\\vec F$ be a vector field whose component functions have continuous partial derivatives on an open region that contains .$E$. Then $$\\iint_S \\vec F \\cdot d\\vec S = \\iiint_E \\text{div } \\vec F\\ dV$$   In words, we can say that the Divergence Theorem says that (under the given conditions) the flux of .$\\vec F$ across the boundary surface of .$E$ is equal to the triple integral of the divergence of .$\\vec F$ over .$E$.  "},{"id":16,"href":"/physics-7b/17/","title":"17: Temperature, Thermal Expansion, \u0026 Ideal Gas Law","section":"Physics 7B","content":"17.1: Atomic Theory #   Atoms are the smallest unit of matter Atomic unit: .$\\text{u} = 1.66\\cdot 10^{-27}$ kg  E.x. Hydrogen weighs .$1.0078 \\text{u}$   Molecular mass of a compound is the sum of the particles (atoms) in the compound  Terms #   Element: Substance that cannot be broken down into smaller substances (gold) Molecule: Group of atoms held together by covalent bonds Compound: Substance made from atoms combined in specific ratios  Brownian Motion #   Random movement seen in pollen/dust, as well as atoms Using Brownian motion, Einstein found the size of an atom to be .$10^{-10}$ meters  Forces #   Atoms and molecules exert an (electric) attractive force on one another by default If an atom/molecule gets too close to another, they exert a repelling force on one another Matter states:  Solid:  Atoms held in matrix formation by strong attractive forces. Atoms vibrate around their mean position   Liquid:  Force between atoms is weaker so atoms move more rapidly within   Gas:  Atom attractive forces are so weak compared to their kinetic energy that they move randomly If two atoms collide, the attractive force is so weak that they may just bounce off one another      17.2: Temperature and Thermometers #   Matter property changes under different temperatures  Sidewalks expand under the sun Electric resistance increases with heat Lightbulb filament glows    Thermometers Types #   Originally used alcohol which expands linearly with heat (water doesn\u0026rsquo;t) Bimetalic strips bend at slightly different rates under heat Electronic thermometers measure resistance change and often have digital screens  Scales #   Fahrenheit: Water freezes at 32 and boils at 212 deg Celsius: Water freezes at 0 and boils at 100 deg Kelvin: Celsius + 273.15K. Written without degree sign. Absolute = 0K Conversions: $$T(^\\circ C) = \\frac{5}{9}(T(^\\circ F)-32)$$ $$T(^\\circ F) = \\frac{9}{5}(T(^\\circ C)) + 32$$ Different materials expand at different rates ro we use constant-volume thermos because it\u0026rsquo;s pressure linearly relates to the temperature  17.3 0th Law of Thermodynamics #   If objects .$A$ and .$B$ are at equilibrium with object .$C$ , then .$A$ and .$B$ are also at equilibrium with one another Systems naturally reach equilibrium over time  Thermal Expansion #   Most materials expand when heated Expansion amount depends on the material Equations (assuming a constant volume .$V$ )  Linear Expansion:  .$\\alpha$ is the coefficient of linear expansion and depends on the material with units .$(^\\circ C)^{-1}$ $$\\Delta l \\approxeq \\alpha l_0 \\cdot \\Delta T$$ $$l_i + \\Delta l = l_f = l_i ( 1 + \\alpha\\Delta T)$$ $$\\frac{dl}{dT} = \\alpha(T)\\cdot l$$ If .$\\Delta T$ is too large such that the temperature dependence of .$\\alpha$ is too large, we can do the following: $$\\int_{l_i}^{l_f} \\frac{1}{l}dl = \\int_{T_i}^{T_f} \\alpha(T) dT$$   Volume Expansion: $$\\beta = \\frac{1}{V} \\frac{dV}{dT}$$ $$V_f \\approxeq V_0 ( 1 + \\beta\\Delta T)$$  .$\\beta \\approx 3\\cdot\\alpha$ = coefficient of volume expansion.   Coefficient of expansion varies at extremely high heats so it only works with small .$\\Delta T$ \u0026rsquo;s Materials must be isotropic (have same expansion properties in all directions) for us to say .$\\alpha \\approx 3\\cdot\\beta$ (Linear) expansion doesn\u0026rsquo;t exist for gas or liquids because they have no fixed space like solids.   Weird water property  .$0 - 4 ^\\circ C$ : Water increases in density .$\\rho^+\\Longrightarrow$ decreases in volume .$V^-$ .$4^\\circ C +$ : Water acts \u0026ldquo;normally\u0026rdquo;: increase in volume .$V$ proportional to temperature .$T$ This explains why pipes burst when frozen and why ice cubes float    17.5 Thermal Stresses #   When the ends a solid (rod) are fixed (such as in beams), temperature changes induce thermal stress due to the clamp limiting expansion/contraction Process Steps:  Beam tries to expand/contract by .$\\Delta l$ Mount reacts with an opposite reactive force, keeping it at it\u0026rsquo;s original length: $$\\Delta l = \\frac{1}{E} \\cdot \\frac{F}{A} \\cdot l_0$$ where .$E$ is Young\u0026rsquo;s modulus for the material. We can also re-write for stress: $$\\frac{F}{A} = \\Delta l \\cdot E \\cdot \\frac{1}{l_0} = (\\alpha l_0 \\Delta T) E \\cdot \\frac{1}{l_0} = \\alpha E \\Delta T$$    17.6 Gas Laws and Absolute Temperature #   Equation at State describes how pressure varies with Temperature, Number of Particles (Molecules), and Volume State is the physical condition of a system Equilibrium State: .$T, N, \\\u0026amp;\\ V = \\text{Constant}$  Laws #   Assume that gasses aren\u0026rsquo;t too dense (so .$P \\sim$ atmospheric pressure) and that they aren\u0026rsquo;t close to liquefaction (boiling) point either (for oxygen, this is .$~183^\\circ \\text{C}$.)      Boyle\u0026rsquo;s Law  .$V \\propto P^{-1}$ [Constant Temperature] .$P$ is absolute, not gauge, pressure Alternatively, .$PV =$ const or .$P_1V_1 = P_2V_2$    Charles\u0026rsquo;s Law  .$V \\propto T$ [Constant Pressure] Alternatively, .$\\frac{V_1}{T_1} = \\frac{V_2}{T_2}$    Gay Lussac\u0026rsquo;s Law  .$P \\propto T$ [Constant Volume] Alternatively, .$\\frac{P_1}{T_1} = \\frac{P_2}{T_2}$      17.7 Ideal Gas Law #  $$PV = nRT = n k_B N_a T = N k_B T$$   .$P$ is the pressure of the gas [Pascals] .$V$ is the volume of the gas [Cubic Meters] .$T$ is the absolute temperature of the gas [Kelvins] .$N$ is the number of molecules of gas   .$n$ is the amount of substance of gas (number of moles) [Moles] .$R$ is the ideal, or universal, gas constant, equal to .$k_B \\cdot N_a = 8.314 \\frac{J}{K\\cdot \\text{mol}}$  Using mass of a gas, different gasses have different proportionality constants So we used number of moles, in which case .$R$ becomes the constant for all gasses      .$k_B $ is the Boltzmann constant  Relates the average relative kinetic energy of particles in a gas with the thermodynamic temperature of the gas   .$N_a$ is the Avogadro constant  The number of particles that are contained in one mole of gas .$n = N/N_A$       This equation is Ideal in that the equation only works for gasses around atmospheric pressure and not excessive temperatures  Moles #   Mole is the SI unit for amount of substance 1 mole = Number of particles in .$\\text{12g}$ of Carbon 1 mole = Number of grams of a substance numerically equal to the molar mass $$n \\text{(moles)} = \\frac{\\text{mass (grams)}}{\\text{molecular mass (g/mol)}}$$  17.8 Problem Solving with .$PV = nRT$ #  STP: Standard Temperature and Pressure #   .$T = 273 \\text{K}$ .$P = 1.00 \\text{atm} = 1.013\\cdot10^5 \\text{N/m}^2 = 101.3 \\text{kPA}$ .$1 \\text{mol of ideal gas} = 22.4\\text{L}$ in volume If P is in liters and V is in atm, then we can use .$R = 0.0821 \\frac{\\text{L} \\cdot \\text{atm}}{\\text{mol} \\cdot \\text{K}}$ Since .$n$ and .$R$ are constants, we can say: $$\\frac{P_1 V_1}{T_1} = \\frac{P_2 V_2}{T_2}$$  17.9 Ideal Gas with Avogadro\u0026rsquo;s Number #   Avogadro\u0026rsquo;s hypothesis:  Equal volume of gas with the same .$P$ and .$T$ have an equal .$n$ umber of particles (molecules) .$N_a$ is avogadro\u0026rsquo;s number: the number of particles that are contained in one mole of gas (or one gram of hydrogen).  .$N_a = 6.022 \\cdot 10^{23}\\ \\text{particles/mole}$   Therefore, if .$N$ is the number of molecules of a gas sample and .$n$ is the number of moles, then $$N = n\\cdot N_A \\Longrightarrow n = \\frac{N}{N_A} \\Longrightarrow PV = \\frac{N}{N_A}RT = Nk_B T$$ where .$k_B $ is Boltzmann\u0026rsquo;s constant .$\\frac{R}{N_A} = 1.38 \\cdot 10^{-23} \\frac{\\text{J}}{\\text{K}}$    17.10 Ideal Gas Temperature #   Triple point: A precise temperature and pressure where the three phases (gas, liquid, and solid) of a substance can coexist in thermodynamic equilibrium. .$P_3 = 4.88\\ \\text{torr};\\ T_3 = 0.01^\\circ C$ for water Ideal Gas, constant volume: $$T = (273.16 K)\\bigg(\\frac{P}{P_3}\\bigg)$$ Constant volume: $$T = (273.16 K)\\lim_{P_3 \\to 0}\\bigg(\\frac{P}{P_3}\\bigg)$$     A typical phase diagram. The solid green line applies to most substances; the dashed green line gives the anomalous behavior of water. For more see 18.4\n   "},{"id":17,"href":"/physics-7b/18/","title":"18: Kinetic Theory of Gases","section":"Physics 7B","content":"18.1 Ideal Gas Laws and Molecular Interpolation #  Ideal Gas Law Assumptions #   There are a large number of molecules, .$N$, each of mass .$m$ that move in random directions at random speeds Molecules are, on average, sufficiently far away from one another (separation .$\\gg$ diameter) Molecules obey classical mechanics so .$KE \\gg PE$ when colliding Collisions are perfectly elastic  Micro and Macroscopic views related through Energy #   In a system with .$N$ molecules each of mass .$m$ and average speed .$\\bar{v}^2$ (also denoted as .$\\langle v^2 \\rangle$), we can combine the ideal gas law with the .$\\overline{KE}$ equation: $$\\overline{K} = \\frac{1}{2} m \\bar{v}^2 = \\frac{3}{2}k_B T$$  This shows .$\\overline{KE} \\propto T$ which makes sense intuitively; cold = slow particle motion E.x: A container is filled with a light and heavy molecule. Which has a greater speed? The lighter molecules do because they are less massive.   And since the system\u0026rsquo;s internal energy .$E_{\\text{int}} = N \\cdot \\overline{K}$ then we can write an important .$PV$ relation + find the gas.$E_{\\text{int}}$: $$T = \\frac{\\frac{1}{2} m\\bar{v}^2}{\\frac{3}{2}k_B} = \\frac{2}{3} \\cdot \\frac{E_{\\text{int}}}{N k_B} \\Longrightarrow PV = \\frac{2}{3}E_{\\text{int}}$$ $$E_{\\text{int}} = N\\cdot \\frac{1}{2}m\\bar{v}^2 \\Longrightarrow PV = \\frac{Nm}{3}\\bar{v}^2 $$ Which shows us that .$(P,V)$ is a representation of (kinetic) energy!  We can think of any point on a .$PV$ diagram in terms of energy    Absolute 0 #    Before, we said .$T = 0K$ exists when .$P = 0$\n  Now we can also see that .$KE = 0$ when .$T = 0$ as well. This would mean that at absolute 0, there is no particle movement\n  We can then write an equation for the root-mean-square (or RMS): $$\\overline{K} = \\frac{3}{2}k_B T \\Longrightarrow \\frac{1}{2}m\\bar{v}^2 = \\frac{3}{2}k_B T;\\ v_{\\text{rms}} = \\sqrt{\\bar{v}^2} = \\sqrt{3k_B\\frac{T}{m}} = \\sqrt{3 R\\frac{T}{M}} $$ $$\\bar v ^2 = \\frac{1}{N}\\sum_i^N n_i v_i^2 \\Longrightarrow v_{\\text{rms}} = \\frac{1}{\\sqrt N} \\sqrt{\\int_0^\\infty n(v)\\cdot v^2 dv} $$\n This is the typical velocity of particles that make up the gas/liquid .$M$ is the molar mass of the gas [kilograms per mole] .$v_{\\text{rms}}$ is also called the thermal velocity, .$v_{\\text{th}}$ Fun fact: Less than 1% of particles of particles exceed .$v_{\\text{rms}}$ Example problems:  If a sample is quasistatically shrunk to half it\u0026rsquo;s original volume with no change in pressure, the new root-mean-square speed is .$1/\\sqrt{2}$ times the original rms speed If we double the root-mean-square speed (thermal speed) of the molecules of a gas, then its temperature must increase by a factor of 4      18.2 Distribution of Molecular Speeds #   $$f(v) = 4\\pi N \\bigg( \\frac{m}{2 \\pi k_B T}\\bigg)^{3/2} v^2 e^{ -\\frac{1}{2} \\cdot \\frac{mv^2}{k_B T}}$$   Recognize that .$f(v) \\propto T^{-3/2}, v^2$ and exponentially .$\\propto KE/T$  If .$T$ increases, so does .$KE$ and .$v$ thus variance .$\\sigma^2$ increases and the distribution becomes \u0026ldquo;stretched\u0026rdquo; (lower max, thicker tail) Spread of important values (.$v_p, v_{\\text{avg}}, \\text{etc.}$) are spread out further from one another Area stays constant (always equal to .$N$)   .$f(v)\\ dv$ represents the number of molecules with .$v \\in [v, v+dv]$  That is, .$\\int_0^\\infty f(v) dv = N$   .$\\sigma^2$ is the variance, or standard deviation squared, which can be found from the equation .$\\langle v^2 \\rangle - \\langle v \\rangle ^2$ Chemical Reactions  Some reactions only occur at a certain energy levels (activation energy) Warmer conditions lead to faster moving particles which have energy That\u0026rsquo;s why reaction speed .$\\propto$ temperature    Important Values #  $$v_p = 1.41 \\sqrt{k_B\\frac{T}{m}}$$  $$v_{\\text{avg}} = 1.60 \\sqrt{k_B\\frac{T}{m}}$$  $$v_{\\text{rms}} = \\sqrt{3 k_B \\frac{T}{m}}$$    Notice how .$v \\propto m^{-1/2}$, which explains why it\u0026rsquo;s easier for lighter particles to escape earth\u0026rsquo;s atmosphere!  18.3 Real Gases and Phase Changes #    (a) Each curve represents the relationship between .$P$ and .$V$ at a fixed temperature; the upper curves are at higher temperatures. The lower curves are not hyperbolas, because the gas is no longer an ideal gas. (b) An expanded portion of the diagram for low temperatures, where the phase can change from a gas to a liquid.\n  Phase changes can only be explained if we\u0026rsquo;re considering the behavior of a real \u0026ndash; not ideal \u0026ndash; gas  This is because phase changes involve intermolecular bonds which we only factor in when considering real gases   At high enough pressures, gases take up less volume than expected.  This effect is magnified with lower temperatures   At lower temperatures, the .$PE$ attractive forces between particles aren\u0026rsquo;t negligible with respect to .$KE$ At the critical points (when .$PV$ curve is horizontal), gases may no longer change to liquid under any pressure  This point varies by substance Gas below the critical point is vapor Gas above the critical point is just gas   Sublimation: When substance changes from solid to gas, skipping liquefaction step     Ideal gases would have a straight line along a .$PV/nRT \\text{ vs } P$ graph Real gases vary don\u0026rsquo;t follow this line and deviate from it proportional to their molecule size and weight (resulting in higher .$a$ and .$b$ values respectively \u0026ndash; see 18.5)  18.4 Vapor, Pressure, and Humidity (not covered) #  Evaporation #   Molecules in liquid are held tightly together with intermolecular attractive forces (covalent hydrogen bonds) Some molecules may momentarily leave the liquid if their velocity is fast enough  If velocity isn\u0026rsquo;t too large, then the particle will be pulled back to the liquid surface If velocity is large enough, then the particle will break the intermolecular bonds and leave the liquid to enter their gas form  Low probability of occurring     Because .$v_{\\text{particle}} \\propto T$, the .$\\text{evaporation rate} \\propto T$ As fast moving (thus hot) particles leave the liquid, the liquid\u0026rsquo;s temperature decreases  That is, evaporation is a cooling process    Vapor Pressure #   A typical phase diagram. The solid green line applies to most substances; the dashed green line gives the anomalous behavior of water\n Green line = SL Line; transition between solid .$\\iff$ liquid (melting/freezing) Red line = SV; transition between solid .$\\iff$ vapor (sublimation/deposition) Blue line = LV; transition between liquid .$\\iff$ vapor (vaporizing/condensing)        When evaporation particles go from gas to liquid, it\u0026rsquo;s called condensation The number of particles in vapor increases until the rate of particles condensing is equal to the number of particles becoming vapor (equilibrium!)  When this state is reached, the space above the water is considered saturated Pressure of vapor saturation is called (saturated) vapor pressure   Saturated Vapor Pressure varies with the volume of container  If volume above the liquid was reduced, then the density would increase so particles would condense back to liquid Assuming .$T$ is constant, vapor pressure would stay constant too   Since at high temperatures there are more particles (entering/already in) the vapor phase, higher pressure is required for equilibrium When the volume is large, it\u0026rsquo;s likely that all the liquid evaporates before equilibrium  Boiling #   Boiling occurs when saturated vapor pressure equals external pressure Bubbling forms as temperature approaches boiling temperature  If the pressure in the bubbles are less than the external pressure, the bubbles are crushed Otherwise, bubbles are able to rise to surface   Boiling point is proportional to pressure  Lower pressure = lower temperature required for boiling point    Partial Pressure and Humidity #   In gases composed of multiple other gases, the total pressure is the sum of all partial pressures for each of other sub gas Partial Pressure is the pressure a single gas would exert by itself  The partial pressure of water in the air can be as low as zero and vary up to a maximum equal to the saturated vapor pressure (of water at the given temperature)   Relative Humidity: ratio of partial pressure of water vapor to the saturated vapor pressure at a given temperature $$\\text{Relative Humidity} = \\frac{\\text{partial pressure of }H_2O}{\\text{saturated vapor pressure of }H_2O} \\cdot 100\\%$$ Super Saturation: .$P_{\\text{partial}} \u0026gt; P_{\\text{saturated vapor pressure}}$  Happens when temperature decreases Excess water condenses as dew / mist    18.5 Van der Waals Equation of State #  Microscopic (molecular) view accounts for\u0026hellip;\n Finite size of molecules (before we assumed separation .$\\gg$ diameter, ignoring density)  Since gas particles aren\u0026rsquo;t negligible in size, we can\u0026rsquo;t use all of our volume Particles are solid spheres that can\u0026rsquo;t get closer than .$2r$ to one another  That means .$V$ is over-estimated: .$V_{\\text{real}} \u0026lt; V_{\\text{ideal}}$ Lower volume mean more collisions, leading to pressure being higher than estimated with the ideal gas law: .$P_{\\text{real}} \u0026gt; P_{\\text{ideal}}$   The unavailable volume due to particles, .$b$, depends on the .$n$umber of moles $$ P(V-nb) = nRT \\Longrightarrow P\\bigg(\\frac{V}{n} - b\\bigg) = RT\\ \\ \\ \\big[\\text{Clausius Equation of State}\\big]$$ Where .$b$ is the volume consumed by 1 mol of gas with the units .$\\text{V/mols}$   Forces between molecules (before we assumed that forces only played an effect in collisions)  At low .$T$, electric attractive forces aren\u0026rsquo;t 0  Particles towards the edge are slowed down by the other particles attractive forces For that reason, our pressure is lower than estimated with the ideal gas law: .$P_{\\text{real}} \u0026lt; P_{\\text{ideal}}$   On the contrary, with higher temperatures gases appear more ideal because .$KE$ is greater than the intermolecular .$PE$ \u0026ldquo;Slow down\u0026rdquo; is proportional to the gas density  M ore dense means more molecules means more intermolecular forces   Pressure reduced by the following equation where .$n/V$ is the gas density and .$a$ is a constant unique to the gas that measures the attractive forces between particles $$ a\\bigg( \\frac{n}{V}\\bigg)^2$$ .$a \\propto m$ and boiling point because the lower the boiling point, the less energy is required to break the internal bonds     Thus, we can rewrite the ideal gas law with the last two equations as $$ \\bigg(P+ \\frac{a}{(V/n)^2}\\bigg)\\bigg(\\frac{V}{n} - b\\bigg) = RT \\ \\ \\big[\\text{Van der Waals Eq of State}\\big]$$  Note that these equations aren\u0026rsquo;t accurate in all cases, but they\u0026rsquo;re the best generalization we can do and they show the relation With low densities, .$a\\big/(V/n)^2 \\ll P$ and .$b \\ll V/n$ so Van der Waals equation reduces to the ideal gas law    18.6 Mean Free Path #   Molecules bump into each other a lot which slow them down Mean free path: Average distance between collisions is proportional to .$\\rho ^{-1}, r^{-1}$ $$l_m = \\frac{1}{4\\pi \\sqrt{2}r^2 (N/V)}$$  18.7 Diffusion (not covered) #   Particles diffuse from high to low concentrations until equilibrium is reached (when .$\\rho$ is constant throughout) Given a tube with a cross section area .$A$, two concentrations, .$C_1$ and .$C_2$, separated by .$\\Delta x$, we can write the rate of diffusion, .$J$, as $$J = DA \\frac{C_1 - C_2}{\\Delta x} = DA \\frac{dC}{dx} \\ \\ \\text{[Fick\u0026rsquo;s Law]}$$ .$D$ is the diffusion constant  Varies with temperature, viscosity, and particle size    "},{"id":18,"href":"/physics-7b/19/","title":"19: Heat \u0026 First Law of Thermo","section":"Physics 7B","content":"19.1 Heat as Energy Transfer #  Units #   Heat unit is calorie (cal)  The amount of heat needed to raise the temperature of 1 gram of water by 1 celsius $$4.186 \\text{ J} = 1 \\text{ cal}$$   Kilocalorie (kcal, Calorie) is more common  Amount of heat needed to raise 1 kg of water by 1 celsius $$4.186 \\text{ kJ} = 1 \\text{ kcal}$$      British system of units has British thermal units (Btu)  One Btu is the heat needed to raise the temperature of 1 lb of water by 1 Fahrenheit $$1 \\text{ Btu} = 0.252 \\text{ kcal} = 1056 \\text{ J}$$ Gas companies use the unit therm: .$10^5 \\text{ Btu}$      Heat #   Heat is energy transferred from one object to another because of a difference in temperature.  Energy transfers from hot to cold object until equilibrium   The SI units for heat is the joule: this is because heat is a form of energy!  19.2 Internal Energy #   Internal Energy: The sum of all the energy of all the molecules in an object  Sometimes called thermal energy    Difference between Temp, Heat, and Internal Energy #   Temperature is the average kinetic energy of all of the molecules Internal energy is the sum of the energy of all of the molecules  E.x. Two equal-mass iron ingots could the same temperature as a single ingot, but the two would have double the internal energy   Heat refers to the transfer of energy from one object to another due to a difference in temperatures  Direction of transfer depends on temperature, not internal energy E.x. .$50\\text{ g}$ of .$30^\\circ\\text{ C}$ water mixed with .$200 \\text{ g}$ of .$25^\\circ \\text{ C}$ water results with heat transferring from the smaller sample with less internal energy to the larger sample with more internal energy.    Calculating Internal Energy #   Internal energy is the sum of all the translational kinetic energy of the molecules in a monatomic gas  Monatomic: Gas with one atom per molecule   We can re-write this as the average KE per molecule times the total number of molecules, .$N$ $$E_{\\text{int}} = N \\bigg(\\frac{1}{2}m\\bar{v}^2\\bigg) = \\frac{3}{2}Nk_B T = \\frac{3}{2}nRT$$ We can see that internal energy for a monatomic gas depends only on the temperature and number of moles If a gas isn\u0026rsquo;t monatomic, then we need to consider the rotational and vibrational energy of the molecules  Non-monatomic gasses result in a internal energy at a given temperature compared to a monatomic   The internal energy of real gases depends mainly on temperature  There are some exceptions of gases depending on pressure and volume as well   Internal energy of liquids and solids is more complex  It includes electric potential energy of the chemical bonds    19.3 Specific Heat #   Amount of heat required to change the temperature of a material is found with the following: $$\\Delta Q = mc \\Delta T$$  .$c$ specific heat capacity that depends on the material .$[\\text{J}/(\\text{C}^\\circ\\text{ kg})]$   For water at .$15 ^\\circ \\text{ C}$ and constant pressure .$1 \\text{atm}$, .$c = 4168 \\text{ J}/(\\text{C}^\\circ\\text{ kg}) = 1.00 \\text{ kcal}/(\\text{C}^\\circ \\text{ kg})$  .$c$ does vary to some extent with temperature (and slightly pressure), but for small .$\\Delta T$ we can say .$c$ is a constant   Relative to other materials/substances, water has a high specific heat capacity  19.4 Calorimetry #  Types of Systems #   System: Any (set of) object(s) we choose to consider Closed System: Mass is constant, but energy may be exchanged within environment  Isolated: If no energy in any form passes across its boundaries We idealize systems to be closed systems, which is rare in the real world Heat will flow from hot to cold region of system until equilibrium We can assume that no energy is lost; heat lost in one part = heat gained in another part or .$\\Sigma Q = 0$   Open System: Mass and energy may enter/leave  Calorimeter #   Calorimetry: Quantitative measure of heat exchange Calorimeter tend to have insulation so that no heat is exchanged with the surrounding air Often use thermometer to measure change the temperature E.x. a substance sample will be heated up, measured, then quickly placed inside cool water of calorimeter  The heat lost from the sample will be gained by the water and the calorimeter cup Measuring final temperature of the mixture lets us calculate the specific heat   Assume that small masses like the thermometer/stirrer are negligible  19.5 Latent Heat #   Change of Phase: When a material changes from solid to liquid or liquid to gas.  A certain energy is required for a phase change During phase changes, temperature stops increasing and all energy goes into the phase change Latent heat is lost during phase change (often in the form of heat) Heat of fusion  .$L_F$: Heat required to change .$1.0 \\text{ kg}$ of a substance from solid to liquid state Heat fusion of water is .$79.7 \\text{kcal/kg} = 333 \\text{kJ/kg}$   Heat of Vaporization  .$L_V$: Heat required to change a substance from liquid to vapor phase Heat vaporization is .$539 \\text{kcal/kg} = 2260 \\text{kJ/kg}$      Heat involved in the phase change depends on the mass and latent heat: $$\\Delta Q = mL$$ Therefore, when considering the change in a system involving heating a substance to a phase change (e.g. boiling at temperature .$T$), we can write: $$\\Delta Q_{\\text{total}} = m_L c \\Delta T + m_S L$$  .$m_L$ is the total mass of the substance before the phase change (e.x. initial mass of substance, don\u0026rsquo;t subtract amount that vaporized) .$m_S$ is the mass of the substance that underwent a phase change (e.x. mass that vaporized)    Evaporation #   Heat of Vaporization of water increases slightly with a decrease in Temperature At .$20^\\circ \\text{ C}$, it\u0026rsquo;s .$585 \\text{ kcal/kg}$ When liquid evaporates, the remaining liquid cools because the heat/energy comes from the water itself Therefore, internal energy decreases with evaporation  Kinetic Theory of Latent Heats #   At melting point, the latent heat of fusion doesn\u0026rsquo;t increase the average KE / temperature Rather, the energy goes into overcoming the PE associated with the forces between the molecules  Once the molecules in a solid are broken from there lattice formation, they can freely roll over one another as a liquid   More energy is required for liquid to gas phase because the average distance between the molecules is greatly increased  The larger the distance that the molecules have to be separated, the more work has to be done to pull them apart    19.6 First Law of Thermo #   Heat and work are different  Heat is the transfer of energy due to a difference in temperature \u0026ndash; hot/cold bath around gas chamber Work is the transfer of energy not due to a temperature difference \u0026ndash; piston applying force to a gas   Internal energy and temperature are both proportional to heat and work though with the First law equation: $$\\Delta E_{\\text{int}} = Q - W = E_{\\text{int, 2}} - E_{\\text{int, 1}} \\ \\ \\ \\text{[First Law of Thermo.]}$$  .$W$ is net work done by the system  Work done by system is .$\\texttt{+}$ Work done on the system is .$\\texttt{-}$ Gas expands .$\\Longrightarrow$ sys looses energy      .$Q$ is net heat added to the system  Heat added is .$\\texttt{+}$ Heat lost is .$\\texttt{-}$ Gas is heated .$\\Longrightarrow$ sys gains energy       .$Q$ and .$W$ are not state variables in that a static state doesn\u0026rsquo;t have \u0026ldquo;heat\u0026rdquo; or \u0026ldquo;work\u0026rdquo; \u0026ndash; only when the system changes through thermodynamic process can we measure heat/work.  This is unlike .$P, V, T$ and .$E_{\\text{int}}$ which are state variables (can be measured at all states)   We can also extend the first law to include systems that have KE and PE: $$\\Delta K + \\Delta U + \\Delta E_{\\text{int}} = Q - W = E_{\\text{int, 2}} - E_{\\text{int, 1}}$$  19.7 Thermodynamic Process and the 1st Law #  Isothermal Process (.$\\Delta T = 0$) #    When temperature is constant, .$PV$ is constant too Each label of points in the graph above represent the systems states (it\u0026rsquo;s pressure and temperatures) Isotherms: curves in PV diagram  At a lower temperature, an isothermal process would be represented by the isotherm .$A\u0026rsquo;B'$   We also assume that the container is a heat reservoir: a body whose mass is so big that the temperature doesn\u0026rsquo;t change when heat is exchanged We increase internal energy by doing work, such as by decreasing the volume of the container with by applying a force to a piston over some distance  We assume that expansion/compression is  quasistatic: we decrease the volume slow enough that we can consider it a series of equilibrium states all at the same temperature   E.x. if we started with state .$A$ and added heat .$Q$ to the system, the system would reach point .$B$  If .$T$ remain constant, the volume will expand, both doing work .$W$ on the environment and decreasing the .$P$ We know .$E_\\text{int} = \\frac{3}{2}nR\\Delta T$, and since .$\\Delta T = 0 \\Longrightarrow E_\\text{int} = 0$ Thus, .$E_\\text{int} = Q - W \\Longrightarrow W = Q$    $$$$ $$$$ $$W = \\int_{V_A}^{V_B} P \\ dV$$ $$\u0026hellip; = nRT \\int_{V_A}^{V_B} \\frac{dV}{V}$$ $$\u0026hellip; = nRT \\ln{\\frac{V_B}{V_A}}$$    Adiabatic Process (.$\\Delta Q = 0$) #   No heat allowed to flow in our out of system. This can happen if\u0026hellip;  Process happens so quickly that heat, a slow process, has no time to flow in/out  E.x. a combustion engine happens quickly it\u0026rsquo;s nearly adiabatic   System is well insulated   If a system experiences an adiabatic process slowly, it will look similar to curve .$AC$ Since .$Q = 0 \\Longrightarrow \\Delta E_\\text{int} = -W$ In a reverse processes represented by .$CA$ (adiabatic compression), work is done on the gas so .$E_\\text{int}$ and .$T$ rise    $$$$ $$$$ $$W = \\int_{V_A}^{V_B} P \\ dV$$ $$\u0026hellip; = P_A V_A ^\\gamma \\int_{V_A}^{V_B} \\frac{1}{V^\\gamma}\\ dV$$ $$\u0026hellip; = \\frac{P_A V_A - P_B V_B}{1-\\gamma}$$   19.9 Adiabatic Expansions #   The .$PV$ curve for adiabatic expansion (.$Q = 0$) is slightly less steep than isothermal processes (.$\\Delta T = 0$)  This means that for the same change in volume, the pressure will be greater in adiabatic processes Therefore, the temperature of a gas must drop in adiabatic expansion and rise in adiabatic compression Likewise, if during an adiabatic process the volume increases then the internal energy must decrease   We can relate .$P$ and .$V$ for a quasistatic expansion / compression with $$PV^\\gamma = \\text{[constant] for } \\gamma = \\frac{C_P}{C_V} = 1 + \\frac{R}{C_V}$$ \u0026hellip;which can also be written as the following (with .$d$ = degrees of freedom) $$T_A^{C_V/R} V_A = T_B^{C_V/R} V_B$$  $$C_V = \\frac{d}{2}R$$  $$C_P = \\frac{d+2}{2}R$$  $$\\gamma = \\frac{d+2}{d}$$     Free Expansion #   A type of adiabatic process where gas is allowed to expand in a volume without doing any work Must be done with insulated containers so that no heat is able to flow in/out; .$Q = 0$ No work is done either because no object is moved; .$W = 0$ Thus, .$\\Delta E_\\text{int} = 0$ and .$\\Delta T = 0$ In reality, we see temperature slightly drops meaning internal energy does depend on pressure or volume as well as temperature.  Isobaric and Isovolumetric .$(\\Delta P = 0, \\Delta V = 0)$ #     Isobaric: .$\\Delta P = 0 \\Longrightarrow Q = \\Delta E_\\text{int} + W = \\Delta E_\\text{int} + P\\Delta V$. The heat transferred to the system does work, but also changes the internal energy of the system  Isovolumetric: .$\\Delta V = 0 \\Longrightarrow W = 0 \\Longrightarrow Q = \\Delta E_\\text{int}$. The thermodynamic process is the addition or removal of heat. First law of thermo holds for both of these processes  $$$$ $$$$ $$W_{\\text{Isovol.}} = 0$$ $$W_{\\text{Isobaric}} = \\int_{V_A}^{V_B} P \\ dV$$ $$\u0026hellip; = P \\Delta V$$ $$\u0026hellip; = P_B(V_B - V_A)$$ $$\u0026hellip; = nRT_B(1 - \\frac{V_A}{V_B})$$     Work done in volume changes .$(\\Delta V \\neq 0)$ #   For quasistatic processes: $$dW = \\vec{F} \\cdot d\\vec{l} = PA d\\vec{l} = P\\ dV \\ \\ \\ \\text{(1)}$$ $$W = \\int dW = \\int_{V_A}^{V_B} P\\ dV \\ \\ \\ \\text{(2)}$$ .$\\text{(1)}$ Where .$F = PA$ is the force the gas exerts on the piston and .$d\\vec{l}$ is the (small) distance the piston moves .$\\text{(2)}$ This shows that the work done is the area under the .$PV$ curve  This equations are valid for work done in any volume change (solid, liquids, gas)   .$W$ (and even .$Q$) depends on the initial and final states and also on the process (or path)  19.8 Molar Specific Heats for Gases and Equipartition of Energy #  Molar Specific Heat #   Specific heat for gases depends heavily on the process and how it\u0026rsquo;s carried out Specific heat for constant pressure and constant volume vary We use molar specific heat for gases: .$C_V$ and .$C_P$ which are defined as the heat required to raise .$1 \\text{ mol}$ of gas by .$1^\\circ \\text{ C}$ at a constant volume or pressure respectively. We then use .$n$ instead of .$m$ in our heat equations: $$\\Delta Q = nC_V \\Delta T = mc_V \\Delta T\\ \\ \\ \\text{[Constant Volume]}$$ $$\\Delta Q = nC_P \\Delta T = mc_P \\Delta T\\ \\ \\ \\text{[Constant Pressure]}$$ which we can then relate to the specific heat with .$M$ as the molecular mass of the gas, .$m/n$ in grams/mol: $$C_V = Mc_V$$  $$C_p = Mc_p$$    In a heating process, when .$\\Delta V = 0$ then the heat added, .$Q_V$ goes entirely into internal energy: .$Q_V = \\Delta E_\\text{int}$ However, when pressure is constant work is done. Thus, heat added, .$Q_P$, goes towards increasing internal energy and work: .$W = P\\Delta V$  Therefore, more heat is needed for a constant pressure system: .$Q_P = \\Delta E_\\text{int} + P\\Delta V$   Since .$\\Delta E_\\text{int}$ is the same for both processes, we can write .$Q_P - Q_V = P \\Delta V$  With an ideal gas, we know .$V = nRT/P$ so .$\\Delta V = nR\\Delta T/P$ which we can combine with the prior equations to get: $$nC_P\\Delta T - nC_V \\Delta T = P\\bigg(\\frac{nR\\Delta T}{P}\\bigg) \\Longrightarrow C_P - C_V = R$$   We can also relate internal energy to molar specific heat for gases at constant volumes: $$\\Delta E_\\text{int} = Q_V \\Longrightarrow \\frac{\\text{[Deg. of Freedom]}}{2}nRT = nC_V\\Delta T \\Longrightarrow C_V = \\frac{3}{2}R$$ We can then plug in our new value for .$C_V$ into the second to last equation .$C_P - C_V = R$ to get .$C_P = \\frac{5}{2}R$ for a monatomic gas. We can also combine our equations to write a relation between internal energy and temperature again: $$\\Delta E_\\text{int} = nC_V \\Delta T$$  Equipartition of Energy #    Degrees of Freedom: The number of independent ways a molecule can posses energy  Degrees of freedom depend on the temperature At low temperatures, the only degree of freedom is from translational .$KE$  Starting after .$0K$ Diatomic gas: .$C_V = \\frac{3}{2}R$ (3 for each axis) Sum of .$\\frac{1}{2}m \\langle v_x, v_y, v_z \\rangle$   At \u0026ldquo;regular\u0026rdquo; temperatures, the molecules posses rotation energy  Around .$50K$ Diatomic gas: .$C_V = \\frac{5}{2}R$ Sum of .$\\frac{1}{2}I \\langle 0, \\omega_y, \\omega_z \\rangle$ (since it\u0026rsquo;s rotating about .$\\hat x$ meaning .$E_{\\text{rotational, }x}) = 0$   At higher temperatures, the molecules gain energy associated with their vibrations:  Around .$1000K$ One from KE of the molecules vibrating back and forth: .$\\frac{1}{2}mv_{\\text{COM}}^2$ The second from PE of the vibrational motion (think of this as a spring\u0026rsquo;s PE): .$\\frac{1}{2}kx^2$   Solids:  The molar temperature of solids at high temperatures is close to .$3R$. At high temperatures, there are six degrees of freedom: three from vibrational KE in the .$x, y,$ and .$z$ axis and three more from spring PE in the same axis Some of these degrees of freedom aren\u0026rsquo;t active at lower temperatures     Principle of Equipartition of Energy: Energy is shared equally among degrees of freedom and each degrees has energy .$\\frac{1}{2}k_B T$  Thus, for a particle with three degrees of freedom (such as a monatomic gas) .$C_V = \\frac{3}{2}R$ Diatomic gases have five degrees so they have .$C_V = \\frac{5}{2}R = 4.97 \\text{ cal/(mol K)}$ and have .$E_\\text{int} = N(\\frac{5}{2}k_B T) = n C_V \\Delta T = \\frac{5}{2}nRT$ where .$n$ is the number of moles and .$N$ is the number of molecules    19.10 Heat Transfer #  Conduction #   Heat transfer by contact Conduction can be visualized thinking of molecular collisions  The hot end of an object has fast moving molecules These molecules bump into other molecules, transferring them some of their own KE This keeps repeating down the object   Free electrons are the primary source of these collisions Heat conduction only occurs when there is a difference in temperatures Heat conduction rate is proportional to the difference in temperatures: $$\\frac{\\Delta Q}{\\Delta t} = - kA\\frac{T_1 - T_2}{l}$$ Where .$A$ is the cross section area, .$l$ is the distance between the two ends, and .$k$ is a constant called thermal conductivity that depends on the material  Good insulator / poor thermal conductors have a low .$k$  Metals have .$k\u0026gt;1$ Wood, plastics have small .$k$s   Building materials sometimes list the thermal resistance, .$R$, which is equal to .$R = \\frac{l}{k}$ where .$l$ is the material\u0026rsquo;s thickness  Larger .$R$ means better insulation     If .$k$ or .$A$ isn\u0026rsquo;t constant, we consider a small thickness: $$ \\frac{dQ}{dt} = -kA \\frac{dT}{dx}$$ .$\\frac{T_1 - T_2}{l} \\text{ and } \\frac{dT}{dx}$ are called the temperature gradients We have a negative sign in the equation above because the direction of heat flow is opposite to the temperature gradient A steady system state is reached when heat flow through each layer of an object is equal  Convection #   Heat flow by movement of mass Convection involves heat flowing by the bulk movement of molecules from one place to another Whereas conduction involved molecules/electrons moving over small distances, convection involves the movement of a large number of molecules over a long distance Natural Convection occurs in systems where a cold substance (air, water) is warmed and subsequently expands, decreasing density and thus rising Warm fluid/gases are less dense, thus they rise compared to colder fluid/gas  Radiation #   Whereas conduction and convection require a medium, radiation doesn\u0026rsquo;t  The sun\u0026rsquo;s rays are a form of heat and travel through (nearly empty) space  Radiation of the sun\u0026rsquo;s rays arrive on a clear day at a rate around .$1000 \\text{W/m}^2$   Most of the time radiation consists of electromagnetic waves, but infrared (IR) wavelengths are responsible for heating Earth   The rate at which energy leaves a radiation object, .$Q/t$, is $$ \\frac{\\Delta Q}{\\Delta t} \\varepsilon \\sigma A T^4$$  .$\\varepsilon$ is called emissivity.  Between 0 and 1 Characteristic of the surface of the radiating material Black surfaces close to one, shiny metal surfaces close to zero Depends slightly on the temperature of the material A good absorber is also a good emitter  A black tee shirt gets very hot because it absorbs nearly all the radiation that hits it     .$\\sigma$ is the Stefan-Boltzmann constant: .$\\sigma = 5.67 \\cdot 10^{-8} \\text{ W/(m}^2 \\text{K}^4\\text{)}$   Objects also absorb heat of surrounding objects. This net heat flow can be found by $$ \\frac{\\Delta Q}{\\Delta t} \\varepsilon \\sigma A (T_1^4 - T_2^4)$$  Where .$T_1$ is the object\u0026rsquo;s temperature and .$T_2$ is the surrounding environment\u0026rsquo;s temperature .$T_1 \u0026gt; T_2$: net flow of heat is from object to the surroundings .$T_1 \u0026lt; T_2$: net flow of heat is from surroundings into object, raising the object temperature    "},{"id":19,"href":"/physics-7b/20/","title":"20: Second Law of Thermo","section":"Physics 7B","content":"20.1 Intro #   Second law states that systems only increase in entropy over time That is, most systems are on directional  E.x. mixing salt and pepper together result in an mixture. No matter how much you keep mixing it, they won\u0026rsquo;t naturally separate and return to the initial state even though it follows first law of thermo (conserving energy)   (Specific) Second Law of Thermo  Heat can flow spontaneously from a hot object to a cold object; heat will not flow spontaneously from a cold object to a hot object.\n   20.2 Heat Engines #   Heat Engine: Any device that changes thermal energy into mechanical work, such as steam or car engine  Show importance in developing the second law of thermo   Mechanical energy can only be obtained from thermal energy when heat is allowed to flow from high temp to low temp  During this process, some of the heat can be transformed to mechanical work   Heat engines run in a repeating cycle: the system returns repeatedly to its starting point and thus can run continuously   In each cycle .$\\Delta E_{\\text{int}} = 0$ because it returns to the initial state Thus, heat input .$Q_H$ at a .$T_H$ is partly transformed into work .$W$ and partly exhausted as heat .$Q_L$ at .$T_L$ By conservation of energy, .$Q_H = W+Q_L$. Operating Temperatures: The high and low temperatures, .$T_H, T_L$ .$Q_H, Q_L, W \u0026gt; 0$       Change in temperature is required for a change in pressure  Gas exhaust is cooled to a lower temperature and condensed so that the exhaust pressure is less than intake pressure Thus, the work the piston must do on the gas to expel it is less than the work done by the gas on the piston during the intake    20.3 (Ir)reversible Processes; Carnot Engine #   Carnot engine is ideal: doesn\u0026rsquo;t take into account turbulence in gas, friction, etc. Consist of four processes done in a cycle  Isothermal expansion (.$\\Delta T = 0$) with the addition of heat .$Q_H$ along path .$ab$ at temperature .$T_H$ Adiabatic expansion (.$Q = 0$) lowering temperature to .$T_L$ along path .$bc$ Isothermal compression (.$\\Delta T = 0$) leads to heat .$Q_L$ flowing out along path .$cd$ Adiabatic compression (.$Q = 0$) occurs path .$da$, returning to temperature .$T_H$   Each process is reversible; that is, each occurs infinitely slowly so that the process could be considered a series of equilibrium states  Real processes are irreversible      Work done in a cycle is proportional to area enclosed by the curve representing the cycle on a .$PV$ diagram (.$abcd$) Efficiency is given by .$e = 1-\\frac{Q_L}{Q_H} \\Longrightarrow e_{\\text{ideal}} = 1 - \\frac{T_L}{T_H}$ Carnot\u0026rsquo;s Theorem:  All reversible engines operating between the same two constant temperatures .$T_H$ and .$T_L$ have the same efficiency. Any irreversible engine operating between the same two fixed temperatures will have an efficiency less than this.\n  Only at absolute zero would 100% efficiency be reachable. But getting to absolute zero is a practical (as well as theoretical) impossibility Kelvin-Planck statement of the second law of thermodynamics:  no device is possible whose sole effect is to transform a given amount of heat completely into work.\n   20.4 Refrigerators, AC, Heat Pumps #   Refrigerators, air conditioners, and heat pumps are just the reverse of heat engines  Each transfer heat ouf of a cool environments into a warm environment   A perfect fridge (no work required to take heat from low temp to high temp) is impossible  No device is possible whose sole effect is to transfer heat from one region at a temperature .$T_L$ into a second region at a higher temperature .$T_H$ (Clausius statement)\n         Coefficient of Performance (COP): .$\\text{COP} = \\frac{Q_L}{W}$\n The more heat .$Q_L$ removed from a fridge for a given amount of work, the more efficient it is Energy is conserved, so we can write .$Q_L + W = Q_H$ or .$W = Q_H-Q_L$ We can then write .$\\text{COP} = \\frac{Q_L}{W} = \\frac{Q_L}{Q_H-Q_L} \\Longrightarrow \\text{COP}_{\\text{ideal}} = \\frac{T_L}{T_H-T_L}$    Heat pump\n Electric motor does work .$W$ to take heat .$Q_L$ from outside at low temperature and delivers heat .$Q_H$ to inside at a hot temperature Whereas fridges cool (remove .$Q_L$), heat pumps heat (deliver .$Q_H$) Thus, COP uses .$Q_H$ instead of .$Q_L$: .$\\text{COP} = \\frac{Q_H}{W}$ COP is greater than 1 because .$W+Q_L = Q_H$     20.5 Entropy #   Entropy, unlike heat, is a state variable and measures the (dis)order of a system When heat is added to a system by a reversible process then change in entropy is $$\\Delta S = \\frac{Q}{T} \\ \\ \\text{[Constant T]} \\Longrightarrow dS = \\frac{dQ}{T} \\ \\ \\text{[Non-const T]}$$ The change of entropy between two states doesn\u0026rsquo;t depend on the process. Thus, $$\\Delta S = S_b - S_a = \\int_a^b dS = \\int_a^b \\frac{dQ}{T}$$  20.6 Entropy and Second Law #   In an isolated system with two objects that eventually reach equilibrium, we can write the change (increase) in entropy as $$\\Delta S = \\Delta S_H + \\Delta S_L = - \\frac{Q}{T_{HM}} + \\frac{Q}{T_{LM}}$$ .$T_{HM}$ is the average temperature between .$T_H$ and .$T_M$ where .$T_M$ is the average between .$T_H$ and .$T_L$  E.x. if .$T_H = 0^\\circ C, T_L = 0^\\circ C$, then .$T_M = 4^\\circ C$ so .$T_{HM} = 6^\\circ C$ and .$T_{LM} = 2^\\circ C$. Also, we use .$Q = mc \\Delta T$ to find heat and use half .$T_{M}$ (in this case .$4^\\circ C$) for .$\\Delta T$ Since .$T_{HM} \u0026gt; T_{LM}, \\Delta S \u0026gt; 0$ is always true While one system may decrease in entropy, the other one always increases more so net always increases   For adiabatic processes, we know .$dQ = dW = P dV$, thus $$\\Delta S_\\text{gas} = \\int \\frac{dQ}{T} = \\frac{1}{T} \\int_{V_1}^{V_2} P\\ dV$$ and since we know through the idea gas law that .$P = nRT/V$ so $$\u0026hellip;= \\frac{1}{T} \\int_{V_1}^{V_2} \\frac{nRT}{V}\\ dV = nR \\ \\ln \\bigg(\\frac{V_2}{V_1}\\bigg)$$  20.7 Order to Disorder (not covered) #   If we say that entropy is a measure of (dis)order in a system, we can write the second law as  Natural processes tend to move toward a state of greater disorder\n  When ice melts to water at 0°C, the entropy of the water increases.  Intuitively, we can think of solid water, ice, as being more ordered than the less orderly fluid state which can flow all over the place. This change from order to disorder can be seen more clearly from the molecular point of view: the orderly arrangement of water molecules in an ice crystal has changed to the disorderly and somewhat random motion of the molecules in the fluid state.   When a hot substance is put in contact with a cold substance, heat flows from the high temperature to the low until the two substances reach the same intermediate temperature.  At the beginning of the process we can distinguish two classes of molecules: those with a high average kinetic energy (the hot object), and those with a low average kinetic energy (the cooler object). After the process in which heat flows, all the molecules are in one class with the same average kinetic energy; we no longer have the more orderly arrangement of molecules in two classes \u0026ndash; Order has gone to disorder Furthermore, the separate hot and cold objects could serve as the hot and cold-temperature regions of a heat engine, and thus could be used to obtain useful work. But once the two objects are put in contact and reach the same temperature, no work can be obtained. Disorder has increased, because a system that has the ability to perform work must surely be considered to have a higher order than a system no longer able to do work.   When a stone falls to the ground, its macroscopic kinetic energy is transformed to thermal energy.  Thermal energy is associated with the disorderly random motion of molecules, but the molecules in the falling stone all have the same velocity downward in addition to their own random velocities. Thus, the more orderly kinetic energy of the stone as a whole (which could do useful work) is changed to disordered thermal energy when the stone strikes the ground. Disorder increases in this process, as it does in all processes that occur in nature.    20.8 Unavailability of Energy; Heat Death (not covered) #   In any natural process, some energy becomes unavailable to do useful work\n  That is, as time goes on, both energy is degraded and entropy increases  A rock that falls to the ground could instead used it\u0026rsquo;s energy towards useful work versus exerting kinetic/thermal energy while falling Two separate hot and cold objects could serves as the high and low temperature regions for a heat engine (obtaining useful work). Instead, if the tow objects are put in contact with one another, they\u0026rsquo;ll eventually reach the same uniform temperature and not be able to do any work.   Heat Death: All energy of the universe degrades into thermal energy  Very far out Scientists are unsure whether this is inevitable or whether we can even extrapolate the 2nd law to the scale of our universe    20.9 Statistical Interpretation of Entropy/2nd (not covered) #   We can only realistically observe macrostates and not microstates  However, we can make inferences about microstates with probabilities Each microstate is equally probable of occurring Thus, the number of microstates that give the same macrostate correspond to the relative probability of that macrostate occurring   The most probable state of a gas is one in which the molecules take up the whole spaces and move about randomly (in a maxwell distribution) At the same time, the very orderly arrangement of all molecules located in one corner of the room and all moving with the same velocity is extremely unlikely Therefore, the probability is directly related to the disorder and hence entropy of the system  The most probably state is the one with greatest entropy or greatest disorder and randomness It\u0026rsquo;s also the macrostate that corresponds to the most microstates   The netropy of a system in a given macro state can be written as: $$ S = k \\ \\ln\\mathscr{W}$$ .$k$ is the Boltzmann\u0026rsquo;s constant and .$\\mathscr{W}$ is the number of microstates corresponding to the given macrostate  That is, .$\\mathscr{W}$ is proportional to the probability of occurrence of that state .$\\mathscr{W}$ is also called the thermodynamic probability or the disorder parameter    20.10 Thermo Temperature; Third Law (not covered) #   Ideal Carnot Cycles always have the ratio $$\\frac{Q_L}{Q_H} = \\frac{T_L}{T_H}$$ Note that this relation doesn\u0026rsquo;t depend on the working substance, thus it can server as the basis for the Kelvin scale The closer a temperature is to abs zero, the more difficult it is to reduce the temp further Third Law:  It is not possible to reach absolute zero in any finite number of processes\n  Thus, since .$e = 1 - \\frac{T_L}{T_H}$ and because .$T_L$ can\u0026rsquo;t ever be zero then 100% efficiency is never possible  "},{"id":20,"href":"/physics-7b/21/","title":"21: Electric Charges \u0026 Fields","section":"Physics 7B","content":"21.1 Static Electricity; Electric Charge and its Conservation #   \u0026ldquo;Charged\u0026rdquo; objects posses a net electric charge Unlike charges attract; like charges repel  Charges on glass are positive, charges on plastic is negative   Law of Conservation of Electric Charge:  Whenever a certain amount of charge is produced in one object, an equal amount of the opposite type of charge is produced in another object  Charges cannot be destroyed or created   E.x. a plastic ruler is rubbed with a paper towel. The plastic acquires a negative charge and the towel obtains an equal positive charge In other words, the net amount of electric charge produced in any process is zero: .$\\Sigma Q = 0$    21.2 Electric Charge in the Atom #   Atoms are made up of positive nucleus surrounded by at least one negatively charged electron.  Inside the nucleus are protons which are positively charged and neutrons which have no charge The charges of electrons and protons are equal in magnitude   E.x. neutral atoms with no charge contain an equal number of protons and electrons When an atom gains a charge (by losing/gaining electrons), it then has a net charge and is called an ion Neutral objects have a net charge of zero  Over time, objects left alone with a charge tend to lose their charge This is because over time, electrons are exchanged with water molecules in the air  Water molecules are polar: They are neutral, their charges aren\u0026rsquo;t equally distributed   Thus, on rainy days it\u0026rsquo;s harder for an object to maintain a charge for too long    21.3 Insulators and Conductors #   Conductor: Material that allow charge to flow between objects  Metals tend to be good conductors Electrons (charges) are relatively lose: can move freely within metal, but can\u0026rsquo;t leave easily  Called free or conduction electrons     Insulator: Opposite of conductors; don\u0026rsquo;t easily allow a flow of charge  Most materials other than metals tend to be good insulators  Notably rubber and wood   Electrons are bound very tightly to the nuclei Almost no free electrons   Semiconductors: Somewhere between the two former  Silicon, germanium Less free electrons than a conductor, but more than an insulator    21.4 Induced Charge; Electroscope #   Conduction: Charge transfer by physical contact  E.x. a positively charged metal rod touches a neutral metal rod. Free electrons from the neutral rod will then flow (transfer) to the charged rod, leaving the formerly neutral rod now slightly positively charged   Induction: Charge distribution altered by bringing two objects close, but not touching  Unlike conduction, induction doesn\u0026rsquo;t alter the net charge of objects when the inducer is taken away However, induction can redistribute the existing charges on the induced object   Grounded Objects  Objects can be ground to the earth with a conducting wire The earth is very large and can conduct, so it easily accepts/gives up electrons Therefore, when an object is induced by another charged object, the original objects will become charged If the wire is ever cut when the object is under induction, the charge will stay in the object    Electroscope  .$\\vec F \\propto \\text{angle of deflection}$ .$y$-axis: .$F_{T1} \\sin \\theta_1 = F_{21}$ .$x$-axis: .$F_{T1} \\cos \\theta_0 = m_1 g$ .$F_{21} = m_1 g \\tan \\theta_1 \\approx m_1 g \\theta_1$ .$F_{21} = - F_{12}$ ( Newton\u0026rsquo;s Third) .$ \\Longrightarrow \\theta_1/\\theta_2 = m_2/m_1$ .$d = l (\\theta_1 + \\theta_2)$       21.5 Coulomb\u0026rsquo;s Law #  Coulomb\u0026rsquo;s Law: $$E_\\text{source} = k \\frac{Q_\\text{source}}{r^2} \\Longrightarrow F = EQ = \\bigg(k \\frac{Q_1}{r^2}\\bigg) (Q_2) = k\\frac{Q_1 Q_2}{r^2}$$ where .$k$ is a constant equal to .$\\frac{1}{4\\pi\\varepsilon_0} = 8.988 \\cdot 10^9 \\text{ N m$^2$/C$^2$}$   Very similar to universal gravitation equation  However\u0026hellip;  .$F_C$ can repel, whereas .$F_G$ is always attractive .$F_C$ only acts on charged objects, whereas .$F_G$ acts on neutral objects too   .$F_G/F_C \\approx 10^{-40} \\Longrightarrow F_C \\gg F_G$   The coulomb (.$\\text{C}$) is the SI unit for charge Properties of Coulomb Force:  It can be attractive and repulsive It is not a contact force Inversely proportional to .$r^2$ Proportional to amount of charge .$Q$   The smallest charge we\u0026rsquo;ve observed is the elementary charge: .$e = 1.6022 \\cdot 10^{-19} \\text{ C}$  Electrons have a charge equal to .$-e$ Protons have a charge equal to .$+e = -Q_\\text{electron}$ Charges are Quantized  That is, all charges are multiples of .$e$ Since electrons are elementary particles, by definition they can\u0026rsquo;t be divided.     .$k$ can also be written as .$\\frac{1}{4\\pi\\varepsilon_0}$  .$\\varepsilon_0$ is called the permittivity of free space .$\\varepsilon_0 = \\frac{1}{4\\pi k} = 8.85 \\cdot 10^{-12} \\text{C$^2$/N m$^2$}$    21.6 Electric Field #   Electric fields extend outward from every charge and permeates all of space $$\\overrightarrow E = \\lim_{q\\to0}\\frac{\\overrightarrow F}{q} \\Longrightarrow \\overrightarrow F = q \\overrightarrow E$$  .$q$ is a positive charge .$\\overrightarrow F$ is the forces the field exserts on .$q$ Has units newtons per coulomb (.$\\text{N/C}$)   We can combine this with Coulomb\u0026rsquo;s law to get $$\\overrightarrow E = \\frac{kqQ/r^2}{q} = k \\frac{Q}{r^2} = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r^2}$$  We see that .$\\overrightarrow E$ is independent of the non-source particle .$q$ .$Q$ is the particle that is responsible for the field in the first place   An electric field at a given point is the sum of all other electric fields that act on that point $$\\overrightarrow E = \\overrightarrow E_1 + \\overrightarrow E_2 + \u0026hellip;$$  21.7 Electric Field Calculations for Continuous Charge Distributions #   We can extend our previous definition to calculus as $$\\overrightarrow E = \\int d \\overrightarrow E = k \\int \\frac{1}{r^2}\\ dq = \\frac{1}{4\\pi\\varepsilon_0} \\int \\frac{1}{r^2}\\ dq$$  .$dq = \\lambda\\ dl \\text{ (line)} = \\sigma\\ dA \\text{ (disk)} = \\rho\\ dV \\text{ (sphere)}$    Calculating field generated by a continuous charge distribution\n Draw an arbitrary \u0026ldquo;piece\u0026rdquo; of charge distribution; don\u0026rsquo;t choose a special point such as the end or exact middle. The piece should be infinitesimally long and/or wide. Thus, its length or width will be something like .$dx$ or .$ds$ Write an expression for .$dq$, the corresponding infinitesimal charge of that piece in terms of .$dx$ or .$ds$ or whatever. Recall .$dq = \\frac{\\text{total charge}}{\\text{total length}} \\times \\text{(tiny length of piece)}$ Using Coulomb\u0026rsquo;s law, find the infinitesimal electric field at that point of interest (e.x. some point .$P$) generated by the piece chosen in step 1. When necessary, break .$d\\vec E$ into components, .$dE_x$ and .$dE_y$ Integrate .$dE_x$ or .$dE_y$ over the whole charge distribution to obtain the total electric field in the .$x$ or .$y$ direction respectively    When solving problems, it\u0026rsquo;s a good idea to use symmetry, check charge direction, and (when applicable) use bounds of .$r \\in [0, \\infty]$ We can write equation for an infinite plane holding a uniform surface charge density .$\\sigma$ $$2A \\cdot \\overrightarrow E = \\frac{\\sigma A}{\\varepsilon_0} \\Longrightarrow \\overrightarrow E = \\frac{\\sigma}{2\\varepsilon_0}$$  This also applies in the case where a charge is close to an infinite surface (so that the distance to the surface is much greater than the distance to the edges) In the case where there are two oppositely charged sheets parallel to one another, the field is .$\\vec E = \\frac{\\sigma}{\\varepsilon_0}$ since there are two charges creating the field   The case involving an infinitely long wire can be written generally as $$\\overrightarrow E \\cdot 2\\pi RL = \\frac{\\lambda L}{\\varepsilon_0} \\Longrightarrow \\overrightarrow E = \\frac{\\lambda}{2\\pi\\varepsilon_0 \\cdot r}$$  .$r$ is the distance from a particle to the wire    21.8 Field Lines #   To visualize electric fields, we draw electric field lines or lines of force Three properties of Electric Field Lines:  Electric field lines indicate the direction of the electric field; the field points are in the direction tangent to the field line at any point \u0026ndash; see point .$P$ in .$\\text{(a)}$ The lines are drawn so that the magnitude of the electric field, .$E$, is proportional to the number of lines crossing unit area perpendicular to the lines (i.e. a circle \u0026lsquo;hugging\u0026rsquo; a point charge). The closer together the lines, the stronger the field. Electric field lines start on positive charges and end on negative charges; and the number starting or ending is proportional to the magnitude of the charge.  .$\\text{Density} = \\frac{\\text{number of lines crossing surface}}{\\text{area surface}}$ .$\\text{1 Coulomb} = \\frac{1}{\\varepsilon_0} \\cdot \\text{ lines}$ .$\\therefore \\text{Density} = \\frac{q}{\\varepsilon_0 4\\pi r^2} \\Longrightarrow \\vec E$     In the case of two oppositely charged parallel \u0026amp; equally spaces plates \u0026ndash; such as case .$\\text{(d)}$ \u0026ndash; we can write the field as $$\\overrightarrow E =\\text{const.} = \\frac{\\sigma}{\\varepsilon_0}=\\frac{Q}{\\varepsilon_0 A}$$  .$Q =\\sigma A$ is the charge on one plate of area .$A$   Field lines never cross because it wouldn\u0026rsquo;t make sense for an electric field to have two directions at the same point.      Electric Dipole #   A combination of two equal but opposite charges next to one another \u0026ndash; see .$(\\text{a})$ above  Dipole Moment is when represented by vector .$\\vec{p}$ of magnitude .$Ql$  Molecules that have dipole moments are called polar molecules      A dipole in a uniform electric field feels no net force, but does have a net torque (unless .$\\vec p \\parallel \\vec E$) If .$\\vec p \\not \\parallel \\vec E$, .$W =\\int_{\\theta_1}^{\\theta_2} \\tau d\\theta$ where .$\\tau = -\\vec p\\vec E\\sin\\theta = \\vec p \\times \\vec E$  Simplifies to .$W =\\vec p\\vec E(\\cos\\theta_2 - \\cos\\theta_1)$ Thus, work/torque is most at .$\\theta = 90^\\circ$ or .$180^\\circ$ depending on .$\\vec E$ direction Pay attention to right hand rule when solving   If .$r \\gg l \\Longrightarrow \\overrightarrow E \\propto 1/r^3$    21.9 Electric Fields and Conductors #   The static electric field inside a conductor is zero (in static situations where electrons have had time to stop moving)  For that reason, any net charge on a conductor distributes itself on the surface Charges inside conductors act as if the conductor isn\u0026rsquo;t there   All the electric field lines just outside a charged conductor are perpendicular to the surface  21.10 Motion of Charged Particle #   Vector Form of Forces $$\\overrightarrow F_{12} = k \\frac{q_1 q_2}{r^2} \\cdot \\widehat r_{21}$$  Notation:  .$\\overrightarrow F_{12}$ means force on .$q_1$ by .$q_2$ since .$q_2$ is the source charge .$\\widehat r_{21} = - \\widehat r_{12} \\Longrightarrow \\overrightarrow F_{12} = -\\overrightarrow F_{21}$   Direction  If .$q_1 q_2 \u0026gt; 0$ (same sign, repulse), then the force and unitary vectors both point away from the two charges          If .$q_1 q_2 \u0026lt; 0$ (opposite sign, attract), then the force vector points towards the two charges and the unitary direction vector still points away from the two charges      Superposition Principle  In a system considering multiple (3+) charges, forces acting on .$q_1$ by .$q_2$ (.$F_{12}$) is independent from whether other charges are present Total forces acting on .$Q_1$ can be written as .$\\overrightarrow F = \\overrightarrow F_{12} + \\overrightarrow F_{13} + \\dots$  Remember to break down the vectors into .$x/y$ components when adding them  E.x. .$F_{1x} = F_{12x} + F_{13x} + \\dots$   Realize that the axis are arbitrary   .$\\theta = \\tan^{-1}\\Big(\\frac{F_x}{F_y}\\Big)$   Charges in Fields  Charge moving with .$\\vec v$ that is parallel to uniform field .$\\overrightarrow E$  .$\\overrightarrow F = q \\overrightarrow E = m \\vec a \\Longrightarrow a_x = \\frac{q}{m}\\overrightarrow E = \\text{const.}$ .$\\vec v = \\sqrt{2a_x \\vec d} = \\sqrt{\\frac{2q}{m}\\overrightarrow E_x \\vec d}$   Charge moving with .$\\vec v$ that is orthogonal to uniform field .$\\overrightarrow E$  Similar to projectile in gravitational field: .$\\vec g \\sim \\overrightarrow E$ .$\\overrightarrow F_x = 0 \\Longrightarrow v_{x2} = v_{x1};\\ \\ a_x = 0$ .$\\overrightarrow F_y = q \\overrightarrow E = m a_y;\\ \\ a_y = \\vec a = \\frac{q}{m}\\overrightarrow E = \\text{const.}$ .$y(t) = \\frac{1}{2} \\frac{q\\overrightarrow E}{m}t^2$      21.11 Electric Dipoles #   Notes for this chapter are under 21.8 \u0026ndash; Electric Dipole  "},{"id":21,"href":"/physics-7b/22/","title":"22: Flux \u0026 Gauss's Law","section":"Physics 7B","content":"22.1 Electric Flux #   Electric Flux: Electric field that passes through a given area  E.x. for a uniform field .$\\vec E$ passing through an area .$A$ at angle .$\\theta$ between the field direction and line perpendicular to the area, the flux is defined as $$\\Phi_\\vec{E} = \\vec E_\\perp A = \\vec EA_\\perp = \\vec E A \\cos \\theta = \\vec E \\cdot \\vec A$$    The .$N$umber of field lines passing through unit area perpendicular to the field .$A_\\perp$ is proportional to the magnitude of the field .$\\vec E$ $$\\vec E \\propto N/A_\\perp \\Longrightarrow N \\propto \\vec EA_\\perp = \\Phi_\\vec{E}$$ For non-uniform fields:  We divide up the surface into .$n$ small elements of surface whose areas are .$dA$ where .$dA$ is small enough (1) to be considered flat and (2) so .$E$ varies so little it can considered uniform $$\\Phi_\\vec{E} = \\oint_A \\vec E \\cdot d\\vec A$$ If .$\\Phi \u0026gt; 0$, flux is entering the volume and .$\\Phi \u0026lt; 0$ is flux leaving   Direction:  For closed surfaces, .$\\vec A$ points outwards from the enclosed volume, so flux is positive Further, .$\\theta$ (angle between .$d\\vec A$ and .$E$) should always be, for electric field\u0026hellip;  Leaving the volume: Less than .$\\pi/2$ (so .$\\cos\\theta \u0026gt; 0$) and .$\\Phi \u0026gt; 0$) Entering the volume: Greater than .$\\pi/2$ (so .$\\cos\\theta \u0026lt; 0$ and .$\\Phi \u0026lt; 0$)         Net Flux  In the example above, every line that enters also leaves so .$\\Phi = 0$ meaning there is no net flux into or out of the enclosed surface Flux will only be nonzero if one of more lines start or end within the surface  Flux through .$A_1$ is positive, .$A_2$ is negative    Net flux through .$A$ is negative        22.2 Gauss\u0026rsquo;s Law #    Gauss\u0026rsquo;s Law: We can relate flux through a surface and net charge enclosed within said surface by $$\\Phi = \\oint \\vec E \\cdot d\\vec A = \\frac{Q_\\text{enclosed}}{\\varepsilon_0}$$\n This tells us the difference between the input and output flux of the electric field over any surface is due to charge within that surface. This is because we defined .$1 \\text{ Coulomb} = \\varepsilon_0^{-1} \\text{ field lines}$ Notice that it doesn\u0026rsquo;t matter the distribution of the charge inside the surface A charge outside the chosen surface may affect the position of the electric field lines, but it won\u0026rsquo;t affect the number of lines entering of leaving the surface    Irregular Surfaces:   Since flux is proportional to the flux lines passing in/out, and the number of lines is the same for .$A_1$ and .$A_2$, so $$\\oint_{A_1} \\vec E \\cdot d \\vec A = \\oint_{A_2} \\vec E \\cdot d \\vec A = \\frac{Q}{\\varepsilon_0}$$ Therefore, this is true for any surface surrounding a single point charge .$Q$      The superposition principle from last chapter also applies to Gauss\u0026rsquo;s law: The total field .$\\vec E$ is equal to the sum of the fields due to each separate charge: $$\\oint \\vec E_i \\cdot d \\vec A = \\oint \\Big(\\Sigma \\vec E_i \\Big) \\cdot d \\vec A = \\sum \\frac{Q_i}{\\varepsilon_0} = \\frac{Q_\\text{enclosed}}{\\varepsilon_0}$$\n  22.3 Applications of Gauss\u0026rsquo;s #  Gauss\u0026rsquo;s Law to calculate electric fields\n Using symmetry and intuition, draw the electric field lines. Enclose all or part of the charge distribution with a Gaussian surface. The electric field should have the same strength at all points on (at least part of) the surface. Apply Gauss\u0026rsquo;s law: .$\\Phi_\\vec{E} = \\oint \\vec E \\cdot d\\vec A = \\frac{Q_\\text{enclosed}}{\\varepsilon_0}$. If .$E$ is constant over (part of) the Gaussian surface, you can pull it outside the integral. This simplification is what allows you to solve for the field.  Recall .$Q_\\text{enclosed} = \\frac{\\text{(total charge)}}{\\text{(total area)}}\\times \\text{(area enclosed by Gaussian surface)}$ If you can\u0026rsquo;t pull .$E$ outside the flux integral, then Gauss\u0026rsquo;s law don\u0026rsquo;t work! Use the continuous charge distribution strategy from the prior chapter.     Uniformly Charged Solid Spherical Conductor #   Charge Outside:  .$\\vec E$ will have the same magnitude at all points along the surface .$A_1$ Since .$\\vec E$ is always orthogonal to the surface, the cosine is always .$1$ $$\\Longrightarrow E = \\frac{1}{4\\pi\\varepsilon_0}\\frac{Q}{r^2}$$ We see that the field outside is as if all of the charge was from a single point   Charge Inside:  .$\\vec E$ will have the same magnitude at all points along the surface .$A_2$ Thus, .$Q = 0$ because the charge inside the surface .$A_2$ is zero Hence, .$E = 0$ for .$r \u0026lt; r_0$      Initial radius is .$r_0$; outside radius is .$r$ Enclosed charge has charge .$Q$  This result is the same for both hollow and solid spheres because all the charge would lie in a thin layer at the surface.     If .$Q \\neq 0$, current would flow inside the conductor which would build up charge on the exterior of the conductor. This charge would oppose the field, ultimately (in a few nanoseconds for a metal) canceling the field to zero.  Solid Sphere of Charge #   Charge .$Q$ is distributed uniformly throughout a nonconducting sphere of radius .$r_0$     Charge Outside:  Same rational as before, $$\\oint \\vec E \\cdot d\\vec A = E (4\\pi r^2) = \\frac{Q}{\\varepsilon_0}$$ $$\\Longrightarrow E = \\frac{1}{4\\pi\\varepsilon_0}\\frac{Q}{r^2}$$ Again, the field outside is the same as for a point charge in center of sphere   Charge Inside: $$\\oint \\vec E \\cdot d\\vec A = E (4\\pi r^2) = \\frac{Q_{\\text{enclosed in }A_2}}{\\varepsilon_0}$$  Since .$Q_{\\text{enclosed\u0026hellip;}} \\neq Q$, we define the charge density .$\\rho_E$ as the charge per unit volume (.$dQ/dV$) which is constant We can then write $$Q_{\\text{enclosed}} = Q \\cdot \\frac{\\frac{4}{3}\\pi r^3 \\rho_E}{\\frac{4}{3}\\pi r_0^3 \\rho_E} = Q\\cdot \\frac{r^3}{r^3_0}$$ $$ \\Longrightarrow E = \\frac{1}{4\\pi\\varepsilon_0}\\frac{Q}{r_0^3}r$$ $$$$      "},{"id":22,"href":"/physics-7b/23/","title":"23: Electric Potential","section":"Physics 7B","content":"23.1 Electric Potential Energy and Difference #   PE can only be defined for conservative forces  That is, work done by said force is independent of the path taken  Coulomb\u0026rsquo;s Law is conservative because the dependence on position is conservative   Hence, we define .$\\Delta U = -W$ with  .$\\Delta U = U_b - U_a$ is for a situation where a point charge .$q$ moves from point .$a$ to point .$b$ This is equal to negative work, .$-W = -\\vec F d = -(q\\vec E) d$ (for a uniform .$\\vec E$)    23.2 Relation between Electric Potential and Field #   Electric Potential: Electric PE per unit charge, such as for a charge at point .$a$ $$V_a = \\frac{U_a}{q}$$ We only really care about difference though, which is defined as $$V_{ba} = \\Delta V = \\frac{U_b - U_a}{q} = - \\frac{W_{ba}}{q}$$ We can now also define PE in terms of electric potential: $$\\Delta U = U_b - U_a = q(V_b - V_a) = qV_{ba}$$ Electric potential difference is a measure of how much energy an electric charge can acquire in a given situation. Since energy is the ability to do work, the electric potential difference is also a measure of how much work a given charge can do.  The exact amount of energy or work depends both on the potential difference and on the charge.   If a positive charge is free, it will tend to move from high to low potential  Inverse for opposite charge    23.3 Potential due to Point Charges #  $$\\Delta U = U_b - U_a = - \\int_a^b \\vec F \\cdot d \\vec l$$\n .$dl$ is an infinitesimal increment of displacement along the path from .$a$ to .$b$  Keep in mind that .$\\vec F$ must be conservative Thus the integral can be taken along any path from point .$a$ to point .$b$.   Knowing .$\\vec E = \\vec F / q$ and .$V_{ba} = (U_b - U_a) / q$, we can write the electric potential equation as\u0026hellip;  $$V_{ba} = V_b - V_a = - \\int_a^b \\vec E \\cdot d \\vec l$$ $$V_{ba, \\text{uniform $\\vec E$}} = -E\\int_a^b d\\vec l = -Ed$$ \u0026hellip;where .$d$ is the distance of a straight line from point .$a$ to .$b$     Charged Conducting Sphere #  1. Electric Potential Outside Sphere #   We know .$\\vec E = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r^2}$ for outside a conducting sphere (.$r \u0026gt; r_0$) Therefore, we can write $$V_{ba} = - \\int_{r_a}^{r_b} \\vec E \\cdot d \\vec l = - \\frac{Q}{4\\pi\\varepsilon_0}\\int_{r_a}^{r_b} \\frac{dr}{r^2}$$ $$\\dots = \\frac{Q}{4\\pi\\varepsilon_0} \\bigg(\\frac{1}{r_b} - \\frac{1}{r_a}\\bigg)$$ $$\\dots = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r} \\text{ [$r_b = \\infty$]}$$     2. Electric Potential On Sphere #   From .$(a)$, as .$r$ approaches .$r_0$, we see $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r_0}$$ at the surface of the sphere. This makes sense because the charge is distributed on the surface of the sphere.   3. Electric Potential Inside Sphere #   Inside the conductor, .$\\vec E = 0$ Therefore, there is no change in .$\\vec E$ from .$0$ to .$r_0$ (or any point within the conductor) gives zero change in .$V$ Hence, within the conductor, .$V$ is a constant: $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r_0}$$     Thus, the whole conductor, not just its surface, is at this same potential. We can also generalize the first case to the electric potential .$r$ from a single point charge .$Q$  Coulomb potential #   The potential outside a uniformly charged sphere is the same as if all the charge were concentrated at its center  The potential near a positive charge is large, and it decreases toward zero at very large distances    For a negative charge, the potential is negative and increases toward zero at large distances      23.4 Potential due to Any Charge Distribution #   If .$\\vec E$ is a function of position (or otherwise unknown), we can find .$V$ by calculating the potential due to the many tiny charges that make up .$\\vec E$: $$V = \\frac{1}{4\\pi\\varepsilon_0} \\int \\frac{dq}{r}$$ where .$r$ is the distance from a tiny element of charge .$dq$ to the point where .$V$ is being determined  23.5 Equipotential Lines and Surfaces #   The electric potential can be represented by drawing equipotential lines, or, in three dimensions, equipotential surfaces An equipotential surface has all points at the same potential.  That is, the potential difference between any two points on the surface is zero Thus, no work is required to move a charge from one point on the surface to another.   Equipotential surfaces are perpendicular to the electric field (field lines) For a positive point charge, the equipotential surface with the largest potential is closest to the positive charge Unlike electric field lines, which start and end on electric charges, equipotential lines/surfaces are always continuous and never end   Electric field lines and equipotential surfaces for a point charge.    Equipotential lines (green, dashed) are always perpendicular to the electric field lines (solid red) shown here for two equal but oppositely charged particles (an electric dipole).    23.6 Potential Due to Dipole (Moment) #  $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q}{r} + \\frac{1}{4\\pi\\varepsilon_0} \\frac{(-Q)}{(r+\\Delta r)} = \\frac{Q}{4\\pi\\varepsilon_0} \\frac{\\Delta r}{r(r + \\Delta r)}$$\n .$r$ is the distance from (some arbitrary point) .$P$ to the positive charge and .$r + \\Delta r$ is the distance to the negative charge  If .$r \\gg l$, then .$r \\gg \\Delta r \\approx l \\cos \\theta$ so we can neglect .$\\Delta r$ $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Ql \\cos\\theta}{r^2} = \\frac{1}{4\\pi\\varepsilon_0} \\frac{p \\cos\\theta}{r^2} $$ Notice the potential decreases .$\\propto r^2$, whereas for a single point charge the potential decreases .$\\propto r$ It is not surprising that the potential should fall off faster for a dipole:  When you are far from a dipole, the two equal but opposite charges appear so close together as to tend to neutralize each other      --      23.7 .$\\vec E$ Determined from .$V$ #   We know that .$V_b - V_a = - \\int_a^b \\vec E \\cdot d\\vec l$, which we can write in differential form as .$dV = -\\vec E \\cdot d\\vec l = - E_l dl$. This can be written as $$E_l = - \\frac{dV}{dl}$$ .$dV$ is the tiny difference in potential between two points a distance .$dl$ apart, and .$E_l$ is the component of the electric field in the direction of the tiny displacement .$d\\vec l$ This is called the gradient of .$V$ in a particular direction: The general case is $$\\vec E = - \\nabla \\vec V = - \\bigg\\langle \\frac{\\delta V}{\\delta x}, \\frac{\\delta V}{\\delta y}, \\frac{\\delta V}{\\delta z} \\bigg\\rangle$$ This states that the electric field points \u0026ldquo;downhill\u0026rdquo; towards lower voltages (where there is lower potential)  23.8 Electrostatic PE; The Electron Volt #   The electric potential and energy potential due to one point charge .$Q_1$ on another point charge .$Q_2$ separated by .$r_{12}$ are $$V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q_1}{r_{12}}$$ $$U = Q_2 V = \\frac{1}{4\\pi\\varepsilon_0} \\frac{Q_1 Q_2}{r_{12}}$$ The PE is the negative work needed to separate the two charges to infinity. For three points, we can use the superposition principle like we have prior to write $$U = \\frac{1}{4\\pi\\varepsilon_0}\\bigg( \\frac{Q_1 Q_2}{r_{12}}+ \\frac{Q_1 Q_3}{r_{13}} + \\frac{Q_2 Q_3}{r_{23}} \\bigg)$$  Electron Volt #   Joules are a very large unit for dealing with energy of the electron scale; as such, the electron volt (.$eV$) is often used One electron volt is the energy acquired by a particle carrying a charge .$e$ (the magnitude of an electron) as a result of moving through a potential difference of .$1 V$ $$1 \\text{ eV} = 1.6022 \\cdot 10^{-19} \\text{ J}$$ E.x., an electron (charge .$e = 1.6\\cdot10^{-19}$) that accelerates through a potential difference of .$1000 \\text{ V}$ will lose .$1000 \\text{ eV}$ of potential energy and gain .$1000 \\text{ eV}$ of kinetic energy  23.9 Digital; Binary Numbers; Signal Voltage (not covered) #   Batteries and wall sockets provide a steady supply voltage as power Signal voltage provide/carry information  Analog signal voltage has voltage that varies continuously (i.e .$\\sin$) Digital signals are more complicated and encode information, often in binary  Bytes have 8 bits which allow .$2^8 = 256$ numbers Digital signals are transmitted at some rate (bit-rate) given in .$\\text{Mb/s}$       Analog to digital converters, ADCs, convert analog signals to boxy digital waves  The difference between the original continuous and it\u0026rsquo;s digital approximation is called the quantization error / loss This error varies by primarily:  Resolution or bit depth which is the number of bits for the voltage of each sample Sampling rate which is the number of times per second the original analog voltage is measured (sampled)   E.x., CDs are sampled at .$44.1 \\text{ kHz}$ with a bit depth of .$16 \\text{ bits per sample}$      The red analog sine wave, which is at a 100-Hz frequency (1 wavelength is done in 0.010 s), has been converted to a 2-bit (4 level) digital signal (blue).     Digital Signals  Digital to Analog, DACs, exist too because some appliances require an analog signal Digital signals can be compressed: Repeated information can be reduced so that less memory (bits) is needed  Fun fact: Bit is the contraction of \u0026ldquo;binary digit\u0026rdquo;, leaving out the 8 letters between   Digital signals are more resistant from noise, which badly corrupts analog signals  Any electronic signal involves electric charges whose electric field can affect charges in another nearby signal External fields, as from high voltage wires, motors, or fluorescent lamps, can produce noise Thermal noise refers to random motion of electrons, much like the “thermal motion” of the molecules in a gas Moving electrons can be affected by the medium (wire, etc.), altering the signal      "},{"id":23,"href":"/physics-7b/24/","title":"24: Capacitance, Dielectrics, Electric Energy Storage","section":"Physics 7B","content":"24.1 Capacitors #   Capacitors are devices that store an electric charge  Normally consists of two conducting objects; plates, sheets  When a voltage is applied, the two plates become charged: one positive, one negative   Conductors are placed near one another, but not touching  This distance is typically due to an insulator between sheets Capacitors are typically rolled so that they take up less room     Two main use cases  Storing energy for later use; e.x. camera flash Block surges of charge and energy to protect circuits   The amount of charge .$Q$ acquired by each plate is proportional to  .$V$: The potential difference of the two plates (Volts) .$C$: The constant capacitance of the capacitor (Coulombs per volt, farad) $$Q = CV$$    24.2 Determination of Capacitance #   In the real world, capacitance is determined experimentally by using the prior equations For ideal cases where the sheets are separated by a vacuum or air, however, we can use the following equations For a parallel-plate capacitor where .$A$ is the area of each plate and .$d$ is the distance between plates: $$E = \\frac{\\sigma}{\\varepsilon_0} = \\frac{Q}{\\varepsilon_0 A}$$  We also know this because .$E = \\sigma / \\varepsilon_0$ and .$\\sigma = Q/A$   Since .$V = \\int E\\ dl = \\frac{Qd}{\\varepsilon_0 A}$, we can relate it to .$C$ as $$C = \\frac{Q}{V} = \\varepsilon_0 \\cdot \\frac{A}{d}$$  Capacitance-finding strategy\n Assign an arbitrary charge .$\\pm q$ to the two plates. Using Gauss\u0026rsquo;s law or other techniques, calculate the electric field between these two plates From that electric field, calculate the potential difference between the plates, .$V = -\\int \\vec E \\cdot d \\vec s$ Calculate the capacitance using .$C = q/V$. The arbitrary charge .$q$ from (1) should cancel out.   24.3 Capacitors in Series and Parallel #  Series #   The current/charge on each capacitor has the same magnitude: $$Q = Q_1 = Q_2 = \\dots$$   The total voltage across all capacitors is sumo of the voltage drops of the individual components: $$V = V_1 + V_2 + \\dots = I(R_1 + R_2 + \\dots)$$ And since .$V = Q/C$, capacitance is then $$\\frac{Q}{C_\\text{eq}} = \\frac{Q}{C_1} + \\frac{Q}{C_2} + \\dots \\Longrightarrow \\frac{1}{C_\\text{eq}} = \\frac{1}{C_1} + \\frac{1}{C_2} + \\dots $$  Notice that the equivalence capacitance is smaller than the smallest contributing capacitance    Parallel #   The total current/charge is the sum of the currents flowing through each component $$Q = Q_1 + Q_2 + \\dots = V (R^{-1}_1 + R^{-1}_2 + \\dots)$$   Voltage (potential difference) is the same across all paths/capacitors $$V = V_1 = V_2 = \\dots$$ Therefore, we can use .$V = Q/C$ to write the equivalent capacitance as $$Q = C_1 V + C_2 V + \\dots$$ $$Q = C_\\text{eq} V = (C_1 + \\dots)V \\Longrightarrow C_\\text{eq} = C_1 + \\dots$$  The net effect of connecting capacitors in parallel is to increase the capacitance  Makes sense: We\u0026rsquo;re essentially increasing area of the plates   The overall working voltage is always limited by the smallest working voltage of an individual capacitor.    24.4 Storage of Electric Energy #   The energy stored in a capacitor is equal to the work done to charge it.  Initially, an uncharged capacitor requires no work to move the first few bits of charge As more charge is stored, more work is needed to add more charge of the same sign because of the electric repulsion That is, the more charge already on a plate, the more work required to add additional charge   Since we know .$dW = V\\ dq$ and .$V = q/C$, we can write the work needed to store charge .$Q$ as $$W = \\int_0^Q V\\ dq = \\frac{1}{C}\\int_0^Q q \\ dq = \\frac{1}{2} \\frac{Q^2}{C}$$ Since .$U = W$ and .$Q = CV$, we can write the energy stored in a capacitor with charges .$+Q$ and .$-Q$ on its two conductors as $$U = \\frac{1}{2} \\frac{Q^2}{C} = \\frac{1}{2}CV^2 = \\frac{1}{2}QV$$ It is useful to think of the energy stored in a capacitor as being stored in the electric field between the plates.  E.x. lets find the energy stored in a parallel-plate capacitor in terms of the electric field  We know for two close parallel plates we can find the potential difference as .$V = Ed$ where .$d$ is distance between plates We also know .$C = \\varepsilon_0 A/d$ for parallel plate capacitors, thus we can write $$U = \\frac{1}{2}CV^2 = \\frac{1}{2}\\bigg(\\frac{\\varepsilon_0 A}{d}\\bigg)(E^2 d^2) = \\frac{1}{2} \\varepsilon_0 E^2 Ad$$ We can recognize .$Ad$ as the volume between the plates where .$E$ exists If we divide both sides of by this volume, we can an equation for the energy density .$u$: $$u = \\frac{\\text{energy}}{\\text{volume}} = \\frac{1}{2}\\varepsilon_0 E^2$$   Thus, electric energy stored per unit volume in any region of space is proportional to the square of the electric field We proved this with parallel plates, but this can be shown for any region with an electric field    24.5 Dielectrics #   Dielectrics are the insulating material sheet placed between conductors They serve to  Because they don\u0026rsquo;t break down, they allow electric charge to flow as easily as air so higher voltages can be applied without charge passing across the gap Allow the plates to be placed closer together without touching, allowing an increased capacitance because the thickness .$d$ is smaller Dielectrics increase the capacitance by a factor .$K$ (known as the dielectric constant) $$C = KC_0$$  .$C_0$ is the capacitance when the space is a vacuum/air .$C$ is the capacitance with the dielectric filling the space     For parallel-plate capacitors, we use .$C = Q/V = \\varepsilon_0 A/d$ and .$C = KC_0$ $$C = K \\varepsilon_0 \\frac{A}{d}$$ Energy density also changes with a dielectric as $$u = \\frac{1}{2}K \\varepsilon_0 E^2 = \\frac{1}{2}\\varepsilon E^2$$ Likewise, .$E$ and .$V$ are both also altered:  With no dielectric, the field is .$E_0 = \\frac{V_0}{d}$ where .$V_0$ is the potential difference If the capacitor is isolated (i.e. not connected to a battery) so that the charge stays constant, potential difference drops: .$V = V_0/K$ Therefore, .$E = \\frac{V}{d} = \\frac{V_0}{Kd} = \\frac{E_0}{K}$ .$\\varepsilon$ is the permittivity of the dielectric material defined as .$\\varepsilon = K \\varepsilon_0$    "},{"id":24,"href":"/physics-7b/25/","title":"25: Electric Current and Resistance","section":"Physics 7B","content":"25.1 The Electric Battery #   Batteries produce electricity by transforming chemical energy into electric energy Simple battery (cells) contain two plates or rods of dissimilar metals called electrodes  The portion of rods outside of the solution are called the terminals Anode: The positive electrode Cathode: The negative electrode   These electrodes are emersed in the electrolyte: a solution such as a dilute acid  Chemical Process:\n The acid dissolve the zinc electrode, causing zinc atoms to leave two electrons behind on the electrode and enters the solution as a positive ion. The zinc electrode thus acquires a negative charge. Then the electrolyte becomes positively charged and can pull electrons off the carbon electrode. Thus the carbon electrode becomes positively charged. Because there is an opposite charge on the two electrodes, there is a potential difference between the two terminals.       When a battery isn\u0026rsquo;t connected, only a small amount of zinc is dissolved  The zinc electrode becomes increasingly negative Thus, any new positive zinc ions produced are attracted back to the electrode   That is, if a charge is allowed to flow then the zinc can dissolve The voltage depends ot the electrodes' material and their relative ability to give up electrons  25.2 Electric Current #   When a circuit is formed, charge can move (flow) through the wires from one terminal to the other  Any flow of charge is called an electric current Flow can only occur on a continuos conducting path (a complete circuit) If there\u0026rsquo;s any break, our circuit is called an open circuit and no current flows   The symbol for battery is the following:     Conventional current from .$+$ to .$-$ is equivalent to a negative electron flow from .$-$ to .$+$     Current in a wire is defined as the net amount of charge that passes through the wire\u0026rsquo;s full cross section at any point in time: $$\\bar I = \\frac{\\Delta Q}{\\Delta t} \\Longrightarrow I = \\frac{dQ}{dt}$$ Current is measured in coulombs per second; ampere (amp): .$\\text{1 A = 1 C/s}$  25.3 Ohm\u0026rsquo;s Law: Resistance and Resistors #   For a current to exist, there must be a potential difference (e.g. between the terminals of a battery) That is, the current is proportional to the potential difference: $$I \\propto V$$  E.x., a wire connected to a .$6V$ battery results in a current twice that of a .$3V$ battery   The current depends on the resistance that the wires offers  The electron flow is impeded partly due to the atoms in the wire .$R$ is this proportionality factor between voltage and current Thus, we get Ohm\u0026rsquo;s Law: $$V = IR$$   Ohm\u0026rsquo;s law only works for when .$R$ is a constant, i.e a metal conductor  In reality, .$R$ isn\u0026rsquo;t constant if temperature changes much Materials that follow Ohm\u0026rsquo;s law are labeled as \u0026ldquo;ohmic\u0026rdquo; Resistance has the units/notation .$\\text{1 $\\Omega$ = 1 V/A}$   Resistors are used to limit/control the current in a circuit  toolbox.mehvix.com/resistor As a current passes through a resistor, the charge/current stays the same but the electric potential decreases  Clarifications of Behavior\n Current\u0026rsquo;s magnitude depends on that device\u0026rsquo;s resistance  Can be though of as the \u0026ldquo;response\u0026rdquo; to the voltage: increases if voltage increases or resistance decreases Current is constant \u0026ndash; it\u0026rsquo;s energy so it cannot be destroyed by components and it\u0026rsquo;s not created by a battery   Resistance is a property of the device/wire Voltage is external to the wire of device \u0026ndash; it\u0026rsquo;s applied across the two ends of the wire  Batteries maintain a constant potential difference \u0026ndash; act as a source of voltage     25.4 Resistivity #   Resistivity has experimentally been found as $$R = \\rho \\frac{l}{A}$$  .$\\rho$ is the resistivity (constant of proportionality) and depends on the material  Has units .$\\Omega \\cdot \\text{m = V/A $\\cdot $ m}$   .$l$ is the wire length .$A$ is the cross-section area   The reciprocal of resistivity is conductivity: .$\\sigma = \\rho^{-1}$  Temperature #   Resistivity varies (generally increasing) with temperature $$\\rho_T = \\rho_0 = \\bigg[ 1+ \\alpha (T-T_0)\\bigg]$$  .$\\rho_0$ is the resistivity at some reference temperature .$T_0$ (i.e .$0^\\circ \\text{ C}$) .$\\rho_T$ is the new resistivity at the current (higher) temperature .$T$ .$\\alpha$ is the temperature coefficient of resistivity that depends on material   Note that the temperature coefficient for semiconductors can be negative.  At higher temperatures, some of the electrons that are normally not free in a semiconductor can become free and contribute to the current. Thus, the resistance of a semiconductor can decrease with an increase in temperature.    25.5 Electric Power #   Electric energy is transformed into thermal energy (and light) in stove burners, toasters, etc.  The current creates collisions between the moving electrons and the atoms in the wire That is, the KE from the wire\u0026rsquo;s atoms increases meaning the temperature increases too $$P = \\frac{dU}{dt} = \\frac{dq}{dt}\\cdot V$$  This is because energy is transformed when a tiny charge .$dq$ moves through a potential difference .$V$ is .$dU = V\\ dq$     The charge that flows per second, .$dq/dt$, is the electric current .$I$: $$P = IV = I^2 R = \\frac{V^2}{R}$$  The SI unit for power is the watt: .$\\text{1 W = 1 J/s}$ We get the last two equations by plugging in .$V = IR$    25.7 Alternating Current #   When a battery is connected to a circuit, the current moves steadily in one direction (DC: Direct Current) Electric generators at power plants produce AC: alternating current  Reverses direction many times per second and is commonly sinusoidal $$V = V_0 \\sin(2\\pi ft) = V_0 \\sin(\\omega t)$$ .$\\omega$ = .$2\\pi f$ .$f$ is the frequency: number of complete oscillations per second  Commonly .$\\text{60 Hz}$ in NA   Potential .$V$ oscillates between .$\\pm V_0$, the peak voltage   Current equation still works: $$I = \\frac{V}{R} = \\frac{V_0}{R}\\sin\\omega t = I_0 \\sin\\omega t$$  .$I_0 = V_0/R$ is the peak current Avg current is 0; it\u0026rsquo;s positive and negative for an equal amount of time  Doesn\u0026rsquo;t mean that no heat is created or no power is needed Electrons are still moving though!     Power is also consistent $$P = I^2R = I_0^2 R \\sin\\omega t = \\frac{V_0^2}{R} \\sin\\omega t$$  Power is always positive because current is squared Since the .$\\sin\\dots$ oscillates between 1 and 0, the average power is $$\\overline P = \\frac{1}{2}I_0^2R = \\frac{1}{2} \\frac{V_0^2}{R}$$ This can also be calculated by using the RMS values for .$I$ and .$V$ $$I_\\text{rms} = \\sqrt{\\overline I^2} = \\frac{I_0}{\\sqrt{2}} \\approx 0.707 I_0$$ $$V_\\text{rms} = \\sqrt{\\overline V^2} = \\frac{V_0}{\\sqrt{2}} \\approx 0.707 V_0$$ $$\\dots \\Longrightarrow \\overline P = I_\\text{rms} V_\\text{rms} = I_\\text{rms}^2 R = \\frac{V_\\text{rms}^2}{R}$$ Fun fact: we can use the rms of a value to find the peak of it, e.x. $$V_0 = \\sqrt{2} V_\\text{rms}$$ Keep in mind that this is the average power. Instantaneous power varies from .$0$ to .$2\\overline P$    25.8 Microscopic View of Current #   We\u0026rsquo;ve seen that electric current can be carried by negatively charged electrons in metal wires, and that in liquid solutions current can also be carried by positive and/or negatively charged ions When a potential difference is applied to the two ends of a wire, the direction of the electric field .$\\vec E$ is parallel to the walls of the wire  This field within the conducting wire does not contradict our earlier result that .$\\vec E = 0$ inside a conductor in the electrostatic case, as we are no longer dealing with the static case. That is, charges are free to move in a conductor, and hence can move under the action of the electric field.  If all the charges are at rest, then .$\\vec E = 0$       Current Density #   Current density, .$\\vec j$, is the current per area $$j = \\frac{I}{A} \\Longrightarrow I = \\int \\vec j \\cdot d \\vec A$$  .$I$ is the current through the whole surface .$d\\vec A$ is an element of surface area over which the integration is taken Direction of the density is the same direction as .$\\vec E$ \u0026ndash; the direction that a positive charge would move    Drift Speed #   Inside a wire, we can imagine the free electrons as moving about randomly at high speeds, bouncing off the metal atoms of the wire  Somewhat like the molecules of a gas   When an electric field exists in the wire the electrons feel a force and initially begin to accelerate but they soon reach a more or less steady average speed, known as their drift speed .$v_d$  Collisions with atoms in the wire keep them from accelerating further The drift speed is normally very much smaller than the electrons' average random speed inside the metal wire     Black zagged line represents the motion of an electron in a metal wire due to an electric field. The field .$\\vec E$ gives electrons in random motion a net drift velocity .$\\vec v_d$. Its direction (the net charge flow) is in the opposite direction of .$\\vec E$ because electrons have a negative charge and .$\\vec F = q \\vec E$   We can relate drift speed with the macroscopic view:  In some time, the electrons travel (the average) distance .$l = v_d \\Delta t$ In that same time, electrons in volume .$V = Al = A v_d \\Delta t$ pass through area .$A$ of the wire If there are .$n$ free electrons each of charge .$-e$ per unit volume, then the total electrons is .$N = nV$ Thus, the charge is $$\\Delta Q = \\text{(number of charges, $N$)$\\times$(charge per particle, $-e$)}$$ $$\\dots = (nV)(-e) = -(nAv_d\\Delta T)(e)$$ We can then easily find the current (density): $$I = \\frac{\\Delta Q}{\\Delta t} = -neAv_d$$ $$j = \\frac{I}{A} = -nev_d$$ Notice that the negative sign indicates that the direction of (positive) current flow is opposite to the drift speed of electrons.    Field inside a Wire #   Voltage can be written in terms of microscopic values (in addition to the macro: .$V = IR$) Recall that resistance is related to density by .$R = \\rho \\frac{l}{A}$ We can then write .$V$, .$I$ and .$j$ as $$V = El = IR = (jA)\\bigg(\\rho \\frac{l}{A}\\bigg) = j \\rho l$$  $$I = jA$$  $$j = \\frac{1}{\\rho}E = \\sigma E$$    .$\\sigma$ is the conductivity of the wire .$\\rho, \\sigma$ do not vary with .$V$ and thus neither .$E$   We can then write the microscopic statement of Ohm\u0026rsquo;s Law: $$\\vec j = \\sigma \\vec E = \\frac{\\vec E}{\\rho}$$  25.9 Superconductivity #   At very low temperatures, the resistivity of certain metals and certain compounds or alloys becomes zero Materials in such a state are said to be superconducting In general, superconductors become superconducting only below a certain transition (critical) temperature, .$T_C$   "},{"id":25,"href":"/physics-7b/26/","title":"26: DC Circuits","section":"Physics 7B","content":"26.1 EMF and Terminal Voltage #  EMF #   To have a current, we need an emf (electromotive force) device to transform one type of energy (chemical, mechanical, light) into electric energy  The term “electromotive force” is a misnomer: it does not refer to a “force,” which is measured in newtons. To avoid confusion, we use the abbreviation, emf.   EMF of the Source: The potential difference between the terminals of a source when no current flows to an external circuit .$\\mathscr{E}$ is used for emf and it\u0026rsquo;s units is (V)olts  Batteries #   Batteries don\u0026rsquo;t have constant current (it varies with resistance of the circuit) Voltage is nearly constant, but decreases when battery cannot supply charge fast enough to maintain full emf  This occurs because the charge must move between/through the electrodes in the battery Additionally, the battery has some internal resistance, .$r$   Batteries are treated as a perfect emf .$\\mathscr{E}$ in a series with a resistor .$r$  The terminal voltage is .$V_\\text{ab} = V_a - V_b$  When a battery is being charged, a current is forced to pass through it; we then have to write .$V_\\text{ab} = \\mathscr{E} + Ir$   When no current is drawn, .$V_\\text{ab} = \\mathscr{E} - Ir$  .$Ir$ comes from the fact that when .$I$ flows from the battery it causes an internal voltage drop .$Ir$   Since .$\\mathscr{E} - Ir = IR \\Longrightarrow \\mathscr{E} = I(R+r)$ for .$R$ as the resistance of the circuit    26.2 Resistors in Series and Parallel #  Series #   Any charge that passes through one resistor passes through all  Hence, the same current .$I$ passes through each too (constant) If this wasn\u0026rsquo;t true, then it would imply the charge was not conserved   Voltage from the battery is split between each resistor proportional to .$R$ $$V = V_1 + V_2 + \\dots = I R_1 + I R_2 + \\dots = I(R_1 + R_2 + \\dots)$$  Thus, .$R_\\text{eq} = R_1 + R_2 + \\dots$   Note that when you add more resistance to the circuit\u0026hellip;  The current that passes through each resistor decreases The equivalent resistance increases Voltage stays the same since the battery is unaltered    Parallel #   Current is split from the source path into branches  Thus, paths outside of one\u0026rsquo;s branch doesn\u0026rsquo;t impact/interrupt current The current from each branch must equal the total current; i.e $$I = I_1 + I_2 + \\dots$$   Voltage across each resistor is equivalent; $$I_1 = \\frac{V}{R_1}, I_2 = \\frac{V}{R_2}, \\dots \\Longrightarrow I_\\text{eq} = \\frac{V}{R_\\text{eq}}$$  Thus, .$R_\\text{eq}$ is equal to $$ \\frac{1}{R_\\text{eq}} = \\frac{1}{R_1} + \\frac{1}{R_2} + \\dots$$   Note that when you add another resistor to the circuit\u0026hellip;  Net resistance goes down  Adding another resistor adds another path causing current to decrease   Voltage stays the same since the battery is unaltered Consistent with .$R = \\rho l/A$ definition of resistance  Series is effectively increasing the length Parallel increases the area through which current flows      26.3 Kirchhoff\u0026rsquo;s Rules #  We use Kirchhoff\u0026rsquo;s two rules when circuits get too complex for trivial analysis\n1. Junction Rule: At any junction point, the sum of all currents entering the junction must equal the sum of all currents leaving the junction.   That is, what goes out must come back in Based on conservation of electric charge Mathematically, $$\\sum_{k=1}^{n} I_k = 0$$  .$n$ is the total number of branches with currents flowing towards or away from the node.       The current entering any junction is equal to the current leaving that junction: .$I_2 + I_3 = I_1 + I_4$\n   2. Loop Rule: The sum of the changes in potential around any closed loop of a circuit must be zero.   That is, what goes up must come back down  There is as much up as there is down At the battery, the gain/loss on each terminal cancel one another along the closed circuit path   Based on conservation of energy Mathematically, $$\\sum_{k=1}^{n} V_k = 0$$  .$n$ is the total number of voltages measured.       The sum of all the voltages around a loop is equal to zero: .$V_1 + V_2 + V_3 + V_4 = 0$\n   26.4 EMFs in Series and Parallel; Charging a Battery #   (a) Two similarly arranged batteries in a series sum their voltages; e.x. 3V (b) Two oppositely arranged batteries in a series subtract their voltages; e.x. 8V  How battery charging works The 20V source is charging up the 12V battery Because of it\u0026rsquo;s greater voltage, the 20V is forcing charge back into the 12V   (c) Two batteries in parallel, which if the emfs are the same, can provide more energy when large currents are needed.  Each of the cells in parallel has to produce only a fraction of the total current, so the energy loss due to internal resistance is less than for a single cell Thus, the batteries will drain less quickly.        26.5 RC Circuits: Resistor \u0026amp; Capacitor in Series #  RC Circuits differ in that they have varying current\nCapacitor Charging #   After the switch .$S$ closes in the RC circuit shown in (a), the voltage across the capacitor increases with time as shown in (b), and the current through the resistor decreases with time as shown in (c).\n    (a) When closed, the current starts flowing through the circuit from the negative terminal through .$R$ and accumulate on the upper plate of the capacitor which creates potential difference equal to .$V_C = Q/C$  Current is then reduced because of this opposing voltage on the capacitor   (b) Eventually, the potential equals the emf, .$\\mathscr{E}$, and then no current flows and no potential difference across the resistor  Potential difference, .$V_C$, across the capacitor is equal to the charge on it, .$V_C = Q/C$ Because charge increases with time, so does voltage until this point The emf .$\\mathscr{E}$ of the battery will equal the sum of the voltage drops across the resistor and the capacitor: $$\\mathscr{E} = IR + \\frac{Q}{C}$$  .$R$ is total circuit resistance, including battery .$I$ is current at all points in the circuit at any instant .$Q$ is the charge of the capacitor at that same instant Notice: .$\\mathscr{E}, R, C$ are constants, .$Q, I$ are functions of time     (c) As charge builds up on the capacitor, the current decreases exponentially in time with a time constant .$\\tau$ equal to .$RC$     The rate at which charge flows thorough the resistor (.$I = dQ/dT$) is equal to the rate at which charge accumulates on the capacitor: $$ \\mathscr{E} = \\bigg(\\frac{dQ}{dt}\\bigg)R + \\frac{1}{C}Q$$ This can then be used to find an equation of .$Q$: $$ \\Longrightarrow \\frac{dQ}{C\\mathscr{E} - Q} = \\frac{dt}{RC} \\Longrightarrow \\int_0^Q \\frac{dQ}{C\\mathscr{E} - Q} = \\frac{1}{RC}\\int_0^t dt$$ $$ \\Longrightarrow \\ln\\bigg(1 - \\frac{Q}{C \\mathscr{E}}\\bigg) = - \\frac{t}{RC} \\Longrightarrow 1 - \\frac{Q}{C\\mathscr{E}} = e^{-t/RC}$$ $$ \\Longrightarrow Q = C\\mathscr{E}(1-e^{-t/RT}) = Q_0 (1-e^{-t/RT})$$  .$Q_0 = C \\mathscr{E}$ represents the maximum charge on the capacitor  .$Q_0 \\neq \\text{charge $(Q)$ at $t = 0$}$ The potential difference across the capacitor is .$V_C = Q/C$ so the maximum value is $$ V_C = \\mathscr{E}(1-e^{-t/RC})$$     .$\\tau = RC$ is the axis units on graph (b) and is aptly called the time constant of the circuit  Represents the time required for the capacitor to reach .$(1-e^{-1}) = 0.63 = 63\\text{%}$ of its full charge and voltage  Also represents the time for the current to drop to .$1/e \\approx 0.37$ of it\u0026rsquo;s initial value   Thus, it measures how quickly the capacitor becomes charged We use this as a measurement since the maximums only occur as we take .$t \\to \\infty$, but these values reach 86% of the way in .$2RC = 2\\tau$, 95% in .$3\\tau$, 98% in .$4\\tau$, so on   The current in the circuit at any time can be found by differentiating the following: $$I = \\frac{dQ}{dt} = \\frac{\\mathscr{E}}{R}e^{-t/RC}$$  This is an exponential decay function: when .$t = 0$, the current is largest because there is no charge on the capacitor to impede it That is, .$I = I_0 = \\mathscr{E}/R$ As charge builds up, the current decreases exponentially in time (as shown in (c))    Capacitor Discharging #   Now imagine the opposite case; we start fully charged at .$Q_0$ with voltage .$V_0$ and have to discharge through resistance .$R$ The voltage across the resistor at any instant equals that across the capacitor: $$V = IR = \\frac{Q}{C}$$ We can use this to find the functions for both .$Q_0$ and .$V_C$: $$ - \\frac{dQ}{dt} R = \\frac{Q}{C} \\Longrightarrow \\frac{dq}{Q} = - \\frac{dt}{RC}$$ $$ \\ln \\frac{Q}{Q_0} = - (t/RC) \\Longrightarrow Q = Q_0 e^{-t/RC}$$ $$ \\dots \\Longrightarrow V_C = V_0 e^{-t/RC}$$  For the RC circuit shown in (a), the voltage .$V_C$ across the capacitor decreases with time, as shown in (b), after the switch S is closed at .$t = 0$. The charge on the capacitor follows the same curve because .$Q \\propto V_C$   $$$$ $$$$\n .$V_0 = Q_0 / C$ is the initial voltage, related to initial charge We can see the charge on the capacitor, thus the voltage across it, decreases exponentially in time Current is found to be $$I = - \\frac{dQ}{dt} = \\frac{Q_0}{RC}e^{-t/RC} = I_0 e^{-t/RC}$$ The charge on the capacitor, the voltage across it, and the current in the resistor all decrease to 37% of their original value in one time constant .$t = \\tau \\ RC$      26.6 Electric Hazards and Safety (not covered) #   Current above .$\\text{1 mA}$ can be felt Current above .$\\text{10 mA}$ cause severe contraction of muscles (may not be able to let go of source) Current above .$\\text{80-100 mA}$ that passes through the torso (passing through the heart for a second) will cause ventricular fibrillation (heart stops pumping blood properly) It\u0026rsquo;s current that harms, even though voltage drives the current  The seriousness of a shock depends on the current and thus the applied voltage and the effective resistance of the body More voltage shocks, more current kills Wet skin has resistance of .$10^3 \\Omega$ while dry skin is around .$10^5 \\Omega$    26.7 Ammeters and Voltmeters: Measurement Affects Quantity Measured (not covered) #   Measuring is hard to do both precisely and consistently Ammeters measure current (amps) and voltmeters measure potential difference or voltage (volts) An analog ammeter or voltmeter uses a galvanometer  The full scale sensitivity, .$I_m$, is the electric current required to make the needle deflect a full scale; typically .$50 \\mu\\text{A}$     An ammeter is a galvanometer in parallel with a shunt resistor with low resistance, .$R_\\text{sh}$    A voltmeter is a galvanometer in series with a resistor with high resistance, .$R_\\text{ser}$     (b) Because an ammeter is used to measure the current flowing in the circuit, it must be inserted directly into the circuit, in series with the other elements. The smaller its internal resistance, the less it affects the circuit. (c) A voltmeter is connected “externally,” in parallel with the circuit element across which the voltage is to be measured. It measures the potential difference between two points. Its two wire “leads” (connecting wires) are connected to the two points.  Only .$R_1$ is being measured above        If the resistance of a voltmeter is much higher than the resistance of the circuit, it will have little effect and its readings can be more accurate  At least to the manufactured precision of the meter, which for analog meters is typically 3% to 4% of full-scale deflection.   Sensitivity: The sensitivity of a voltmeter is specified on its face as, for example, .$10,000\\ \\Omega/\\text{V}$. Then on the .$5\\text{V}$ scale, the voltmeter would have a resistance given by .$\\text{(5V)(10,000 $\\Omega$/V) = 50,000 $\\Omega$}$ Even an ammeter can interfere with a circuit, but the effect is minimal if its resistance is much less than that of the circuit as a whole. For both voltmeters and ammeters, the more sensitive the galvanometer, the less effect it will have on the circuit.  "},{"id":26,"href":"/physics-7b/27/","title":"27: Magnetism","section":"Physics 7B","content":"27.1 Magnets and Magnetic Fields #   Every magnet has two ends or faces called poles which are where the magnetic field is strongest  If a magnet is suspended so it can move freely, one pole will point north Aptly, this side is called the north pole   Magnetic poles aren\u0026rsquo;t like electric charge: Positive or negative charge can easily be isolated, but we can never isolate a magnetic pole  That is, if you cut a magnet is half you don\u0026rsquo;t obtain isolated north and south poles. Rather, you end up with two new magnets each with north and south poles   Ferromagnetic: Materials with a strong magnetic effect i.e. iron, cobalt, nickel, gadolinium Similar to how we picture electric fields around a charge, we can picture magnetic fields surround a magnet  Field lines should be drawn so that (1) the direction of the magnetic field is always tangent to a field line everywhere and (2) the number of lines per unit area is proportional to the magnetic field strength    (a) Visualizing magnetic field lines around a bar magnet, using iron filings and compass needles. The red end of the bar magnet is its north pole. The N pole of a nearby compass needle points away from the north pole of the magnet. (b) Diagram of magnetic field lines for a bar magnet.\n   Earth\u0026rsquo;s Magnetic Field #   Earth\u0026rsquo;s magnetic poles are not exactly through the geographic pole (axis of rotation) The angular difference between the direction of the compass needle (which points along the magnetic field lines) at any location and true (geographical) north varies between .$0 - 20^\\circ$ with location Earth\u0026rsquo;s magnetic field at most location is not tangent to earth\u0026rsquo;s surface  Angle of Dip: The angle that Earth\u0026rsquo;s magnetic field makes with the horizontal at any point       The Earth acts like a huge magnet. But its magnetic poles are not at the geographic poles (on the Earth\u0026rsquo;s rotation axis).\n   27.2 Electric Currents Produce Magnet Fields #    (a) Deflection of compass needles near a current-carrying wire, showing the presence and direction of the magnetic field. (b) Iron filings also align along the direction of the magnetic field lines near a straight current-carrying wire. (c) Diagram of the magnetic field lines around an electric current in a straight wire. (d) Right-hand-rule-1 for remembering the direction of the magnetic field: when the thumb points in the direction of the conventional current, the fingers wrapped around the wire point in the direction of the magnetic field. (.$\\vec B$ is the symbol for magnetic field).\n 27.3 Force on an Electric Current in a Magnetic Field #   By Newton\u0026rsquo;s third law, we can see that a magnet exerts a force on a current-carrying wire  The direction of the force is always perpendicular to the direction of the current and also perpendicular to the direction of the magnetic field .$\\vec B$ Use right hand rule! $$dF_\\vec{B} = dq (\\vec v \\times \\vec B) = dq\\bigg(\\frac{d\\vec l}{dt}\\times \\vec B\\bigg) = I (d\\vec l \\times \\vec B)$$ $$\\dots\\ \\vec F = I (\\vec l \\times \\vec B) = I l b \\sin\\theta$$ .$\\vec l$ is the vector whose magnitude is the length of the wire its direction is along the (straight) wire in the direction of the conventional (positive) current We use the last equation if .$\\vec B$ isn\u0026rsquo;t uniform or if the wire doesn\u0026rsquo;t form angle .$\\theta$ with .$\\vec B$ everywhere    27.4 Force on an Electric Charge Moving in a Magnetic Field #   Recall, .$N$ particles, each charge .$q$, pass by a given point in time .$t$, they constitute current .$I = N q/t$  Lets say in .$t$ time, a particle charge .$q$ moves distance .$l$ in a magnetic field .$\\vec B$ We know from kinematics that .$\\vec l = \\vec v t$ where .$\\vec v$ is the velocity of the particle Using the 27.3 equation, we can find the force on all of these .$N$ particles as $$\\vec F = I\\vec l \\times \\vec B = (Nq/t)(\\vec v t) \\times \\vec B = Nq\\vec v \\times \\vec B$$ Thus, the force on just one of the .$N$ particles is $$\\vec F = q \\vec v \\times \\vec B = qvB \\sin\\theta$$   Realize that we can save a lot of pain if we know that the magnetic field is uniform in which case .$\\vec F_\\vec{B} = 0$ because the forces on opposite segments (sides) cancel out  Uniform Field Path #    Force exerted by a uniform magnetic field on a moving charged particle (in this case, an electron) produces a circular path.\n   Notice the field goes into the paper, denoted with .$\\times$ Because force is always orthogonal to .$\\vec v$, the magnitude of .$\\vec v$ The centripetal acceleration has magnitude .$a = v^2/r$  Thus we can derive $$F = ma \\Longrightarrow qvB = m \\frac{v^2}{r}$$ $$\\dots \\Longrightarrow r = \\frac{mv}{qB}$$   The time .$T$ it takes a particle with charge .$q$ and speed .$v$ to make a revolution is $$T = \\frac{2\\pi\\cdot r}{v} = \\frac{2\\pi m}{qB}$$ $$f = \\frac{1}{T} = \\frac{qB}{2\\pi m}$$    Problem Solving #  Magnetic fields are somewhat analogous to the electric fields, but there are several important differences to recall:\n The force experienced by a charged particle moving in a magnetic field is orthogonal to the direction of the magnetic field (and to the direction of the velocity of the particle), whereas the force exerted by an electric field is parallel to the direction of the field (and independent of the velocity of the particle). The right hand rule, in its different forms, is intended to help you determine the direction of magnetic field, and the force a field exerts, and/or the directions of electric current or charged particle velocity. The right-hand rules to the right are designed to deal with the “perpendicular” nature of these quantities.      With Electric Field #   Lorentz Equation: A particle charge .$q$ moving with velocity .$\\vec v$ in the presence of both a magnetic field .$\\vec B$ and electric field .$\\vec E$ experiences a force $$\\vec F = q (\\vec E + \\vec v \\times \\vec B)$$ Realize that the magnetic field cannot alter speed (do work), it can only alter the direction!  To change an objects speed, you must apply a force along the objects direction of motion The magnetic field exerts a force on particles moving orthogonal to it Therefore, no work can be done because the particle can only move orthogonal to the magnetic field That being said, realize that this field is responsible for the circular, constant speed, motion This is why earth\u0026rsquo;s magnetic field deflects, but doesn\u0026rsquo;t slow down, charged particles from outer space    27.5 Torque on a Current Loop; Magnetic Dipole Moment #   Calculating the torque on a current loop in a magnetic field .$\\vec B$\n   (a) Loop face parallel to .$\\vec B$ field lines; (b) top view; (c) loop makes an angle to .$\\vec B$, reducing the torque since the lever arm is reduced. The vector .$\\vec \\mu$ is the “magnetic moment”.\n   When an electric current flows in a closed wire loop that\u0026rsquo;s in an external magnetic field, the magnetic force on the current can produce a torque $$\\tau = I aB \\frac{b}{2} + I aB \\frac{b}{2}$$ $$\\dots = IabB$$  .$A = ab$ is the area of the loop .$B$ is scalar of the magnetic field Notice, the vertical (orthogonal) sections of wire experience no force from the magnetic field   If we have a coil of .$N$ loops of wire, the current is then .$NI$ so torque becomes $$\\tau = NIAB$$  We call .$\\vec \\mu = NI \\vec A$ the magnetic dipole moment The direction of .$\\vec A$ (and thus .$\\vec \\mu$) is defined as perpendicular to the plane of the coil   We can then re-write our torque eq as $$\\vec \\tau = NI \\vec A \\times \\vec B$$ $$\\dots \\vec \\tau = \\vec \\mu \\times \\vec B$$ Dipoles have some potential energy, found by $$U = \\int \\tau d\\theta = \\int NIAB\\sin\\theta d \\theta$$ $$\\dots = -\\mu B \\cos\\theta = - \\vec \\mu \\cdot \\vec B$$    27.8 Hall Effect #   When a current-carrying conductor is held fixed in a magnetic field, the field exerts a sideways force on the charge moving in the conductor  E.x, if electrons move to the right in the rectangular conductor, the inward magnetic field will exert a downward force: (a) This force is .$F_B = -e\\vec v_d \\times \\vec B$  .$v_d$ is drift velocity     Thus, electrons tend to move towards side .$D$  This creates a potential difference (called the Hall emf), creating field .$\\vec E_H$ This field exerts force .$e\\vec E_H$ on the moving charge   These forces are equal, that is, $$e E_H = ev_d B$$ $$\\therefore E_H = v_d B$$ Hall emf is then, asm uniform .$E_H$, $$\\mathscr{E}_H = E_H d = v_d B d$$  .$d$ is the width of the conductor         The Hall effect. (a) Negative charges moving to the right as the current. (b) Positive charges moving to the left as the current.\n   27.9 Mass Spectrometer #     Mass spectrometers are used to measure the masses of atoms\n  Steps:    Ions are produced (by a current or heating) and they pass through slit .$S_1$ Ions then pass through a region with perpendicular electric and magnetic fields.  Here, .$F_E = qE$ is equal to .$F_B = qvB$ Therefore, .$v = \\frac{E}{B}$ for all ions that pass the slit into .$S_2$; the rest are deflected        Entering .$S_2$, there is only magnetic field .$B'$ so the ios follow a circular path  Newtons second gives us .$F = ma \\Longrightarrow qvB' = mv^2/r$ Since we know all terms, we can solve for mass: .$m = \\frac{qB\u0026rsquo;r}{v} = \\frac{qBB\u0026rsquo;r}{E}$    "},{"id":27,"href":"/physics-7b/28/","title":"28: Sources of Magnetic Field","section":"Physics 7B","content":"28.1 Magnetic Field Due to a Straight Wire #   Magnetic fields due to the electric current in a long straight wire forms circles with the wire at the center This field is proportional directly with current .$I$ and inversely with distance .$r$: $$B = \\frac{\\mu_0}{2\\pi} \\cdot \\frac{I}{r}$$  .$\\mu_0 = 4\\pi \\times 10^{-7} \\text{ T$\\cdot$m/A}$ is the permeability of free space       28.2 Force between Two Parallel Wires #    Since current-carrying wires feel a force in magnetic fields, and because current-carrying wires emit magnetic fields, current-carrying wires exert a force on one another Magnetic field .$B_1$ produced by .$I_1$ is given by $$B_1 = \\frac{\\mu_0}{2\\pi} \\cdot \\frac{I_1}{d}$$ Parallel currents in the same direction attract while antiparallel repel     Using .$F = IlB$ we can write the force .$F_2$ exerted by .$B_1$ on length .$l_2$ carrying .$I_2$ has magnitude: $$F_2 = I_2 l_2 B_1$$  Notice that the force on .$I_1$ is due to the field produced by .$I_1$ Thus, subbing .$B_1$ into the .$F_2$ formula we find the force on length .$l_2$: $$F_2 = \\frac{\\mu_0}{2\\pi} \\cdot \\frac{I_1 I_2}{d}l_2$$    28.3 Definitions of the Ampere and the Coulomb #  One ampere can be defined as that current flowing in each of two long parallel wires exactly 1 m apart, which results in a force of exactly .$2\\times10^{-7}$ N per meter of length of each wire   This was the standard we used prior because it is readily reproducible (that is, it\u0026rsquo;s called an operational definition) Coulomb is defined in terms of the ampere being exactly one ampere-second: .$\\text{1 C = A $\\cdot$ s}$  Now we define an ampere ampere by saying it\u0026rsquo;s .$\\text{1 C = A $\\cdot$ s}$ and we know the Coulomb because it\u0026rsquo;s mutually assigned the exact value .$e = 1.60176636 \\times 10^{-19}\\text{ C}$    28.4 Ampère\u0026rsquo;s Law #   If we don\u0026rsquo;t have a straight line, we use ampere\u0026rsquo;s law given below We take a infinite tiny segments and dot it with the field at the segment: $$\\oint \\vec B \\cdot d \\vec l = \\mu_0 I_\\text{encl}$$ Note that .$\\vec B$ in Ampere\u0026rsquo;s law isn\u0026rsquo;t necessarily due only to the current .$I_\\text{encl}$ As with Gauss\u0026rsquo;s law for the electric field, Ampere\u0026rsquo;s law practical value to calculate the magnetic field is limited, however, mainly to simple or symmetric situations.  Its importance is that it relates the magnetic field to the current in a direct and mathematically elegant way.        Ampère\u0026rsquo;s law is considered one of the basic laws of electricity and magnetism: It is valid for any situation where the currents and fields are steady and not changing in time, and no magnetic materials are present  Problem Solving: #   Ampère\u0026rsquo;s law, like Gauss\u0026rsquo;s law, is always a valid statement. But as a calculation tool it is limited mainly to systems with a high degree of symmetry. The first step in applying Ampère\u0026rsquo;s law is to identify useful symmetry. Choose an integration path that reflects the symmetry. Search for paths where .$\\vec B$ has constant magnitude along the entire path or along segments of the path. Make sure your integration path passes through the point where you wish to evaluate the magnetic field. Use symmetry to determine the direction of .$\\vec B$ along the integration path. With a smart choice of path, .$\\vec B$ will be either parallel or perpendicular to the path. Determine the enclosed current, .$I_\\text{encl}$. Be careful with signs. Let the fingers of your right hand curl along the direction of .$\\vec B$ so that your thumb shows the direction of positive current. If you have a solid conductor and your integration path does not enclose the full current, you can use the current density (current per unit area) multiplied by the enclosed area.   28.5 Magnetic Field of a Solenoid and a Toroid #   Solenoid: A long looping coil of wire carrying a dc current  The current in each loop produces a magnetic field The total magnetic field is the sum of the fields due to each loop Direction is determined by the right hand rule $$\\oint \\vec B \\cdot d \\vec l = \\mu_0 NI$$     Magnetic field due to a solenoid (a) a few loosely spaced loops; (b) for many closely spaced loops, the field is nearly uniform.\n   Cross-sectional view into a solenoid. The magnetic field inside is straight except at the ends. Red dashed lines indicate the path chosen for use in Ampère\u0026rsquo;s law. .$\\odot$ and .$\\otimes$ are electric current direction (in the wire loops) out of the page and into the page.\n $$\\int_c^d \\vec B \\cdot d \\vec l = Bl_{cd}$$\n   With .$n = N/l$ is number of loops per unit length we can simplify to $$B = \\mu_0 nI$$ Now, we see that the field does not depend on position within the solenoid, so .$\\vec B$ is uniform.  This is strictly true only for an infinite solenoid, but it is a good approximation for tightly wound real ones for points not close to the ends.    28.6 Biot-Savart Law #   A current .$I$ flowing in any path can be considered as many tiny current elements, such as .$d \\vec l$  Then, .$d\\vec B$ at any point .$P$ in space due to this element of current is given by Biot-Savart law: $$d\\vec B = \\frac{\\mu_0 I}{4\\pi} \\frac{d\\vec l \\times \\hat r}{r^2} = \\frac{\\mu_0 I}{4\\pi} \\frac{dl \\sin\\theta}{r^2}$$ .$\\vec r$ is the displacement vector from the element .$d \\vec l$ to the point .$P$ .$\\hat r$ is the unit vector in the direction .$\\vec r$ .$\\theta$ is the angle between .$d\\vec l$ and .$\\vec r$      Biot-Savart Law The field at P due to current element .$I d\\vec l$ is .$d \\vec B = (\\mu_0 I/4\\pi)(d\\vec l \\times \\hat r/r^2)$\n    An important difference between the Biot-Savart law and Ampère\u0026rsquo;s law is that the later, .$\\oint \\vec B \\cdot d\\vec l = \\mu_0 I_\\text{encl}$, .$\\vec B$ is not necessarily due only to the current enclosed by the path of integration. But in the Biot-Savart law the field .$d\\vec B$ is due only, and entirely, to the current element .$I d\\vec l$ \u0026ndash; that is, to find the total .$\\vec B$ at any point in space, it is necessary to include all currents.  Biot-Savart strategy for finding a magnetic field\n Select some tiny piece of wire .$d \\vec l$ and draw the vector .$\\vec r$ pointing from said piece to the location at which you\u0026rsquo;re finding the magnetic field Using Biot-Savart, calculate the magnitude and direction of the infinitesimal magnetic field .$d\\vec B$ generated by that piece Add up all those magnetic field contributions by integrating over the wire, using vector components if needed.   Straight Wire #  $$B = \\frac{\\mu_0 I}{4\\pi}\\int_{y =-\\infty}^{+\\infty} \\frac{dy \\sin\\theta}{r^2}$$ $$dy = dl; r^2 = R^2 + y^2$$ $$dy = \\dots = \\frac{r^2 d\\theta}{R}$$ $$B = \\frac{\\mu_0 I}{4\\pi}\\frac{1}{R}\\cdot \\bigg[-\\cos\\theta\\bigg]_{\\theta = 0}^\\pi $$ $$\\dots = B = \\frac{\\mu_0 I}{2\\pi R}$$   Current Loop #  $$dB = \\frac{\\mu_0 I dl}{4\\pi r^2}$$ $$d\\vec l \\perp \\vec r; \\vert d\\vec l \\times \\hat r \\vert = dl$$ $$B = \\int dB \\cos \\phi = \\int dB \\frac{R}{r}$$ $$\\dots = \\int dB \\frac{R}{(R^2 + x^2)^{\\frac{1}{2}}}$$ $$\\dots = \\frac{\\mu_0 I}{4\\pi}\\frac{R}{(R^2 + x^2)^{\\frac{3}{2}}} \\bigg[L\\bigg]_{L = 2\\pi R}$$ $$\\dots = \\frac{\\mu_0 I}{2R}$$ Quarter Wire Segment #  $$dB = \\frac{\\mu_0 I}{4\\pi}dl$$ $$B = \\frac{\\mu_0 I}{4\\pi} \\bigg[L\\bigg]_{L =\\frac{1}{4}\\cdot 2\\pi R}$$ $$\\dots = \\frac{\\mu_0 I}{8 R}$$\n  28.6.1 Magnetic Dipole Field #   Recall that a magnetic dipole is .$\\mu = NIA$ (number of loops, current, and area of coil) The magnetic field produced by magnetic dipoles is $$B = \\frac{\\mu_0 IR^2}{2(R^2 + x^2)^{\\frac{3}{2}}}$$ This can be written in tirms of the magnetic dipole .$\\mu = IA = I\\pi R^2$ for one loop: $$B = \\frac{\\mu_0}{2\\pi} \\frac{\\mu}{(R^2 +x^2)^{\\frac{3}{2}}}$$ and at distances far from the loop .$x \\gg R$ this becomes $$B \\approx \\frac{\\mu_0}{2\\pi} \\frac{\\mu}{x^3}$$     28.7 Magnetic Field Due to a Single Moving Charge #   Realize that Biot-Savart works only when considering constant currents that do not change in time significantly over a significant length of wire Additionally, the law is difficult to confirm experimentally:  Particles would shoot out of the field before they (and thus the field) could be measured for any significant .$B$.  If .$v$ is slow enough to be measured, .$B$ is small enough it\u0026rsquo;s going to be drowned out by experimental noise   From the particles frame, it\u0026rsquo;s at rest (not moving wrt itself). And since it\u0026rsquo;s at rest, it shouldn\u0026rsquo;t create a field. However, it\u0026rsquo;s moving because it\u0026rsquo;s creating a field!  Einstein explains this with special relativity Observers in two different reference frames, moving relative to each other, will not observe the same .$\\vec E$ and .$\\vec B$ fields        What see from the perspective other than the particle: The magnetic field at one single instant due to a single positive charge .$q$ moving at velocity .$\\vec v$.\n 28.8 Magnetic Materials—Ferromagnetism (not covered) #   Magnetic fields are produced by (1) magnets and (2) electric currents Ferromagnetism: Materials that are magnetic  At a small enough resolution (less than 1mm areas!), domains exist which behave like tiny magnets \u0026ndash; they have two poles The more domains that are aligned in one direction, the stronger the magnetic field   These domains can be moved around (through dropping or hammering the magnet) Heating also reduces magnetism \u0026ndash; increasing temp increases the random thermal motion of atoms  Above the Curie Temperature (1043K for iron), a magnet cannot be made at all As a consequence, at lower temperatures, some materials are magnetic       (a) An unmagnetized piece of iron is made up of domains that are randomly arranged. Each domain is like a tiny magnet; the arrows represent the magnetization direction, with the arrowhead being the N pole. (b) In a magnet, the domains are preferentially aligned in one direction (down in this case), and may be altered in size by the magnetization process.\n    Today, we believe that all magnetic fields come from electric currents  Electrons produce a (tiny) magnetic field, as if they and their electric charges were spinning about their own additional axes   Realize that while .$\\vec B$ lines form closed loops, .$\\vec E$ lines go from a positive to negative electron  28.9 Electromagnets and Solenoids—Applications (not covered) #    Solenoids act like magnets; they have poles (determined by the right hand rule)\n  Magnetic field of a solenoid. The north pole of this solenoid, thought of as a magnet, is on the right, and the south pole is on the left.\n   If a piece of iron is placed inside a solenoid, the magnetic field is increased greatly\n The domains of the iron are aligned by the magnetic field produced by the current; that is, the iron becomes a magnet. This system of the iron-core solenoid is called an electromagnet The resulting magnetic field is the sum of the field due to the solenoid\u0026rsquo;s current and the field due to the iron, and can be hundreds or thousands of times larger than the field due to the current alone     The alloys of iron used in electromagnets acquire and lose their magnetism quite readily when the current is turned on or off, and so are referred to as “soft iron.” (It is “soft” only in a magnetic sense.) Soft iron is usually used in electromagnets so that the field can be turned on and off readily.    Iron that holds its magnetism even when there is no externally applied field is called “hard iron.” Hard iron is used in permanent magnets. Whether iron is hard or soft depends on heat treatment, type of alloy, and other factors.     Sometimes an iron core is not present—the magnetic field then comes only from the current in the wire loops.  A large field .$B$ in this case requires a large current .$I$ which produces a large amount of waste heat since .$P = I^2 R$.   But if the current-carrying wires are made of superconducting material kept below the transition temperature then very high magnetic fields can be produced, and no electric power is needed to maintain the large current in the superconducting coils.  Note that energy is required to refrigerate the coils at the low temperatures where they superconduct.    28.10 Magnetic Fields in Magnetic Materials; Hysteresis (not covered) #   The solenoid field is produced just .$n$ loops per unit length is .$B_0 = \\mu_0 n I$ If a solenoid contains a ferromagnetic material (e.x. iron), then we need to consider it\u0026rsquo;s field .$B_M$ produced in our total field calculation: $$\\vec B = \\vec B_0 + \\vec B_M$$  Often, .$B_M \\gg B_0$   We can also write this equation as $$B = \\mu n I$$  .$\\mu$ is the magnetic permeability (not electric dipole moment!) However, while .$\\mu$ is a characteristic of the material, it is not constant for ferromagnetic materials; rather, it depends on the value of the “external field” .$B_0$ .$\\mu \\gg \\mu_0$ for ferromagnetic materials    "},{"id":28,"href":"/physics-7b/29/","title":"29: Electromagnetic Induction \u0026 Faraday's Law","section":"Physics 7B","content":"29–1 Induced EMF #   A changing magnetic field induces an emf  That is, changing .$\\vec B$, not .$\\vec B$ itself, induces current Constant magnetic fields produce no current in a conductor This process is called electromagnetic induction   It doesn\u0026rsquo;t matter if the magnet or coil moves, only that there is relative motion between the two    (a) A current is induced when a magnet is moved toward a coil, momentarily increasing the magnetic field through the coil. (b) The induced current is opposite when the magnet is moved away from the coil (.$\\vec B$ decreases). In (c), no current is induced if the magnet does not move relative to the coil. It is the relative motion that counts here: the magnet can be held steady and the coil moved, which also induces an emf.\n 29–2 Faraday\u0026rsquo;s Law of Induction; Lenz\u0026rsquo;s Law #   EMF is proportional to the rate of change of the magnetic flux .$\\Phi_B$ passing through the circuit or loop with area .$A$  Given a uniform magnetic field .$\\vec B$ we write $$\\Phi_B = B_\\perp A = BA \\cos\\theta = \\vec B \\cdot \\vec A$$    For non-uniform fields, we need to integrate: $$\\Phi_B = \\int \\vec B \\cdot d \\vec A$$     The unit of magnetic flux is the tesla-meter, called the weber: .$\\text{1 Wb = 1 T$\\cdot$ m$^2$}$ Faraday\u0026rsquo;s law of induction  The emf .$\\mathscr{E}$ induced in a circuit is equal to the rate of change of magnetic flux through the circuit: $$\\mathscr{E} = -N\\frac{d\\Phi_B}{dt}$$  .$N$ is the number of loops closely wrapped so the flux passes through each     Lenz\u0026rsquo;s Law  A current produced by an induced emf creates a magnetic field that opposes the original change in magnetic flux  Faraday\u0026rsquo;s law is negative accordingly   Realize that we know have to magnetic fields:  The changing magnetic field or flux that induces the current, and The magnetic field produced by the induced current (all currents produce a magnetic field) which opposes the charge in the first   Note: The magnetic field created by induced current opposes change in external flux, not necessarily opposing the external field   It is important to note that an emf is induced whenever there is a change in flux through the coil \u0026ndash; this can be done in three ways:  Changing the magnetic field Changing the area .$A$ of the loop in the field Changing the loop\u0026rsquo;s orientation .$\\theta$ wrt the field    Problem Solving \u0026ndash; Lenz\u0026rsquo;s Law #  Lenz\u0026rsquo;s law is used to determine the direction of the (conventional) electric current induced in a loop due to a change in magnetic flux inside the loop. (The loop may already be carrying its own ordinary current.) To produce an induced current you need (1) a closed conducting loop, and (2) an external magnetic flux through the loop that is changing in time.\n Determine whether the magnetic flux .$\\Phi_B = \\vec B \\cdot \\vec A$ inside the loop is decreasing, increasing, or unchanged. The magnetic field due to the induced current: (a) points in the same direction as the external field if the flux is decreasing; (b) points in the opposite direction from the external field if the flux is increasing; or (c) is zero if the flux is not changing. Once you know the direction of the induced magnetic field, use the right hand rule to find the direction of the induced current that would give this induced .$\\vec B$ Always keep in mind that there are two magnetic fields: (1) an external field whose flux must be changing if it is to induce an electric current, and (2) a magnetic field produced by the induced current. If a wire is already carrying an electric current, the total current while the magnetic field is changing will be the algebraic sum of the original current and the induced current.   29–3 EMF Induced in a Moving Conductor #   If a conductor begins to move in a magnetic field, an emf is induced  We can use Faraday\u0026rsquo;s law and kinematics to derive an equation: $$\\mathscr{E} = \\frac{d\\Phi_B}{dt} = \\frac{B dA}{dt} = \\frac{B (l\\cdot v\\ dt)}{dt} = Blv$$  .$v$ is the speed of the conductor .$dA = l\\ dx = lv\\ dt$ is the change in area over time .$t$   Be careful! This is a generalization where .$B, l, v$ are mutually perpendicular  If they aren\u0026rsquo;t, we use the component of each that are mutually perpendicular     An emf induced on a conductor moving ina magnetic field is sometimes called a motional emf We could also derive this using our force eq from ch27: $$\\vec F = q\\vec v \\times \\vec B$$\n When the conductor moves with .$v$, as do its electrons Since .$\\vec \\perp \\vec B$, each electron feels force .$F = qvB$  The direction determined by the right hand rule (red)   If the rod is not in contact with the conductor, electrons would collect at the upper end leaving the lower positive  Therefore, there must be an induced emf!   If the rod is in contact with the conductor, the electrons will flow into the conductor and there will be a clockwise current in the loop  To calculate emf, we determine the work .$W$ needed to move a charge .$q$ from one end of the rod to the other against this potential difference: $$W = F \\times d = (qvB) \\times (l)$$ $$\\mathscr{E} = W/q = qvBl/q = Blv$$       (a) A conducting rod is moved to the right on the smooth surface of a U-shaped conductor in a uniform magnetic field .$\\vec B$ that points out of the page. The induced current is clockwise. (b) Force on an electron in the metal rod (moving to the right) is upward due to .$\\vec B$ pointing out of the page. Hence electrons can collect at the top of the rod, leaving .$+$ charge at the bottom.\n     29–4 Electric Generators #   Electric generators produce electricity by transforming mechanical energy into electric energy  Also called dynamos Opposite of what a motor does   Consists of many wires wound around an armature that can rotate in a magnetic field  This axel is turned by mechanical means (belt, steam, water falling, etc.) and an emf is induced in the rotating coil An ac current is thus the output of a generator      An ac generator     Each brush is fixed and presses against a continuous slip ring that rotates with the armature If the armature is rotating clockwise; then, .$\\vec F = q \\vec v \\times \\vec B$ applied to a charged particles in the wire  Lenz\u0026rsquo;s law tells us that the (conventional) current in the wire .$b$ on the armature is outwards, towards us, thus, the current is outwards, through brush .$b$   After one-half revolution, wire .$b$ will be where .$a$ is now and the current at .$b$ will be inwards. Thus, the current produced is alternating! If the loop is made to rotate in a uniform field .$\\vec B$ with constant angular velocity .$\\omega$, the emf produced is $$\\mathscr{E} = - \\frac{d\\Phi_B}{dt} = - \\frac{d}{dt}\\int \\vec B \\cdot d \\vec A = -\\frac{d}{dt}\\big[BA\\cos\\theta\\big]$$  .$A$ is the area of the loop .$\\theta$ is the angle between .$\\vec B$ and .$\\vec A$   Since .$\\omega = d\\theta/dt \\Longrightarrow \\theta = \\theta_0 + \\omega t$, we choose .$\\theta_0 = 0$ so $$\\mathscr{E} = - N BA \\frac{d}{dt}(\\cos(\\omega t)) = N BA \\omega \\sin (\\omega t)$$  .$N$ is the number of loops in the rotating coil, assumed to be .$1$ unless stated otherwise Thus, the output wave is sinusoidal  Amplitude .$\\mathscr{E}_0 = NBA\\omega$ .$\\mathscr{E}_\\text{rms} = \\frac{\\mathscr{E}_0}{\\sqrt{2}}$ .$f = \\omega / 2\\pi$  .$\\text{60 Hz}$ for USA + Canada, .$\\text{50 Hz}$ for EU         dc generators  Same for ac, except the slip rings are replaced by split-ring commutators (just like a dc motor) The curve output becomes more smooth by placing a capacitor in parallel with the output  More commonly, is the use of many armature windings A capacitor tends to store charge and, if the time constant .$RC$ is long enough, helps to smooth out the voltage as shown in the figure to the right.         (a) A dc generator with one set of commutators, and (b) a dc generator with many sets of commutators and windings.\n   29–6 Transformers and Transmission of Power #   Transformer: Device used to increase or decrease an ac voltage  Made up of two coils know as the primary and secondary coil  Primary is the input, secondary is the output These can be interwoven (with insulated wire); or can be linked by an iron core that\u0026rsquo;s laminated   We assume energy losses (in resistance and hysteresis) can be ignored   When an ac voltage is applied to the primary coil, the changing magnetic field it produces will induce an ac voltage of the same .$f$requency in the secondary coil However, secondary voltage, .$V_S$, changes according to the number of turns or loops in each coil: $$V_S = N_S \\frac{d\\Phi_B}{dt}$$  .$N_S$ is the number of turns in the secondary coil .$\\Phi_B/dt$ is the rate at which the magnetic flux changes through each coil   The input voltage, .$V_P$, is related to this rate too: $$V_P = N_P \\frac{d\\Phi_B}{dt}$$  .$N_P$ is the number of turns in the primary coil This follows because the changing flux produce a back emf, .$N_P\\ d\\Phi_B / dt$, in the primary that exactly balances the applied voltage .$V_P$  This is because of Kirchhoff\u0026rsquo;s rules This is only the case if the resistance of the primary can be ignored (which we assume)     Then, we can divide these two equations, assuming little or no flux loss, to find $$\\frac{V_S}{V_P} = \\frac{N_S}{N_P}$$  .$V_S$ and .$V_P$ can be the rms or peak values for both Step-up (.$N_S \u0026gt; N_P$) increase voltage; step-down (.$N_S \u0026lt; N_P$) decrease This is called the transformer equation which tells us how the secondary (output) is related to the primary (input) DC voltages don\u0026rsquo;t work in a transformer because there\u0026rsquo;d be no change in magnetic flux   But muh conservation of energy!  Power output is essentially the power input since transformers tend to be 99%+ efficient  The little amount of energy lost is to heat   Since .$P = IV$ and .$P_P \\approx P_S$, we have $$I_P V_P = I_S V_S \\Longrightarrow \\frac{I_S}{I_P} = \\frac{V_S}{V_P} = \\frac{N_P}{N_S}$$    29–7 A Changing Magnetic Flux Produces an Electric Field #   A changing magnetic flux produces an electric field  This applies not only to wires and other conductors, but is a general result that applies to any region in space An electric field will be produced (induced) at any point in space where theres is a changing magnetic field These electric fields are not static, as are the electric fields due to electric charges at rest    Faraday\u0026rsquo;s Law \u0026ndash; General Form #  $$ \\mathscr{E} = \\oint \\vec E \\cdot d \\vec l = - \\frac{d\\Phi_B}{dt}$$\n The first two terms come from the fact that the emf .$\\mathscr{E}$ induced in a circuit is equal to the work done per unit charge by the electric field This is then combined with the relation of a changing magnetic flux to the the field it produces  Forces Due to Changing .$\\vec B$ are non-conservative #   Electric field lines produced by a changing magnetic field are continuous; they form closed loops That is, while a conservative force (such as a electrostatic magnetic field) integrated over a line integral is zero .$\\big(\\oint \\vec E_\\text{electrostatic} \\cdot d \\vec l = 0\\big)$, the electric field created by an magnetic field is not zero: .$\\oint \\vec E_\\text{non-static} \\cdot d \\vec l = - \\frac{d\\Phi_B}{dt}$ This implies that forces due to changing magnetic fields are non-conservative and we can\u0026rsquo;t define a potential energy (or even a potential function!) at a given point in space  "},{"id":29,"href":"/physics-7b/30/","title":"30: Inductance, Electromagnetic Oscillations, \u0026 AC Circuits","section":"Physics 7B","content":"30.1 Mutual Inductance #   When two wires are near one another, they induce an emf in one another  This emf is proportional to the rate of change of the flux passing through it The flux passing through the coil is generated by the other coil\u0026rsquo;s current     If the two coils are held in place then the total flux is proportional to the mutual inductance $$M = \\frac{N_2 \\Phi_{21}}{I_1}$$  .$\\Phi_{21}$ is the total flux passing through coil 2 (induced by the current in coil 1, .$I_1$) .$M$ depends on “geometric” factors such as the size, shape, number of turns, and relative positions of the two coils, and whether a ferromagnetic material is present The SI unit for mutual inductance is the Henry; .$\\text{1 H = 1 V$\\cdot$s/A = 1$\\Omega \\cdot$s}$       A changing current in one coil will induce a current in the second coil.\n    The emf induced in coil 2 due to a change in current 1 can be written now as $$\\mathscr{E_2} = -N_2 \\frac{d\\Phi_{21}}{dt} = -M \\frac{dI_1}{dt}$$  30.2 Self-Inductance; Inductors #   This concept also applies to isolated coils too  When a changing current passes through a coil (or solenoid), a changing magnetic flux is produced inside the coil, and this in turn induces an emf in that same coil. This induced emf opposes the change in flux (Lenz\u0026rsquo;s law).  If the current through the coil is increasing, the increasing magnetic flux induces an emf that opposes the original current and tends to retard its increase. If the current is decreasing in the coil, the decreasing flux induces an emf in the same direction as the current, thus tending to maintain the original current.   If this inductance (coil) is in a circuit, it thus can provide a source of emf, in addition to any battery present or other sources of emf.   Self-inductance .$L$ and the emf it induces is given by $$L = \\frac{N\\Phi_B}{I}$$  $$\\mathscr{E} = -N \\frac{d\\Phi_B}{dt} = -L \\frac{dI}{dt}$$    An ac circuit always contains some inductance, but often it is quite small unless the circuit contains a coil of many loops or turns. A coil that has significant self-inductance .$L$ is called an inductor  Inductance can serve a useful purpose in certain circuits, but it\u0026rsquo;s often just a nuisance in a circuit. If inductance is large, the change in the current will be small, and therefore the current itself if it is ac will be small.  The greater the inductance, the less the ac current. An inductance thus acts something like a “resistance” to impede the flow of alternating current.      Solenoid Self-Inductance #   The magnetic field of a solenoid is .$B = \\mu_0 nI$ where .$n = N/l$ Thus, the flux is .$\\Phi_B = BA = \\mu_0 NIA/l$ so we can derive $$L = \\frac{N \\Phi_B}{I} = \\frac{\\mu_0 N^2 A}{l}$$  30.3 Energy Stored in a Magnetic Field #   When an inductor with inductance .$L$ is carrying current .$I$ which is changing at the rate .$dI/dt$, energy is being supplied to the inductor at the rate $$P = I \\mathscr{E} = LI \\frac{dI}{dt}$$ Thus, the work needed to increase the current in an inductor from zero to some .$I$ is $$W = \\int P dt = \\int_0^I LI\\ dI = \\frac{1}{2}LI^2$$  This is also the (potential) energy stored in a conductor when it is carrying current .$I$   Just as the energy stored in a capacitor can be considered to reside in the electric field between its plates, so the energy in an inductor can be considered to be stored in its magnetic field.  E.x. the energy stored in a solenoid is $$U = \\frac{1}{2}LI^2 = \\frac{1}{2} \\bigg( \\frac{\\mu_0 N^2 A}{l} \\bigg)\\bigg( \\frac{Bl}{\\mu_0 N}\\bigg)^2 = \\frac{1}{2} \\frac{B^2}{\\mu_0}Al$$ We can think of this energy as residing in the volume enclosed by the windings; .$Al$ Then the energy density (energy per unit volume) is $$u = \\text{energy density} = \\frac{1}{2}\\frac{B^2}{\\mu_0}$$  This equation is analogous to that for an electric field, .$ \\frac{1}{2}ϵE^2$      30.4 LR Circuits #    (a) LR circuit; (b) growth of current when connected to battery.\n  At the instant the switch connecting the battery is closed, the current starts to flow.  It is opposed by the induced emf in the inductor because of the changing current. As soon as current starts to flow, there is also a voltage drop across the resistance; .$V = IR$ Hence, the voltage drop across the inductance is reduced and the current increases less rapidly as it approaches .$I_0 = V_0 / R$ as seen in (b)   The emfs in the circuit are the battery voltage .$V_0$ and the emf .$\\mathscr{E} = -L (dI/dt)$ in the inductor (which opposes the current)  Hence, we can find sum of potential charges around the loop where .$I$ is the current at any instance by using the loop rule: $$V_0 - IR - L \\frac{dI}{dt} = 0 \\Longrightarrow L \\frac{dI}{dt} + RI = V_0$$ We can integrate the later term from .$t = 0, I = 0$ to a later time .$t$ when current is .$I$: $$\\int_0^I \\frac{dI}{V_0 - IR} = \\int_0^t \\frac{1}{L}dt \\Longrightarrow - \\frac{1}{R} \\ln \\bigg( \\frac{V_0 - IR}{V_0} \\bigg) \\frac{t}{L}$$ $$\\dots \\Longrightarrow \\frac{V_0 - IR}{V_0} = e^{- \\frac{Rt}{L}} \\Longrightarrow I = \\frac{V_0}{R}(1-e^{-t/\\tau})$$  .$\\tau = \\frac{L}{R}$ is the time constant: the time required for the current .$I$ to reach 63% of it\u0026rsquo;s maximum value .$V_0/R$       When the battery is removed from the circuit\u0026hellip;  Voltage .$V_0$ becomes zero, so .$L \\frac{dI}{dt} + RI = 0$ We can integrate this and solve for .$I$ $$\\int_{I_0}^I \\frac{dI}{I} = - \\int_0^t \\frac{R}{L} dt$$ $$\\dots \\Longrightarrow I = I_0 e^{-t/\\tau}$$ - .$\\tau = L/R$ is the time it takes current to decrease to 37% of it\u0026rsquo;s initial       30.5 LC Circuits and Electromagnetic Oscillations #   Any electric circuit can contain the three basic components: resistance, capacitance, and inductance, in addition to a source of emf.    Suppose the adjacent circuit is initially charged so one plate has charge .$Q_0$ and the other .$-Q_0$ and that the potential difference is .$V = Q/C$ At .$t = 0$ the capacitor immediately begins to discharge. As it does so, the current .$I$ through the inductor increases. We now apply Kirchhoff\u0026rsquo;s loop rule (sum of potential changes around a loop is zero): $$-L \\frac{dI}{dt} + \\frac{Q}{C} = 0$$     Because charge leaves the positive plate on the capacitor to produce the current .$I = dQ/dt$ so we can rewrite the equation as $$\\dots \\Longrightarrow \\frac{d^2 Q}{dt^2} + \\frac{Q}{LC} = 0 \\Longrightarrow Q = Q_0 \\cos(\\omega t + \\phi)$$  .$Q_0$ and .$\\phi$ are constants that depend on the initial conditions .$\\omega t + \\phi$ is in radians.  Because we have .$\\phi$, the amplitude isn\u0026rsquo;t .$Q_0$ unless .$\\phi = 0$   .$\\omega = 2\\pi f = \\sqrt{ \\frac{1}{LC} }$     We can then plug in our sinusoidal equation to find a function for .$I$: $$I = -\\frac{dQ}{dt} = \\omega Q_0 \\sin(\\omega t + \\phi)$$ $$\\dots \\Longrightarrow I_0 \\sin(\\omega t + \\phi)$$ Energy stored in capacitor: $$U_E = \\frac{1}{2}\\frac{Q^2}{C} = \\frac{Q_0^2}{2C}\\cos^2(\\omega t + \\phi)$$ Energy stored in magnetic field: $$U_B = \\frac{1}{2}LI^2 = \\frac{Q_0^2}{2C}\\sin^2(\\omega t + \\phi)$$ Total energy stored: $$U = U_B + U_E = \\frac{Q_0^2}{2C}$$     Period: .$T = \\frac{1}{f} = \\frac{2\\pi}{\\omega} = 2\\pi \\sqrt{LC}$\n   "},{"id":30,"href":"/math-53/trig/","title":"Trig Identities","section":"Math 53","content":"Reciprocal Identities #  $$\\sin(x)=\\frac{1}{\\csc(x)}$$  $$\\cos(x)=\\frac{1}{\\sec(x)}$$  $$\\tan(x)=\\frac{\\sin(x)}{\\cos(x)}=\\frac{1}{\\cot(x)}$$   Pythagorean Identities #  $$\\sin^2(x) + \\cos^2(x) = 1$$  $$1+\\tan^2(x) = \\sec^2(x)$$  $$1+\\cot^2(x)=\\csc^2(x)$$   Cofunction Identities #  $$\\sin\\Big(\\frac{\\pi}{2}-x\\Big) = \\cos(x)$$ $$\\csc\\Big(\\frac{\\pi}{2}-x\\Big) = \\sec(x)$$  $$\\cos\\Big(\\frac{\\pi}{2}-x\\Big) = \\sin(x)$$ $$\\sec\\Big(\\frac{\\pi}{2}-x\\Big) = \\csc(x)$$  $$\\tan\\Big(\\frac{\\pi}{2}-x\\Big) = \\cot(x)$$ $$\\cot\\Big(\\frac{\\pi}{2}-x\\Big) = \\tan(x)$$   Even/Odd Identities #  $$ \\sin(-x) = -\\sin(x)$$ $$ \\csc(-x) = -\\csc(x)$$  $$ \\cos(-x) = \\cos(x)$$ $$ \\sec(-x) = \\sec(x)$$  $$ \\tan(-x) = - \\tan(x)$$ $$ \\cot(-x) = -\\cot(x)$$   Bonus fact: .$\\int_{-A}^A \\text{[odd]}(x)\\ dx = 0$; .$\\int_{-A}^A \\text{[even]}(x)\\ dx = \\int_0^A \\text{[even]}(x)\\ dx$  Sum and Difference Formulas #  $$ \\sin(u \\pm v) = \\sin(u) \\cdot \\cos(v) \\pm \\cos(u) \\cdot \\sin(v)$$ $$ \\cos(u \\pm v) = \\cos(u) \\cdot \\cos(v) \\pm \\sin(u) \\cdot \\sin(v)$$ $$\\tan(u \\pm v) = \\frac{\\tan(u) \\pm \\tan(v)}{1 \\mp \\tan(u) \\tan(v)}$$\nDouble-Angle Formula #  $$ \\sin(2u) = 2 \\sin(u) \\cos(u)$$  $$ \\cos(2u) = 2 \\cos^2(u) - 1$$ $$ \u0026hellip; = 1- 2 \\sin^2(u) $$ $$ \u0026hellip; = \\cos^2(u) - \\sin^2(u) $$  $$ \\tan(2u) = \\frac{2 \\tan(u)}{1 - \\tan^2(u)}$$   Power Reducing Formulas #  $$\\sin^2(u) = \\frac{1 - \\cos(2u)}{2}$$  $$\\cos^2(u) = \\frac{1 + \\cos(2u)}{2}$$  $$\\tan^2(u) = \\frac{1 - \\cos(2u)}{1 + \\cos(2u)}$$   Sum to Product Formulas #  $$\\sin(u) + \\sin(v) = 2\\sin\\bigg(\\frac{u + v}{2}\\bigg) \\cos\\bigg(\\frac{u - v}{2}\\bigg)\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $$ $$\\sin(u) - \\sin(v) = 2\\cos\\bigg(\\frac{u + v}{2}\\bigg) \\sin\\bigg(\\frac{u - v}{2}\\bigg)\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $$ $$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\cos(u) + \\cos(v) = 2\\cos\\bigg(\\frac{u + v}{2}\\bigg) \\cos\\bigg(\\frac{u - v}{2}\\bigg)$$ $$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\cos(u) - \\cos(v) = -2\\sin\\bigg(\\frac{u + v}{2}\\bigg) \\sin\\bigg(\\frac{u - v}{2}\\bigg)$$\nProduct to Sum Formulas #  $$\\sin(u) \\sin(v) = \\frac{1}{2}\\Big[\\cos(u - v) - \\cos(u + v)\\Big]\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $$ $$\\sin(u) \\cos(v) = \\frac{1}{2}\\Big[\\sin(u + v) + \\sin(u - v)\\Big]\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $$ $$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\cos(u) \\sin(v) = \\frac{1}{2}\\Big[\\sin(u + v) - \\sin(u - v)\\Big]$$ $$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\cos(u) \\cos(v) = \\frac{1}{2}\\Big[\\cos(u - v) + \\cos(u + v)\\Big]$$\n"},{"id":31,"href":"/math-53/trig-calc/","title":"Trig Calculus","section":"Math 53","content":"Derivatives #  $$\\frac{d}{dx} \\tan(x) = 1 + \\tan^2(x) = \\sec^2(x)$$ $$\\frac{d}{dx} \\csc(x) = -\\cot(x) \\cdot \\csc(x)$$ $$\\frac{d}{dx} \\sec(x) = \\frac{\\sin(x)}{\\cos^2(x)} = \\tan(x) \\cdot \\sec(x)$$ $$\\frac{d}{dx} \\cot(x) = -\\csc^2(x)$$ $$\\frac{d}{dx} \\log_a(x) = \\frac{1}{x\\cdot \\ln(a)}$$ $$\\frac{d}{dx} a^u = a^x \\cdot \\ln (a) du$$ $$\\frac{d}{dx} \\sin^2(x) = \\sin(2x)$$ $$\\frac{d}{dx} \\cos^2(x) = -\\sin(2x)$$ $$\\frac{d}{dx} \\tan^2(x) = 2\\tan(x)\\cdot \\sec^2(x)$$\nIntegrals #  $$\\int a^x dx = \\bigg(\\frac{1}{\\ln(a)}\\bigg) a^x + C $$ $$\\int \\tan(x) dx = -\\ln\\vert \\cos(x) \\vert + C$$ $$\\int \\tan^2(x) dx = \\tan(x) - x + C$$ $$\\int \\csc(x) dx = \\ln\\vert \\csc(x) - \\cot(x)\\vert + C = \\ln \\bigg\\vert \\tan\\bigg(\\frac{x}{2}\\bigg)\\bigg\\vert + C$$ $$\\int \\csc^2(x) dx = -\\cot(x) + C$$ $$\\int \\sec(x) dx = -\\ln\\vert \\sec(x) + \\tan(x)\\vert + C$$ $$\\int \\sec^2(x) dx = \\tan(x) + C$$ $$\\int \\cot(x) dx = \\ln\\vert \\sin(x) \\vert + C$$ $$\\int \\cot^2(x) dx = -\\cot(x) - x + C$$ $$\\int \\frac{1}{\\sin(ax)\\cos(ax)} = \\frac{1}{a} \\ln\\vert\\tan(ax)\\vert + C$$ $$\\int \\frac{1}{x\\sqrt{x^2-a^2}} dx = \\frac{1}{a} \\sec^{-1}\\bigg( \\frac{\\vert x \\vert}{a}\\bigg) + C$$ $$\\int \\frac{1}{\\sqrt{a^2-x^2}} dx = \\sin^{-1}\\bigg( \\frac{x}{a} \\bigg) + C$$ $$\\int \\frac{1}{a^2 + x^2} dx = \\frac{1}{a} \\tan^{-1}\\bigg( \\frac{x}{a} \\bigg) + C$$\n Many more integrals\nTriangle Sub #  $$\\sqrt{b^2x^2-a^2} \\Longrightarrow x = \\frac{a}{b}\\cdot\\sec\\theta; \\theta \\in [0, \\pi/2), (\\pi/2, \\pi]$$ $$\\sqrt{a^2-b^2x^2} \\Longrightarrow x = \\frac{a}{b}\\cdot\\sin\\theta; \\theta \\in [-\\pi/2, \\pi/2]$$ $$\\sqrt{a^2+b^2x^2} \\Longrightarrow x = \\frac{a}{b}\\cdot\\tan\\theta; \\theta \\in (-\\pi/2, \\pi/2)$$\n"},{"id":32,"href":"/ap/huge/","title":"AP Human Geography","section":"AP Notes","content":"The content of these notes are solid, but formatting is not since they\u0026rsquo;re exported from Notion.  🗺️ Unit 1 — Thinking Geographically #  Developing Understanding\n This first unit sets the foundation for the course by teaching students how geographers approach the study of places. Students are encouraged to reflect on the “why of where” to better understand geographic perspectives. Many other high school courses ask students to read and analyze data, but for this course, students also apply a spatial perspective when reading and analyzing qualitative and quantitative data. Students learn the ways information from data sources such as maps, tables, charts, satellite images, and infographics informs policy decisions such as voting redistricting or expanding transportation networks. They also learn about how people influence and are influenced by their environment; the resulting impact on topography, natural resources, and climate; and the differences between and consequences of environmental determinism and possibilism. Finally, students are introduced to the language of geography, learning discipline-specific terminology and applying that language to contemporary, real-world scenarios so they can better study population processes and patterns in the next unit.\n  BIG IDEA 1 Patterns and Spatial Organization (PSO)\n Why do geographers study relationships and patterns among and between places? BIG IDEA 2 Impacts and Interactions (IMP) How do geographers use maps to help them discover patterns and relationships in the world? BIG IDEA 3 Spatial Processes and Societal Change (SPS) How do geographers use a spatial perspective to analyze complex issues and relationships?   1.1 Introduction to Maps #   IMP 1A Geographers use maps and data to depict relationships of time, space, and scale.\n  Learning Objective: Identify types of maps, the types of information presented in maps, and different kinds of spatial patterns and relationships portrayed in maps. Essential Knowledge:  Types of maps include reference maps and thematic maps  reference maps  Serve to display general features of an area Topographic highway, atlas, etc   thematic maps  Server to display single type of information Types:  graduated circle  size of circle conveys quantitative statistic Example    dot  display pattern, distribution, dispersion of data in an area Example    choropleth  display an average value of data in an area Example          Types of spatial patterns represented on maps include absolute and relative distance and direction, clustering, dispersal, and elevation.  maps are a special form of model that depicts information in two dimensions and usually on paper. A model is a simplified generalization of something in real life relative distance (scale)  Scale: The ratio between the size of an area on a map and he actual size of that same area on the earth\u0026rsquo;s surface Scale gives a frame of reference Representation Factor (RF):  1 inch : 250,000 feet   Verbal:  One inch represents 250,000 feet   Visual  |——————|——————| 0 250,000' 500,000'     direction  absolute direction:  north south, compass   relative direction:  left right, forward backwards, up down based on perspective in certain location     clustering + dispersal  where groups are (not) centered around density vs concentration:  Density is the amount of an object within a certain area concentration is how these objects are distributed.  Box A the distribution is dispersed. There is a clear cluster of stars in the upper left corner for Box C. Box B has concentrations in the left and right sides Box D has a cluster (though not as clustered as C) in the middle left and one outlier.     elevation  Hight from set point, typically water level     All maps are selective in information; map projections inevitably distort spatial relationships in shape, area, distance, and direction  Maps are 1D representations (projection) of a 2D environment, so they\u0026rsquo;ll inherently have distortion Mercator  shape: fairly accurate area: distorts area near north and south pole direction: turns curves into straight lines   Goode\u0026rsquo;s  shape: accurate area: accurate direction: accurate hard to understand   Goode\u0026rsquo;s  shape: everything slightly distorted outwards from 0' 0' area: accurate direction: accurate         1.2 Geographic Data #   IMP 1B Geographers use maps and data to depict relationships of time, space, and scale.\n  Learning Objective: Identify different methods of geographic data collection. Essential Knowledge:  Data may be gathered in the field by organizations or by individuals. Geospatial technologies include geographic information systems (GIS), satellite navigation systems, remote sensing, and online mapping and visualization.  Remote sensing:  Record area from a distance People have used cameras with airplanes, kites, hot-air balloons, etc. for many years Nowadays use satellites Useful for any area that would be otherwise be difficult to travel record   geographic information systems (GIS)  merge mapping software with a database to overlay various data layers on a basic map grid     Spatial information can come from written accounts in the form of field observations, media reports, travel narratives, policy documents, personal interviews, landscape analysis, and photographic interpretation.     1.3 The Power of Geographic Data #   IMP 1C Geographers use maps and data to depict relationships of time, space, and scale.\n  Learning Objective: Explain the geographical effects of decisions made using geographical information. Essential Knowledge:  Geospatial and geographical data, including data and satellite imagery, are used at all scales for personal, business and organizational, and governmental decision making purposes.  Used to measure  climate change pollution spreads of fires military survalliance google maps / personal GPS delivering your packages         1.4 Spatial Concepts #   PSO-1 Geographers analyze relationships among and between places to reveal important spatial patterns.\n  Learning Objective: Define major geographic concepts that illustrate spatial relationships. Essential Knowledge:  Spatial concepts include absolute and relative location, space, place, flows, distance decay, time-space compression, and pattern.  location + place (same thing)  actual position on earth   space  area that is occupied by something can refer to physical and cultural objects on the surface of earth relative space is concerned with where something is in relation to something else and changes constantly as interrelationships between people, places, and things change absolute space is a measurable area with definite boundaries   site  physical location of a place   situation  location of a place based on its relation to other places   flows + patterns  trends of relationships(?)   distance decay  The declining degree of acceptance of an idea or innovation with increasing time and distance from its point of origin or source. Example: The number of phone calls made decreases with distance. Greater number of migrants settled at the edge of the country closer to the country of origin, compared to the number settled on the opposite edge of the country. The diminishing evidence of cultural traits by a group of people, if the explanation clearly shows a link to the fact that due to migration there is less contact between the migrants and their home country. Explanatory factor behind distance decay relationship (e.g., travel cost, information availability).   time-space compression (decrease in friction of distance)  the increasing sense of connectivity that seems to be bringing people closer together even thought their distances are the same. Space time compression is the solution to distance decay because technology (internet,cell phones) is allowing us to communicate more across longer distances.          1.5 Human–Environmental Interaction #   PSO-1 Geographers analyze relationships among and between places to reveal important spatial patterns.\n  Learning Objective: Explain how major geographic concepts illustrate spatial relationships Essential Knowledge:  Concepts of nature and society include sustainability, natural resources, and land use.  sustainability  the use of the earths renewable and nonrenewable natural resources in ways that ensure resource availability in the future 3 Pillars  Environmental  Having Conservation, Nonrenewable and renewable resources and Preservation   Social  Humans need shelter food and clothing to survive so make resources meet those needs   Economic  Having natural resources; supply and demand     Humans take resources that aren\u0026rsquo;t always needed or they take advantage of the resources that we have. But there is a lot of supply and demand and humans don\u0026rsquo;t know how to balance the resources.   natural resources  Resources that come directly from Earth Need to be used in moderation if they aren\u0026rsquo;t renewable   land use  to be sustainable, land has to be used efficiently to get enough value but not worked too hard to the point where it looses nutrients     Theories regarding the interaction of the natural environment with human societies have evolved from environmental determinism to possibilism.  Environmental determinism : The idea that physical environment caused social development Possibilism: (Replaces Environmental Determinism) The idea that environment may limit some human actions, but people have the ability to adapt to their environment       1.6 Scales of Analysis #   PSO-1 Geographers analyze relationships among and between places to reveal important spatial patterns.\n  Learning Objective: Define scales of analysis used by geographers. Essential Knowledge:  Scales of analysis is how information is clustered  global — worldwide regional — groups of states, e.g. North America national — single state, e.g. Wisconsin local — city or town, e.g. Middleton   Scale is what infomation is shown    Learning Objective: Explain what scales of analysis reveal. Essential Knowledge:  Patterns and processes at different scales reveal variations in, and different interpretations of, data.  To understand individual, local, regional, national, and global interrelationships, geographers compare and contrasts different scale views.     Downsides to large scale      1.7 Regional Analysis #   SPS 1 Geographers analyze complex issues and relationships with a distinctively spatial perspective\n  Learning Objective: Describe different ways that geographers define regions. Essential Knowledge:  Regions are defined on the basis of one or more unifying characteristics or on patterns of activity.  A region is an area characterized by similarity or by cohesiveness that sets it apart from other areas. Regions allow us to generalize about a common characteristic so we can better group them A region is an area on the earth identified by two common characteristics: physical and political geography. Physical regions are features such as deserts, mountains, and lakes. Political regions by establishing political boundaries like the borders of countries. Some regions are based on culture (language or religion), while physical geography defines others.   Types of regions include formal, functional, and perceptual/vernacular  Formal (Uniform)  Region with high level of consistency in a certain cultural or physical attribute E.g.  Dairying region of North America Political boundaries Tropical Regions     Functional (Nodal)  A region with a node, sometimes a hearth, surrounded by interconnecting linkages. Usually connections relate to trade, communication, transportation, etc. E.g.  Cell towers Newspaper Circulation School District Metropolitan Area     Perceptual (Vernacular)  A region defined by feelings and prejudices that may or may not be true. A construct of one\u0026rsquo;s mental map E.g.  Bible belt South       Regional boundaries are transitional and often contested and overlapping.  Regions of the world can and do overlap such as the areas of Southeast Asia and Asia. Regions also have transitional boundaries like between North Africa and Sub-Saharan Africa   Geographers apply regional analysis at local, national, and global scales  There is not total agreement, however, among geographers on how all regions are defined.  One geographer may place Chad in the region of North Africa, and another would classify Chad as part of Central Africa. Geographers will also use two different terms to describe the same area; the Middle East and Southwest Asia, for example.         👣 Unit 2 — Population and Migration Patterns and Processes #  Developing Understanding\n This unit addresses the patterns associated with human populations. Populations may increase or decrease as a result of a combination of natural changes (births and deaths) and migration patterns (emigration and immigration). Students examine population distributions at different scales—local, national, regional, and global. Population pyramids demonstrate age-sex structures, revealing the growth or decline of generations and allowing geographers to predict economic needs based on reproductive and aging patterns. Students learn about factors that influence changes in population as well as the long- and short-term effects of those population changes on a place’s economy, culture, and politics. For example, environmental degradation and natural hazards may prompt population redistribution at various scales, which in turn creates new pressures on the environment and on cultural, economic, and political institutions. The study of migration patterns allows students to examine factors contributing to voluntary and forced relocation and the impact of these migrating populations on existing settlements. Combined, the concepts and theories encountered in this unit help students develop connections and transfer their learning in upcoming units to course topics such as cultural patterns, the political organization of space, food production issues, natural resource use, and urban systems.\n  BIG IDEA 1 Patterns and Spatial Organization (PSO)\n How does where and how people live impact global cultural, political, and economic patterns? BIG IDEA 2 Impacts and Interactions (IMP) How does the interplay of environmental, economic, cultural, and political factors influence changes in population? BIG IDEA 3 Spatial Processes and Societal Change (SPS) How do changes in population affect a place’s economy, culture, and politics?   2.1 Population Distribution #   PSO-1 Understanding where and how people live is essential to understanding global cultural, political, and economic patterns.\n  Learning Objective: Identify the factors that influence the distribution of human populations at different scales. Essential Knowledge:  Physical factors (e.g., climate, landforms, water bodies) and human factors (e.g., culture, economics, history, politics) influence the distribution of population.  physical:  humans avoid areas that are  dry  too dry to plant food lack water for crops + regular consumption   wet + hot  combination of rain and heat deplete nutrients from soil typically near equator   cold + high altitude  to rough for easy transportation to cold for crops     places considered too harsh for occupancy have diminished over time people like to go to low-lying areas with fertile soil and temperate climate near a river or ocean is good too    cultural:  economics  history  politics   Factors that illustrate patterns of population distribution vary according to the scale of analysis.  Scale of analysis is the level of detail that a map goes into Demography: study of characteristics of human population, varies according to scale  75% of population live on 5% of land 50% of population live in urban areas Land inhabited called ecumene   most extreme cases occur at small scales  countries vary in size so aren\u0026rsquo;t great for seeing details, but they\u0026rsquo;re better than state        Learning Objective: Define methods geographers use to calculate population density. Essential Knowledge:  The three methods for calculating population density are arithmetic, physiological, and agricultural.  Artihmetic / crude - all people / all land Physiological - all people / agricultural land Agricultural - all farmers / agricultural land     Learning Objective: Explain the differences between and the impact of methods used to calculate population density. Essential Knowledge:  The method used to calculate population density reveals different information about the pressure the population exerts on the land.  High agricultural density implies that farmers aren\u0026rsquo;t extracting the most value from there land (better farmers need less farmers to fully use there land) Low agricultural density implies farmers are very efficient and probably developed High physiological density implies that there is either little farmland or that agricultural land is being used by more and may reach its output limit sooner than a country that has a lower density High arithmetic density implies there are a lot of people in a small area, aka urbanization      2.2 Consequences of Population Distribution #   PSO-2 Understanding where and how people live is essential to understanding global cultural, political, and economic patterns.\n  Learning Objective: Explain how population distribution and density affect society and the environment. Essential Knowledge:  Population distribution and density affects political, economic, and social processes, including the provision of services such as medical care.  redistricting / gerrymandering  Results    provision of services such as medical care  those closer to medical services are more likely be able to use them     Population distribution and density affect the environment and natural resources; this is known as carrying capacity  carrying capacity — how many people an area can support on a sustained basis  sustainability       2.3 Population Composition #   PSO-2 Understanding where and how people live is essential to understanding global cultural, political, and economic patterns.\n  Learning Objective: Describe elements of population composition used by geographers. Essential Knowledge:  Patterns of age structure and sex ratio vary across different regions and may be mapped and analyzed at different scales   most extreme cases occur at small scales  countries vary in size so aren\u0026rsquo;t great for seeing details, but they\u0026rsquo;re better than state   age structure  older in retirement areas younger in military / college towns helps predict how much money is needed for social services  old and young (dependent) require more money to support     sex ratio  more male in military training camps     Learning Objective: Explain ways that geographers depict and analyze population composition. Essential Knowledge:  Population pyramids are used to assess population growth and decline and to predict markets for goods and services.  a representation of a country’s population displayed by age and gender groups on a bar graph. Normally shows the % of the total pop in 5-year age brackets with youngest at base of pyramid and oldest at the top. The length of the bar represents the % of total pop in that group. Males on left, females on right. Young population (bulge at bottom)  Economic Risks  Potential for job shortage Shift in workforce and jobs that target young people   Social  Increasing demand on support for youth Preschools, parks, etc.   Health and Education  Have to be prepared for childhood diseases Increase spending on family planning programs   Middle (bulge in middle)  Economic:  Not enough upcoming workers Possible automation People work longer (later retirement)       Aging population (bulge at top)  Economic  Transition to tertiary jobs Income tax burden falls on a shrinking workforce Over 65 expect long term expensive healthcare Strain on pension system with fewer paying in Capital flow from aging countries shifting global economic power   Social Risks  Migration needed to satisfy labor needs           2.4 Population Dynamics #   IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\n  Learning Objective: Explain factors that account for contemporary and historical trends in population growth and decline. Essential Knowledge:  Demographic factors that determine a population’s growth and decline are fertility, mortality, and migration.  fertility  crude birth rate (CBR) — total live births in a year for every 1,000 people alive in society infant mortality rate (IMR) — annual number of deaths of infants under 1 year of age compared with number of live births  Decrease due to (life expectancy too)    total fertility rate (TFR) — average number of children a woman will have throughout her childbearing years (15-49)   mortality  crude death rate (CDR) — total number of deaths in a year for every 1,000 people alive in society life expectancy — number of years expected for a newborn to live   migration   Geographers use the rate of natural increase and population-doubling time to explain population growth and decline.  Natural increase rate (NIR) — Percentage by which a population grows in a year  CBR - CDR = NIR    Doubling Time — Number of years needed to double the population (assuming a steady rate of growth), is affected by NIR   Social, cultural, political, and economic factors influence fertility, mortality, and migration rates.  Social + cultural  norms  when to get married role of genders     political  laws  anti/pro abortion one child policy (China)          2.5 The Demographic Transition Model #   IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\n  Learning Objective: Explain theories of population growth and decline. Essential Knowledge:  The demographic transition model can be used to explain population change over time.  explains the rising and falling of NIR over time in a country no country has ever reverted back to a previous stage  Stage 1: Hunter-gatherers, scarcity of food Stage 2: Increase in healthcare, still lots of kids Stage 3: Rural to urban, less kids (due to less space / resources in urban area) Stage 4: Developed, stuff balances out Stage 5: Replacement rate isn\u0026rsquo;t enough to sustain population  Reasons for population drop off / decrease        The epidemiological transition explains causes of changing death rates.  stage 1 — prestillence and famine (high CDR):  principal cause of death: infectious and parasitic diseases   stage 2 — receding pandemic (rapidly declining CDR)  factors such as improved sanitation, nutrition, and medicine   stage 3 — degenerative disease (moderately declining CDR)  decrease in deaths by infectious diseases, increase in deaths by chronic disorders associated with aging   stage 4 — delayed degenerative diseases (low but increasing CDR)  death by cardiovascular diseases and cancer delayed because of modern medicine   (possible) stage 5  evolution: infectious disease microbes adapt around drugs, new strains form poverty: infectious diseases are more prevalent in poor areas due to unsanitary conditions and inability to afford medicine / treatment increased connections: advancements in transportation, e.g. air travel, increases contact as well as urbanization   death rates are high during first, the drop off til they level around stage 4 this is due to increase in education and healthcare, as well as contraceptives     Jobs  Economic Activities  Primary: Production of raw materials or natural resource extraction (e.g., agriculture, mining, energy, timber, fishing) Secondary: Processing or refining of natural resources (e.g., manufacturing finished goods, industry, building construction, assembly, factory work, value-added, blue collar) Tertiary: Provision of services (e.g., healthcare, technology, communications, financial, wholesale and retail trade, transportation, personal, professional, business services, white collar)   How these patterns change as courtiers develop       2.6 Malthusian Theory #   IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\n  Learning Objective: Explain theories of population growth and decline. Essential Knowledge:  Malthusian theory and its critiques are used to analyze population change and its consequences.  Thomas Malthus - proposed in his Essay on the Principle of Population 1798, that the population grows faster than the food supply. He claimed that while population expanded at a geometric or exponential rate, food supply increased arithmetically or linearly. However, the continued evolution of agriculture has continued to provide the world with an adequate amount of food. The problem now is distribution of food, not the actual production of it. Also, the birth rates declined sharply in the latter part of the 20th century, thus the world population expanded to only 6 billion compared to Malthus’s predicted 10.  Neo-Malthusians  claim that more LDC’s are in stage 2 of the demographic transition than ever before in history, thus putting a larger strain on the food supply. They also modified Malthus’s theory by stating that the population growth is out-stripping not just food production, but a wide variety of resources, such as oil, natural gas, etc.   Critics of Malthus  claim that population growth stimulates new technology and that as strain is put on any resource, the inventive human being will simply develop an alternative method once it is economically feasible.        2.7 Population Policies #   SPS-2 Changes in population have long- and short-term effects on a place’s economy, culture, and politics.\n  Learning Objective: Explain the intent and effects of various population and immigration policies on population size and composition. Essential Knowledge:  Types of population policies include those that promote or discourage population growth, such as pronatalist, antinatalist, and immigration policies.  countries fearing overpopulation may enact Antinatilist policies, e.g. China\u0026rsquo;s child limit countries fearing dipping below the replacement level, to assure the population continues to replace itself, may enact pronatilist policies, e.g. Scandinavian country\u0026rsquo;s proactive ads, or policy encourage immigration (migration in to the country)      2.8 Women and Demographic Change #   SPS-2 Changes in population have long- and short-term effects on a place’s economy, culture, and politics.\n  Learning Objective: Explain how the changing role of females has demographic consequences in different parts of the world. Essential Knowledge:  Changing social values and access to education, employment, health care, and contraception have reduced fertility rates in most parts of the world.  social:  women have a say in whether or not they want a child   economic:  women joining the workforce leaves less time for relationships   political roles:  women in government can enact laws that better represent what women may need   healthcare:  higher chance of mother and child surviving   contraception  less likely for \u0026lsquo;accidents\u0026rsquo;   Social status change    Changing social, economic, and political roles for females have influenced patterns of fertility, mortality, and migration, as illustrated by Ravenstein’s laws of migration.  Ravenstein\u0026rsquo;s Laws:  Most migrants move only a short distance. Migration proceeds step by step. There is a process of absorption, whereby people immediately surrounding a rapidly growing town move into it and the gaps they leave are filled by migrants from more distant areas, and so on until the attractive force is spent. Migrants going long distances generally go by preference to one of the great centres of commerce or industry. Each current of migration produces a compensating counter-current. Natives of towns are less migratory than those of rural areas Females are more migratory than males within the kingdom of their birth, but males more frequently venture beyond. Most migrants are adults: families rarely migrate out of their country of birth. Large towns grow more by migration than by natural increase. Migration increases in volume as industries and commerce develop and transport improves. The major direction of migration is from the agricultural areas to the centres of industry and commerce. The major causes of migration are economic.   Ravensteins laws aren\u0026rsquo;t scientific Are too specificied  E.g. short distance occurs in Africa where most migrations is due to wars, while most migration from China is to the US (long)        2.9 Aging Populations #   SPS-2 Changes in population have long- and short-term effects on a place’s economy, culture, and politics.\n  Learning Objective: Explain the causes and consequences of an aging population. Essential Knowledge:  Population aging is determined by birth and death rates and life expectancy. An aging population has political, social, and economic consequences, including the dependency ratio.  dependency ratio: ratio of citizens under 15 or 65 and older to those between age 15 and 65  Gives us an idea of how many workers are needed to support the dependent population   If the population is aging:  Government spending for adult daycare, nursing homes, and home care social services will increase Government spending for education, child welfare, and health services will decrease   Why population is aging  Reduced Fertility  Improved education of women, more women working, delays in starting families Children are an economic liability in MDCs, too expensive to have several, societal norms (1–2 children) Birth control: cost, availability, accessibility, acceptance, quality More urban societies: less need for children to work on farms Government and private pensions reduce “children as pension”   Increased Life Expectancy  Improved health care (e.g., medicine, facilities, research/knowledge, personnel, technologies, accessibility) Improved lifestyle (e.g., knowledge of health risks, improved diets, technology, nutrition and exercise) Improved food security/availability Less conflict (e.g., less crime, fewer wars) Improved work conditions (e.g., less physically demanding labor, better safety standards) Improved public health (e.g., sanitation, water supply, housing, standard of living) Improved financial security for elderly (e.g., pensions, care facilities) Improved safety standards (e.g., sports, transportation, building codes)   Out-migration of Youth  Out-migration of youth for better lifestyle (e.g., jobs, security)           2.1 Causes of Migration #   IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\n  Learning Objective: Explain how different causal factors encourage migration. Essential Knowledge:  Migration is commonly divided into push factors and pull factors.  push factors — bad stuff in current location  famine war no jobs disease violence hate crime overcrowding   pull factors — good stuff somewhere else  better jobs lower taxes better climate better schools/social services more room low crime     Push/pull factors and intervening opportunities/obstacles can be cultural, demographic, economic, environmental, or political.  Intervening obstacle — a feature that hinders migration cultural  similar culture to home   demographic  people tend to like to be around similar people (age, race)   economic  better jobs   environmental  distance  Distance Decay: Says that migrants try to minimize the friction of distance  migrants will be more inclined to move to locations closer to them; they will be less interested in moving longer distances  has been on the decline    Intervening Opportunity\u0026rsquo;s: Idea that migrants will choose a location closer rather than farther if all other factors are the same  related to other reasons (time and money go up farther you have to travel)     climate (push + pull) oceans/water rugged terrain (intervening obstacles)   political  social services no war less corruption   age       2.1 Forced and Voluntary Migration #   IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\n  Learning Objective: Describe types of forced and voluntary migration. Essential Knowledge:  Forced migrations include slavery and events that produce refugees, internally displaced persons, and asylum seekers  types of migration:  Immigrant:  person entering another country with intention of living there   Emigrant:  person who is leaving one country with the intention of living in a different country   refugee:  A person who flees, is displaced, or is forced to leave his or her home country, often due to religion, ethnicity, race, or political belief Reasons    IDP — Internally Displaced Person:  A person who is forced out of the home region due to war, political, or social unrest, environmental problems, etc. does not cross any international boarders       Types of voluntary migrations include transnational, transhumance, internal, chain, step, guest worker, and rural-to-urban.  transnational  migration across one or more nation   transhumance  movement between mountains and lowlands, typically practiced by farmers Cyclic Movement: movement that has a closed route repeated annually or seasonally   internal  permanent move w/in the same country. Interregional migration  move from one region to another within country. e.g. from Middleton to North WI boonies   Intraregional migration  move within one region within one country. e.g. moving apartments in downtown Madison     chain migration  migration of people to a certain location because family members (or other contacts), typically of the same nationality, previously migrated there Examples must clearly establish a link/transfer of knowledge between the first group of migrants and subsequent groups OR it should be clear that subsequent migrants are from areas of close proximity to the source area of the early migrants, and that they are migrating to the same destination area.   step  migration to a distant destination that occurs in stages hard to measure / verify e.g. from farm to nearby village to town to city   guest worker  legal immigrant who has work visa, usually short term typically take unskilled labor jobs risk of them overstaying typically citizens of poor countries who temporarily obtain dangerous low-paying jobs in MDC’s that the permanent citizens refuse to accept.   rural-to-urban  migration flow going frow rural to urban areas In LDC’s, the migration trend recently has been rural to urban. In MDC’s, the migration trend has been urban to suburban Counterurbanization — net migration from urban to rural areas.  This has been a trend in MDC’s, as improved technologies enable people to live farther from their places of employment and still enjoy all the amenities the city offers. However, in the U.S., counterurbanization has stopped because of poor economic conditions in the rural areas. Once again, the trend is from non-metropolitan to metropolitan areas, only now it is characterized by a move into the suburbs rather than the inner city.          2.1 Effects of Migration #   IMP-2 Changes in population are due to mortality, fertility, and migration, which are influenced by the interplay of environmental, economic, cultural, and political factors.\n  Learning Objective: Explain historical and contemporary geographic effects of migration. Essential Knowledge:  Migration has political, economic, and cultural effects.  cultural  visually see change in landscape Chinatown, mosques, etc.    political  potentially controversial hate crimes   economic  typically beneficial fill unskilled labor jobs    Migration transition  identified by Wilbur Zelinsky consists of changes in a society comparable to the demographic transition. Stage 1 consists of little migration Stage 2 involves international migration Stages 3 and 4 are characterized by internal migration.   brain drain may occur due to human capital theory of migration (states that smart people are the ones to leave and seek better job opportunities)  smartest/most talented people leave a country, leaving only stupid people benefitial to both countries  in-country gets talented labor and capital out-country gets often gets remittances (payments sent from individuals)     Quotas — maximum limits on the number of people who could immigrate to the U.S. from a country in 1 year — may encourage illegal immigrants some countries rely on immigration from other countries to  stay above the replacement level of 2.1 to assure the population stays even support those who are dependent (under 15, over 65)       Normally shows the % of the total pop in 5-year age brackets with youngest at base of pyramid and oldest at the top. The length of the bar represents the % of total pop in that group.   ⚱️ Unit 3 - Cultural Patterns and Processes #  Developing Understanding\n The main focus of this unit is on cultural patterns and processes that create recognized cultural identities. Students consider the physical environment to determine the effects of geographical location and available resources on cultural practices. Visuals representing artifacts, mentifacts and sociofacts all shed light on cultural landscapes and how they change over time. Practice in analyzing images of different places at different times for evidence of their ethnicity, language, religion, gender roles and attitudes, and other cultural attributes builds students’ understanding of cultural patterns and processes. This unit also considers from a temporal and spatial perspective how culture spreads, through traditional forces such as colonialism and imperialism and through contemporary influences such as social media. Rather than emphasize the details of cultural practices associated with specific languages and religions, this unit instead focuses on the distribution of cultural practices and on the causes and effects of their diffusion. For example, students might study the distribution of Chinese versus English languages or the diffusion patterns of religions such as Hinduism and Islam, at local, national, or global scales. An understanding of the diffusion of cultural practices provides a foundation for the study of political patterns and processes in the next unit\n  BIG IDEA 1 Patterns and Spatial Organization (PSO)\n How does where people live and what resources they have access to impact their cultural practices? BIG IDEA 2 Impacts and Interactions (IMP) How does the interaction of people contribute to the spread of cultural practices? BIG IDEA 3 Spatial Processes and Societal Change (SPS) How and why do cultural ideas, practices, and innovations change or disappear over time?   3.1 Introduction to Culture #   PSO-3 Cultural practices vary across geographical locations because of physical geography and available resources.\n  Learning Objective: Define the characteristics, attitudes, and traits that influence geographers when they study culture. Essential Knowledge:  Culture comprises the shared practices, technologies, attitudes, and behaviors transmitted by a society.  shared practices  teaching style events holidays   technologies  what side of the road we drive on 120/240 volt outlet   attitudes  how we treat different genders   behaviors  how we greet one another   Social customs  originates at a hearth, a center of innovation. Folk customs tend to have anonymous sources, from unknown dates, through multiple hearths  Folk music tells stories or conveys information about daily activities. Isolation promotes cultural diversity as a group’s unique customs develop over several centuries.  Therefore, folk culture varies widely from place to place at one time. Since most folk culture deals in some way with the lives and habits of its people, the physical environment in which the people act has a tremendous impact on the culture.     pop culture generally has a known originator, normally from MDC’s, and results from more leisure time and more capital.  Pop music is written by specific individuals for the purpose of being sold to a large number of people.       Cultural traits include such things as food preferences, architecture, and land use.  Food:  the food we eat daily and the food we experience while traveling around the world all depends upon our location often passed throughout generations brings us together; sharable food in US reflects patterns of migration and what we\u0026rsquo;re capable of growing food also shows if there\u0026rsquo;s any (religious) taboos  Low meat consumption in Africa and S Asia due to large Hindu population, which don\u0026rsquo;t eat beef because they believe the cow to be sacred Muslim and Judaism prohibited from eating pork Somali clans restrict the consumption of fish      Land use:  location determines what foods are grown locally and readily available in a particular region of the world  certain states are known for certain foods; Jersey tomatoes, Florida oranges, Georgia peaches     Architectural trait  reflection of our built land scape can explain what was going on at a given time and what resources were available     Cultural relativism and ethnocentrism are different attitudes toward cultural difference.  relativism  looking at culture objectively / holistically believing nothing is right or wrong   ethnocentrism  viewing other cultures through your own believing that your culture is the norm / superior pride in heritage, devaluation of other groups        3.2 Cultural Landscapes #   PSO-3 Cultural practices vary across geographical locations because of physical geography and available resources.\n  Learning Objective: Describe the characteristics of cultural landscapes. Essential Knowledge:  Cultural landscapes are combinations physical features, agricultural and practices, religious and linguistic characteristics, evidence of sequent occupancy, and other expressions of culture including traditional and postmodern architecture and land-use patterns.  Toponyms  reflect leaders / people of power / religious figures / in immigrant\u0026rsquo;s native language    Religious impact  Religious architecture sacred spaces religious symbols   Architecture  traditional architecture built for elements that impact the area being built on built with materials (abundantly) available post-modern architecture is designed to descriptive / feats of design   Sequent Occupance  early societies leave their cultural imprint on a place old fashion architecture old-street\u0026rsquo;s names land surveys — how land was parceled / divided  square pattern system long-lot (french)   housing  reflects cultural identities of those who lived there and environmental constraints       \u0026ldquo;The cultural landscape is fashioned from a natural landscape by a cultural group. Culture is the agent, the natural area is the medium, the cultural landscape is the result.\u0026rdquo; - Carl Sauer\n  Gentrification  Positive Impacts  Negative Impacts  How govt can slow down + rpevent        Learning Objective: Explain how landscape features and land and resource use reflect cultural beliefs and identities Essential Knowledge:  Attitudes toward ethnicity and gender, including the role of women in the workforce; ethnic neighborhoods; and indigenous communities and lands help shape the use of space in a given society.   positive attitudes encourage chain migration can lead to subsections of area with high concentration of a particular ethnicity  China town little Mexico   generally, women are becoming more equal but there\u0026rsquo;s still progress to be made    3.3 Cultural Patterns #   PSO-3 Cultural practices vary across geographical locations because of physical geography and available resources.\n  Learning Objective: Cultural practices vary across geographical locations because of physical geography and available resources. Essential Knowledge:  Regional patterns of language, religion, and ethnicity contribute to a sense of place, enhance placemaking, and shape the global cultural landscape.  language  dialects phrases    ethnicity  immigrants shape neighborhoods  china town     sense of place   link   Bilingualism    Language, ethnicity, and religion are factors in creating centripetal and centrifugal forces.  countries need a stronger centripetal force than centrifugal force to stay intact forces and produce regionalism or dissimilarity between people in the same country centripetal exist in a place and don\u0026rsquo;t move — typically people don\u0026rsquo;t wanna or can\u0026rsquo;t leave while push/pull are actively working centripetal forces — together  Centripetal forces unify a state (provide stability, strengthen, bind together, create solidarity). culture regligious acceptance ethnic unity and tolerance social equity economic equity just and fair legal system nationalism  history — common heritage    centrifugal forces — apart (repel)  Centrifugal forces divide a state (lead to balkanization/devolution, disrupt internal order, destabilize, weaken). cultural diversity religious differences language ethnic conflict social injustice nationalism legal restrictions physical features economic stratification    “White flight” is the rapid fleeing of whites from the cities as black families emigrate out of the ghettos, or as the ghetto expands. It was encouraged by blockbusting.  blockbusting- the real estate practice of scaring whites into selling their homes at low prices by telling them that blacks would soon be moving in and causing property values to fall. The real estate agents then turned around and sold the homes at extremely high prices to blacks that were emigrating from the inner city. Apartheid-the physical separation of different races into different geographic areas, i.e. South Africa.  The apartheid laws were repealed in 1991 in South Africa, but many years will be needed to erase the legacy of such racist policies.          3.4 Types of Diffusion #   IMP**-3 The in**teraction of people contributes to the spread of cultural practices.\n  Learning Objective: Define the types of diffusion. Essential Knowledge:  Relocation and expansion — including contagious, hierarchical, and stimulus expansion — are types of diffusion   Relocation — hearth moves  act of people physically moving takes time, typically slow not everyone is going to absorb it term: person who uses a term moves to a new location and continues to use the term in the new location, OR a form of media, in which a term is used, is relocated to a new place and the term is used in the new location. Example: Spread of Christianity, when people moved and brought it with them    expansion — hearth stays same place  contagious  diseases rapid spread term: an individual uses, or individuals use, the new word and then acquaintances (or those in close proximity to them) begin to use the word as well Example: Hinduism spreading throughout the Indian subcontinent    hierarchical  intent is to spread selectively term: celebrities start to use the new word and then it spreads to others down the social hierarchy OR people in large cities start to use the word and then the word eventually gets to smaller places or media markets, OR Reverse Hierarchical: minority use of the term spreads up the social ladder to majority group(s). spread by choice, often wealth    stimulus  innovative idea diffuses from its hearth outward, but the original idea is changed by the new adopters Example: Different Menu items from McDonalds around the world.        3.5 Historical Causes of Diffusion #   SPS-3 Cultural ideas, practices, and innovations change or disappear over time.\n  Learning Objective: Explain how historical processes impact current cultural patterns. Essential Knowledge:  Interactions between and among cultural traits and larger global forces can lead to new forms of cultural expression; for example, creolization and lingua franca.  lingua franca  a language that is informally agreed upon as the language of business and trade  Reasons for US being lingua franca / dominant  Historical  Globalization      creolization  mix of languages that form its own language native to some group of people vocab from different language   pidgin  no ones native language usually result of trading between groups of people who don\u0026rsquo;t share the same language     Colonialism, imperialism, and trade helped to shape patterns and practices of culture.  Colonialism + imperialism  The widespread diffusion of English is thanks, in large part, to the colonial practices of the British   trade   link        3.6 Contemporary Causes of Diffusion #   SPS-3 Cultural ideas, practices, and innovations change or disappear over time.\n  Learning Objective: Explain how historical processes impact current cultural patterns. Essential Knowledge:  Cultural ideas and practices are socially constructed and change through both small-scale and large-scale processes such as urbanization and globalization. These processes come to bear on culture through media, technological change, politics, economics, and social relationships.  sense of place is the special perception we have of a certain place based on our feelings, emotion, and associations with that place.  also called distinctive culture    Placelessness is he loss of a place\u0026rsquo;s unique favor and identity because of standardizing influence of popular culture and globalization   Communication technologies, such as the internet and the time-space convergence, are reshaping and accelerating interactions among people; changing cultural practices, as in the increasing use of English and the loss of indigenous languages; and creating cultural convergence and divergence.  the internet has united us more  pros  easier to share + spread culture english is language of the internet, universal   cons  culture can be easily judged without full context english is prereq and reducing usage of other languages          3.7 Diffusion of Religion and Language #   IMP**-3 The** interaction of people contributes to the spread of cultural practices.\n  Learning Objective: Explain what factors lead to the diffusion of universalizing and ethnic religions. Essential Knowledge:  Language  Language families, languages, dialects, world religions, ethnic cultures, and gender roles diffuse from cultural hearths. Diffusion of language families, including Indo-European, and religious patterns and distributions can be visually represented on maps, in charts and toponyms, and in other representations.   Religion  Hinduism  Hearth: Pakistan in ~2300 BCE Because Hinduism is an ethnic religion it primarily diffused via relocation diffusion to India and Nepal   Judaism  Hearth: Isreal/Palestine in ~1800 BCE Due to persecution from many countries, Judaism has diffused across many countries but is most prominent in Isreal and the United States now.   Christianity  Hearth: Jerusalem on 1 AD Christianity largely spread due to conquest throughout much of the Roman Empire, and again later on through colonialism. Now it’s the most practiced religion and is most influential in Europe, the Americas, South Africa, and Australia   Islam  Hearth: Arabian Peninsula/Saudi Arabia in ~600 CE Spread via conquest and trade, concentrated primarily in the Middle East, North Africa, Southwest Asia, and some portions of Southeast Asia   Buddhism  Hearth: Nepal in ~500 BCE Missionaries and trade helped diffuse Buddhism, and it’s not found in Southeast and East Asia, India, Sri Lanka, and Tibet     Religion can identify, unit, or divide a group of people  RELIGION IS ARGUABLY THE MOST VOLITALE OF ALL HUMAN RELATIONS AND THE SOURCE OF MOST VIOLENCE THROUGHOUT HISTORY. EUnion forbid any religious symbols such as crucifixes, crosses, etc. on public school walls and calls them a violation of religious and educational freedom Religion is nearly always suppressed in communist countries. Leaders believe that religion has a tendency to upset stability and therefore ban it altogether, though often they just concrete the people’s religious adherence instead of destroying it.     Religions have distinct places of origin from which they diffused to other locations through different processes. Practices and belief systems impacted how widespread the religion diffused.  Romans came and pushed out Jews, forcing them to diffuse Many religions spread via trade routes  Christian countries tended to have many trade routes, so it spread to a range of areas Islamic countries didn\u0026rsquo;t trade very far outside Africa and Asia (a bit to Europe)   Buddhism barely diffused from Asia   Universalizing religions, including Christianity, Islam, Buddhism, and Sikhism, are spread through expansion and relocation diffusion.  Anyone can become a member of a universalizing religion universalizing religion stories often attempt to explain the mystical and there calendar\u0026rsquo;s main purpose in calendars is to commemorate events in the founder’s life, thus the seasons or weather are not central to the structure Christianity, Buddhism, and Islam are the three main  Buddhism and Islam are the universalizing religions that place the most emphasis on identifying shrines/holy places.  In universalizing religions, the holy places are generally locations at which memorable events happened in the founder’s life, such as Mecca is in Islam because it is Muhammad’s birthplace. Holy places in ethnic religions are often physical features that are closely tied to the religion (For example, in Hindu one of the most important rituals is the bathing of oneself in the Ganges River.)     Members actively proselytize, or seek new converts by sending missionaries through the world to spread their beliefs Excluding Hinduism, this shows diffusion of universalizing religions   Ethnic religions, including Hinduism and Judaism, are generally found near the hearth or spread through relocation diffusion.  Only really spread from generation to generation Ethnic religious creation stories tend to deal with the physical environment and natural events and typically organize their calendars around the seasons, other natural events, or the physical geography Ethnic religions rarely diffuse, and when they do, it is to a small extent  Judaism is an exception in that it has diffused widely throughout the years, mainly because its people have had to flee persecution from many areas in the world.   Traditional religions  subgroup of ethnic practiced by small groups, typically within a village or tribe          3.8 Effects of Diffusion #   SPS-3 The interaction of people contributes to the spread of cultural practices.\n  Learning Objective: Explain how the process of diffusion results in changes to the cultural landscape Essential Knowledge:  Acculturation, assimilation, syncretism, and multiculturalism are effects of the diffusion of culture.   Acculturation  process of adopting some of the values, customs, and behaviors of the host culture immigrants may adopt the language and a few other customs of the host group but will retain many distinctive customs   assimilation  Assimilation is the process whereby individuals or groups of differing ethnic heritage are totally absorbed into the dominant culture of a society. The process of assimilating involves taking on the traits of the dominant culture to such a degree that the assimilating group becomes socially indistinguishable from other members of the society. as we become more assimilated, languages become lost   syncretism  blending of cultures and ideas from different places   multiculturalism  grouping of various cultures in a certain area can lead to loss of cultural uniqueness, languages, and general \u0026ldquo;sameness\u0026rdquo; — link       🏛️Unit 4 - Political Patterns and Processes #  Developing Understanding\n This unit addresses the political organization of the world. Building on knowledge of populations and cultural patterns learned in previous units, students examine the contemporary political map and the impact of territoriality on political power and on issues of identity for peoples. Students also look at the different types of political boundaries, how they function, and their scale, as they consider both internal and international boundaries. The interplay of political and cultural influences may cause tensions over boundaries to arise, such as sovereign states making claims on what other states consider to be international waters. Students also examine forms of government and how forces such as devolution may alter the functioning of political units and cause changes to established political boundaries. Separatist and independence movements that challenge the sovereignty of political states may arise from economic and nationalistic forces, as seen in Scotland, Northern Ireland, and Spain. The influence of supranational organizations such as the United Nations or European Union and their role in global affairs presents another challenge to nationalist sovereignty. Student understanding of cultural patterns and processes helps inform their understanding of the consequences of centrifugal and centripetal forces.\n  BIG IDEA 1Patterns and Spatial Organization (PSO)\n How do historical and current events influence political structures around the world? BIG IDEA 2 Impacts and Interactions (IMP) How are balances of power reflected in political boundaries and government power structures? BIG IDEA 3Spatial Processes and Societal Change (SPS) How can political, economic, cultural, or technological changes challenge state sovereignty?   4.1 Introduction to Political Geography #   PSO-4 The political organization of space results from historical and current processes, events, and ideas.\n  Learning Objective: For world political maps: a. Define the different types of political entities. b. Identify a contemporary example of political entities. Essential Knowledge:  Independent states are the primary building blocks of the world political map. Types of political entities include nations, nation-states, stateless nations, multinational states, multistate nations, and autonomous and semiautonomous regions, such as American Indian reservations.  state:  a country and not a political subdivision within the united states, such as Nevada or Maine has sovereignty, boundaries, and a permanent population   nations:  unified group of people with a common culture Navajo, Roma   nation-states:  States in which over 90 percent of the population are the same specific culture or group of people A politically organized area in which nation and state occupy the same space. can act as a centripetal factor to those of the same ethnicity as majority Japan, Iceland, Armenia, Bangladesh, Lesotho   stateless nations  A nationality that is not represented by a state.   multinational states  states made up of a two or more ethnic groups United states, Canada, China, Russia, India, Brazil    multistate nations  country with two or more nationalities within its borders (a nation that exists in multiple states) Kurds, French, Basque   Buffer state  States that are allowed to exist by neighboring states (to help relieve tension between the neighboring states). Mongolia between China and Russia   autonomous  a group of people or territory are self-governing, thus not under the control of a higher level of government   semiautonomous regions  a group of people that have some level of automity, but are still controlled by another entity         4.2 Political Processes #   PSO-4 Explain the processes that have shaped contemporary political geography.\n  Learning Objective: Explain the processes that have shaped contemporary political geography. Essential Knowledge:  The concepts of sovereignty, nation-states, and self-determination shape the contemporary world  sovereignty  internationally recognized exercise of a country\u0026rsquo;s power over its people and territory   nation-states   URL   self-determination  the concept that ethnicities have the right to govern themselves can lead to irredentism     Colonialism, imperialism, independence movements, and devolution along national lines have influenced contemporary political boundaries.  Colonialism  when a group of people impose a set of formal controls by the mother country over its colonies or outside territories Colonizers colonize because of  Gold — seek monitary gains at (most of the time) any expense God — want to spread there own religion Glory — clout   Effects still present today  Social unrest typically speak langauge of colonizers  French in Northern Africa, English (British) in Southern Africa     boundaries expand that aren\u0026rsquo;t physically connected to mother country   imperialism  the use of military, cultural domination, and or economic sanctions to gain control of a country and its resources boundaries expand from mother country   independence movements  can result in section breaking off   devolution   Quizlet the transition of power from the central government to regional governments in a state is done by  Altering of a constitution Experiments on new governmental body Internal Division (Ethnocultural, Economic, or Spatial)   results in  Creation of an independent state Calls for Autonomy   can result in section breaking off          4.3 Political Power and Territoriality #   PSO-4 Explain the processes that have shaped contemporary political geography.\n  Learning Objective: Describe the concepts of political power and territoriality as used by geographers Essential Knowledge:  Political power is expressed geographically as control over people, land, and resources, as illustrated by neocolonialism, shatter belts, and choke points.  neocolonialism  Refers to the economic control that MDCs are sometimes believed to have over LDCs. Through organizations such as the IMF, the MDCs are able to dictate precisely what LDCs economic policies are, or are able to use their economic subsidies to put LDCs industries out of business.   shatter belts  an area of instability between regions with opposing political and cultural values   choke points  A geographical land feature such as a valley or water way narrowing causing a decrease in forces making their way through.     Territoriality is the connection of people, their culture, and their economic systems to the land.  boundaries are set to connect people with same/similar culture and that want to have an economic relation with one anther     Stages of Economic Growth and Core Periphery Model (Core-Periphery) Core Periphery  Stages of each Reasons for economic location Core-periphery leads to uneven spatial distribution of economic, political, or cultural power       4.4 Defining Political Boundaries #   IMP-4.Political boundaries and divisions of governance, between states and within them, reflect balances of power that have been negotiated or imposed.\n  Learning Objective: Define types of political boundaries used by geographers. Essential Knowledge:  Types of political boundaries (barriers)include relic, superimposed, subsequent, antecedent, geometric, and consequent boundaries.  relic  boundary that used to exist, but is no longer active / present You can often still see effects of relic boundary even if they aren\u0026rsquo;t there e.g. great wall of China, East and West Germany   superimposed  boundary imposed by an outside force may not reflect cultural landscape e.g. treaties, Africa during Colonial era    subsequent  corresponds to group that is there, often regardless of cultural divide boundary set after the settlements of different groups meet often correspond to ecumene wall impacts   consequent boundaries  A boundary line that coincides with some cultural divide, such as religion or language. E.g. India   antecedent  pre-existing; most commonly physical features such as rivers, bays, mountains, desserts can potentially be removed with technology  road build across dessert whole through mountain     geometric  straight lines US-Canada boarder because they aren\u0026rsquo;t visible, can lead to conflict   Shapes  compact  round easy defense and communication   prorupted or protruded  round with a large extension increases access to resources or water/ports   elongated  long, narrow difficult communication between areas   fragmented  two or more areas separated by another country or body of water difficult communication   perforated  totally surrounds another country can abuse country w trade taxes/tariffs   landlocked          4.5 The Function of Political Boundaries #   IMP-4. Political boundaries and divisions of governance, between states and within them, reflect balances of power that have been negotiated or imposed.\n  Learning Objective: Explain the nature and function of international and internal boundaries. Essential Knowledge:  Boundaries are defined, delimited, demarcated, and administered to establish limits of sovereignty, but they are often contested.  defined  Treaty or legal document   delimited  Drawn on map in agreement   demarcated  VISUALLY MARKED walls, posts, fence   administered  the enforcement \u0026amp; maintaining of a boundary by government who can cross? what goods can cross? demarcated?     Political boundaries often coincide with cultural, national, or economic divisions. However, some boundaries are created by demilitarized zones or policy, such as the Berlin Conference.  most of the time are made to not piss people / countries off if made by a supranational org   Land and maritime boundaries and international agreements can influence national or regional identity and encourage or discourage international or internal interactions and disputes over resources. The United Nations Convention on the Law of the Sea defines the rights and responsibilities of nations in the use of international waters, established territorial seas, and exclusive economic zones.  UN came up with these zones  EEZ is important because you can tax ships that travel and make money  Includes islands too which has put pressure / created conflict at some islands  South China Sea     UN came in because otherwise it was hard to figure out who owned what area and lead to conflicts       4.6 Internal Boundaries #   IMP-4.Political boundaries and divisions of governance, between states and within them, reflect balances of power that have been negotiated or imposed.\n  Learning Objective: Explain the nature and function of international and internal boundaries. Essential Knowledge:  Voting districts, redistricting, and gerrymandering affect election results at various scales.  Voting districts  subsections in states specifically for voting    redistricting  occurs once in every 10 years in US after census goal is to be drawn fairer and group like people often results in gerrymandering   gerrymandering  redistricting in such a way that it favors a political party         4.7 Forms of Governance #   IMP-4.Political boundaries and divisions of governance, between states and within them, reflect balances of power that have been negotiated or imposed.\n  Learning Objective: Define federal and unitary states. Essential Knowledge:  Forms of governance include unitary states and federal states  unitary states  most power lies in centralized govt areas far away from central power aren\u0026rsquo;t represented equally can pull a country together    federal states  most power lies in local govt  country is split into states / provinces, typically to group like-people   can better represent areas Green = Federal       Learning Objective: Explain how federal and unitary states affect spatial organization. Essential Knowledge:  Unitary states tend to have a more top-down, centralized form of governance, while federal states have more locally based, dispersed power centers.  unitary states  focus on central government or big city   federal states  multiple nodal points   stateless  compact around a center nodal point small boarders         4.8 Defining Devolutionary Factors #   SPS-4.Political, economic, cultural, or technological changes can challenge state sovereignty.\n  Learning Objective: Define factors that lead to the devolution of states Essential Knowledge:  Factors that can lead to the devolution of states include the division of groups by physical geography, ethnic separatism, ethnic cleansing, terrorism, economic and social problems, and irredentism.   physical geography  if state is physically separated by land, water, etc.   ethnic separatism  rise of ethnic groups in a state that want there own statehood   ethnic cleansing  not genocide  genocide = killing people   ethnic cleansing is moving certain people out   political justification  Heartland-rimland theory  justified eu colonization during 19th century by claiming EU was the heartland and the surrounding territories comprised of the rimland the heartland was well positioned to dominate the world because of the immense size of its mass. since Russia formed the major part of the heartland, Mackinder (creator of theory) influenced politicians of the day to try to limit Russia\u0026rsquo;s expansion by colonizing territories near Russia tl;dr — Politicians used some crappy justification that aligned with the biases to further there agenda   domino thoery  once a country became communist, the neighboring countries around it were likely to also become communist     terrorism  goal is to intimidate or coerce a govt to do the terrorists political or social objective serves to pull country apart   economic  richer areas can want to split off so that they don\u0026rsquo;t have to pay a majority in taxes to people they don\u0026rsquo;t know/relate to   social problems  due to differences between cultural groups   irredentism  the goal of a group of people to want to unit with another group of people who share cultural elements with, but are divided by national boundaries can result in civil wars       4.9 Challenges to Sovereignty #   SPS-4.Political, economic, cultural, or technological changes can challenge state sovereignty.\n  Learning Objective: Explain how political, economic, cultural, and technological changes challenge state sovereignty.  political  superimposed boarders can lead to people upset   economic  area wanting less taxes because they\u0026rsquo;re paying an unequal amount terrorist groups attacking transportation / pipes   cultural  e.g. one group wanting an official language and another group wanting a different official language     Essential Knowledge:  Devolution occurs when states fragment into autonomous regions; subnational political territorial units, such as those within Spain, Belgium, Canada, and Nigeria; or when states disintegrate, as happened in Sudan and the former Soviet Union.  autonomous regions; subnational political territorial units   Link E.g. Spain, Belgium, Canada, and Nigeria   disintegrate  E.g. Sudan and the former Soviet Union     Advances in communication technology have facilitated devolution, supranationalism, and democratization.  devolution — link supranationalism  easier to connect with similar people and want to join them Political, economic, and/or cultural cooperation among national states to promote shared objectives Tendency for states to give up political power to a higher authority in pursuit of common objectives (political, economic, military, environmental) Venture involving multiple national states (two or more, many, several) with a common goal   democratization  easier to see how much better it is outside your country with internet     Global efforts to address transnational and environmental challenges and to create economies of scale, trade agreements, and military alliances help to further supranationalism.  economies of scale trade agreements military alliances   Supranational organizations—including the United Nations (UN), North Atlantic Treaty Organization (NATO), European Union (EU), Association of Southeast Asian Nations (ASEAN), Arctic Council, and African Union— can challenge state sovereignty by limiting the economic or political actions of member states.  international group which the power and influence of member states transcend national boundaries or interest to share in decision making and vote on issues concerning the collective body member states give up some rights for common good of supranational organziation cooperation should resolve conflict sometimes used for collective defense can make economic stuff easier by opening boarders to member states set standards        4.1 Consequences of Centrifugal and Centripetal Forces #   SPS-4.Political, economic, cultural, or technological changes can challenge state sovereignty.\n  Learning Objective: Explain how the concepts of centrifugal and centripetal forces apply at the state scale. Essential Knowledge:  Centrifugal forces may lead to failed states, uneven development, stateless nations, and ethnic nationalist movements.  failed states  political body that has disintegrated to a point where basic conditions and responsibilities of a sovereign govt no longer function most LDCs   uneven development  tend to be poor with corrupt govt   stateless nations  can serve as a centrifugal factor to state they\u0026rsquo;re in united inside there own area typically grouped by ethnic groups   ethnic nationalist movements  lead to separation movements riots against govt if not adequately represented     Centripetal forces can lead to ethnonationalism, more equitable infrastructure development, and increased cultural cohesion.  ethnonationalism  nationalism of people with common background / language unites people   more equitable infrastructure development increased cultural cohesion       🚜Unit 5 — Agriculture and Rural Land-Use Patterns and Processes #  Developing Understanding\n This unit examines the origins of agriculture and its subsequent diffusion. Students learn about the ways agricultural practices have changed over time as a result of technological innovations, such as equipment mechanization and improvements in transportation that create global markets. In addition, they examine the consequences of agricultural practices such as the use of high-yield seeds and chemicals, revisiting the human–environmental relationships studied in Unit 1. Course emphasis on spatial patterns is evident in this unit as students consider the differences in what foods or resources are produced and where they are produced. These agricultural production regions are impacted by economic and technological forces that increase the size of agricultural operations and the carrying capacity of the land. This has in turn created a global system of agriculture and the interdependence of regions of agricultural consumption and production. Student understanding of this global system of agriculture based on government cooperation lays the foundation for a deeper understanding of economic development in the final unit of the course.\n  BIG IDEA 1Patterns and Spatial Organization (PSO)\n How do a people’s culture and the resources available to them influence how they grow food? BIG IDEA 2 Impacts and Interactions (IMP) How does what people produce and consume vary in different locations? BIG IDEA 3Spatial Processes and Societal Change (SPS) What kind of cultural changes and technological advances have impacted the way people grow and consume food?   5.1 Introduction to Agriculture #   PSO 5 Availability of resources and cultural practices influence agricultural practices and land-use patterns.\n  Learning Objective: Explain the connection between physical geography and agricultural practices. Essential Knowledge:  Agricultural practices are influenced by the physical environment and climatic conditions, such as the Mediterranean climate and tropical climates.  During the First Agricultural Revolution:  Sarted around 11,000 BC Unknown origins / how it happened (before recording of history) Humans radically changed their behavior: Went from hunting/gather life style to settling in to single areas and cultivating the land, planting crops, and raising animals   Agriculture is impacted by:  Land — cheap, near market + transportation, good quality soil Labor — cheap, skilled (enough), enough quantity Climate — have to meet requirements of crop, enough rain   Mediterranean Agriculture:  produces grapes and olives (cash crops), alongside citruses and figs — helps attract tourists, contributes to culture still produce cereals, especially wheat for pasta/bread requires warm year-round climate with lots of sunshine and boardering a sea horticulture: growing fruits, veggies, and flowers     Intensive farming practices include market gardening, plantation agriculture, and mixed crop/livestock systems.  Land: Small — land isn\u0026rsquo;t cheap so only small portions of high quality land is used High yield (food produced) to feed consumers Location: Closest to market Relies on lots of labor and tech (pesticides, fertilizer, etc.) (Oftentimes) variety of products produced — polyculture Examples:  market gardening  close to market small scale production of cash crops: fruits, vegetables, and flowers (apples, asparagus, cherries, lettuce, mushrooms, tomatoes) sold directly to local consumers. truck farming: truck means \u0026ldquo;barter\u0026rdquo; or \u0026ldquo;exchange\u0026rdquo;, not a physical truck   plantation agriculture (cash crop, cashcrop)  highly efficient tend to be established in or near the tropics produce a cash crop    mixed crop/livestock systems  Both animal and crops are farmed in the same area. Most common form of agriculture in US Crops, like maize and soybeans, are grown primarily to feed animals Utilizes crop rotation: cycles various crops and fields left to fallow (naturally grow over) to allow nutrient replenishing   China, India, and SE Asia rely on this type of agriculure to double-crop  Fit 2 years of harvest in 1 year       Extensive farming practices include shifting cultivation, nomadic herding, and ranching.  Land: Large Location: Farther from market — land isn\u0026rsquo;t cheap so it\u0026rsquo;s not that great and far away from market Examples:  Shifting cultivation  (slash-and-burn) vegetation is cut down and then ignited to make the ground more productive low yield / ineffective occurs in tropics  More notes   Nomadic herding  (animal husbandry) based on herding domesticated animals. can result in desertification low yield, but only needs to support tribe/family   Ranching  commercial grazing of livestock over an extensive area practiced is semi-arid or arid land, where vegetation is too sparse or the soil to too poor to support crops prominent in later 19th century in the American West; on the decline due to low profit margins — more intensive to go into mono farming           5.2 Settlement Patterns and Survey Methods #   PSO 5 Availability of resources and cultural practices influence agricultural practices and land-use patterns.\n  Learning Objective: Identify different rural settlement patterns and methods of surveying rural settlements. Essential Knowledge:  Specific agricultural practices shape different rural land-use patterns.  Rural defined as \u0026lt; 2500 residents, and between 1 and 999 person per square mile 3 factors that affect the pattern of rural setllement:  The kind of resource/feature that attracts people to the area (forests, farmlands, fields) The transportation method avaliable at the time of settlement (rivers, roads) Role of government policy, especially the land survey system (metes-and-bonds, long lot, rectangle, etc.)     Rural settlement patterns are classified as clustered, dispersed, or linear.  clustered  A clustered rural settlement typically includes homes, barns, tool sheds, and other farm structures, plus personal services, such as religious structures and schools.   dispersed  characterized by farmers living on individual farms isolated from neighbors rather than alongside other farmers in the area.   linear  Linear rural settlements feature buildings clustered along a road, river, or dike to facilitate communications.   nucleated  a number of families live in close proximity to each other, with fields surrounding the collection of houses and farm buildings (e.g., Asian longhouse)     Rural survey methods include metes and bounds, township and range, and long lot.  Rectangular survey system  Also called the Public Land Survey The system was used by the U.S. Land Office Survey to parcel land west of the Appalacian mountains. The system divides land into a series of rectangular parcels.   metes and bounds  A system of land surveying east of the Appalachian Mountains (EU) It is a system that relies on descriptions of land ownership and natural features such as streams or trees.    township and range  rectangular land division scheme designed by Thomas Jefferson grid system Intended to disperse settlers evenly across farmlands of the U.S. interior    long lot  Distinct regional approach to land surveying found in the Canadian Maritimes, parts of Quebec, Louisiana, and Texas designed to give everyone an equal type of land / soil (one person shouldnt get all poor land / land on a road or river / etc.) Land is divided into narrow parcels stretching back from rivers, roads, or canals.          5.3 Agricultural Origins and Diffusions #   SPS 5 Agriculture has changed over time because of cultural diffusion and advances in technology.\n  Learning Objective: Identify major centers of domestication of plant sand animals. Essential Knowledge:  Early hearths of domestication of plants and animals arose in the Fertile Crescent and several other regions of the world, including the Indus River Valley, Southeast Asia, and Central America.  Fertile Crescent (Mesopotamia) — 10,000 years ago  1200 years ago it became good for sedentary agriculture In the Middle East that includes most of Iraq (Known as Mesopotamia in the past), Syria, Lebanon, Israel, and the Nile River basin in Egypt.    Huang He (Yellow) Valley — 10,000 years ago  Flooding of rivers resulted in people settling near them and using them to farm Barley, wheat, lentils, and olives Diffused west to EU + Central Asia Experienced the Primary Revolution later than in the Fertile Crescent/Mesopotamia   Nile River Valley — 8,000 years ago  Used crop rotation with lagoons and cereals to reduce salt build up Settlements around Nile   Indus River Valley — 4,000 years ago  Extended from modern-day northeast Afghanistan to Pakistan and northwest India. Important innovations of this civilization include standardized weights and measures, seal carving, and metallurgy with copper, bronze, lead, and tin.    Central America.  Uncertain time period, but probably happened last Some scholars estimate 2000 BC, but may go up to the discovery of the Americas by the Europeans because some Native Tribes had not progressed to the First Agricultural Revolution by that time Beans, maize (corn), and cotton Diffused North and South   Sub-Saharan Africa  Sorghum, yams, milet, and rice 10,000 years ago Diffused south       Learning Objective: Explain how plants and animals diffused globally. Essential Knowledge:  Patterns of diffusion, such as the Columbian Exchange and the agricultural revolutions, resulted in the global spread of various plants and animals.      5.4 The Second Agricultural Revolution #   SPS 5 Agriculture has changed over time because of cultural diffusion and advances in technology.\n  Learning Objective: Explain the advances and impacts of the second agricultural revolution. Essential Knowledge:  New technology and increased food production in the second agricultural revolution led to better diets, longer life expectancies, and more people available for work in factories.  Page 105 in Barron\u0026rsquo;s Occurred in 1700\u0026rsquo;s through 1940\u0026rsquo;s (alongside industrial revolution) Advances:  Motors, specifically tractors, which further advanced stuff in the 1930\u0026rsquo;s People used crop rotation instead of letting land grow over   Where:  Happened in Europe and North America  Started with horse-drawn hoes in England     Outcomes:  Surplus of crops in England diffused through EU People ate healthier because more food was available at lower prices Allowed more people to move to cities which led to industrial revolution women needed less kids for farms Farming changed from family to commercial enterprise (agribusiness) that emphasized single crops and profits Vertical integration (contracts between farmer and purchaser) caused farm outputs to increase by 1990s         5.5 The Green Revolution #   SPS 5 Agriculture has changed over time because of cultural diffusion and advances in technology.\n  Learning Objective: Explain the consequences of the Green Revolution on food supply and the environment in the developing world. Essential Knowledge:  The Green Revolution was characterized in agriculture by the use of high-yield seeds, increased use of chemicals, and mechanized farming  Machines have replaced human labor New seeds, chemical pesticides, and fertilizers increased yield MDC often get newest tech first   The Green Revolution had positive and negative consequences for both human populations and the environment.  Started in mid-1970\u0026rsquo;s when scientists developed hybrid higher-yield seeds and new fertilizers to use alongside them. + New seeds and fertilizers diffused from core to periphery countries to help eradicate hunger + China, India, and SE Asia had rice harvests increase + Decrease land devoted to farms + Less expensive food + Reduce poverty + More consistent yield - Many poor farmers couldn\u0026rsquo;t afford new seeds - Africa couldn\u0026rsquo;t take advantage of seeds (there chief foods are millet, sorghum, yams, and cassavas - Increased irrigation, causing environmental damage - Focus on cash crops - Some soil has lost majority of nutrients due to over use - Biodiversity and native food crops have gone down, increased chance of blight       5.6 Agricultural Production Regions #   PSO Availability of resources and cultural practices influence agricultural practices and land-use patterns.\n  Learning Objective: Explain how economic forces influence agricultural practices Essential Knowledge:  Agricultural production regions are defined by the extent to which they reflect subsistence or commercial practices (monocropping or monoculture).  Subsistence vs Commercial:  Subsistence is :  Food grown for the farmer or farmer’s family/kin Food grown for local consumption for village/community market Food NOT grown for commercial purposes/sold for revenue     Monocropping or Monoculture — cultivation of a single crop Occurs in mostly commercial farms in MDCs — US in 1950\u0026rsquo;s minimizes risks — climate, cost of inputs like labor or fertilizer, market demand, etc. maximize profits — choice of crop best suited for growing, potential pricing, etc.  Supply and demands influences farmers to raise the crops that have high demands Governments disort market influence by subsidizing certain crops (rice in Japan, milk in US)     Intensive and extensive farming practices are determined in part by land costs (bid-rent theory).  bid-rent: geographical economic theory: refers to how the price and demand on real estate changes as the distance towards the Central Business District (CBD) increases. intensive agriculture: any kind of agriculture activity that involves effective and efficient use of labor on small plots of land to maximize crop yield extensive agriculture: an agricultural system characterized by low inputs of labor per unit land area        5.7 Spatial Organization of Agriculture #   PSO Availability of resources and cultural practices influence agricultural practices and land-use patterns.\n  Learning Objective: Explain how economic forces influence agricultural practices. Essential Knowledge:  Large-scale commercial agricultural operations are replacing small family farms.  Occured during 20th century due to larger profits  Further notes   Complex commodity chains link production and consumption of agricultural products.  Von Thunen   Technology has increased economies of scale in the agricultural sector and the carrying capacity of the land.  More food leads to people spending less time trying to figure out how to eat and shifting to figuring out how to grow / be smarter Technology has lead to intensive farming that has optimized how we use land       5.8 Von Thünen (Thunen) Model #   PSO Availability of resources and cultural practices influence agricultural practices and land-use patterns.\n  Learning Objective: Describe how the von Thünen model is used to explain patterns of agricultural production at various scales Essential Knowledge:  Von Thünen’s model helps to explain rural land use by emphasizing the importance of transportation costs associated with distance from the market; however, regions of specialty farming do not always conform to von Thünen’s concentric rings.  The closer the land is to the city, the more expensive it  Because perishable items, e.g. Milk, and difficult to transport items must be grown very closely to their market  Milkshed is ring around market where dairy farming occurs Weberian theory   Sort of not true with advances in transportation and that all land is able to support it\u0026rsquo;s designated task   Forest resources (needed for fuel) could be grown and harvested further out than fruits/veggies from the market  Market example with automobiles    Grain could be harvested even further out because it could be grown, harvested, and stored easily and cheaply until needed Limitations  Livestock then could be raised in the outer ring where cheap, larges pastures were pentiful        5.9 The Global System of Agriculture #   PSO Availability of resources and cultural practices influence agricultural practices and land-use patterns.\n  Learning Objective: Explain the interdependence among regions of agricultural production and consumption Essential Knowledge:  Food and other agricultural products are part of a global supply chain.  MDCs tend to have access to best tech and get far ahead compared to LDCs LDCs with land arable for certain foods may be funded by MDCs for a specific product that they (MDCs) can\u0026rsquo;t produce   Some countries have become highly dependent on one or more export commodities.  Country\u0026rsquo;s that have a monopoly on foods can exploit other countries that depend on them If there\u0026rsquo;s a pest+drought+other issue that stops production of producer country from making food, then all dependents are screwed too   The main elements of global food distribution networks are affected by political relationships, infrastructure, and patterns of world trade.  Tariffs can screw over trade agreements Country\u0026rsquo;s with more infrastructure are more likely to receive investment because its key to exporting goods Core-periphery model applies to agriculture       5.1 Consequences of Agricultural Practices #   IMP Agricultural production and consumption patterns vary in different locations, presenting different environmental, social, economic, and cultural opportunities and challenges.\n  Learning Objective: Explain how agricultural practices have environmental and societal consequences. Essential Knowledge:  Environmental effects of agricultural land use include pollution, land cover change, desertification, soil salinization, and conservation efforts.  pollution land cover change desertification  overgrazing leads to land being perminent damage to land via erosion of unprotected topsoils   soil salinization conservation efforts For rice farming For rice farming For mechanization / wheat farming   Agricultural practices—including slash and burn, terraces, irrigation, deforestation, draining wetlands, shifting cultivation, and pastoral nomadism—alter the landscape.  terraces  creating an embankment (a terrance) at a right angle to sloping land in order to allow water to soak into the soil rather than move down the slope, taking the soil with it   irrigation  more efficient, developed to keep up with population demand   deforestation plantation farming  mainly specialize in 1-2 crops mostly in tropics, Latin America, Africa, some Asia Mostly produce prodcuts for sale is MDCs   Intensive subsistence with wet rice dominant  High agricultural density — lots of farmers, little land must produce enough food for family or small village wet rice:  field prep: plow flooding: rain, river, or irrigation transplanting: rice seedling grow on dry land then moveod to flooded field to grow harvest: by hand   double cropping: finishing 2 harvests in 1 year   Intensive subsistence with wet rice NOT dominant  climate prevents growing of rice in some regions where summer preciiptation is too low and/or winters are too harsh wheat, barley, millet, oats, corn, and some cash crops (cotton, flax, hemp) grown small land worked fulley commonly use crop rotation   shifting cultivation  based on growing crops in different fields on a rotating basis, e.g.  Maya in the Yucatan grow maize by rotating fields (on a seven-year cycle)   crops include rice, maize, manioc, millet, sorghum, yams, surgercane, veggies fields are cut and burned each year to enrich the soil with nutrients  process called swidden or slash-and-burn   seeds are planted in time for rainy season cultivated fields are used for two or three years until all nutrients are used critics it should be replaced by a more efficient means defenders say it is the most environmentally sound approach occupies 25% of world\u0026rsquo;s land, but practiced by just 5% of people used to be tradiationally done by village, now mostly private companies being replaced by logging, ranching, and cashcrops (monofarming)    pastoral nomadism  animals are herded in a seasonal migratory pattern 200+ million pastoralists in the world often cattle, goats, sheet, camels, and reindeer often in arid, marginal alnds — N Africa, Central Asia, Middle east when herds are moved from land to land, it\u0026rsquo;s called transhumance declining in popularity because modern tech can make better use of pastures  mining, irrigation, petroleum       Societal effects of agricultural practices include changing diets, role of women in agricultural production, and economic purpose.  changing diets  food security plays a large role in LDCs  you can\u0026rsquo;t flourish if you\u0026rsquo;re physical and mental power is spent on getting food   maps   additional notes   role of women in agricultural production economic purpose       5.1 Challenges of Contemporary Agriculture #   IMP Agricultural production and consumption patterns vary in different locations, presenting different environmental, social, economic, and cultural opportunities and challenges.\n  Learning Objective: Explain challenges and debates related to the changing nature of contemporary agriculture and food-production practices. Essential Knowledge:  Agricultural innovations such as biotechnology, genetically modified organisms, and aquaculture have been accompanied by debates over sustainability, soil and water usage, reductions in biodiversity, and extensive fertilizer and pesticide use.  biotechnology, genetically modified organisms, and aquaculture  technological innovations have led to much higher yield   debates over sustainability, soil and water usage, reductions in biodiversity, and extensive fertilizer and pesticide use  pesticides kill off good bugs, possibly whipe out entire vital species by accident the majority of the latest tech is avaliable only the core countries, not periphery agricultural diversity has been on the decline, increased chance of blight  New, or very old, disease comes back and, because of lack of genetic diversity, most crops highly susciptible       Patterns of food production and consumption are influenced by movements relating to individual food choice, such as urban farming, community-supported agriculture (CSA), organic farming, value-added specialty crops, fair trade, local-food movements, and dietary shifts.  urban farming community-supported agriculture (CSA) organic farming  avoid using synthetic chemical fertilizers and GMOs aim to protect earth and produce safe, healthy food with \u0026ldquo;zero impact\u0026rdquo; on environment   value-added specialty crops fair trade local-food movements dietary shifts  Most typical citizen is an asian farmer who produces enough to get by MDCs people eat a lot more Cliamte affects what people eat  MDCs this is less of an impact due to better tech making shipping faster LDCs can only really eat what is avaliable locally   Cultural prefences still dictate diet  \u0026lsquo;Fast-food\u0026rsquo; diet   Meat consumption:  MDCs get 1/3 of protein from meat LDCs get 1/10 of protein from meat, rely more on grains        Challenges of feeding a global population include lack of food access, as in cases of food insecurity and food deserts; problems with distribution systems; adverse weather; and land use lost to suburbanization.  food access (food insecurity and food deserts problems with distribution systems adverse weather land use lost to suburbanization     The location of food-processing facilities and markets, economies of scale, distribution systems, and government policies all have economic effects on food-production practices.     5.1 Women in Agriculture #   IMP Agricultural production and consumption patterns vary in different locations, presenting different environmental, social, economic, and cultural opportunities and challenges.\n  Learning Objective: Explain geographic variations in female roles in food production and consumption. Essential Knowledge:  The role of females in food production, distribution, and consumption varies in many places depending on the type of production involved.  Historically, Men gathered the materials and women used these materials to manufacture household objects and maintained there house Obstacles to equality + empowerment      Impact of empowerment effects of this women empowerment / equality on population growth effects of this women empowerment / equality on economic development effects of this women empowerment / equality on gender roles in the developing world.    "},{"id":33,"href":"/ap/cmech/","title":"AP Physics C: Mechanics","section":"AP Notes","content":"This are very disjoint notes I took long ago. I would recommend using this for practice qs and perhaps equation review after you have a solid understanding of the chapters. My other notes are much more comprehensive, I swear! :)  1. Kinematics #  Four Primary Equations #   $$\\Delta x=\\frac{1}{2}(v_f-v_i)\\Delta t \\text{ \u0026ndash; no } a$$ $$v_f=v_i+a\\Delta t \\text{ \u0026ndash; no } x$$ $$\\Delta x=v_i \\Delta t+\\frac{1}{2}a \\Delta t^2 \\text{ \u0026ndash; no } v_f$$ $$\\Delta x=v_f \\Delta t-\\frac{1}{2}a \\Delta t^2 \\text{ \u0026ndash; no } v_i$$ $$v_f^2=v_i^2+2a \\Delta x \\text{ \u0026ndash; no } t$$   Used when .$a$cceration is constant  Slope and Area #    Top is .$x$, middle is .$v$, bottom is .$a$   Projectile Motion #   Half of parabolic flight time: $$t_\\text{top}=\\frac{v_i*\\sin\\theta}{g}$$ Peak in .$y$ direction: $$y_\\text{max}=\\frac{v_i*\\sin^2\\theta}{2g}$$ Distance traveled in .$x$ direction: $$x_\\text{max}=\\frac{v_i*\\sin2\\theta}{g}$$ Desmos tools   Projectile motion  Displacement, Velocity, and Acceleration    Practice #   FRQs to study ↕   Graphs  Changing Acceleration / Velocity       Example Qs ↕  1.2.3.4.5.6.7.8.      2. Forces #   .$N = \\text{kg m/s}^2$ \u0026ndash; a force of 1N causes a 1kg mass to accelerate at 1ms.$^{-2}$ Normal doesn\u0026rsquo;t always equal mg!  Friction #   Kinetic friction only acts when the force breaks past the static friction threshold The friction force is always the lesser of .$\\mu \\cdot N$ or the force it\u0026rsquo;s resisting $$F_s \\le \\mu_s \\cdot F_N$$  Spring #  $$F_\\text{spring} = -kx$$  $$k=\\frac{\\Delta F}{\\Delta x}$$    Thus, the slope .$\\Delta y / \\Delta x$ of a force vs. distance is .$k$  Centripital #  $$F_\\text{centripetal} = \\frac{mv^2}{r}$$\nGravity #  $$mg\\sin(θ) = F_\\text{gx} \\text{ \u0026ndash; Acceleration down ramp w/no friction}$$ $$mg\\cos(θ) = F_\\text{gy} \\text{ \u0026ndash; Normal force when no other forces act in the y direction}$$\nPulleys + Atwoods #  $$\\text{Acceleration of a Pulley} = \\frac{Mg}{m+M} = \\frac{Mg-\\mu mg}{m+M}$$\nDrag Force #   Drag on x-axis:  Drag on y-axis:   Practice #   FRQs to study ↕  Drag Multiple Bodies (pulleys, carts)     Practice Qs ↕                     3. Energy #  Work #  $$W = \\int F\\ dx = \\vec F_\\parallel \\cdot x = +\\Delta KE = -\\Delta PE = \\int P dt$$\n Force parallel to distance traveled If force is opposing motion and acceleration changes, work stays the same  Potential #  $$F = -\\frac{dU}{dx}$$\n Potential Energy can only depend on position Negative relation with force indicates that the direction of the force is always towards lower PE Derivation   Conservation #  Consider the total work done by a force that acts on a particle as the particle moves around a closed path and returns to its starting point. If this total work is zero, we call the force a conservative force. If the total work for the round trip is not zero, we call the force a non-conservative force. Consider the work done by a force that acts on an object as the object moves from an initial position to a final position along any arbitrarily chosen path. If this work is the same for all such paths, we call the force a conservative force. If the work is not the same for all paths, we call the force a non-conservative force.  $$\\Delta K + \\Delta U + \\Delta E_\\text{int}= W_\\text{ext}$$\n Conservative — NO external forces  Mechanical Energy conserved; ME = ME' Gravity, Spring Force Always have a potential energy associated with it Conservative force\u0026rsquo;s magnitude and direction only depend on the object\u0026rsquo;s location, not on how the object is moving   Non-conservative — external force present  Mechanical Energy lost; ME \u0026gt; ME' Friction, Air resistance (drag)   Internal Energy   Power #  Rate at which work is done $$P=\\frac{dW}{dt}=\\frac{dKE}{dt}=\\frac{W}{t}=\\vec F \\cdot \\vec v$$\nSprings #  $$W_\\text{spring}=\\int F_\\text{spring} dx= \\int (-kx)dx = -\\frac{1}{2}kx^2 $$ $$U_\\text{spring} = -W_\\text{spring}=\\frac{1}{2}kx^2$$\n Springs are most compressed in collisions when velocity of both objects are equal  Therefore, we can treat the system as inelastic at that moment Steps     Equilibrium #   Neutral Equilibrium is where the Potential Energy of the object remains constant regardless of position. For example, a ball rolling on a level surface. Stable Equilibrium is where the Potential Energy of the object increases as the position of the object moves away from the equilibrium position and therefore the object naturally returns to the equilibrium position. For example, a water bottle being tipped to the side. Unstable Equilibrium is where the Potential Energy of the object decreases as the position of the object moves away from the equilibrium position and therefore the object naturally moves away from the equilibrium position. For example, a marker being tipped to the side.   Practice #   Practice Qs ↕                         4. Momentum #  Collisions #  Elastic — bounce off #   KE conserved Momentum conserved (while no unbalanced ext forces) If the final velocity of an object is less than half of the initial velocity of the object (v_i/2), then the object it\u0026rsquo;s colliding with has more mass $$v_1+v_1'=v_2+v_2'$$ $$v_1'=\\frac{m_1-m_2}{m_1+m_2}v_1$$ $$v_2'=\\frac{2m_1}{m_1+m_2}v_2$$  Inelastic — Stick #   KE lost Momentum conserved (while no unbalanced ext forces) Maximum speed when m \u0026laquo; M   Impulse — Force and Time #  $$\\vec J = \\int \\vec F dt = \\vec F_\\text{avg} \\Delta t= \\Delta \\vec p = m \\Delta \\vec v$$\nCenter of Mass #   When only gravity is acting on a object that is thrown, it will spin (pivot) around the center of mass If you split an object along the center of mass line, both sides aren\u0026rsquo;t equal in mass unless density / form is the same for both. $$x_\\text{cm}=\\frac{\\Sigma(m_ix_i)}{\\Sigma(m)}=\\frac{\\int x \\lambda \\cdot dx}{\\Sigma M}$$ $$v_\\text{cm}=\\frac{\\Sigma(m_iv_i)}{\\Sigma(m)}$$ $$\\Sigma p=mv_\\text{cm}$$ $$\\Sigma F=ma_\\text{cm}$$  Practice #   Practice Qs ↕       a. Integrate 0m to 4m              5. Rotation #  Rotational Kinematics #  Used when α is constant\n $$ \\Delta \\theta=\\frac{1}{2}(\\omega_f-\\omega_i)\\Delta t \\text{ \u0026ndash; no } \\alpha$$ $$ \\omega_f=\\omega_i+\\alpha\\Delta t \\text{ \u0026ndash; no } \\theta$$ $$\\ \\Delta \\theta=\\omega_i \\Delta t+\\frac{1}{2}\\alpha \\Delta t^2 \\text{ \u0026ndash; no } \\omega_f$$ $$\\ \\Delta \\theta=\\omega_f \\Delta t-\\frac{1}{2}\\alpha \\Delta t^2 \\text{ \u0026ndash; no } \\omega_i$$ $$\\omega_f^2=\\omega_i^2+2\\alpha \\Delta \\theta \\text{ \u0026ndash; no } t$$  Rotational Inertia #    Pulleys ↕  with finishing with none+blue same time, then green, then red     Rolling Down an Incline ↕      Rolling Down an Incline \u0026#43; Slipping ↕      Rolling Up an Incline ↕      Rolling Up an Incline ↕      Rolling Up an Incline \u0026#43; Slipping ↕  Should be Blue \u0026gt; Green \u0026gt; Red (0)    Practice Qs #   Practice Qs ↕      where green has lower moment of inertia, and red has larger moment of inertia      Answer     9 10 11 12 13      "},{"id":34,"href":"/ap/stats/","title":"AP Statistics","section":"AP Notes","content":"The content of these notes are solid, but formatting is not since they\u0026rsquo;re exported from Notion.  Unit 1: Exploring One-Variable Data #  Types of Variables #   Categorical variables assigns labels that place each individual into a particular group, called a category.  Zip code. hair color   Quantitative variables takes number values that are quantities—counts or measurements.  Height, GPA   Explanatory  x on graph independent variable — what we\u0026rsquo;re changing measures an outcome of a study.   Response  y on graph (potentially) dependent variable — what we\u0026rsquo;re measuring may help predict or explain changes in a response variable   Confounding  Any factor that messes skews data Confounding occurs when two variables are associated in such a way that their effects on a response variable cannot be distinguished from each other. If you are asked to identify a possible confounding variable in a given setting, you are expected to explain how the variable you choose (1) is associated with the explanatory variable and (2) is associated with the response variable.    Frequencies #   A frequency table shows the number of individuals having each value.  A relative frequency table shows the proportion or percent of individuals having each value. A marginal relative frequency gives the percent or proportion of individuals that have a specific value for one Categorical variable.  What percent of people in the sample are environmental club members?  What proportion of people in the sample never used a snowmobile?    A joint relative frequency gives the percent or proportion of individuals that have a specific value for one Categorical variable and a specific value for another Categorical variable.  We can compute marginal relative frequencies for the row totals to give the distribution of snowmobile use for all the individuals in the sample:  We can compute marginal relative frequencies for the column totals to give the distribution of environmental club membership in the entire sample of 1526 park visitors    A conditional relative frequency gives the percent or proportion of individuals that have a specific value for one Categorical variable among individuals who share the same value of another Categorical variable (the condition).  What proportion of snowmobile renters in the sample are not environmental club members?  What percent of environmental club members in the sample are snowmobile owners?     Types of Graphs #   Pie Chart — Categorical  Need frequency value and corresponding label  Doesn\u0026rsquo;t show sample size     Bar Graph — Categorical  Needs bar labels, axis names, units, vertical axis scale should start at 0 A side-by-side bar graph displays the distribution of a Categorical variable for each value of another Categorical variable. The bars are grouped together based on the values of one of the Categorical variables and placed side by side. A segmented bar graph displays the distribution of a Categorical variable as segments of a rectangle, with the area of each segment proportional to the percent of individuals in the corresponding category.  Doesn\u0026rsquo;t show sample size, only proportions  This can be fixed by using a mosaic plot which scales the width corresponding to size       Dotplot — Quantitative  A dot plot shows each data value as a dot above its location on a number line. Needs title, axis label, unit of measurement How to find percentile  Percentile is the percent of people you\u0026rsquo;re better than, or percent of people that are worse than you Find how many points the decided point is ahead of, then divide by sample size The blue point is greater than 17 points, making it 17/20 —\u0026gt; in the 85% percentile     Stemplot — Quantitative  A stemplot shows each data value separated into two parts: a stem, which consists of all but the final digit, and a leaf, the final digit. The stems are ordered from lowest to highest and arranged in a vertical column. The leaves are arranged in increasing order out from the appropriate stems. Needs key and title  Key should give context   Key: 8|2 is a [context — student whose resting pulse rate] is 82 [beats per minute]\n    Histogram — Quantitative  A histogram shows each interval of values as a bar. The heights of the bars show the frequencies or relative frequencies of values in each interval. Needs title, axis label, unit of measurement   Boxplot — Quantitative  Describing Distributions (SOCS) + Context #   Always be sure to include context when you are asked to describe a distribution. This means using the variable name, not just the units the variable is measured in. When comparing distributions of Quantitative data, it’s not enough just to list values for the center and variability of each distribution. You have to explicitly compare these values, using words like “greater than,” “less than,” or “about the same as.”\n Shape (Skew) #    A distribution is skewed to the right if the right side of the graph is much longer than the left side. A distribution is skewed to the left if the left side of the graph is much longer than the right side.   The distribution of [context] is [skewed left/right/sym]\n Outlier #   Gaps too Low outliers \u0026lt; Q1 − 1.5 × IQR High outliers \u0026gt; Q3 + 1.5 × IQR Doesn\u0026rsquo;t follow trend, large residual   The [context — games played with 5 points / person with a height of 3'] appears to be an outlier\n Center #   Mean / average  The mean is sensitive to extreme values in a distribution.  These may be outliers, but a skewed distribution that has no outliers will also pull the mean toward its long tail.   We say that the mean is not a resistant measure of center — Shouldn\u0026rsquo;t be used with skew or outliers   Median  Resistant — should be used with outliers and skew    Spread / Variability #   Range  Not resistant — Shouldn\u0026rsquo;t be used with skew or outliers   The data vary from [min] to [max] [context — points scored / heights] meaning it had a range of [max - min]\n  Standard Deviation  Measure of the typical distance of the values in a distribution from the mean. It should be used only when the mean is chosen as the measure of center. sx is not a resistant measure of variability — Shouldn\u0026rsquo;t be used with skew or outliers Larger values of sx indicate greater variation sx is always greater than or equal to   The Interquartile Range (IQR)  What  The quartiles of a distribution divide the ordered data set into four groups having roughly the same number of values. To find the quartiles, arrange the data values from smallest to largest and find the median. The first quartile Q1 is the median of the data values that are to the left of the median in the ordered list. The third quartile Q3 is the median of the data values that are to the right of the median in the ordered list. IQR = Q3 - Q1   Resistant because they are not affected by a few extreme value — should be used with outliers    Why is it important? #   They might be inaccurate data values. Maybe someone recorded a value as 10.1 instead of 101. Perhaps a measuring device broke down. Or maybe someone gave a silly response, like the student in a class survey who claimed to study 30,000 minutes per night! Try to correct errors like these if possible. If you can’t, give summary statistics with and without the outlier. They can indicate a remarkable occurrence. For example, in a graph of net worth, Bill Gates is likely to be an outlier. They can heavily influence the values of some summary statistics, like the mean, range, and standard deviation. It can make it easier to see associations between variables  An association exists when there is a difference in outcome for different inputs We can only find definitive associations for the sample, and we have to use test to find out if we can extrapolate this data to a larger sample For example, there may be an association between AP Stats students and not having post-HS plans and overall being less likely to go to University when compared to AP Calc students    Five number summary (+ boxplot) #   Min Q1 Median Q3 Max  Standardized score (z-score) — the \u0026lsquo;test statistic\u0026rsquo; #    Tells us how many standard deviations from the mean the value falls, and in what direction.\n  Values larger than the mean have positive z-scores. Values smaller than the mean have negative z-scores.\n  Shape must be close to normal for z-scores to work\n  Never say that a distribution of Quantitative data is Normal. Real-world data always show at least slight departures from a Normal distribution. The most you can say is that the distribution is “approximately Normal.” 68–95–99.7  Approximately 68% of the observations fall within σ of the mean μ Approximately 95% of the observations fall within σ 2 of the mean μ Approximately 99.7% of the observations fall within σ 3 of the mean μ    Transforming Data #   Multiplying / dividing by a constant (Units converted)  Multiplies (divides) center and location (mean, five-number summary, percentiles) by b Multiplies (divides) measures of variability (range, IQR, standard deviation) by b Does not change the shape of the distribution   Adding/subtracting constant  Adds a to (subtracts a from) measures of center and location (mean, five-number summary, percentiles) Does not change measures of variability (range, IQR, standard deviation) Does not change the shape of the distribution    Percentile #   invNorm(.9, 0, 1) would find the z-score of 90%  Good video   Unit 2: Exploring Two-Variable Data #  How to Describe a Scatterplot #   Use CONTEXT Direction (association) Two variables have a positive association when above-average values of one variable tend to accompany above-average values of the other variable and when below-average values also tend to occur together.  More [x-unit], more [y-unit]   Two variables have a negative association when above-average values of one variable tend to accompany below-average values of the other variable.  More [x-unit], less [y-unit]   There is no association between two variables if knowing the value of one variable does not help us predict the value of the other variable.  Form: #   A scatterplot can show a linear form or a nonlinear form. The form is linear if the overall pattern follows a straight line. Otherwise, the form is nonlinear.  Strength (correlation): #   A scatterplot can show a weak, moderate, or strong association. An association is strong if the points don’t deviate much from the form identified. An association is weak if the points deviate quite a bit from the form identified. Correlation doesn’t imply causation.  In many cases, two variables might have a strong correlation, but changes in one variable are very unlikely to cause changes in the other variable   \u0026lsquo;r\u0026rsquo; — Correlation Coefficie  It is only appropriate to use the correlation to describe strength and direction for a linear relationship Has same sign (positive or negative) as the slope r measures the direction and strength of the association, and does not measure form The correlation r is always a number between −1 and 1 (−1 ≤ r ≤ 1) The correlation r indicates the direction of a linear relationship by its sign: r \u0026gt; 0 for a positive association and r \u0026lt; 0 for a negative association. The extreme values r = −1 and r = 1 occur only in the case of a perfect linear relationship, when the points lie exactly along a straight line. If the linear relationship is strong, the correlation r will be close to 1 or −1. If the linear relationship is weak, the correlation r will be close to 0.     Unusual features: #   outliers  that fall outside the overall pattern and distinct clusters of points — doesn\u0026rsquo;t follow trend large residual  definition link   influential point  if you remove the point, then there would be substantial changes on slope, y-int, or r    Interpreting #   There is a [strength — fairly strong/weak], [direction — positive / negative] [form — (non)linear] relationship between [x var] and [y-var] with [any outliers + outlier point].\n Residuals #   a = y-int, b = slope, s = s, R-sq = .$r^2$\nLeast-squares Regression Line (LSRL) #   A regression line is a line that describes how a response variable y changes as an explanatory variable x changes. Made to reduce the residual  Regression lines are expressed in the form where ŷ(pronounced “y-hat”) is the predicted value of y for a given value of x.  Extrapolation is the use of a regression line for prediction far outside the interval of x values used to obtain the line. Such predictions are often not accurate.  Don’t make predictions using values of x that are much larger or much smaller than those that actually appear in your data.   Interpretation — NEEDS CONTEXT  y-int y=b0+b1*x  b0   For a [context of x-var] with a [x-unit] of 0, the predicted [y-var] is [b0]\n  Slope  b1   For every increase of 1 in [x-unit], the predicted [y-unit] increases by [b1] [y-units]\n    Residual  Difference between actual and predicted value Interpretation:  The actual [y-var] for a [context] of [x-input \u0026amp; x-units] is [actual value (point we know) - predicted value] [lower/higher] than predicted by the LSRL.\n  Plug in respective values to LSRL to get the predicted value Residual Plot  a scatterplot that displays the residuals on the vertical axis and the explanatory variable on the horizontal axis. To determine whether the regression model is appropriate, look at the residual plot.  If there is no leftover curved pattern in the residual plot, the regression model is appropriate. LSRL is good Interpretation:  Because the residual plot does not show a clear pattern, the linear model is appropriate for the data\n  If there is a leftover curved pattern in the residual plot, consider using a regression model with a different form. LSRL is bad Interpretation:  Because the residual plot shows a clear patter, the linear model is not appropriate for the data\n         Standard deviation of residuals: .$s$ #   The standard deviation of the residuals s measures the size of a typical residual. That is, s measures the typical distance between the actual y values and the predicted y values. Interpretation:  The actual [y-var] [units] is typically around [s] away from the predicted by the least-squares regression line with x = [x-units]\n   The coefficient of determination: .$r^2$ #   The coefficient of determination .$r^2$ measures the percent reduction in the sum of squared residuals when using the least-squares regression line to make predictions, rather than the mean value of y. In other words, .$r^2$ measures the percent of the variability in the response variable that is accounted for by the least-squares regression line. Interpretation:  About [.$r^2$ in percent form]% of the variability for [y-var] is accounted for by the least-squares regression line with x = [x-var]\n    Unit 3: Collecting Data #  Chapter 4\nSampling #   The population in a statistical study is the entire group of individuals we want information about. A census collects data from every individual in the population. A sample is a subset of individuals in the population from which we collect data. A sample survey is a study that collects data from a sample that is chosen to represent a specific population.  Poor Sampling #   Convenience sampling selects individuals from the population who are easy to reach. Voluntary response sampling allows people to choose to be in the sample by responding to a general invitation Bias:  any difference between the sample result and the truth about the population that tends to occur in the same direction whenever you use the same sampling method The design of a statistical study shows bias if it is very likely to underestimate or very likely to overestimate the value you want to know. Bias is not just bad luck in one sample, it’s the result of a bad study design that will consistently miss the truth about the population in the same way If you’re asked to describe how the design of a sample survey leads to bias, you’re expected to do two things:  Describe how the members of the sample might respond differently from the rest of the population Explain how this difference would lead to an underestimate or overestimate.   Suppose you were asked to explain how using your statistics class as a sample to estimate the proportion of all high school students who own a graphing calculator could result in bias. You might respond, “This is a convenience sample . It would probably include a much higher proportion of students with a graphing calculator than in the population at large because a graphing calculator is required for the statistics class. So this method would probably lead to an overestimate of the actual population proportion.”   Undercoverage  occurs when some members of the population are less likely to be chosen or cannot be chosen in a sample. Most samples suffer from some degree of undercoverage. A sample survey of households, for example, will miss not only homeless people but also prison inmates and students in dormitories.   Nonresponse  Nonresponse occurs when an individual chosen for the sample can’t be contacted or refuses to participate Nonresponse leads to bias when the individuals who can’t be contacted or refuse to participate would respond differently from those who do participate. Consider a telephone survey that asks people how many hours of television they watch per day. People who are selected but are out of the house won’t be able to respond.   Response Bias  Response bias occurs when there is a systematic pattern of inaccurate answers to a survey question. The way questions are worded or the order in which they\u0026rsquo;re asked can lead to response bias    Good Sampling #   Simple random sample (SRS)  Involves using a chance process to determine which members of a population are included in the sample . Gives each possible sample an equal chance of being selected A simple random sample (SRS) of size n is chosen in such a way that every group of n individuals in the population has an equal chance to be selected as the sample. For example, to choose a random sample of 6 students from a class of 30, start by writing each of the 30 names on a separate slip of paper, making sure the slips are all the same size. Then put the slips in a hat, mix them well, and pull out slips one at a time until you have identified 6 different students.   Strata, Stratified random sample  Strata are groups of individuals in a population who share characteristics thought to be associated with the variables being measured in a study. good for when sample sizes between population groups (stratas) are different Stratified random sampling selects a sample by choosing an SRS from each stratum and combining the SRSs into one overall sample. For example, in a study of sleep habits on school nights, the population of students in a large high school might be divided into freshman, sophomore, junior, and senior strata. After all, it is reasonable to think that freshmen have different sleep habits than seniors. The following activity illustrates the benefit of choosing appropriate strata.   Clusters, Cluster sampling  A cluster is a group of individuals in the population that are physically located near each other. Cluster sampling selects a sample by randomly choosing clusters and including each member of the selected clusters in the sample . Cluster sampling is often used for practical reasons, like saving time and money. Imagine a large high school that assigns students to homerooms alphabetically by last name, in groups of 25. Administrators want to survey 200 randomly selected students about a proposed schedule change. It would be difficult to track down an SRS of 200 students, so the administration opts for a cluster sample of homerooms. The principal (who knows some statistics) selects an SRS of 8 homerooms and gives the survey to all 25 students in each homeroom.   Systematic Random Sampling  In systematic random sampling, the researcher first randomly picks the first item or subject from the population . Then, the researcher will select each n\u0026rsquo;th subject from the list. The procedure involved in systematic random sampling is very easy and can be done manually. The results are representative of the population unless certain characteristics of the population are repeated for every n\u0026rsquo;th individual, which is highly unlikely.    Experiments #   Goal is to  reduce bias and  allow replication with the hopes that we find statistically significant results that we can infer/extrapolate to the population Four conditions of Experimental Design  Comparison. Use a design that compares two or more treatments. Random assignment. Use chance to assign experimental units to treatments. Doing so helps create roughly equivalent groups of experimental units by balancing the effects of other variables among the treatment groups. Control. Keep other variables the same for all groups, especially variables that are likely to affect the response variable. Control helps avoid confounding and reduces variability in the response variable. Replication. (more than one experimental unit in each treatment group) — Use enough experimental units in each group so that any differences in the effects of the treatments can be distinguished from chance differences between the groups.   Study:  Observational Study: observes individuals and measures variables of interest but does not attempt to influence the responses. Observational Study vs experiment  experiment (randomly) assigns treatments in studies the researcher has no interaction/input whatsoever   data is observed and recorded naturally, scientists had no say  can reduce bias from scientists   no random assignment of subjects, but random sample can be taken  therefore, we can make inferences about the population from which the individuals were chose, but not about cause and effect ( link)     Vocab  Experiment: deliberately imposes some treatment on individuals to measure their responses  Response / Explanatory / Confounding Variables Placebo: A placebo is a treatment that has no active ingredient, but is otherwise like other treatments.  The placebo effect describes the fact that some subjects in an experiment will respond favorably to any treatment, even an inactive treatment.   Control: In an experiment, control means keeping other variables constant for all experimental units. Treatment: A specific condition applied to the individuals in an experiment Control group  In an experiment, a control group is used to provide a baseline for comparing the effects of other treatments. Depending on the purpose of the experiment, a control group may be given an inactive treatment (placebo), an active treatment, or no treatment at all.   Experimental unit: the object to which a treatment is randomly assigned Subjects: When the experimental units are human beings, they are often called subjects. Factor: In an experiment, a factor is a variable that is manipulated and may cause a change in the response variable.  Levels: In an experiment, a factor is a variable that is manipulated and may cause a change in the response variable. The different values of a factor are called levels.   Blinds  In a double-blind experiment, neither the subjects nor those who interact with them and measure the response variable know which treatment a subject received. In a single-blind experiment, either the subjects don’t know which treatment they are receiving or the people who interact with them and measure the response variable don’t know which subjects are receiving which treatment   Replication  In an experiment, replication means using enough experimental units to distinguish a difference in the effects of the treatments from chance variation due to the random assignment.   Sampling Variability  Refers to the fact that different random samples of the same size from the same population produce different estimates. Larger random samples tend to produce estimates that are closer to the true population value than smaller random samples. In other words, estimates from larger samples are more precise.   Statistically significant  When the observed results of a study are too unusual to be explained by chance alone, the results are called statistically significant.     Types of Experiments  Block, Randomized block design  A block is a group of experimental units that are known before the experiment to be similar in some way that is expected to affect the response to the treatments. In a randomized block design, the random assignment of experimental units to treatments is carried out separately within each block.    Matched Pairs  A matched pairs design is a common experimental design for comparing two treatments that uses blocks of size 2. In some matched pairs designs, two very similar experimental units are paired and the two treatments are randomly assigned within each pair. In others, each experimental unit receives both treatments in a random order.   Random Assignment: In an experiment, random assignment means that the treatment / placebo is randomly given out   Scope of Inference  Inference: The process of drawing conclusions about a population based on samples, since we infer information about the population from what we know about the samples. Random Selection — sample units are selected randomly  allows inference about the population from which the individuals were chosen groups may not be representative of population includes studies   Random Assignment — experimental units are assigned to treatments using a chance process.  allows inference about cause and effect. groups may differ between studies if not randomly assigned tend to average out all other uncontrollable factors so that they aren\u0026rsquo;t confounding with the treatment effects not studies   Additional Requirements:  The association is strong. The association is consistent. Larger values of the explanatory variable are associated w/ stronger responses. The alleged cause precedes the effect in time.     Criteria for Establishing Causation When an Experiment CANNOT Be Done ● The association is strong. ● The association is consistent. ● Larger values of the explanatory variable are associated w/ stronger responses. ● The alleged cause precedes the effect in time. ● The alleged cause is plausible. Ethics  All planned studies must be reviewed in advance by an institutional review board charged with protecting the safety and well-being of the subjects. All individuals who are subjects in a study must give their informed consent before data are collected. All individual data must be kept confidential. Only statistical summaries for groups of subjects may be made public.     Unit 4: Probability, Random Variables, and Probability Distributions #  Chapters 5 \u0026amp; 6\nProbability #   LAW OF LARGE NUMBERS  A law that states if we observe more and more repetitions of any chance process, the proportion of times a specific outcome occurs approaches its actual probability. We cannot accurately predict outcomes in the SHORT RUN; Order only emerges in the LONG RUN. No such thing as Law of Averages – Only Law of Large Numbers!!!!!   Probibility  The probability of any outcome of a chance process is a number between 0 and 1 that describes the proportion of times the outcome would occur in A VERY LONG SERIES OF REPETITIONS. Outcomes that will never ever occur Probability = 0 Outcomes that will always occur Probability = 1   Simulation  The imitation of chance behavior, based on a model that accurately reflects the situation. The Simulation Process  Describe how to use a chance device to imitate one trial (repetition) of the simulation. Tell what you will record at the end of each trial.  Remember that every label needs to be the same length. In the golden ticket lottery example, the labels should be 01 to 95 (all two digits), not 1 to 95. When sampling without replacement, be sure to mention that repeated numbers should be ignored.   Perform many trials of the simulation. Use the results of your simulation to answer the question of interest. Example      Probability Model: A description of some chance process that consists of 2 parts:  a list of all possible outcomes  SAMPLE SPACE: The list of all possible outcomes.   the probability for each outcome   EVENT Any collection of outcomes from some chance process — A subset of the entire sample space. MUTUALLY EXCLUSIVE Two events A \u0026amp; B are mutually exclusive if they have no outcomes in common and so can never occur together – that is, if P(A and B) = 0. General Rules $$0 ≤ P(A) ≤ 1 \\text{ for any event }A$$ $$P(S) = 1 \\text{ if }S\\text{ is the sample space in a probability model}$$ $$P(A)=\\frac{\\text{Number of outcomes in event } A}{\\text{Total number of outcomes in sample space}}\\text{ in the case of EQUALLY LIKELY outcomes,}$$ $$\\text{Complement Rule: } P(A^c)=1-P(A); \\text{where }A^c=\\text{the event that A does not occur}$$ $$\\text{Addition rule for mutually exclusive events: }P(A \\text{ or } B)=P(A \\cup B) = P(A) + P(B)$$ $$\\text{General addition rule: } P(A \\text{ or } B) =P(A \\cup B)= P(A) + P(B) − P(A \\text{ and } B) $$ $$\\text{Dependent events: } P(A \\text{ and } B) = P(A ∩ B) = P(A) ⋅ P(B | A)$$ $$\\text{Independent events: } P(A \\text{ and } B) = P(A ∩ B) = P(A) ⋅ P(B)$$ $$\\text{Probability of A given B: } P(A|B)=\\frac{P(A \\text{ and } B)}{P(B)} $$ Conditional  CONDITIONAL PROBABILITY  Example  The probability that one event happens given that another event is known to have happened. The conditional probability that event B happens GIVEN that event A has happened is denoted by P(B | A).     INDEPENDENT EVENTS  A and B are independent events if knowing whether or not one event has occurred does not change the probability that the other event will happen.  In other words, events A and B are independent if $$P(A ∣ B) = P(A ∣ B ^c ) = P(A)$$ Alternatively, events A and B are independent if $$P(B ∣ A) = P(B ∣ A^c) = P(B)$$    Random Variables #   DISCRETE RANDOM VARIABLE  A random variable that has a countable number of outcomes with gaps. Examples: ACT Scores; # of Free-Throws Made, etc.   CONTINUOUS RANDOM VARIABLE  A random variable that has an infinite number of outcomes with no gaps. Examples: Temperature; Race Times; Heart Rate, etc.   Mean  Variance  Standard Deviation  Transforming — only works for independent!  When MULTIPLYING (or DIVIDING) each value in a probability distribution by some number b, the ● mean is MULTIPLIED (or DIVIDED) by b ● variance is MULTIPLIED (or DIVIDED) by b^2 ● standard deviation is MULTIPLIED (or DIVIDED) by b When ADDING (or SUBTRACTING) the number a to each value in a probability distribution, the ● mean INCREASES (or DECREASES) by a ● variance STAYS THE SAME ● standard deviation STAYS THE SAME   Combining — only works for independent! Suppose we add two normal distributions (X + Y) or we subtract two normal distributions (X – Y). The shape of the resulting distribution will be NORMAL and the mean and standard deviation can be calculated using the RULES. where \\row (no ^2) is standard deviation Difference between the binomial setting and the geometric setting  Binomial  Binomial Setting:  Binary? Each observation falls into 1 of 2 categories: SUCCESS or FAILURE Independent? The n observations are all INDEPENDENT. (knowing one outcome of a trial has no effect on the other trials)  Note: if sampling w/o replacement, you need to check the 10% condition   Number? There is a fixed number n of TRIALS/OBSERVATIONS. Success? The probability of success, p, is SAME for each trial.   BINOMIAL DISTRIBUTION  If large counts is verified, then the binomial distribution\u0026rsquo;s shape is approximately normal The distribution of the count X of successes in the binomial setting with parameters n and p. n = # of Trials/Observations p = Probability of Success (per Trial) Possible Values for X = whole #s 0 to n Abbreviation = B (n, p)   BINOMIAL COEFFICIENT  The number of ways to arrange k successes among n trials; “Combinations”    Binomial Probability Formula  binomialPdf / Cdf also works      Geometric:  The Geometric Setting  Binary? Each observation falls into 1 of 2 categories: SUCCESS or FAILURE Independent? The n observations are all INDEPENDENT. (knowing one outcome of a trial has no effect on the other trials). Trials? The goal is to count the number of trials until the FIRST SUCCESS Success? The probability of success, p, is SAME for each trial.   Shape  skewed right    GEOMETRIC PROBABILITY FORMULA  geometCdf / Pdf also works        Unit 5: Sampling Distributions #  Chapter 7 + 10\nSampling Distribution: #   The sampling distribution of a statistic is the distribution of values taken by the statistic in all possible samples of the same size from the same population. Always say “the distribution of [blank],” being careful to distinguish the distribution of the population, the distribution of sample data, and the sampling distribution of a statistic. Sampling distribution of the sample proportion  The sampling distribution of the sample proportion p hat describes the distribution of values taken by the sample proportion p hat in all possible samples of the same size from the same population.  Conditions  Random: The data must come from a well-designed RANDOM sample or a RANDOMIZED experiment. Normal: The sampling distribution is approximately NORMAL, meaning we can use a z-test statistic.  Large Counts: (np ≥ 10) \u0026amp; (n (1 − p) ≥ 10 )   Independent:  If 2 samples, both samples must be independent 10% Condition: When sampling w/o replacement to verify the use of our standard deviation ( 10n \u0026lt; N )       Sampling distribution of the sample mean  The sampling distribution of the sample mean x describes the distribution of values taken by the sample mean x in all possible samples of the same size from the same population.  Conditions  Random: The data must come from a well-designed RANDOM sample or a RANDOMIZED experiment. Normal: The sampling distribution is approximately NORMAL, meaning we can use a z-test/t-test statistic.  Either (or both) condition(s) must be met: CLT  n ≥ 30 — n_diff ≥ 30 for paired data The central limit theorem (CLT) says that when n is larger than 30, the sampling distribution of the sample mean x is approximately Normal.   Distribution shouldn\u0026rsquo;t be skewed  values above the median are much more variable than the values below the median      Independent:  If 2 samples, both samples must be independent 10% Condition: When sampling w/o replacement to verify the use of our standard deviation ( 10n \u0026lt; N ) — 10*n_diff \u0026lt; N_diff for paired data       Sampling Variability: Sampling variability refers to the fact that different random samples of the same size from the same population produce different values for a statistic.  Parameter: A number computed from a population Statistic  A number computed from a SAMPLE What makes a statistic a good estimator of a parameter?  LOW BIAS (Randomization) High bias is usually because of a poor sampling design (lack of randomness). LOW VARIABILITY (Sample Size) Reduce the variability of a statistic is to INCREASING SAMPLE SIZE.     Difference between proportions  Difference between means Many students use “accurate” when they really mean “precise.” For example, a response that says “increasing the sample size will make an estimate more accurate” is incorrect   Paired Data #   Paired data result from recording two values of the same Quantitative variable for each individual or for each pair of similar individuals. 2 sets of data that are not independent from each other, then they\u0026rsquo;re paired Analyzing Paired Data: To analyze paired data, start by computing the difference for each pair. Then make a graph of the differences. Use the mean difference x and the standard deviation of the differences as summary statistic.   Confidence Intervals #   Point estimator:  a statistic that provides an estimate of a population parameter. The value of that statistic from a sample is called a point estimate.  Ideally our “best guess” at the value of an unknown parameter. Because the sample mean ¯x is an unbiased estimator of the population mean μ, we use the statistic ¯x as a point estimator ****of the parameter μ. The best guess for the value of μ is ¯x   Unbiased Estimator: A statistic used to estimate a parameter is an unbiased estimator if the mean of its sampling distribution is equal to the value of the parameter being estimated.   Confidence Level α  The confidence level C% gives the overall success rate of the method used to calculate the confidence interval. Interpretation  If we were to select many random samples from a population and construct a C% confidence interval using each sample, about C% of the intervals would capture the [parameter in context].\n    Confidence interval  When interpreting a confidence interval, make sure that you are describing the parameter and not the statistic. Interpretation  “We are C% confident that the interval from [min] to [max] captures the true value of the [parameter in context].”\n    Margin of error  describes how far, at most, we expect the estimate to vary from the true population value. In a C% confidence interval, the distance between the point estimate and the true parameter value will be less than the margin of error in C% of all samples. How to decrease MOE  The confidence level decreases. To obtain a smaller margin of error from the same data, you must be willing to accept less confidence. The sample size n increases. In general, increasing the sample size n reduces the margin of error for any fixed confidence level.   Margin of error accounts for only the variability we expect from random sampling. It does not account for practical difficulties, such as undercoverage and nonresponse in a sample survey   Critical Value  The critical value is a multiplier that makes the interval wide enough to have the stated capture rate. Z-score when we know stdiv t-score when we don\u0026rsquo;t know stdiv   Standard Error (SE)   Proportions #   Four-step process:  State  What parameter do you want to estimate and at what confidence level? 1 proportion  \u0026ldquo;We wish to estimate the true proportion of all [parameter], with [C%] confidence.\u0026rdquo;\n  2 proportions  \u0026ldquo;We wish to estimate the true difference of the proportion of all [parameter 1] and all [parameter 2] for [context], with [C%] confidence.\u0026rdquo;\n    Plan  Identify the appropriate inference method  \u0026ldquo;We\u0026rsquo;ll carry out a [ONE/TWO]-SAMPLE Z INTERVAL FOR A POPULATION PROPORTION (because we\u0026rsquo;re estimating a proportion and we know the standard deviation.)\u0026rdquo;\n  Check conditions   Do  Perform the calculations.   \u0026ldquo;Because the conditions are true, we can do our calculations:\u0026rdquo;   1 proportion  2 proportions  where z* is the critical value for the standard Normal curve with C% of its area between −z* and z*.   Conclude  Interpret your interval in the context of the problem.  We are [C%] confident that the interval of [min] to [max] [units] captures the true proportion of all [context]\n  2 sample difference  If 0 is within confidence interval range:  Because 0 is contained in the [C%] confidence interval it is plausible there is no difference between [parameter 1] and [parameter 2]. We do not have convincing evidence of a difference of proportions of [context]\n  If 0 is NOT within confidence interval range:  Because 0 is not contained in the [C%] confidence interval it is plausible there is a difference between [parameter 1] and [parameter 2]. We have convincing evidence of a difference of proportions of [context]\n         Means #   Four-step process  State  What parameter do you want to estimate and at what confidence level? 1 proportion  We wish to estimate the true mean of all [parameter], with [C%] confidence.\n  2 proportions  We wish to estimate the true difference of the mean of all [parameter 1] and all [parameter 2] for [context], with [C%] confidence.\n    Plan  Identify the appropriate inference method  If we know stdiv  We\u0026rsquo;ll carry out a [ONE/TWO]-SAMPLE Z INTERVAL FOR A POPULATION MEAN(because we know the standard deviation.)\n  If we don\u0026rsquo;t know stdiv  We\u0026rsquo;ll carry out a [ONE/TWO]-SAMPLE Z INTERVAL FOR A POPULATION MEAN(because and we don\u0026rsquo;t know the standard deviation.)\n    Check conditions   Do  Perform the calculations. z-score  Because we know conditions are true, can do our calculations   1 mean  2 means with z* score and \\row   t-score  Because we know conditions are true, we can say that the t-distribution\u0026rsquo;s degree of freedom (df) is df = n - 1 and we\u0026rsquo;ll carry out a [one/two]-sample t interval for a population mean   1 mean  2 means  Difference      Conclude  Interpret your interval in the context of the problem.  We are [C%] confident that the interval of [min] to [max] [units] captures the true mean of all [context]\n  2 sample difference  If 0 is within confidence interval range:  Because 0 is contained in the [C%] confidence interval it is plausible there is no difference between [parameter 1] and [parameter 2]. We do not have convincing evidence of a difference between means of [context]\n  If 0 is NOT within confidence interval range:  Because 0 is not contained in the [C%] confidence interval it is plausible there is a difference between [parameter 1] and [parameter 2]. We have convincing evidence of a difference between means of [context]\n        t-scores  A t-distribution is specified by its degrees of freedom (df) calculated df = n - 1 The spread of the t-distribution is MORE than that of a standard Normal distribution. The t-distribution has MORE probability in the tails than the standard Normal distribution, since substituting the estimate sx for the parameter σ introduces MORE variation into the statistic. As degrees of freedom increases, the t-distribution becomes CLOSER to the standard Normal distribution, since sx estimates MORE accurately when the sample size is large.    Choosing sample size #   Sometimes, we want to choose our sample size (n) so that we may estimate a proportion within a particular margin of error. We must choose our sample size before we start sampling.  Conservative Approach: Use p .5 , because it maximizes the margin of error. Better Approach if Possible: Make a guess about the value of p based on prior knowledge, common knowledge, previous studies, etc. $$Z^*\\sqrt{\\frac{p(1-p)}{n}} \\leq ME, \\text{and solve for n}$$   Sample Size for a Desired Margin of Error when Estimating μ  To determine the sample size n that will yield a C% confidence interval for a population mean with a specified margin of error ME:  Get a reasonable value for the population standard deviation σ from an earlier or pilot study. Find the critical value z* from a standard Normal curve for confidence level C%. Set the expression for the margin of error to be less than or equal to ME and solve for n:       Tests #  Shared Vocab #   Significance Test  A formal procedure for comparing OBSERVED DATA with a CLAIM whose truth we want to assess.   Null hypothesis — H0  A test is designed to assess the strength of the evidence AGAINST this. This hypothesis is often the statement of “no difference.”   Alternative hypothesis — Ha  The claim about the population we are trying to find evidence FOR. This hypothesis should always be created BEFORE seeing the data. One sided  less than or greater than   Two sided  not equal     Both Null \u0026amp; Alternative Hypotheses refer to a POPULATION and use PARAMETERS (μ \u0026amp; p) p-value  Assuming H0 is true, the probability the statistic (such as p^hat or x^bar) would take a value as extreme or more extreme than the one actually observed. The smaller the p-value, the STRONGER the evidence is AGAINST the H0 Interpretation  \u0026ldquo;Assuming H0 is true, there is a [P-val] probability of getting the [sample val] [or even smaller/larger] by random chance with a sample size of [n]\u0026rdquo;\n    significance level  The level at which that, when our p-value falls below it, we consider it to be SIGNIFICANT We consider that our sample is so unlikely to happen IF H0 is true, that it likely did NOT happen by chance   error + power  Type 1:  When H0 is true, but we REJECT H0 P(Type I) = confidence level α   Type 2:  When Ha is true, but we FAIL TO REJECT H0 P(Type II) = 1 - Power   Power  The ability of a test to correctly detect the alternative when it\u0026rsquo;s true.  When Ha is true, and we CORRECTLY REJECT H0   Interpretation  \u0026ldquo;Given Ha is true (in context), there is a (power) probability we correctly rejecting H0 (finding convincing evidence for Ha)\n  Power = 1 – P(Type II Error) How to increase  INCREASE the sample size (n), INCREASE the Confidence Level (α), or Make Ha further away from H0     STANDARDIZED TEST STATISTIC  A standardized test statistic measures how far a sample statistic is from what we would expect if the null hypothesis H0 were true, in standard deviation units.       Proportions #   Four-step process  State  State your Hypotheses: H[relation] = [p/µ] interpret values — 1 proportion  where p is the true proportion of [context] and Significance Level (alpha)\n  interpret values — 2 proportion  where p is the true difference between the proportions of [parameter 1] and [parameter 2] of [context] and Significance Level (alpha)\n    Plan  Identify the appropriate testing method  We\u0026rsquo;ll carry out a [ONE/TWO]-SAMPLE Z TEST FOR A POPULATION PROPORTION (because we\u0026rsquo;re estimating a proportion and we know the standard deviation)\n  Check conditions   Do  Perform the calculations.  Because we know conditions are true, can do our calculations   1 sample  2 sample Proportion Difference find p-value   Conclude  Interpret your p-value in the context of the problem.  P-value less than  Assuming the [H0] is true, there is a [p-value] probability of getting [statistic found] or [more [and/neither] less — more for H0 \u0026lt; Ha; less for Ha \u0026lt; H0; both for H0 ≠ Ha] in a sample of [sample size] purely by chance. Because [p-value] is less than [alpha] of [confidence level], we have evidence to reject the null hypothesis, and have some evidence that the null hypothesis may be true, meaning [context]\n  P-value greater than  Assuming the [H0] is true, there is a [p-value] probability of getting [statistic found] or [more [and/neither] less — more for H0 \u0026lt; Ha; less for Ha \u0026lt; H0; both for H0 ≠ Ha] in a sample of [sample size] purely by chance. Because [p-value] is greater than [alpha] of [confidence level], we do not have enough evidence to reject the null hypothesis, meaning [context]          Means #   Four-step process  State  State your Hypotheses: H[relation] = [p/µ] interpret values — 1 proportion  where p is the true mean of [context] and Significance Level (α)\n  interpret values — 2 proportion  where p is the true difference between the means of [parameter 1] and [parameter 2] of [context] and Significance Level (α)\n    Plan  Identify the appropriate testing method  We\u0026rsquo;ll carry out a [[ONE/TWO]-SAMPLE]/MATCHED PAIRS] T TEST FOR A POPULATION MEAN\n  Check conditions   Do  Perform the calculations.  Because we know conditions are true, can do our calculations with (n-1) degrees of freedom   1 sample  2 sample Mean Difference Paired Paired find P-value   Conclude  Interpret your p-value in the context of the problem.  P-value less than  Assuming the parameter is true, there is a [p-value] probability of getting [statistic found] or more/less in a sample of [sample size] purely by chance. Because [p-value] is less than [alpha] of [confidence level], we have evidence to reject the null hypothesis, and have some evidence that the null hypothesis may be true, meaning [context]\n  P-value greater than  Assuming the parameter is true, there is a [p-value] probability of getting [statistic found] or more/less in a sample of [sample size] purely by chance. Because [p-value] is greater than [alpha] of [confidence level], we do not have enough evidence to reject the null hypothesis, meaning [context]\n         "}]