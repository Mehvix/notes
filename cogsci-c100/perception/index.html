<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Definition of sensation and perception #   As humans, we are cognitive beings who&mldr;  Acquire information about the world around us (perception) Integrate that information with prior knowledge from our stored memory Store that knowledge in our memory so we can use it later to help us achieve our goals   First step in this process of acquiring knowledge about the world involves sensation and perception  Sensation: process by which our sensory receptors and nervous system receive stimulus energies from the environment and transduce them into neural impulses (transduction)."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="Perception"><meta property="og:description" content="Definition of sensation and perception #   As humans, we are cognitive beings who&mldr;  Acquire information about the world around us (perception) Integrate that information with prior knowledge from our stored memory Store that knowledge in our memory so we can use it later to help us achieve our goals   First step in this process of acquiring knowledge about the world involves sensation and perception  Sensation: process by which our sensory receptors and nervous system receive stimulus energies from the environment and transduce them into neural impulses (transduction)."><meta property="og:type" content="article"><meta property="og:url" content="http://notes.mehvix.com/cogsci-c100/perception/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2022-03-04T00:21:26-08:00"><title>Perception | notes.mehvix.com</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.89a77f7e702a8626749b948bbfb01109823daf6c1246ca407d1378833494c402.css integrity="sha256-iad/fnAqhiZ0m5SLv7ARCYI9r2wSRspAfRN4gzSUxAI=" crossorigin=anonymous><script defer src=/flexsearch.min.js></script>
<script defer src=/en.search.min.8f4aaeb02c9f2d788b552eb377e1c25355d744990b594dc9559353fc2364d113.js integrity="sha256-j0qusCyfLXiLVS6zd+HCU1XXRJkLWU3JVZNT/CNk0RM=" crossorigin=anonymous></script>
<script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script>
<link rel=icon href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>📓</text></svg>"><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>MathJax={tex:{inlineMath:[["$","$"],[".$","$"]],processEscapes:!0,processEnvironments:!0,macros:{bigsup:["#1{^{\\vbox{\\hbox{$\\scriptstyle#1$}\\nointerlineskip\\hbox{}}}}",1]}},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script id=MathJax-script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.min.js?config=TeX-AMS_CHTML" integrity="sha512-9DkJEmXbL/Tdj8b1SxJ4H2p3RCAXKsu8RqbznEjhFYw0cFIWlII+PnGDU2FX3keyE9Ev6eFaDPyEAyAL2cEX0Q==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:".$",right:"$",display:!1},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><link rel=stylesheet href=http://notes.mehvix.com/css/custom_styling.css></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>notes.mehvix.com</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-254493c648c1f0be4cf9348c45ddbe37 class=toggle checked>
<label for=section-254493c648c1f0be4cf9348c45ddbe37 class="flex justify-between"><a role=button>CogSci C100</a></label><ul><li><a href=http://notes.mehvix.com/cogsci-c100/intro/>Introduction</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/perception/ class=active>Perception</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/non-visual/>Non-Visual Perception</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/attention/>Attention</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/sleep/>Sleep & Dreams</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/consciousness/>Consciousness</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/mindfulness/>Mindfulness</a></li><li><a href=http://notes.mehvix.com/cogsci-c100/memory/>Memory</a></li></ul></li><li><input type=checkbox id=section-20c391324c82ffdef893b60d754b7005 class=toggle>
<label for=section-20c391324c82ffdef893b60d754b7005 class="flex justify-between"><a role=button>EECS 16A</a></label><ul><li><a href=http://notes.mehvix.com/eecs-16a/0/>Week 0: System Design & Linear Equations</a></li><li><a href=http://notes.mehvix.com/eecs-16a/1/>Week 1: Gaussian Elim. & Matrices + Vectors</a></li><li><a href=http://notes.mehvix.com/eecs-16a/2/>Week 2: (In)dependence & Circuit Analysis</a></li><li><a href=http://notes.mehvix.com/eecs-16a/3/>Week 3: Transformations & Inverse</a></li><li><a href=http://notes.mehvix.com/eecs-16a/4/>Week 4: Vector Spaces & Eigenstuff</a></li><li><a href=http://notes.mehvix.com/eecs-16a/5/>Week 5: Basis & Circuit Analysis</a></li><li><a href=http://notes.mehvix.com/eecs-16a/6/>Week 6: Voltage Dividers & Measurement</a></li><li><a href=http://notes.mehvix.com/eecs-16a/7/>Week 7: 2D Touchscreens & Superposition + Equivalence</a></li></ul></li><li><input type=checkbox id=section-7571d6f544c6ffc847948b0f74d82ef1 class=toggle>
<label for=section-7571d6f544c6ffc847948b0f74d82ef1 class="flex justify-between"><a role=button>Engineering 29</a></label><ul><li><a href=http://notes.mehvix.com/e-29/0/>Week 0: Intro & Tolerancing</a></li><li><a href=http://notes.mehvix.com/e-29/1/>Week 1: Fundamentals of Graphical Communication & Subtractive Processes</a></li><li><a href=http://notes.mehvix.com/e-29/2/>Week 2: Cutting-based Processes & Other Subtractive Processes</a></li><li><a href=http://notes.mehvix.com/e-29/3/>Week 3: Additive Processes: Intro & Extrusion</a></li><li><a href=http://notes.mehvix.com/e-29/4/>Week 4: Additive Processes: Light-based, etc.</a></li><li><a href=http://notes.mehvix.com/e-29/5/>Weeks 5 & 6: Forming Processes</a></li><li><a href=http://notes.mehvix.com/e-29/6/>Weeks 6 & 7: Joining processes</a></li><li><a href=http://notes.mehvix.com/e-29/7/>Week 7-8: Visualization</a></li></ul></li><li><input type=checkbox id=section-32aba3efd274a559b3dccd4e800c9d4b class=toggle>
<label for=section-32aba3efd274a559b3dccd4e800c9d4b class="flex justify-between"><a href=http://notes.mehvix.com/docs/math-53/>Math 53</a></label><ul><li><a href=http://notes.mehvix.com/math-53/10/>10: Parametric Equations and Polar Coordinates</a></li><li><a href=http://notes.mehvix.com/math-53/12/>12: Vectors & Geometry of Space</a></li><li><a href=http://notes.mehvix.com/math-53/13/>13: Vector Functions</a></li><li><a href=http://notes.mehvix.com/math-53/14/>14: Partial Derivatives</a></li><li><a href=http://notes.mehvix.com/math-53/15/>15: Multiple Integrals</a></li><li><a href=http://notes.mehvix.com/math-53/16/>16: Vector Calculus</a></li><li><a href=http://notes.mehvix.com/math-53/trig/>Trig Identities</a></li><li><a href=http://notes.mehvix.com/math-53/trig-calc/>Trig Calculus</a></li></ul></li><li><input type=checkbox id=section-98c46cabf82aecebcca8f97f2965f738 class=toggle>
<label for=section-98c46cabf82aecebcca8f97f2965f738 class="flex justify-between"><a href=http://notes.mehvix.com/docs/physics-7b/>Physics 7B</a></label><ul><li><a href=http://notes.mehvix.com/physics-7b/17/>17: Temperature, Thermal Expansion, & Ideal Gas Law</a></li><li><a href=http://notes.mehvix.com/physics-7b/18/>18: Kinetic Theory of Gases</a></li><li><a href=http://notes.mehvix.com/physics-7b/19/>19: Heat & First Law of Thermo</a></li><li><a href=http://notes.mehvix.com/physics-7b/20/>20: Second Law of Thermo</a></li><li><a href=http://notes.mehvix.com/physics-7b/21/>21: Electric Charges & Fields</a></li><li><a href=http://notes.mehvix.com/physics-7b/22/>22: Flux & Gauss's Law</a></li><li><a href=http://notes.mehvix.com/physics-7b/23/>23: Electric Potential</a></li><li><a href=http://notes.mehvix.com/physics-7b/24/>24: Capacitance, Dielectrics, Electric Energy Storage</a></li><li><a href=http://notes.mehvix.com/physics-7b/25/>25: Electric Current and Resistance</a></li><li><a href=http://notes.mehvix.com/physics-7b/26/>26: DC Circuits</a></li><li><a href=http://notes.mehvix.com/physics-7b/27/>27: Magnetism</a></li><li><a href=http://notes.mehvix.com/physics-7b/28/>28: Sources of Magnetic Field</a></li><li><a href=http://notes.mehvix.com/physics-7b/29/>29: Electromagnetic Induction & Faraday's Law</a></li><li><a href=http://notes.mehvix.com/physics-7b/30/>30: Inductance, Electromagnetic Oscillations, & AC Circuits</a></li></ul></li><li><a href=http://notes.mehvix.com/asamst-20a/>ASAMST 20A</a></li><li><input type=checkbox id=section-a18e6d23bfa638ffa382e954bd79207f class=toggle>
<label for=section-a18e6d23bfa638ffa382e954bd79207f class="flex justify-between"><a role=button>AP Notes</a></label><ul><li><a href=http://notes.mehvix.com/ap/huge/>AP Human Geography</a></li><li><a href=http://notes.mehvix.com/ap/cmech/>AP Physics C: Mechanics</a></li><li><a href=http://notes.mehvix.com/ap/stats/>AP Statistics</a></li></ul></li></ul><ul><li><a href=https://cs61a.rouxl.es/ target=_blank rel=noopener>CS61A (Anto's)</a></li><li><a href=# target=_blank rel=noopener>—</a></li><li><a href=https://www.mehvix.com target=_blank rel=noopener>w³.mehvix.com</a></li><li><a href=https://pass.mehvix.com target=_blank rel=noopener>pass.mehvix.com</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Perception</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#definition-of-sensation-and-perception>Definition of sensation and perception</a></li><li><a href=#early-models-of-object-perception>Early models of object perception</a><ul><li><a href=#template-matching-model>Template matching model</a></li><li><a href=#feature-analysis-model>Feature analysis model</a></li><li><a href=#recognition-by-components-model>Recognition-by-components model</a></li><li><a href=#david-marrs-model-of-visual-processing>David Marr’s Model of Visual Processing</a></li><li><a href=#prototype-model>Prototype model</a></li><li><a href=#alternative-modes-of-perception>Alternative modes of perception</a></li><li><a href=#neural-networks>Neural Networks</a><ul><li><a href=#ex-how-might-a-computer-recognize-a-9-using-neural-networks>Ex: How might a computer recognize a “9” using neural networks?</a></li><li><a href=#learning-in-neural-nets-backpropagation>Learning in Neural Nets: Backpropagation</a></li><li><a href=#other-neural-networks-qa>Other Neural Networks Q&A</a></li></ul></li></ul></li><li><a href=#top-down-processing-in-object-recognition>Top-down processing in object recognition</a><ul><li><a href=#objective-reality-is-often-not-as-objective-as-we-think>“Objective reality” is often not as objective as we think&mldr;</a></li><li><a href=#effects-of-expectations-experience-emotional-patterns-and-beliefs-on-perception>Effects of expectations, experience, emotional patterns, and beliefs on perception</a></li><li><a href=#self-fulfilling-prophecies>Self-fulfilling prophecies</a></li><li><a href=#perceptual-constancies>Perceptual Constancies</a></li><li><a href=#effects-of-color-in-marketing>Effects of color in marketing</a></li></ul></li><li><a href=#neurological-disorders-of-visual-perception>Neurological disorders of visual perception</a><ul><li><a href=#face-perception-and-prosopagnosia>Face perception and prosopagnosia</a></li><li><a href=#modular-processing>Modular Processing</a></li><li><a href=#other-neurological-disorders-related-to-visual-perception>Other Neurological Disorders Related to Visual Perception</a></li><li><a href=#two-pathways-of-visual-perception>Two pathways of visual perception</a></li></ul></li><li><a href=#development-of-perception>Development of perception</a></li></ul></nav></aside></header><article class=markdown><h1 id=definition-of-sensation-and-perception>Definition of sensation and perception
<a class=anchor href=#definition-of-sensation-and-perception>#</a></h1><ul><li>As humans, we are cognitive beings who&mldr;<ul><li><strong>Acquire</strong> information about the world around us (perception)</li><li><strong>Integrate</strong> that information with prior knowledge from our stored memory</li><li><strong>Store</strong> that knowledge in our memory so we can use it later to help us achieve our goals</li></ul></li><li>First step in this process of acquiring knowledge about the world involves sensation and perception<ul><li><strong>Sensation:</strong> process by which our sensory receptors and nervous system receive stimulus energies from the environment and transduce them into <strong>neural impulses</strong> (transduction). The inherent stimuli. Objective</li><li><strong>Perception:</strong> process of <em>interpreting</em> and <em>organizing</em> sensory information through use of previous knowledge. What gives stimuli meaning. Subjective.</li></ul></li></ul><h1 id=early-models-of-object-perception>Early models of object perception
<a class=anchor href=#early-models-of-object-perception>#</a></h1><ul><li>Lots of machines are built on these old theories</li><li>The models aren&rsquo;t respected nowadays, but had useful tid-bits of information (for cogsci, ML, etc)</li></ul><h2 id=template-matching-model>Template matching model
<a class=anchor href=#template-matching-model>#</a></h2><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li><strong>Template matching model:</strong> object perception involves a comparison of the stimulus with set of templates or specific patterns stored in memory</li><li>Static, unchanging</li><li><em>Problem:</em> cannot account for complexity and flexibility of object recognition<ul><li>e.g. individual differences in handwriting</li></ul></li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/template.png alt=Template></div></div><h2 id=feature-analysis-model>Feature analysis model
<a class=anchor href=#feature-analysis-model>#</a></h2><ul><li>Feature-analysis model: discrimination of objects is based on <em>small number of distinct characteristics</em> of stimuli<ul><li>Are these two the same letter?: <code>G M</code> <code>P R</code><ul><li>People are faster at deciding whether <code>G</code> and <code>M</code> are different than <code>P</code> and <code>R</code> because there are fewer similarities</li></ul></li><li>Supported by neurological evidence: some neurons respond only to horizontal lines, others to diagonals, etc.</li></ul></li><li><em>Problem:</em> Cannot explain recognition of complex objects with features that move and distort (e.g., horse or kangaroo)
<img src=/docs/cogsci-c100/perception/roo.png alt></li></ul><h2 id=recognition-by-components-model>Recognition-by-components model
<a class=anchor href=#recognition-by-components-model>#</a></h2><p><img src=/docs/cogsci-c100/perception/geons.png alt><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li><strong>Recognition-by-components model:</strong> view that an object is represented as an arrangement of simple 3-D shapes called
<a href=https://en.wikipedia.org/wiki/Geon_%28psychology%29><em>geons</em></a></li><li>Six main geons above</li></ul><blockquote><p><img src=/docs/cogsci-c100/perception/cup.png alt>
Cup/pail composed of cylinder and curved tube geons in a particular arrangement</p></blockquote></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/rbc-ex.png alt></p><blockquote><p>Easier to tell the object from the rightmost column versus the center, despite the latter containing more lines</p></blockquote></div></div></p><h2 id=david-marrs-model-of-visual-processing>David Marr’s Model of Visual Processing
<a class=anchor href=#david-marrs-model-of-visual-processing>#</a></h2><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><blockquote><p>Not on Exam</p></blockquote><ul><li>The image is then transformed into a 3-D sketch in which the the axes of symmetry and elongation link the object parts<ul><li><strong>Symmetry axis:</strong> line that divides an object into mirror image halves</li><li><strong>Elongation axis:</strong> line defining direction along which main bulk or mass of a shape is distributed</li></ul></li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/marr.gif alt></div></div><ul><li>The 3-D sketch is object-centered – the object’s parts are described relative to one another and are linked on the basis of shared properties and axes<ul><li>This solves the object constancy problem, allowing recognition of an object presented in different orientations and under different conditions, e.g., lighting changes</li></ul></li></ul><h2 id=prototype-model>Prototype model
<a class=anchor href=#prototype-model>#</a></h2><ul><li><strong>Prototype model:</strong> object perception involves a comparison of the stimulus with ideal, abstract example<ul><li>People are faster at identifying sparrow as a bird than penguin</li></ul></li><li>One of the most famous models in all of cognitive psychology (and developed at Berkeley!)</li><li>It has been hypothesized that our sensory systems act primarily as a <strong>selective filtering mechanism</strong><ul><li>Prototypes more easily pass this filter</li><li>This filter sorts things according to a limited number of variables (e.g., warm, unpleasant, green) out of which we construct our world</li><li>But prototype theory suggests that our minds can also perceive objects in a very different way&mldr;</li></ul><blockquote><p><em>That which is essential is invisible to the eye.</em> – de Saint-Exupery</p></blockquote></li></ul><h2 id=alternative-modes-of-perception>Alternative modes of perception
<a class=anchor href=#alternative-modes-of-perception>#</a></h2><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li><strong>Alternative modes of perception:</strong> Mindfulness is largely about seeing the “suchness” of things, that is, seeing things directly without conceptual filters</li><li>What assumptions might you make about this woman if you were told she is from New England? from California?<ul><li>Our preconceived notions prevent us from seeing the real person in front of us</li><li>Stereotyping</li></ul></li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/women.png alt></div></div><blockquote><p><em>If the doors of perception were cleansed, everything would appear to man as it is, infinite.</em><br></p><p><em>To see a World in a Grain of Sand,</em><br><em>And a Heaven in a Wildflower,</em><br><em>Hold Infinity in the palm of your hand,</em><br><em>And Eternity in an hour.</em> &ndash; Blake</p></blockquote><h2 id=neural-networks>Neural Networks
<a class=anchor href=#neural-networks>#</a></h2><blockquote><p>On Quiz 2!</p></blockquote><ul><li>Artificial Neural Networks in Pattern Recognition</li><li>Human neurons<div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/syn.png alt></div><div class="flex-even markdown-inner"><ul><li>Many different neurons connect to the dendrites of each neuron<ul><li>Some produce excitatory effect; others produce inhibitory effect</li><li>There are also different levels of intensity of these effects</li></ul></li><li>Around a thousand connections are connected to each neurons<ul><li>If the activation of the neuron reaches a certain minimum threshold, the neuron will fire</li></ul></li></ul></div></div></li></ul><details><summary>16A Notes</summary><div class=markdown-inner><blockquote><p>Because circuit analysis translates to a wide range of fields, we can model many physical systems as electrical circuits, often gaining insight about the system. You may have heard of neural networks, an important machine learning tool that can be used to “learn” tasks such as image and voice recognition from examples instead of explicit programming. Neural networks are modeled after biological neural networks, which are fundamentally circuits operating on electrical signals within a brain:</p><figure><img src=/docs/cogsci-c100/perception/16A.png></blockquote></figure><blockquote><p>In a general sense, studying circuits provides you with the conceptual and mathematical tools needed to analyze such networks. More broadly, circuit concepts are relevant to understanding network analysis and signal flows in systems, which can be applied to areas ranging from transportation analysis to social network analysis. (
<a href=https://eecs16a.org/lecture/Note0.pdf>from EECS16A Note0</a>)</p></blockquote></div></details><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>Artificial neural networks (ANN)<ul><li>The nodes or neurons are organized into layers in much the same way that human neural networks are</li><li>The <strong>weights</strong> attached to the connections between pairs of units in adjacent layers determine the overall behavior of the network<ul><li>This is similar to the way in which <em>excitatory</em> and <em>inhibitory</em> neurons of various strengths connect to a particular neuron in human neural networks</li></ul></li><li>The <strong>bias term</strong> indicates what the weighted sum needs to be before the node/neuron will activate<ul><li>This is similar to the threshold necessary for activation of a neuron in human neural networks</li></ul></li></ul></li></ul></div><div class="flex-even markdown-inner"><blockquote><p><img src=/docs/cogsci-c100/perception/AANw.png alt>
An artificial neural network is an interconnected group of nodes, inspired by a simplification of neurons in a brain. Here, each circular node represents an
<a href=https://en.wikipedia.org/wiki/Artificial_neuron>artificial neuron</a> and an arrow represents a connection from the output of one artificial neuron to the input of another.</p></blockquote></div></div><h3 id=ex-how-might-a-computer-recognize-a-9-using-neural-networks>Ex: How might a computer recognize a “9” using neural networks?
<a class=anchor href=#ex-how-might-a-computer-recognize-a-9-using-neural-networks>#</a></h3><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/aircAruvnKk style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><ul><li>There is huge variety of ways in which people write 9’s</li><li>To simplify things, we can represent the “9” by decomposing it to a grid of 28 x 28 pixels of varying shades of gray (between 0 and 1)</li></ul><ol><li>First (input) layer of network<div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>Starts with bunch of neurons or nodes corresponding to an array of 28 x 28 pixels in the image</li><li>Each node holds a number that represents the grayscale value of the corresponding pixel, ranging from 0 for black to 1 for white</li><li>This is the neuron’s activation level</li><li>Activations in one layer bring about activations in the next layer, which in turn bring about activations in the next layer&mldr;</li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/s1.png alt></div></div><ul><li>This is loosely analogous to how, in biological networks of neuron, some groups of neurons cause other neurons to fire</li></ul></li><li>Second layer (or first “hidden layer”)<ul><li>Each neuron in the second layer might pick up on whether there is an edge in one particular region</li><li>You assign a weight to each one of the connections between a particular neuron in the second layer and the neurons in the first layer</li><li>Then you take all the activations from the first layer and compute their weighted sum according to the weights<div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>Could make the weights associated with almost all of the pixels 0 except for some positive weights in target region</li><li>To really pick up on whether there is an edge here, could also have some negative weights associated with the surrounding pixels<ul><li>Sum is largest when those middle pixels are bright but surrounding pixels are darker</li></ul></li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/s2.png alt></div></div><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>But maybe you don’t want the neuron to light up anytime the sum is bigger than zero &ndash; maybe you only want it to be active when the sum is bigger than say 10</li><li>So you add in some other number (the bias), like -10, to the weighted sum<ul><li>The bias tells you how high the weighted sum needs to be before the neuron starts getting meaningfully active</li></ul></li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/s3.png alt></div></div></li><li>The connections between the other layers also have weights and biases associated with them</li></ul></li><li>Third layer (or second “hidden layer”)<ul><li>When we recognize digits, we piece together various components<ul><li>e.x: A “9” has a loop near the top and a line on the right whereas an “8” has a loop on the top and one below<div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>Each neuron in the third layer corresponds to one of these subcomponents<ul><li>e.x: A particular neuron in the third layer might be activated by any generally loopy pattern toward the top</li></ul></li><li>These subcomponents are made up of the various edges from the second layer</li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/s4.png alt></div></div></li></ul></li></ul></li><li>Last (output) layer<div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>Has 10 neurons, each representing one of the digits</li><li>The activation in these neurons – some number between 0 and 1 – represents how much the system thinks a given image corresponds with a given digit</li><li>Learning is about getting the computer to find a setting for all of the different weights and biases so that it will actually solve the problem at hand<ul><li>This is done through
<a href=https://en.wikipedia.org/wiki/Backpropagation><strong>backpropagation</strong></a></li></ul></li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/s5.png alt></div></div></li></ol><h3 id=learning-in-neural-nets-backpropagation>Learning in Neural Nets: Backpropagation
<a class=anchor href=#learning-in-neural-nets-backpropagation>#</a></h3><ul><li>ANNs can compute any function that can be computed by a digital computer<ul><li>However, it was not until the emergence of backpropagation learning algorithm that it became possible to train multilayer neural networks</li></ul></li><li>The strength or weight of the connections between neurons in adjacent layers varies: neural networks learn by modifying these weights<ul><li>Learning algorithms that are programmed into the ANN change the weights of the connections between pairs of neurons in adjacent layers in order to reduce the “mistakes” that the network makes</li><li>The basic idea is that each hidden unit connected to an output unit bears a degree of “responsibility” for the error of that output unit</li><li>If the activation level of an output unit is too low, then the weight between the output unit and each hidden unit connected to it is increased to decrease the error</li><li>The network then assigns error levels to the next layer of hidden units, so the error is propagated back down through the network until the input layer is reached</li></ul></li><li><strong>tl;dr:</strong> neural networks have to &rsquo;learn&rsquo; by adjusting stimuli weights. When a network gets an answer wrong, it has to recursively pop back each layer and adjust the corresponding weights (increasing correct value weights, decreasing activated incorrect value weights)</li></ul><h3 id=other-neural-networks-qa>Other Neural Networks Q&A
<a class=anchor href=#other-neural-networks-qa>#</a></h3><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><p><strong>Q:</strong> How many neurons should there be in each hidden layer?<br><strong>A:</strong> There are a number of empirically-derived rules-of-thumb. Of these, the most commonly relied on is “the optimal size of the hidden layer is usually between the size of the input and size of the output layers”</div><div class="flex-even markdown-inner"><p><strong>Q:</strong> How many hidden layers are needed? Are more layers better?<br><strong>A:</strong> No. Situations in which performance improves with additional hidden layers are very few. One hidden layer is sufficient most of the time.</div><div class="flex-even markdown-inner"><p><strong>Q:</strong> Why are more hidden layers not necessarily better?<br><strong>A:</strong> Increasing the number of hidden layers much more than the sufficient number will cause the network to <strong>overfit</strong> the training set. It will learn the training data, but it won’t be able to generalize to new unseen data.</div></div><blockquote><p>Overfit Dataset:<figure><img src=/docs/cogsci-c100/perception/fits.png></figure></p></blockquote><h1 id=top-down-processing-in-object-recognition>Top-down processing in object recognition
<a class=anchor href=#top-down-processing-in-object-recognition>#</a></h1><ul><li>Limitations of models of object perception discussed above: assumes, in theory, perception is <em>objective</em> and <em>accurate</em>; in real life, that is often not the case&mldr;<ul><li>What we perceive, the way we perceive, is not always what would be predicted by these models</li><li>Our <strong>concepts, expectations, and beliefs</strong> play a much bigger role in perception than we usually realize</li></ul></li><li>Perception engages both top-down and bottom-up processing<ul><li><strong>Bottom-up processing:</strong> analysis of information coming from stimuli through sensory receptors<ul><li>Object perception as combination of stimulus information from sensory receptors</li><li>Emphasizes the importance of information coming from the outside world</li></ul></li><li><strong>Top-down processing:</strong> information processing guided by higher-level processes, such as our beliefs, expectations, and memories<ul><li>Our knowledge, beliefs about the world inform our perceptions</li><li>Emphasizes the importance of information coming from our minds</li></ul></li><li>Note: we use both throughout everyday situations, rarely exclusively either or<ul><li>Models can almost be sort of categorized/grouped by which of the two processing model they put emphasis on</li></ul></li><li>E.x. you see a water bottle on your desk<ul><li>You know it&rsquo;s a water bottle since it&rsquo;s physically there. You can see, and perhaps touch it</li><li>You know it&rsquo;s a water bottle because of it&rsquo;s features which have meaning to you through living in the modern world (perhaps owning a water bottle yourself!)<ul><li>If you were an alien, or a homosapien from a very long time ago, you wouldn&rsquo;t know that the object was a water bottle (among other things&mldr;)</li></ul></li></ul></li></ul></li></ul><details><summary>Optional: Deductive versus Inductive Reasoning</summary><div class=markdown-inner><ol><li><strong>Deductive reasoning</strong> works from the more general to the more specific, i.e., “top-down” approach.<ul><li>In deductive reasoning there is usually a first premise, then a second premise (both of which are proven through observations), and finally an inference.</li><li>Ex: All men are mortal. Smerdley is a man. Therefore, Smerdley is mortal.</li></ul></li><li>Inductive reasoning works the other way, moving from specific observations to broader generalizations and theories, i.e., “bottom-up” approach<ul><li>Inductive reasoning extracts a likely (but not certain) premise from specific and limited observations.</li><li>Ex: I have a bag of many coins, and I’ve pulled 10 at random and they’ve all been pennies, therefore this is probably a bag full of pennies.</li></ul></li></ol></div></details><h2 id=objective-reality-is-often-not-as-objective-as-we-think>“Objective reality” is often not as objective as we think&mldr;
<a class=anchor href=#objective-reality-is-often-not-as-objective-as-we-think>#</a></h2><blockquote><p><em>A fool sees not the same tree that a wise man sees.</em> &mdash; William Blake</p></blockquote><ul><li><p>Reversible figures (e.g., Necker cube; vase/profiles)</p></li><li><p>Ambiguous figures (e.g., old woman/young woman &ndash; also old people tend to see the old figure first, and vis-versa)</p><blockquote><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/beans.png alt>
<img src=/docs/cogsci-c100/perception/young-old.png alt></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/rubin.png alt>
<img src=/docs/cogsci-c100/perception/necker.png alt></div></div></blockquote><blockquote><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>Effect of expectations on perception<ul><li>Perceptual set brain teasers: SOAK FOLK CROAK</li><li>Context effects (e.g. bea(r|n),
<a href=https://www.independent.co.uk/news/science/presidential-optical-illusion-offers-clues-to-how-brain-processes-faces-a191716.html>Presidential illusion</a>)</li></ul></li></ul><h2 id=docscogsci-c100perceptionmonsterpng><img src=/docs/cogsci-c100/perception/monster.png alt>
<a class=anchor href=#docscogsci-c100perceptionmonsterpng>#</a></h2></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/prez.jpg alt>
<img src=/docs/cogsci-c100/perception/doggy.png alt></div></div></blockquote></li></ul><h2 id=effects-of-expectations-experience-emotional-patterns-and-beliefs-on-perception>Effects of expectations, experience, emotional patterns, and beliefs on perception
<a class=anchor href=#effects-of-expectations-experience-emotional-patterns-and-beliefs-on-perception>#</a></h2><ul><li>Effects of Prior Experience on Perception<ul><li>Children who have been physically abused are significantly more likely to misperceive a fearful face as angry (Pollak)<blockquote><p><img src=/docs/cogsci-c100/perception/fear.png alt></p></blockquote></li></ul></li><li>Cultural effects on perception<ul><li>What is above the woman’s head?</li><li>Is this an indoor or outdoor scene? (Gregory and Gombrich, 1973)<blockquote><p><img src=/docs/cogsci-c100/perception/outside.png alt></p></blockquote></li></ul></li><li>Rorscharch and Thematic Apperception Test (TAT)<blockquote><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/woman.png alt></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/ink.png alt></div></div></blockquote><ul><li>When angry, people more often perceive neutral objects as guns (Baumann & DeSteno, 2010)</li><li>Effect of beliefs/preconceived notions on perception<ul><li>Rosenhan study on effects of psychological labeling</li></ul></li></ul></li></ul><h2 id=self-fulfilling-prophecies>Self-fulfilling prophecies
<a class=anchor href=#self-fulfilling-prophecies>#</a></h2><ul><li><strong>Self-fulfilling prophecies:</strong> People generally think that it is our experiences and perceptions that create our beliefs, but often, it is actually our beliefs that create our experiences and perceptions<figure><img src=/docs/cogsci-c100/perception/proph.jpg></figure></li><li>Our beliefs and expectations influence <strong>others’</strong> behavior<ul><li><strong>The Pygmalion effect:</strong> study found that students who were (randomly) labeled intellectual “spurters” showed significantly greater gains in IQ and academic performance after 8 months than controls<ul><li>Follow-up: If teacher believed that girls learn to read faster than boys, they did</li></ul></li><li>Children who were told they were neat and tidy became more neat and tidy than those who were told they should be neat and tidy<ul><li>Follow-up: children who are told that they are good at math showed greater improvements in math scores than those who were told that they should try to become good at math</li></ul></li><li>Those who over-idealize romantic partners as having many virtues and few faults tend to have happier and longer-lasting relationships (Miller, Niehuis, & Huston, 2006)<ul><li>Moreover, the partners who are over-idealized tended to develop those traits over time! (Sandra Murray)</li><li>People live up to their expectations &ndash; we tend to bring out what we focus on</li></ul></li></ul></li><li>Our beliefs and expectations influence <strong>our own</strong> behavior<ul><li>Study by Mark Snyder found that when a man was led to believe that a woman found him attractive, she was more likely to act as if she did</li><li>&ldquo;
<a href="https://www.youtube.com/watch?v=bDt90EyZnWA&t=1295s">Gus Hansen refused to acknowledge the odds and the odds disappear</a>&rdquo;<blockquote><p><em>Assume a virtue if you have it not.</em> – Shakespeare</p></blockquote></li></ul></li></ul><h2 id=perceptual-constancies>Perceptual Constancies
<a class=anchor href=#perceptual-constancies>#</a></h2><ul><li><strong>Perceptual constancy:</strong> perceiving objects as unchanging (having consistent lightness, color, shape, and size) even as illumination and retinal images change<ul><li>Many visual illusions result from the overuse of strategies employed to achieve perceptual constancy<blockquote><p><img src=/docs/cogsci-c100/perception/tile.png alt>
Is Tile A or Tile B darker or are they the same color?</p><ul><li>Illusion results from visual system’s attempt to maintain lightness constancy: we perceive an object as having a constant color, even if changing illumination alters the wavelengths reflected by the object</li></ul></blockquote></li></ul></li></ul><p><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li><strong>Shape constancy:</strong> we perceive the form of familiar objects as constant even while our retinal images of them change<ul><li>A door casts an increasingly trapezoidal image on our retinas as it opens, yet we still perceive it as rectangular</li></ul></li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/door.png alt></div></div><br><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>Müller-Lyer illusion:<ul><li>Is line AB or line BC longer?</li><li><strong>Size-distance constancy:</strong> Our brains are used to perceiving angles as corners that are near or far away and sees the inward-facing corners as more distant and therefore smaller</li></ul></li></ul><p><img src=/docs/cogsci-c100/perception/ponzo.gif alt></p><ul><li>Are the two parallelograms the same size and shape?</li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/MLw.png alt></p><ul><li>Ponzo illusion:<ul><li>Which line is longer?</li></ul></li></ul><p><img src=/docs/cogsci-c100/perception/tables.png alt></p></div></div></p><ul><li><strong>Moon illusion:</strong> Does the moon appear larger near the horizon or when it is high in the sky?<blockquote><p><img src=/docs/cogsci-c100/perception/moon.png alt></p><ul><li>When the moon is near the horizon we perceive it to be farther away from us than when it is high in the sky, but since the moon is actually the same size, our minds make it look bigger when it is near the horizon to compensate for the increased distance</li></ul></blockquote></li><li>The Magical Kingdom of Salt<blockquote><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/boot.png alt></div><div class="flex-even markdown-inner"><br><ul><li>In the Salar de Uyuni of Bolivia, the world’s largest salt flat, with no other objects in sights, the human eye loses its ability to establish a proper field of depth. The result is some bizarre pictures.</li></ul></div></div></blockquote></li></ul><h2 id=effects-of-color-in-marketing>Effects of color in marketing
<a class=anchor href=#effects-of-color-in-marketing>#</a></h2><ul><li>Assume that you are considering buying condoms<ul><li>You enter a store and notice that the store doesn’t carry all the brands you may be familiar with, so you’re going to have to make your choice based on the product package alone</li><li>You are really interested in finding a brand that is considered<ul><li>Durable, strong, and well built (“rugged” condition) OR</li><li>Classy, attractive, and refined (“sophisticated” condition)</li></ul></li></ul></li><li>Which would you choose?
<img src=/docs/cogsci-c100/perception/condoms.png alt></li><li>Match the colors with the following
<img src=/docs/cogsci-c100/perception/match.png alt><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>Sincerity: white, yellow.$^1$</li><li>Excitement: red, orange.$^1$</li><li>Competence: blue</li></ul></div><div class="flex-even markdown-inner"><ul><li>Sophistication: black, pink, purple</li><li>Ruggedness: brown</li><li>.$^1$Marginally significant</li></ul></div></div></li></ul><h1 id=neurological-disorders-of-visual-perception>Neurological disorders of visual perception
<a class=anchor href=#neurological-disorders-of-visual-perception>#</a></h1><h2 id=face-perception-and-prosopagnosia>Face perception and prosopagnosia
<a class=anchor href=#face-perception-and-prosopagnosia>#</a></h2><ul><li>Face recognition is “special”<ul><li>Single-cell recordings of monkeys show activation of particular cells in lower temporal only when full-face photos of other monkeys are presented</li></ul></li><li>Recognition accuracy for faces and houses: parts vs. whole<div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>Study (Tanaka and Farah, 1993) in which participants were shown series of faces with person’s name and series of houses with owner’s name</li><li>Later on recognition test, they showed greater recall of<ul><li><em>Parts of</em> houses but</li><li><em>Whole</em> faces</li></ul></li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/house.png alt></div></div><ul><li>Do people tend to perceive men or women more in “parts”? Women (Gervais, Vescio , Forster et al., 2012)</li></ul></li><li><strong>Prosopagnosia:</strong> failure to recognize particular people by the sight of their faces<ul><li>After stroke, sheep rancher could not recognize people but could recognize sheep<ul><li>Someone would walk in the room and he wouldn&rsquo;t be able to tell if it was the wife/neighbor/robber/etc</li></ul></li><li>Note: the eyes also play a special role in perception<blockquote><p><img src=/docs/cogsci-c100/perception/eyes.png alt>
70-90% of famous portrait paintings sampled from the last five centuries have an eye at or within 5% of the painting’s exact centerline (Christopher W. Tyler)<br><br><em>Every man indicates in his eye the exact indication of his rank.</em> – Emerson</p></blockquote></li></ul></li></ul><h2 id=modular-processing>Modular Processing
<a class=anchor href=#modular-processing>#</a></h2><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>Visual illusions suggest that the mind is at least in part modular (Jerry Fodor)<ul><li>That is, it is not solely organized in terms of faculties, such as memory and attention, that can process any type of information</li><li>Rather, there are specialized information-processing modules that<ul><li>Respond automatically</li><li>Cannot be “switched off”</li></ul></li></ul></li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/cog-head.png alt></div></div><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><br><p><img src=/docs/cogsci-c100/perception/break.png alt></div><div class="flex-even markdown-inner"><p>Modular processes are usually characterized by&mldr;</p><ul><li>Fixed neural architecture<ul><li>It is sometimes possible to identify determinate regions of the brain that are associated with particular types of modular processing<ul><li>e.x: fusiform face area for face recognition</li></ul></li></ul></li><li>Specific breakdown patterns<ul><li>Modules can fail in highly determinate ways, which provide clues on the form and structure of processing<ul><li>e.x: prosopagnosia</li></ul></li></ul></li></ul></div></div><h2 id=other-neurological-disorders-related-to-visual-perception>Other Neurological Disorders Related to Visual Perception
<a class=anchor href=#other-neurological-disorders-related-to-visual-perception>#</a></h2><ul><li><strong>Visual agnosia:</strong> inability to recognize/identify visual objects despite relatively good visual perception<ul><li>Usually due to damage in occipital or temporal lobes<ul><li>“Mr. P” in Oliver Sacks’ Man Who Mistook His Wife for a Hat</li><li>Man with agnosia puzzling over a picture of a cow suddenly found himself making alternating up-and-down movements with fists. He looked down at his hands and said, “Oh, a cow!”</li><li>Due to some error between vision and verbal communication</li></ul></li></ul></li><li><strong>Visual neglect syndrome</strong> or <strong>unilateral spatial neglect</strong>:<ul><li>Tendency to ignore – or to be unaware of – information on one half of visual field, usually the left side</li><li>Typically occurs after damage (e.g., stroke) to right hemisphere, particularly damage to the parietal and frontal lobes</li><li>Relatively common, easy to test for<div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><blockquote><p><img src=/docs/cogsci-c100/perception/lines.png alt>
Patients are asked to bisect each line. Their markings are typically skewed to the right, as if they do not see the leftmost segment</p></blockquote></div><div class="flex-even markdown-inner"><blockquote><p><img src=/docs/cogsci-c100/perception/drawing.png alt>
Patients are asked to draw from memory or to copy an illustration (Driver & Vuilleumier, 2001)</p></blockquote></div></div><details><summary>House</summary><div class=markdown-inner><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/house0.png alt></div><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/house1.png alt></div></div><blockquote><p><em>Experimenter:</em> Are the two houses the same or different?<br><em>Patient:</em> The same.<br><em>Experimenter:</em> Which house would you prefer to live in?<br><em>Patient:</em> The left house.</p></blockquote></div></details></li></ul></li></ul><hr><ul><li><strong>Capgras syndrome:</strong> characterized by belief that family and/or friends are imposters<ul><li>Damage to pathway between visual cortex and amygdala, which regulates emotions</li><li>Emotional “glow” that we normally feel around people we are close to is missing</li><li>Ramachandran argues that this emotional “glow” is, to a large extent, what gives us a sense of continuity in our relationships</li><li>Classified as some kind of schizophrenia</li></ul></li><li><strong>Functional blindness</strong> (conversion disorder): unexplained vision loss with no organic basis<ul><li>Cambodian women who had witnessed horrible war atrocities became either partially or wholly blind</li><li>Impairs primarily body functions / processes<ul><li>Psychological defense mechanism</li></ul></li></ul></li><li><strong>Blindsight:</strong> vision without awareness<div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>Blindness resulting from damage to visual cortex</li><li>When presented with various shapes like circles and square, or photos of faces of men and women, patient could not tell (or guess) what his eyes were gazing at</li><li>However, when shown pictures of people with angry or happy faces, he was able to guess the emotions expressed, at a rate far better than chance</li><li>Patients are also able to correctly “guess” the identity or location of particular objects</li><li>Patients report that they get a “gut” feeling that allows them to perform these tasks</li></ul></div><div class="flex-even markdown-inner"><blockquote><p><img src=/docs/cogsci-c100/perception/wander.png alt>
Blindsight patient was able to meander around all the clutter in a hallway that he was told was empty (Weiskrantz)</p></blockquote></div></div><ul><li>A second pathway of visual perception may account for this phenomenon</li></ul></li></ul><h2 id=two-pathways-of-visual-perception>Two pathways of visual perception
<a class=anchor href=#two-pathways-of-visual-perception>#</a></h2><p><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/waldo.png alt></div><div class="flex-even markdown-inner"><ul><li>Study looked at speed with which people were able to find a specific hidden object among a group of similar objects</li><li>Participants were instructed to<ol><li>Passively allow the target to just “pop” into their minds OR</li><li>Actively direct their attention to the target</li></ol></li><li>Participants in Passive Group 1 outperformed those in Group 2 (Smilek, Enns, Eastwood et al., 2006)</li></ul></div></div><details><summary>Targets</summary><div class=markdown-inner><p><img src=/docs/cogsci-c100/perception/targets.png alt></p><ul><li>Look for the circle with just one gap, and say whether the gap is on the left or the right</li><li>Use “relax” strategy, then try active search strategy</li></ul></div></details></p><ul><li>Proposed explanation:<ul><li>Participants who were basically told to relax and go with their gut instinct used a secondary pathway of visual perception that</li><li>Does not go through the visual cortex</li><li>Instead simply makes a very short loop through the limbic system: the emotional, instinctual center of the brain
<img src=/docs/cogsci-c100/perception/proposed.png alt></li></ul></li></ul><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/rat.png alt></div><div class="flex-even markdown-inner"><ul><li>Research evidence for existence of two pathways:<ul><li>Auditory cortex of rats was destroyed, then rats were exposed to tone paired with an electric shock</li><li>Rats quickly learned to fear tone, though they could not “hear” it!</li><li>Explanation: the sound took the direct route from ear to thalamus to amygdala, bypassing all higher avenues (Joseph Ledoux)</li></ul></li></ul></div></div><h1 id=development-of-perception>Development of perception
<a class=anchor href=#development-of-perception>#</a></h1><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><p><img src=/docs/cogsci-c100/perception/restrict.png alt></p><ul><li>Adults who were born blind and later gained vision through newly-developed surgical interventions (e.g., cataract surgery) usually have some difficulty recognizing objects<ul><li>At age 3, Mike May lost his vision in an explosion. Decades later, a new cornea restored vision to his right eye.</li><li>Unfortunately, although signals were now reaching his visual cortex, it lacked the experience to interpret them<ul><li>May could not recognize expression, or faces, apart from features such as hair</li><li>Yet he can see an object in motion</li></ul></li><li>Ended up committing suicide because he found himself in a world he didn&rsquo;t (couldn&rsquo;t) understand or comprehend</li></ul></li></ul></div><div class="flex-even markdown-inner"><br><ul><li>There is a critical period for normal sensory and perceptual development</li><li>Kittens reared in a cylinder with only vertical black and white stripes later had difficulty perceiving horizontal bars<ul><li>Kitten would play with rod only when it was held upright</li><li>As if they couldn&rsquo;t see the horizontal rod<br><br><br></li></ul></li></ul><p><img src=/docs/cogsci-c100/perception/ball.png alt></div></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/Mehvix/notes/commit/5698073d2411f8eda860c966b8261a7be289eb93 title="Last modified by Max Vogel | March 4, 2022" target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>March 4, 2022</span></a></div><div><a class="flex align-center" href=https://github.com/Mehvix/notes/edit/master/hugo/content/docs/cogsci-c100/perception.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><script>(function(){function e(n){const e=window.getSelection(),t=document.createRange();t.selectNodeContents(n),e.removeAllRanges(),e.addRange(t)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#definition-of-sensation-and-perception>Definition of sensation and perception</a></li><li><a href=#early-models-of-object-perception>Early models of object perception</a><ul><li><a href=#template-matching-model>Template matching model</a></li><li><a href=#feature-analysis-model>Feature analysis model</a></li><li><a href=#recognition-by-components-model>Recognition-by-components model</a></li><li><a href=#david-marrs-model-of-visual-processing>David Marr’s Model of Visual Processing</a></li><li><a href=#prototype-model>Prototype model</a></li><li><a href=#alternative-modes-of-perception>Alternative modes of perception</a></li><li><a href=#neural-networks>Neural Networks</a><ul><li><a href=#ex-how-might-a-computer-recognize-a-9-using-neural-networks>Ex: How might a computer recognize a “9” using neural networks?</a></li><li><a href=#learning-in-neural-nets-backpropagation>Learning in Neural Nets: Backpropagation</a></li><li><a href=#other-neural-networks-qa>Other Neural Networks Q&A</a></li></ul></li></ul></li><li><a href=#top-down-processing-in-object-recognition>Top-down processing in object recognition</a><ul><li><a href=#objective-reality-is-often-not-as-objective-as-we-think>“Objective reality” is often not as objective as we think&mldr;</a></li><li><a href=#effects-of-expectations-experience-emotional-patterns-and-beliefs-on-perception>Effects of expectations, experience, emotional patterns, and beliefs on perception</a></li><li><a href=#self-fulfilling-prophecies>Self-fulfilling prophecies</a></li><li><a href=#perceptual-constancies>Perceptual Constancies</a></li><li><a href=#effects-of-color-in-marketing>Effects of color in marketing</a></li></ul></li><li><a href=#neurological-disorders-of-visual-perception>Neurological disorders of visual perception</a><ul><li><a href=#face-perception-and-prosopagnosia>Face perception and prosopagnosia</a></li><li><a href=#modular-processing>Modular Processing</a></li><li><a href=#other-neurological-disorders-related-to-visual-perception>Other Neurological Disorders Related to Visual Perception</a></li><li><a href=#two-pathways-of-visual-perception>Two pathways of visual perception</a></li></ul></li><li><a href=#development-of-perception>Development of perception</a></li></ul></nav></div></aside></main></body></html>