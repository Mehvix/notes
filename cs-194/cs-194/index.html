<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="\(\) 08-28: Capturing Light&mldr; in man and machine # Etymology Photo means light Graphy means drawing/writing We take many samples of an image, typically in [0, 255] Rolling shutter occurs when some object is moving noticeably faster than the sampling rate Pictures are not a single instance The Eye # Saccadic eye movement: Unlike an image, we see everything except what we&rsquo;re looking at is blurred Iris: colored annulus with radial muscles Pupil: the hole (aperture) whose size is controlled by the iris Photoreceptor cells (rods and cones) in the retina act as the &lsquo;film&rsquo; Inside-out retina (in humans, and most other animals) is messy: Light has to pass through various layers of &lsquo;wiring&rsquo; Optical nerve produces blind spot (no rods or cones) Two types of light-sensitive receptors: Cones cone-shaped less sensitive operate in high light color vision concentrated in the fovea (center of the retina) Rods rod-shaped highly sensitive operate at night gray-scale vision concentrated in the periphery of the retina When looking at the night sky, you will be able to see more out of the corner of your eye because that&rsquo;s where there are more rods&ndash; cones do very little to help you see the light from the stars."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="Main"><meta property="og:description" content="\(\) 08-28: Capturing Light&mldr; in man and machine # Etymology Photo means light Graphy means drawing/writing We take many samples of an image, typically in [0, 255] Rolling shutter occurs when some object is moving noticeably faster than the sampling rate Pictures are not a single instance The Eye # Saccadic eye movement: Unlike an image, we see everything except what we&rsquo;re looking at is blurred Iris: colored annulus with radial muscles Pupil: the hole (aperture) whose size is controlled by the iris Photoreceptor cells (rods and cones) in the retina act as the &lsquo;film&rsquo; Inside-out retina (in humans, and most other animals) is messy: Light has to pass through various layers of &lsquo;wiring&rsquo; Optical nerve produces blind spot (no rods or cones) Two types of light-sensitive receptors: Cones cone-shaped less sensitive operate in high light color vision concentrated in the fovea (center of the retina) Rods rod-shaped highly sensitive operate at night gray-scale vision concentrated in the periphery of the retina When looking at the night sky, you will be able to see more out of the corner of your eye because that&rsquo;s where there are more rods&ndash; cones do very little to help you see the light from the stars."><meta property="og:type" content="article"><meta property="og:url" content="http://notes.mehvix.com/cs-194/cs-194/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2022-09-17T12:33:59-07:00"><title>Main | notes.mehvix.com</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.89a77f7e702a8626749b948bbfb01109823daf6c1246ca407d1378833494c402.css integrity="sha256-iad/fnAqhiZ0m5SLv7ARCYI9r2wSRspAfRN4gzSUxAI=" crossorigin=anonymous><script defer src=/flexsearch.min.js></script>
<script defer src=/en.search.min.ea8599e69648ba46ad93492969452032845395cbab0110c71b41d57e52914953.js integrity="sha256-6oWZ5pZIukatk0kpaUUgMoRTlcurARDHG0HVflKRSVM=" crossorigin=anonymous></script>
<script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script>
<link rel=icon href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>📓</text></svg>"><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>MathJax={tex:{inlineMath:[["$","$"],[".$","$"]],processEscapes:!0,processEnvironments:!0,macros:{bigsup:["#1{^{\\vbox{\\hbox{$\\scriptstyle#1$}\\nointerlineskip\\hbox{}}}}",1],norm:[`\\left\\lVert#1\\right\\rVert`,1]}},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script id=MathJax-script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.min.js?config=TeX-AMS_CHTML" integrity="sha512-9DkJEmXbL/Tdj8b1SxJ4H2p3RCAXKsu8RqbznEjhFYw0cFIWlII+PnGDU2FX3keyE9Ev6eFaDPyEAyAL2cEX0Q==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:".$",right:"$",display:!1},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><link rel=stylesheet href=http://notes.mehvix.com/css/custom_styling.css><div class=print style=text-align:center><h1 id=print-location>Notes can be found as interactive webpage at</h1></div><script>let a=document.createElement("a");a.appendChild(document.createTextNode(`notes.mehvix.com${window.location.pathname}`)),a.href="http://notes.mehvix.com"+window.location.pathname,document.getElementById("print-location").appendChild(a)</script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>notes.mehvix.com</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-ad45289da5715225c5154e9ed2d01bfd class=toggle checked>
<label for=section-ad45289da5715225c5154e9ed2d01bfd class="flex justify-between"><a role=button>CS 194</a></label><ul><li><a href=http://notes.mehvix.com/cs-194/cs-194/ class=active>Main</a></li></ul></li><li><input type=checkbox id=section-381d9181c0cc4fe35fea10df5bf8d07d class=toggle>
<label for=section-381d9181c0cc4fe35fea10df5bf8d07d class="flex justify-between"><a role=button>MCB C61</a></label><ul><li><a href=http://notes.mehvix.com/mcb-c61/1/>1: Evolution of the Mind, the Brain, and Brain Chemistry</a></li><li><a href=http://notes.mehvix.com/mcb-c61/2/>2: DNA, Synapses, and Neuroanatomy</a></li><li><a href=http://notes.mehvix.com/mcb-c61/3/>3: Pharmacology; Neurodevelopment</a></li><li><a href=http://notes.mehvix.com/mcb-c61/4/>4: Sensory Perception</a></li><li><a href=http://notes.mehvix.com/mcb-c61/5/>5: Connectivity</a></li></ul></li><li><a href=http://notes.mehvix.com/cogsci-c100/>CogSci C100</a></li><li><input type=checkbox id=section-20c391324c82ffdef893b60d754b7005 class=toggle>
<label for=section-20c391324c82ffdef893b60d754b7005 class="flex justify-between"><a role=button>EECS 16A</a></label><ul><li><a href=http://notes.mehvix.com/eecs-16a/0/>0: System Design & Linear Equations</a></li><li><a href=http://notes.mehvix.com/eecs-16a/1/>1: Gaussian Elim. & Matrices + Vectors</a></li><li><a href=http://notes.mehvix.com/eecs-16a/2/>2: (In)dependence & Circuit Analysis</a></li><li><a href=http://notes.mehvix.com/eecs-16a/3/>3: Transformations & Inverse</a></li><li><a href=http://notes.mehvix.com/eecs-16a/4/>4: Vector Spaces & Eigenstuff</a></li><li><a href=http://notes.mehvix.com/eecs-16a/5/>5: Basis & Circuit Analysis</a></li><li><a href=http://notes.mehvix.com/eecs-16a/6/>6: Voltage Dividers & Measurement</a></li><li><a href=http://notes.mehvix.com/eecs-16a/7/>7: 2D Touchscreens & Superp. + Equivalence</a></li><li><a href=http://notes.mehvix.com/eecs-16a/8/>8: Capacitors & Capacitive Touchscreen</a></li><li><a href=http://notes.mehvix.com/eecs-16a/9/>9: Op-Amps, Comparators & Charge Sharing</a></li><li><a href=http://notes.mehvix.com/eecs-16a/10/>10: NFB, GRs & Buffer + Loading</a></li><li><a href=http://notes.mehvix.com/eecs-16a/11/>11: Locationing & Trilateration</a></li><li><a href=http://notes.mehvix.com/eecs-16a/12/>12-13: Least Squares & ML</a></li></ul></li><li><input type=checkbox id=section-7571d6f544c6ffc847948b0f74d82ef1 class=toggle>
<label for=section-7571d6f544c6ffc847948b0f74d82ef1 class="flex justify-between"><a role=button>Engineering 29</a></label><ul><li><a href=http://notes.mehvix.com/e-29/0/>0: Intro & Tolerancing</a></li><li><a href=http://notes.mehvix.com/e-29/1/>1: Fundamentals of Graphical Communication & Subtractive Processes</a></li><li><a href=http://notes.mehvix.com/e-29/2/>2: Cutting-based Processes & Other Subtractive Processes</a></li><li><a href=http://notes.mehvix.com/e-29/3/>3: Additive Processes: Intro & Extrusion</a></li><li><a href=http://notes.mehvix.com/e-29/4/>4: Additive Processes: Light-based, etc.</a></li><li><a href=http://notes.mehvix.com/e-29/5/>5-6: Forming Processes</a></li><li><a href=http://notes.mehvix.com/e-29/6/>6-7: Joining processes</a></li><li><a href=http://notes.mehvix.com/e-29/7/>7-9: Visualization</a></li><li><a href=http://notes.mehvix.com/e-29/10/>10: Metrology</a></li><li><a href=http://notes.mehvix.com/e-29/11/>11-12: GD&T</a></li></ul></li><li><a href=http://notes.mehvix.com/anthro-c12ac/>Anthro C12AC</a></li><li><a href=http://notes.mehvix.com/asamst-20a/>ASAMST 20A</a></li><li><input type=checkbox id=section-32aba3efd274a559b3dccd4e800c9d4b class=toggle>
<label for=section-32aba3efd274a559b3dccd4e800c9d4b class="flex justify-between"><a role=button>Math 53</a></label><ul><li><a href=http://notes.mehvix.com/math-53/10/>10: Parametric Equations and Polar Coordinates</a></li><li><a href=http://notes.mehvix.com/math-53/12/>12: Vectors & Geometry of Space</a></li><li><a href=http://notes.mehvix.com/math-53/13/>13: Vector Functions</a></li><li><a href=http://notes.mehvix.com/math-53/14/>14: Partial Derivatives</a></li><li><a href=http://notes.mehvix.com/math-53/15/>15: Multiple Integrals</a></li><li><a href=http://notes.mehvix.com/math-53/16/>16: Vector Calculus</a></li><li><a href=http://notes.mehvix.com/math-53/trig/>Trig Identities</a></li><li><a href=http://notes.mehvix.com/math-53/trig-calc/>Trig Calculus</a></li></ul></li><li><input type=checkbox id=section-98c46cabf82aecebcca8f97f2965f738 class=toggle>
<label for=section-98c46cabf82aecebcca8f97f2965f738 class="flex justify-between"><a role=button>Physics 7B</a></label><ul><li><a href=http://notes.mehvix.com/physics-7b/17/>17: Temperature, Thermal Expansion, & Ideal Gas Law</a></li><li><a href=http://notes.mehvix.com/physics-7b/18/>18: Kinetic Theory of Gases</a></li><li><a href=http://notes.mehvix.com/physics-7b/19/>19: Heat & First Law of Thermo</a></li><li><a href=http://notes.mehvix.com/physics-7b/20/>20: Second Law of Thermo</a></li><li><a href=http://notes.mehvix.com/physics-7b/21/>21: Electric Charges & Fields</a></li><li><a href=http://notes.mehvix.com/physics-7b/22/>22: Flux & Gauss's Law</a></li><li><a href=http://notes.mehvix.com/physics-7b/23/>23: Electric Potential</a></li><li><a href=http://notes.mehvix.com/physics-7b/24/>24: Capacitance, Dielectrics, Electric Energy Storage</a></li><li><a href=http://notes.mehvix.com/physics-7b/25/>25: Electric Current and Resistance</a></li><li><a href=http://notes.mehvix.com/physics-7b/26/>26: DC Circuits</a></li><li><a href=http://notes.mehvix.com/physics-7b/27/>27: Magnetism</a></li><li><a href=http://notes.mehvix.com/physics-7b/28/>28: Sources of Magnetic Field</a></li><li><a href=http://notes.mehvix.com/physics-7b/29/>29: Electromagnetic Induction & Faraday's Law</a></li><li><a href=http://notes.mehvix.com/physics-7b/30/>30: Inductance, Electromagnetic Oscillations, & AC Circuits</a></li></ul></li><li><input type=checkbox id=section-a18e6d23bfa638ffa382e954bd79207f class=toggle>
<label for=section-a18e6d23bfa638ffa382e954bd79207f class="flex justify-between"><a role=button>AP Notes</a></label><ul><li><a href=http://notes.mehvix.com/ap/huge/>AP Human Geography</a></li><li><a href=http://notes.mehvix.com/ap/cmech/>AP Physics C: Mechanics</a></li><li><a href=http://notes.mehvix.com/ap/stats/>AP Statistics</a></li></ul></li></ul><ul><li><a href=https://cs61a.rouxl.es/ target=_blank rel=noopener>CS61A (Anto's)</a></li><li><a href=# target=_blank rel=noopener>—</a></li><li><a href=https://www.mehvix.com target=_blank rel=noopener>w³.mehvix.com</a></li><li><a href=https://pass.mehvix.com target=_blank rel=noopener>pass.mehvix.com</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Main</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#08-28-capturing-light-in-man-and-machine>08-28: Capturing Light&mldr; in man and machine</a><ul><li><a href=#the-eye>The Eye</a></li><li><a href=#physics-of-light>Physics of Light</a></li><li><a href=#color-vision>Color Vision</a></li><li><a href=#cameras>Cameras</a></li><li><a href=#color-spaces>Color Spaces</a></li></ul></li><li><a href=#09-07-convolution-and-image-derivatives>09-07: Convolution and Image Derivatives</a><ul><li><a href=#convolution>Convolution</a></li><li><a href=#downsampling>Downsampling</a></li></ul></li><li><a href=#9-12-the-frequency-domain>9-12: The Frequency Domain</a></li><li><a href=#09-14-pyramid-blending-templates-nl-filters>09-14: Pyramid Blending, Templates, NL Filters</a><ul><li><a href=#hybrid-images>Hybrid Images</a></li><li><a href=#blending>Blending</a></li><li><a href=#filters>Filters</a><ul><li><a href=#application-template-matching>Application: template matching</a></li></ul></li></ul></li></ul></nav></aside></header><article class=markdown><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script>
<script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>
\(\)</span><h1 id=08-28-capturing-light-in-man-and-machine>08-28: Capturing Light&mldr; in man and machine
<a class=anchor href=#08-28-capturing-light-in-man-and-machine>#</a></h1><ul><li>Etymology<ul><li>Photo means light</li><li>Graphy means drawing/writing</li></ul></li><li>We take many samples of an image, typically in <code>[0, 255]</code><ul><li><a href=http://en.wikipedia.org/wiki/Rolling_shutter>Rolling shutter</a> occurs when some object is moving noticeably faster than the sampling rate</li><li>Pictures are not a single instance</li></ul></li></ul><h2 id=the-eye>The Eye
<a class=anchor href=#the-eye>#</a></h2><ul><li><strong>Saccadic eye movement</strong>: Unlike an image, we see everything except what we&rsquo;re looking at is blurred</li><li><strong>Iris</strong>: colored annulus with radial muscles</li><li><strong>Pupil</strong>: the hole (aperture) whose size is controlled by the iris</li><li>Photoreceptor cells (rods and cones) in the <strong>retina</strong> act as the &lsquo;film&rsquo;<ul><li>Inside-out retina (in humans, and most other animals) is messy:<ul><li>Light has to pass through various layers of &lsquo;wiring&rsquo;</li><li>Optical nerve produces blind spot (no rods or cones)</li></ul></li><li>Two types of light-sensitive receptors:<ol><li>Cones<ul><li>cone-shaped</li><li>less sensitive</li><li>operate in high light</li><li>color vision</li><li>concentrated in the <strong>fovea</strong> (center of the retina)</li></ul></li><li>Rods<ul><li>rod-shaped</li><li>highly sensitive</li><li>operate at night</li><li>gray-scale vision</li><li>concentrated in the periphery of the retina</li></ul><blockquote><p>When looking at the night sky, you will be able to see more out of the corner of your eye because that&rsquo;s where there are more rods&ndash; cones do very little to help you see the light from the stars.</p></blockquote></li></ol></li></ul></li></ul><h2 id=physics-of-light>Physics of Light
<a class=anchor href=#physics-of-light>#</a></h2><ul><li>We can see 400-700 nanometers (visible light on the electromagnetic spectrum)<ul><li>This is the range that the Sun radiates</li></ul></li><li>Color is psychophysical: it&rsquo;s a property of the brain, not the light</li><li>Any patch of light can be completely described physically by its spectrum: the number of photons (per time unit) at each wavelength from 400 to 700 nm.</li><li>The perceived color of an object corresponds to the spectrum of light that it reflects.<ul><li>Small (blue), Medium (green), Large (red) cones then &lsquo;parse&rsquo; the spectrum into color<ul><li>M and L (green and red) are close to one another</li></ul></li></ul></li></ul><h2 id=color-vision>Color Vision
<a class=anchor href=#color-vision>#</a></h2><ul><li>Colorblind (not trichromatic) people have a different set of cones<ul><li>Deuteranopia: green-blind, missing M cones</li><li>Protanopia: red-blind, missing L cones</li><li>Tritanopia: blue-blind, missing S cones</li></ul></li><li>“M” and “L” on the X-chromosome<ul><li>Why men are more likely to be color blind</li><li>“L” has high variation, so some women are tetrachromatic</li></ul></li><li>Some animals have<ul><li>1 (night animals)</li><li>2 (e.g., dogs)</li><li>4 (fish, birds)</li><li>5 (pigeons, some reptiles/amphibians)</li><li>12 (mantis shrimp)</li></ul></li></ul><hr><ul><li>Rods an cones act as a filter on the spectrum:<blockquote><p>The “photometer metaphor” of color perception: Color perception is determined by the spectrum of light on each retinal receptor (as measured by a photometer</p></blockquote><ul><li>We can approximate the spectrum with a linear combination of the three cone responses<ul><li>Most of the information is lost</li></ul></li><li>As a result, two different spectra may appear indistinguishable<ul><li>such spectra are known as <strong>metamers</strong></li></ul></li></ul></li><li>Distribution of color can be interpreted as&mldr;<ul><li>Mean corresponds to the hue</li><li>Variance corresponds to the saturation</li><li>Area corresponds to the brightness</li></ul></li><li><strong>Color Constancy</strong>: the ability to perceive the invariant color of a surface despite ecological Variations in the conditions of observation.</li><li>Another of these hard <strong>inverse problems</strong>: Physics of light emission and surface reflection <em>underdetermine</em> perception of surface color</li></ul><h2 id=cameras>Cameras
<a class=anchor href=#cameras>#</a></h2><ul><li>White balancing<ul><li>Manual<ul><li>Choose color-neutral object to normalize</li></ul></li><li>Automatic (AWB)<ul><li>Grey world: force average color of scene to grey</li><li>White world: force brightest object to white</li></ul></li></ul></li><li>Our eyes are most sensitive to green light, so we often have more green sensors (ex.
<a href=http://en.wikipedia.org/wiki/Bayer_filter>Bayer Filter</a>)</li><li>Storing values in a matrix; <code>x</code> corresponds to the columns and <code>y</code> corresponds to the rows</li></ul><h2 id=color-spaces>Color Spaces
<a class=anchor href=#color-spaces>#</a></h2><ul><li>RGB &ndash; additive (light)<ul><li>Easy for devices</li><li>But not perceptually uniform<ul><li>Where do the grays live?</li><li>Where is hue and saturation?`</li></ul></li></ul></li><li>CMYK (Cyan, Magenta, Yellow, Key) &ndash; subtractive (ink)<ul><li>Used in printing/painting</li><li>White is the background; black is the additive value of all colors</li></ul></li><li>HSV (Hue, Saturation, Value) &ndash; cylindrical<ul><li>Hue (kind of color) is the angle<ul><li>Red: 0</li><li>Green: 120</li><li>Blue: 240</li></ul></li><li>Saturation (purity) is the distance from the center</li><li>Value (lightness) is the total amount of light</li></ul></li><li>Lab (Luminance, a, b) &ndash; perceptually uniform<ul><li>Luminance is the amount of light<ul><li>Humans are much more sensitive to changes L</li></ul></li><li>a corresponds to red to green</li><li>b corresponds to blue to yellow</li></ul></li></ul><h1 id=09-07-convolution-and-image-derivatives>09-07: Convolution and Image Derivatives
<a class=anchor href=#09-07-convolution-and-image-derivatives>#</a></h1><ul><li>When calculating the moving average, it&rsquo;s smart to apply non-uniform weights (e.x gaussian) to account for outliers<ul><li>$\sigma$ (std) determines the extent of smoothing<ul><li>$\sigma \to 0$: more concentrated, single pixel (no smoothing)</li><li>$\sigma \to \infty$: box filter (blurry image)</li></ul></li><li>Kernel (size of rectangle) should be $\approx 3 \sigma$<ul><li>Too big: extra 1-weight around edges</li><li>Too small: doesn&rsquo;t cover full range</li></ul></li></ul></li></ul><h2 id=convolution>Convolution
<a class=anchor href=#convolution>#</a></h2><ul><li>Cross-correlation: $G = H \otimes F$<ul><li>Signal $F$ and filter $H$</li><li>Not commutative (order matters)</li></ul></li><li>Convolution: $G = H \star F$<ul><li>Commutative, associative, distributive over addition, scalars factor out</li><li>Associative shows us that applying multiple filters is equal to applying a single combined filter: $(((a\star b_1)\star b_2) \star b_3 \equiv a \star (b_1 \star b_2 \star b_3)$</li><li>Convolving with self is another Gaussian with $\sigma \sqrt 2$</li></ul></li></ul><h2 id=downsampling>Downsampling
<a class=anchor href=#downsampling>#</a></h2><ul><li>Subsampling: lazy way of downsampling<ul><li>Removes every other row/cols of pixels</li><li>Leads to ugly aliasing</li></ul></li><li>Undersampling: Occurs when too few samples taken</li><li>Gaussian (lowpass) pre-filtering<ul><li>Solution: filter (blur) the image then resample<ul><li>Filter size should double for each 1/2 size reduction</li><li>Applying a blur filter is also smart when taking the gradient of an image</li></ul></li><li>Image pyramids can also be implement to speed up process</li></ul></li></ul><h1 id=9-12-the-frequency-domain>9-12: The Frequency Domain
<a class=anchor href=#9-12-the-frequency-domain>#</a></h1><ul><li>Humans have a wacky non-linear/predictable perception of spatial frequencies<ul><li><a href="https://www.frontiersin.org/articles/10.3389/fnins.2021.626466/full#:~:text=The%20Campbell%2DRobson%20chart%20is%20a%20highly%20popular%20figure%20used,contrast%20from%20bottom%20to%20top.">Campbell-Robson contrast sensitivity curve</a></li><li>Humans have innate antialiasing</li><li>Cats have a left-shifted curve (more sensitive at lower frequencies) for hunting in the dark</li><li>Eagles have a right-shifted curve (more sensitive at higher frequencies) for seeing prey at a distance</li></ul></li><li>We can decompose an image into it&rsquo;s spatial domain ($n^2$ vectors)<ul><li>We can transform this into a series of $sin/cos$ waves composing it&rsquo;s own basis</li><li><a href=/>Jean Baptiste Joseph Fourier (1768-1830)</a> said &ldquo;Any univariate function can be rewritten as a weighted sum of sines and cosines of different frequencies&rdquo;</li><li>We can compose any signal as a sum of sines and cosines<ul><li>$f(x) = A\sin(\omega x + \phi)$</li><li>$\omega$ is the frequency (change in $x$ per cycle)</li><li>$A$ is the amplitude</li><li>$\phi$ is the phase, captures spatial information &ndash; what we discard when going to &lsquo;fourier-basis&rsquo;</li></ul></li><li>We take $f(x) \to_\text{FFT} F(\omega)$<div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><ul><li>For every $\omega$ from 0 to inf, $F(\omega)$ holds the amplitude $A$ and phase $\phi$ of the corresponding sine:</li><li>$F(\omega) = R(\omega) + i l(\omega)$<ul><li>$A = \pm \sqrt{R^2 + l^2}$</li><li>$\phi = \tan ^{-1}\left(\dfrac{l(\omega)}{R(\omega)}\right)$</li></ul></li></ul></div><div class="flex-even markdown-inner"><p><img src=/docs/cs-194/ft-basis.png alt></div></div><ul><li>Sufficient, finite $\omega$ can be stored in a lookup table $\implies$ fast + low memory and very little loss of information</li><li>Technically drops some information that&rsquo;s overlapping, but this is okay because the approximation of the range of $\omega$ is very accurate<ul><li>So basis/representation is not necessarily unique (but it is in most cases in the wild)</li></ul></li><li>Storing/encoding image: $M \cdot f(x) = F(\omega)$<ul><li>$f(x)$ is the input vector of the image</li><li>$M$ is the matrix of sines and cosines</li><li>$F(\omega)$ is the representation in new $\omega$ basis</li></ul></li><li>Decoding image: $M^{-1} \cdot F(\omega) = \hat f(x)$<ul><li>$M^{-1}$ is the inverse of the matrix of sines and cosines</li><li>$F(\omega)$ is the representation in new $\omega$ basis</li><li>$\hat f(x)$ is the output vector of the image</li></ul></li><li>Now store basis of $F \times N$ vectors $\implies$ space complexity is $\mathcal O (FN)$ where $N$ is the number of $\omega$ values<ul><li>$\mathcal O (FN) \ll \mathcal O(N^2)$</li><li>Inverse $M^{-1}$ is easy to compute when knowing $M$</li></ul></li></ul></li></ul></li></ul><blockquote><p><figure><img src=/docs/cs-194/trim.png></figure>Local change in one domain, courses global change in the other</p></blockquote><blockquote><p><figure><img src=/docs/cs-194/filter.png></figure>Low (top) and High (bottom) Pass filtering</p></blockquote><ul><li><p>The Convolution Theorem</p></li><li><p>The Fourier transform of the convolution of two functions is the product of their Fourier transforms
$$F[g \star h] = F[g]F[h]$$</p></li><li><p>The inverse Fourier transform of the product of two Fourier transforms is the convolution of the two inverse Fourier transforms
$$F^{-1}[gh] = F[g]^{-1}\star F[h]^{-1}$$<figure><img src=/docs/cs-194/conv.png></figure></p></li><li><p>We can transform our FFT basis into a series of gaussian</p></li></ul><h1 id=09-14-pyramid-blending-templates-nl-filters>09-14: Pyramid Blending, Templates, NL Filters
<a class=anchor href=#09-14-pyramid-blending-templates-nl-filters>#</a></h1><h2 id=hybrid-images>Hybrid Images
<a class=anchor href=#hybrid-images>#</a></h2><ul><li>We can get the details from an image by subtracting the smoothed version of the image from the original</li><li>Then to sharpen an image we can add a scalar of the details back in<ul><li>This is called an unsharp mask and results in a Laplacian of Gaussian (LoG) filter</li></ul></li><li>Laplacian Pyramid: We can take multiple samples of the difference between the original and increasingly smoothed version os the image (called the octaves)<ul><li>We can then reconstruct the original image by adding the smoothed version of the image back to the details</li></ul></li></ul><h2 id=blending>Blending
<a class=anchor href=#blending>#</a></h2><ul><li>Alpha blending: We can blend two images by linearly interpolating between the two images<ul><li>$I_{blend} = \alpha I_1 + (1 - \alpha) I_2$<ul><li>Total sums to 1 so we have full opacity</li></ul></li><li>Window Size<ul><li>Ideal size is equal to the largest prominent feature, $\phi$</li><li>The larger the window, the more ghosting<ul><li>Minimal ghosting when window &lt;= 2$\cdot \phi$</li></ul></li><li>Too small of a window is a regular crop</li></ul></li><li>Casting in Fourier domain<ul><li>Largest frequency &lt;= 2*smallest frequency</li><li>Image frequency content should occupy one &lsquo;octave&rsquo; (power of two)</li><li>Laplacian Pyramid: Blending<ol><li>Build Laplacian pyramids LA and LB from images A and B</li><li>Build a Gaussian pyramid GR from selected region R<ul><li>High frequency (first level) has fine details, small blend window</li><li>Low frequency (last level) has blurry figures, large blend window</li></ul></li><li>Form a combined pyramid LS from LA and LB using nodes of GR as weights:<ul><li>$LS(i,j) = GR(I,j,)\cdot LA(I,j) + (1-GR(I,j))\cdot LB(I,j)$</li></ul></li><li>Collapse the LS pyramid to get the final blended image</li></ol></li></ul></li><li>Two-band blending:<ul><li>Alternatively to Laplacian Pyramid, you can use high and low frequencies w/o downsmampling</li><li>Blends low freq smoothly</li><li>Blends high freq with no smoothing; use binary $\alpha$</li></ul></li></ul></li><li>Huffman coding: Lossless compression<ul><li>Generate pixel histogram</li><li>Then generate pixel code based how often each pixel in the histogram occurs<ul><li>Most common colors have fewer bits</li></ul></li><li>Maximally 2x compression &ndash; sounds good but not significant</li></ul></li><li>JPEG compression<ul><li>Lossy compression &ndash; takes advantage of human vision not being able to notice high frequencies<ul><li>Colors layers are downsampled since people have bad resolution for colors</li></ul></li><li>Cut into 8x8 blocks (standard) and subtract 128<ul><li>Small block: faster; correlation exists between neighboring pixels</li><li>Large block; better compression in smooth regions</li></ul></li><li>For each block&mldr;<ul><li>Compute DCT (discrete cosine transform)</li><li>Quantize<ul><li>More coarsely for high frequencies (tend to have smaller values anyways)</li><li>Many high frequency values will be 0</li><li>jpeg standard specifies the quantization table</li></ul></li><li>Encode<ul><li>i.e. with Huffman coding</li><li>Can decode with inverse DCT</li><li>Spatial dimension of color channels are reduced by 2</li></ul></li></ul></li></ul></li></ul><h2 id=filters>Filters
<a class=anchor href=#filters>#</a></h2><ul><li>Smoothing filters<ul><li>Gaussian: remove “high-frequency” components; “low-pass” filter</li><li>Values are non-negative and sum to 1<ul><li>Constant regions are not affected by the filter</li><li>Weighted average of neighboring pixels</li></ul></li></ul></li><li>Derivative filters<ul><li>Derivatives of Gaussian</li><li>Values can be negative and sum to 0<ul><li>No response in constant regions</li></ul></li><li>High absolute value at points of high contrast</li></ul></li></ul><hr><h3 id=application-template-matching>Application: template matching
<a class=anchor href=#application-template-matching>#</a></h3><ul><li>Find some object (sub-image) in a larger image</li><li>What is a good similarity or distance measure between two patches?<ul><li>Correlation<ul><li>$h[m,n] = \sum_{i,j} g[i,j]f[m+i,n+j]$</li><li>$f$ is the image, $g$ is the template</li><li>Results in smoothing filter</li></ul></li><li>Zero-mean correlation<ul><li>$h[m,n] \sum_{i,j} (g[i,j] - \bar g)f([m+i,n+j])$</li><li>Even if we subtract the mean, we have false-positives in brighter reasons</li></ul></li><li>Sum Square Difference<ul><li>$h[m,n] = \sum_{i,j} (g[i,j] - f[m+i,n+j])^2$</li><li>Doesn&rsquo;t scale well with varying brightness/intensity</li></ul></li><li>Normalized Cross Correlation<ul><li>$h[m,n] = \dfrac{\sum_{i,j}(g[i,j] - \bar g)(f[m+i,n+j] - \bar f_{m,n})}{\sqrt{\sum_{i,j} (g[i,j] - \bar g)^2 \sum_{i,j} (f[m+i, n+j] - \bar f_{m,n})}}$</li><li>Slowest, invariant to local, invariant to local average intensity/contrast</li></ul></li></ul></li><li>Denoising<ul><li>With gaussian, still preserves &lsquo;salt and pepper&rsquo; noise</li><li>Median filter<ul><li>Replace each pixel with median of its neighbors</li><li>Robust to outliers</li></ul></li></ul></li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/Mehvix/notes/commit/683e4184c65681ec8abbfd3fed12e54838143e15 title='Last modified by Max Vogel | September 17, 2022' target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>September 17, 2022</span></a></div><div><a class="flex align-center" href=https://github.com/Mehvix/notes/edit/master/hugo/content/docs/cs-194/index.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#08-28-capturing-light-in-man-and-machine>08-28: Capturing Light&mldr; in man and machine</a><ul><li><a href=#the-eye>The Eye</a></li><li><a href=#physics-of-light>Physics of Light</a></li><li><a href=#color-vision>Color Vision</a></li><li><a href=#cameras>Cameras</a></li><li><a href=#color-spaces>Color Spaces</a></li></ul></li><li><a href=#09-07-convolution-and-image-derivatives>09-07: Convolution and Image Derivatives</a><ul><li><a href=#convolution>Convolution</a></li><li><a href=#downsampling>Downsampling</a></li></ul></li><li><a href=#9-12-the-frequency-domain>9-12: The Frequency Domain</a></li><li><a href=#09-14-pyramid-blending-templates-nl-filters>09-14: Pyramid Blending, Templates, NL Filters</a><ul><li><a href=#hybrid-images>Hybrid Images</a></li><li><a href=#blending>Blending</a></li><li><a href=#filters>Filters</a><ul><li><a href=#application-template-matching>Application: template matching</a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>